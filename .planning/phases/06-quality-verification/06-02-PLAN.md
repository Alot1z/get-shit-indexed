---
phase: 06-quality-verification
plan: 02
type: execute
wave: 2
depends_on: [06-01]
files_modified: [references/code-review-criteria.md, references/code-review-workflow.md, workflows/execute-plan.md, references/validation-gates.md]
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Code review expert skill is integrated into 5 of 7 quality gates"
    - "Method Circle uses code-review-expert for implementation correctness"
    - "Mad Circle uses code-review-expert for integration completeness"
    - "Mode Circle uses code-review-expert for pattern consistency"
    - "Mod Circle uses code-review-expert for maintainability standards"
    - "Methodd Circle uses code-review-expert for documentation quality"
    - "Code review provides actionable feedback with specific implementable suggestions"
    - "Review outputs follow standardized templates (Approval/Rejection formats)"
  artifacts:
    - path: "references/code-review-criteria.md"
      provides: "Detailed code review criteria for 5 quality gates with severity levels"
      min_lines: 300
      contains: ["Implementation Correctness", "Integration Completeness", "Pattern Consistency", "Maintainability Standards", "Documentation Quality"]
    - path: "references/code-review-workflow.md"
      provides: "Code review workflow with skill integration patterns"
      min_lines: 200
      contains: ["code-review-expert", "skill", "DesktopCommander", "find-skills"]
    - path: "references/code-review-templates.md"
      provides: "Standardized output templates for code review results"
      min_lines: 150
      contains: ["APPROVED", "REJECTED", "APPROVED WITH NOTES", "Quality Score"]
  key_links:
    - from: "references/code-review-criteria.md"
      to: "references/validation-gates.md"
      via: "Code review criteria map to 7-BMAD quality gates"
      pattern: "Gate.*Method|Gate.*Mad|Gate.*Mode"
    - from: "references/code-review-workflow.md"
      to: "references/validation-workflow.md"
      via: "Code review workflow integrates into validation workflow"
      pattern: "validation.*workflow|code.*review.*integration"
    - from: "workflows/execute-plan.md"
      to: "references/code-review-criteria.md"
      via: "Execute workflow references code review criteria"
      pattern: "@.*code-review-criteria\.md"

---

<objective>
Integrate code review expert skill into 7-BMAD validation system for automated quality checks across implementation, integration, patterns, maintainability, and documentation gates.

Purpose: Leverage compressed code-review-expert skill for efficient, token-optimized quality validation across 5 of 7 quality gates
Output: Code review expert skill integrated with detailed criteria, workflow, templates, and output formats
</objective>

<execution_context>
@C:\Users\mose\.claude\get-shit-indexed\workflows\execute-plan.md
@C:\Users\mose\.claude\get-shit-indexed\templates\summary.md
@C:\Users\mose\.claude\rules\code-review.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md

# 7-BMAD Validation Gates (from 06-01)
@references/validation-gates.md

# Code Review Reference
@C:\Users\mose\.claude\rules\code-review.md

# Phase 6-01 Results
@.planning/phases/06-quality-verification/06-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Document code review criteria for 5 quality gates</name>
  <files>references/code-review-criteria.md</files>
  <action>Create references/code-review-criteria.md with detailed review criteria:

1. Gate 1: Implementation Correctness (Method Circle)
   - Checks: Code compiles/builds, logic matches requirements, edge cases handled, performance met, security absent, resource management correct
   - Output format: PASS/FAIL with issues and recommendations
   - Metrics: Build success, test pass rate, performance benchmarks

2. Gate 2: Integration Completeness (Mad Circle)
   - Checks: Dependencies integrated, APIs match specs, data flows correctly, no missing integration points, error handling across boundaries, contract compliance
   - Output format: Integration points checklist with issues
   - Metrics: Integration coverage, contract compliance rate

3. Gate 4: Pattern Consistency (Mode Circle)
   - Checks: Coding patterns used, naming conventions followed, error handling consistent, state management aligned, architecture patterns respected
   - Output format: Pattern violations and consistency issues
   - Metrics: Pattern compliance rate, naming consistency score

4. Gate 5: Maintainability Standards (Mod Circle)
   - Checks: Code readable, comments appropriate, function size reasonable, complexity acceptable, test coverage adequate, no duplication
   - Metrics: Cyclomatic complexity <10, function length <50 lines, class length <300 lines, duplication <3%

5. Gate 7: Documentation Quality (Methodd Circle)
   - Checks: README updated, API docs complete, usage examples provided, changelog updated, inline comments appropriate, architecture docs updated
   - Metrics: Documentation coverage, example completeness

Reference: C:\Users\mose\.claude\rules\code-review.md for structure.</action>
  <verify>references/code-review-criteria.md exists with all 5 gates detailed including checks, output formats, and metrics</verify>
  <done>Code review criteria documented for 5 quality gates</done>
</task>

<task type="auto">
  <name>Task 2: Document code review workflow with skill integration</name>
  <files>references/code-review-workflow.md</files>
  <action>Create references/code-review-workflow.md with skill integration patterns:

1. Skill Invocation Pattern:
   ```
   Use skill: code-review-expert
   Focus: [Specific gate(s) to validate]
   Context: [Relevant files/changes]
   ```

2. DesktopCommander Integration:
   - All file access via DesktopCommander MCP
   - Token efficiency: ~80-90% savings vs native
   - Example: read_multiple_files for batch file analysis

3. find-skills Integration:
   - After code review, check for optimization opportunities
   - Discover better implementation approaches
   - Suggest skill-based alternatives

4. Standard Review Flow:
   - Identify scope (what files changed, purpose, requirements)
   - Load context (changed files, related files, architecture)
   - Execute review (apply all criteria, document findings)
   - Generate report (aggregate findings, prioritize issues)
   - Determine outcome (Approved/Rejected/Approved with Notes)

5. Review Depth Levels:
   - Quick: Changed files only, critical checks
   - Standard: Changed + related, all criteria
   - Comprehensive: Full impact analysis, security, performance

Reference: C:\Users\mose\.claude\rules\code-review.md.</action>
  <verify>references/code-review-workflow.md exists with skill patterns, DesktopCommander integration, find-skills, and review flow</verify>
  <done>Code review workflow documented with skill integration</done>
</task>

<task type="auto">
  <name>Task 3: Create standardized code review output templates</name>
  <files>references/code-review-templates.md</files>
  <action>Create references/code-review-templates.md with output templates:

1. Approval Template:
   ```markdown
   # Code Review: APPROVED ✓
   ## Summary
   [Change description] passes all review criteria.
   ## Files Reviewed
   - [File 1]: [Status]
   ## Criteria Results
   - Implementation Correctness: PASS
   - Integration Completeness: PASS
   - Pattern Consistency: PASS
   - Maintainability Standards: PASS
   - Documentation Quality: PASS
   ## Quality Score: 5/5
   ```

2. Approval with Notes Template:
   ```markdown
   # Code Review: APPROVED WITH NOTES ✓
   ## Criteria Results
   - [Criteria with minor issues noted]
   ## Suggestions
   1. [Low priority suggestion]
   ## Quality Score: 4/5
   ```

3. Rejection Template:
   ```markdown
   # Code Review: REJECTED ✗
   ## Must Fix (Critical)
   1. [Critical issue]
   ## Should Fix (High)
   1. [High priority issue]
   ## Recommendations
   [Specific fixes]
   ## Quality Score: 2/5
   ```

4. Severity Level Definitions:
   - Critical: Security vulnerabilities, data corruption, crashes, breaking changes
   - High: Performance regressions, integration issues, pattern violations, missing error handling
   - Medium: Minor inconsistencies, maintainability issues, missing documentation
   - Low: Stylistic preferences, minor optimizations</action>
  <verify>references/code-review-templates.md exists with Approval, Approval with Notes, Rejection templates and severity definitions</verify>
  <done>Code review output templates standardized</done>
</task>

<task type="auto">
  <name>Task 4: Map code review criteria to 7-BMAD gates</name>
  <files>references/validation-gates.md</files>
  <action>Update references/validation-gates.md to integrate code review criteria:

1. For each gate that uses code-review-expert (Method, Mad, Mode, Mod, Methodd):
   - Add reference to @references/code-review-criteria.md
   - Link specific criteria sections to gate checks
   - Include output format references

2. Document code review tool mapping:
   - Method Circle -> Implementation Correctness criteria
   - Mad Circle -> Integration Completeness criteria
   - Model Circle -> tractatus-thinking (not code review)
   - Mode Circle -> Pattern Consistency criteria
   - Mod Circle -> Maintainability Standards criteria
   - Modd Circle -> tractatus-thinking (not code review)
   - Methodd Circle -> Documentation Quality criteria

3. Add severity levels to gate evaluations:
   - Critical issues block approval
   - High issues should be fixed
   - Medium issues considered
   - Low issues noted

4. Update gate evaluation workflow to include code review skill invocation.

This creates explicit mapping between criteria and gates.</action>
  <verify>references/validation-gates.md maps code review criteria to gates and includes severity levels</verify>
  <done>Code review criteria mapped to 7-BMAD gates</done>
</task>

<task type="auto">
  <name>Task 5: Integrate code review into validation workflow</name>
  <files>references/validation-workflow.md</files>
  <action>Update references/validation-workflow.md to include code review integration:

1. In Phase 2: Quality Assessment:
   - Add code-review-expert skill invocation step
   - Specify skill invocation pattern
   - Include DesktopCommander for file access

2. Document gate-specific tool selection:
   - Method: code-review-expert (Implementation Correctness)
   - Mad: code-review-expert (Integration Completeness)
   - Model: tractatus-thinking (Architecture)
   - Mode: code-review-expert (Pattern Consistency)
   - Mod: code-review-expert (Maintainability)
   - Modd: tractatus-thinking (Extensibility)
   - Methodd: code-review-expert (Documentation)

3. Include find-skills optimization check:
   - After code review, discover better approaches
   - Check for skill-based alternatives
   - Identify token optimization opportunities

4. Add token optimization notes:
   - Compressed skills ~80-90% token savings
   - Targeted analysis on changed files only
   - Cached results for re-validation

This completes validation workflow with skill integration.</action>
  <verify>references/validation-workflow.md includes code review skill invocation, gate-specific tools, and find-skills integration</verify>
  <done>Code review integrated into validation workflow</done>
</task>

<task type="auto">
  <name>Task 6: Add code review invocation to execute-plan workflow</name>
  <files>workflows/execute-plan.md</files>
  <action>Update workflows/execute-plan.md to include code review invocation:

1. Add code review reference to context:
   ```markdown
   # Code Review Reference
   @references/code-review-criteria.md
   @references/code-review-workflow.md
   @references/code-review-templates.md
   ```

2. In task completion section, add code review step:
   - After task verification, invoke code-review-expert
   - Specify which gates to evaluate based on task type
   - Include review outcome in task commit message

3. Add code review to verification section:
   - Run code review after all tasks complete
   - Evaluate all 7 gates (or relevant subset)
   - Generate review report

4. Document code review as part of quality assurance:
   - Mandatory for all code changes
   - Uses skill for token efficiency
   - Generates actionable feedback

This integrates code review into execution flow.</action>
  <verify>workflows/execute-plan.md references code review files and includes invocation in task completion</verify>
  <done>Code review invocation added to execute-plan workflow</done>
</task>

<task type="auto">
  <name>Task 7: Document code review metrics and monitoring</name>
  <files>references/code-review-workflow.md</files>
  <action>Append metrics and monitoring section to references/code-review-workflow.md:

1. Metrics to Track:
   - Review pass rate (target: 95%+)
   - Common issue patterns (top 10)
   - Review duration (target: <5 min standard)
   - Token usage per review (target: 80%+ savings)
   - Agent compliance rate (target: 100%)
   - Severity distribution (Critical/High/Medium/Low)

2. Quality Goals:
   - 95%+ pass rate after fixes
   - <5 minutes per standard review
   - 80%+ token savings vs manual review
   - 100% agent compliance

3. Monitoring Approach:
   - Aggregate metrics across all reviews
   - Track patterns in failing reviews
   - Identify common issues for proactive detection
   - Measure review efficiency over time

4. Continuous Improvement:
   - System learns from failures
   - Update detection patterns
   - Enhance fix suggestions
   - Optimize validation speed

This enables quality tracking and system improvement.</action>
  <verify>references/code-review-workflow.md includes metrics, goals, monitoring approach, and continuous improvement</verify>
  <done>Code review metrics and monitoring documented</done>
</task>

<task type="auto">
  <name>Task 8: Document code review best practices</name>
  <files>references/code-review-workflow.md</files>
  <action>Append best practices section to references/code-review-workflow.md:

1. For Agents:
   - Always invoke via skill, never manual review
   - Use DesktopCommander for file access
   - Provide clear context about what to review
   - Act on feedback - don't ignore review results
   - Iterate quickly - fix issues and re-review

2. For Users:
   - Trust the system - auto-validation catches most issues
   - Review feedback - understand what's flagged
   - Provide overrides only when truly necessary
   - Track patterns - learn from common issues
   - Update criteria - adjust rules as needed

3. Integration Examples:
   - Example 1: Auto-validation integration (full flow)
   - Example 2: Find-skills integration (optimization discovery)
   - Example 3: DesktopCommander integration (token efficiency)

4. Common Pitfalls:
   - Manual review instead of skill (high token cost)
   - Native file operations instead of DesktopCommander
   - Ignoring review feedback
   - Overriding without justification

This provides guidance for effective code review usage.</action>
  <verify>references/code-review-workflow.md includes best practices for agents, users, examples, and pitfalls</verify>
  <done>Code review best practices documented</done>
</task>

<task type="auto">
  <name>Task 9: Create code review troubleshooting guide</name>
  <files>references/code-review-troubleshooting.md</files>
  <action>Create references/code-review-troubleshooting.md with common issues:

1. Issue: Review Fails Unexpectedly
   - Possible causes: Review scope too broad, false positive, outdated criteria
   - Solutions: Narrow scope, update patterns, adjust strictness

2. Issue: Review Takes Too Long
   - Possible causes: Too many files, comprehensive depth, inefficient file access
   - Solutions: Reduce scope, use quick mode, ensure DesktopCommander integration

3. Issue: False Positives
   - Possible causes: Pattern matching errors, outdated rules, project-specific conventions
   - Solutions: Update pattern rules, add project exceptions, adjust criteria

4. Issue: Skill Invocation Fails
   - Possible causes: Skill not available, wrong parameters, context too large
   - Solutions: Verify skill installed, check parameters, reduce context

5. Issue: Review Doesn't Catch Issues
   - Possible causes: Strictness too low, criteria incomplete, scope too narrow
   - Solutions: Increase strictness, update criteria, expand scope

6. Debug Mode:
   - Enable verbose output
   - Log skill invocations
   - Track review decisions

This helps resolve common code review issues.</action>
  <verify>references/code-review-troubleshooting.md exists with 5+ common issues and solutions</verify>
  <done>Code review troubleshooting guide created</done>
</task>

<task type="auto">
  <name>Task 10: Update validation configuration with code review settings</name>
  <files>references/validation-config.md</files>
  <action>Update references/validation-config.md with code review specific settings:

1. Add Code Review Section:
   ```json
   {
     "code_review": {
       "skill": "code-review-expert",
       "depth": "standard",
       "strictness": "standard",
       "file_access": "desktop-commander",
       "token_optimization": true,
       "gates": [
         "method",
         "mad",
         "mode",
         "mod",
         "methodd"
       ]
     }
   }
   ```

2. Document Depth Options:
   - Quick: Changed files only, critical checks
   - Standard: Changed + related files, all criteria
   - Comprehensive: Full impact analysis

3. Document Strictness Options:
   - Lenient: Only critical issues block
   - Standard: Critical + high issues block
   - Strict: All issues must be addressed

4. Add per-gate tool mapping configuration.

This enables customization of code review behavior.</action>
  <verify>references/validation-config.md includes code review section with depth, strictness, and gate mapping</verify>
  <done>Validation configuration updated with code review settings</done>
</task>

</tasks>

<verification>
Overall phase checks:
1. references/code-review-criteria.md exists with 5 gates detailed
2. references/code-review-workflow.md exists with skill integration
3. references/code-review-templates.md exists with output templates
4. references/validation-gates.md maps code review to gates
5. references/validation-workflow.md includes code review integration
6. workflows/execute-plan.md includes code review invocation
7. references/code-review-workflow.md includes metrics and best practices
8. references/code-review-troubleshooting.md created
9. references/validation-config.md includes code review settings
</verification>

<success_criteria>
- [ ] Code review criteria documented for 5 quality gates
- [ ] Code review workflow with skill integration documented
- [ ] Standardized output templates created
- [ ] Criteria mapped to 7-BMAD gates
- [ ] Code review integrated into validation workflow
- [ ] Code review invocation added to execute-plan
- [ ] Metrics and monitoring documented
- [ ] Best practices documented
- [ ] Troubleshooting guide created
- [ ] Validation config includes code review settings
</success_criteria>

<output>
After completion, create `.planning/phases/06-quality-verification/06-02-SUMMARY.md` with:
- Duration metrics
- All 10 task commits
- Code review expert integrated
- 5 of 7 gates using code review
- Files created/modified
- Next: Plan checker implementation
</output>
