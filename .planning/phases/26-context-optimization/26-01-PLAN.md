# Phase 26-01: Context Window Analysis

## Overview
Build intelligent context window analysis that tracks token usage, identifies waste patterns, and optimizes context composition for maximum efficiency.

## Research Required

### Domain Research
1. **Token Counting Methods**
   - Study Claude tokenizer (tiktoken, anthropic tokenizers)
   - Research token estimation accuracy
   - Analyze token counting performance tradeoffs

2. **Context Waste Patterns**
   - Study common context waste sources
   - Research redundant information patterns
   - Analyze protocol overhead in tool calls

3. **Context Optimization Strategies**
   - Research context window management
   - Study information compression techniques
   - Analyze just-in-time context loading

### Technical Research
1. **Tokenization Libraries**
   - Compare: tiktoken, tokenizers, gpt-tokenizer
   - Evaluate accuracy vs speed
   - Test Claude-specific tokenization

2. **Context Analysis Algorithms**
   - Study information theory metrics (entropy, redundancy)
   - Research semantic similarity for deduplication
   - Investigate context summarization techniques

3. **Performance Profiling**
   - Research token counting performance
   - Study efficient data structures for tracking
   - Analyze memory vs speed tradeoffs

## Implementation Tasks

### Sub-task 1: Token Counter
- [ ] Create multi-format token counter
  - Count tokens in text (messages, files)
  - Count tokens in structured data (JSON, tool calls)
  - Count tokens in code (syntax-aware)
  
- [ ] Implement Claude-specific tokenizer
  - Use Anthropic's tokenization model
  - Handle special tokens (role markers, tool annotations)
  - Cache tokenization results
  
- [ ] Build token usage tracker
  - Track cumulative token usage per session
  - Track token usage per command/operation
  - Identify high-token operations

### Sub-task 2: Context Analyzer
- [ ] Implement context waste detection
  - Detect redundant file reads
  - Identify duplicate information
  - Find verbose protocol messages
  
- [ ] Create context composition analyzer
  - Analyze what fills context window
  - Categorize context by source (files, tools, messages)
  - Identify low-value context
  
- [ ] Build optimization opportunity scanner
  - Find replaceable native tools with MCP
  - Find batchable operations
  - Find cacheable results

### Sub-task 3: Metrics & Reporting
- [ ] Design token efficiency metrics
  - Token efficiency score (useful tokens / total tokens)
  - Waste percentage (redundant / total)
  - MCP adoption rate (MCP tools / total tools)
  
- [ ] Implement context usage reports
  - Real-time token usage display
  - Per-command token breakdown
  - Session-level token summary
  
- [ ] Create optimization suggestions
  - Suggest MCP tool replacements
  - Recommend batching opportunities
  - Identify caching candidates

### Sub-task 4: Testing & Validation
- [ ] Token counting accuracy tests
  - Compare against actual Claude token counts
  - Test across various content types
  - Validate Claude-specific tokenization
  
- [ ] Performance benchmarks
  - Token counting speed (>1000 tokens/ms)
  - Context analysis overhead (<5% of total time)
  - Memory usage (<50MB for 100K tokens)
  
- [ ] Integration tests
  - Test with actual GSI workflows
  - Validate token tracking accuracy
  - Test optimization suggestion quality

## Verification Criteria
- [ ] Token counting accuracy >95% vs actual Claude counts
- [ ] Context analysis adds <5% overhead to workflow execution
- [ ] Waste detection identifies >80% of actual redundancies
- [ ] Optimization suggestions provide >30% token savings when applied
- [ ] All tests pass with >80% coverage

## Integration Points
- **lib/context-analyzer/**: New module for context analysis
- **lib/token-counter/**: New module for token counting
- **commands/gsi:progress**: Display context efficiency metrics
- **workflows/**: Add context analysis checkpoints

## Success Metrics
- Token counting accuracy >95%
- Context analysis overhead <5%
- Optimization suggestions save >30% tokens when applied
- User adoption of optimizations >50%
