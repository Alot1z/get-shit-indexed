<documents>
<document index="1">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\package.md</source>
<document_content>

</document_content>
</document>
<document index="2">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\bin\gsi-tools.js</source>
<document_content>
#!/usr/bin/env node

/**
 * GSI Tools — CLI utility for GSI workflow operations
 *
 * Replaces repetitive inline bash patterns across ~50 GSI command/workflow/agent files.
 * Centralizes: config parsing, model resolution, phase lookup, git commits, summary verification.
 *
 * Usage: node GSI-tools.js <command> [args] [--raw]
 *
 * Atomic Commands:
 *   state load                         Load project config + state
 *   state update <field> <value>       Update a STATE.md field
 *   state get [section]                Get STATE.md content or section
 *   state patch --field val ...        Batch update STATE.md fields
 *   install-info                       Show detected install context
 *     [--force-global] [--force-project]
 *   resolve-model <agent-type>         Get model for agent based on profile
 *   find-phase <phase>                 Find phase directory by number
 *   commit <message> [--files f1 f2]   Commit planning docs
 *   verify-summary <path>              Verify a SUMMARY.md file
 *   generate-slug <text>               Convert text to URL-safe slug
 *   current-timestamp [format]         Get timestamp (full|date|filename)
 *   list-todos [area]                  Count and enumerate pending todos
 *   verify-path-exists <path>          Check file/directory existence
 *   config-ensure-section              Initialize .planning/config.json
 *   history-digest                     Aggregate all SUMMARY.md data
 *   summary-extract <path> [--fields]  Extract structured data from SUMMARY.md
 *   state-snapshot                     Structured parse of STATE.md
 *   phase-plan-index <phase>           Index plans with waves and status
 *   websearch <query>                  Search web via Brave API (if configured)
 *     [--limit N] [--freshness day|week|month]
 *
 * Reflection Operations:
 *   reflection list                    Show recent reflections and stats
 *     [--tool <name>] [--type <type>]
 *   reflection patterns                Show extracted patterns
 *     [--min-success N] [--min-freq N] [--type successful|anti]
 *   reflection insights                Show generated insights
 *     [--type <type>] [--impact <level>] [--limit N]
 *   reflection graph                   Show debug-thinking graph stats
 *
 * Phase Operations:
 *   phase next-decimal <phase>         Calculate next decimal phase number
 *   phase add <description>            Append new phase to roadmap + create dir
 *   phase insert <after> <description> Insert decimal phase after existing
 *   phase remove <phase> [--force]     Remove phase, renumber all subsequent
 *   phase complete <phase>             Mark phase done, update state + roadmap
 *
 * Roadmap Operations:
 *   roadmap get-phase <phase>          Extract phase section from ROADMAP.md
 *   roadmap analyze                    Full roadmap parse with disk status
 *
 * Milestone Operations:
 *   milestone complete <version>       Archive milestone, create MILESTONES.md
 *     [--name <name>]
 *
 * Validation:
 *   validate consistency               Check phase numbering, disk/roadmap sync
 *
 * Progress:
 *   progress [json|table|bar]          Render progress in various formats
 *
 * Todos:
 *   todo complete <filename>           Move todo from pending to completed
 *
 * Scaffolding:
 *   scaffold context --phase <N>       Create CONTEXT.md template
 *   scaffold uat --phase <N>           Create UAT.md template
 *   scaffold verification --phase <N>  Create VERIFICATION.md template
 *   scaffold phase-dir --phase <N>     Create phase directory
 *     --name <name>
 *
 * Frontmatter CRUD:
 *   frontmatter get <file> [--field k] Extract frontmatter as JSON
 *   frontmatter set <file> --field k   Update single frontmatter field
 *     --value jsonVal
 *   frontmatter merge <file>           Merge JSON into frontmatter
 *     --data '{json}'
 *   frontmatter validate <file>        Validate required fields
 *     --schema plan|summary|verification
 *
 * Verification Suite:
 *   verify plan-structure <file>       Check PLAN.md structure + tasks
 *   verify phase-completeness <phase>  Check all plans have summaries
 *   verify references <file>           Check @-refs + paths resolve
 *   verify commits <h1> [h2] ...      Batch verify commit hashes
 *   verify artifacts <plan-file>       Check must_haves.artifacts
 *   verify key-links <plan-file>       Check must_haves.key_links
 *
 * Template Fill:
 *   template fill summary --phase N    Create pre-filled SUMMARY.md
 *     [--plan M] [--name "..."]
 *     [--fields '{json}']
 *   template fill plan --phase N       Create pre-filled PLAN.md
 *     [--plan M] [--type execute|tdd]
 *     [--wave N] [--fields '{json}']
 *   template fill verification         Create pre-filled VERIFICATION.md
 *     --phase N [--fields '{json}']
 *
 * Thinking Orchestrator Operations:
 *   thinking analyze <command>         Analyze command complexity
 *     [--json]
 *   thinking config <command>          Generate optimal thinking config
 *     [--profile <name>] [--timeout <ms>]
 *     [--bmad] [--no-bmad]
 *   thinking servers                   List available thinking servers
 *     [--json]
 *   thinking test                      Test thinking server connections
 *     [--server <name>] [--timeout <ms>]
 *   thinking apply-all                 Apply thinking_phase to all GSI commands
 *     [--commands-dir <path>] [--backup-dir <path>]
 *     [--dry-run] [--force]
 *   thinking validate                  Validate thinking_phase configurations
 *     [--commands-dir <path>] [--strict]
 *   thinking rollback                  Rollback thinking_phase changes
 *     [--backup-dir <path>]
 *   thinking factors                   Show complexity factor documentation
 *     [--json]
 *
 * State Progression:
 *   state advance-plan                 Increment plan counter
 *   state record-metric --phase N      Record execution metrics
 *     --plan M --duration Xmin
 *     [--tasks N] [--files N]
 *   state update-progress              Recalculate progress bar
 *   state add-decision --summary "..."  Add decision to STATE.md
 *     [--phase N] [--rationale "..."]
 *   state add-blocker --text "..."     Add blocker
 *   state resolve-blocker --text "..." Remove blocker
 *   state record-session               Update session continuity
 *     --stopped-at "..."
 *     [--resume-file path]
 *
 * Compound Commands (workflow-specific initialization):
 *   init execute-phase <phase>         All context for execute-phase workflow
 *   init plan-phase <phase>            All context for plan-phase workflow
 *   init new-project                   All context for new-project workflow
 *   init new-milestone                 All context for new-milestone workflow
 *   init quick <description>           All context for quick workflow
 *   init resume                        All context for resume-project workflow
 *   init verify-work <phase>           All context for verify-work workflow
 *   init phase-op <phase>              Generic phase operation context
 *   init todos [area]                  All context for todo workflows
 *   init milestone-op                  All context for milestone operations
 *   init map-codebase                  All context for map-codebase workflow
 *   init progress                      All context for progress workflow
 *
 * Patch Manager Operations:
 *   patch backup                       Backup local modifications before update
 *     [--patches-dir <path>]
 *   patch restore                      Restore backed-up modifications after update
 *     [--patches-dir <path>]
 *   patch status                       Show status of local modifications backup
 *     [--patches-dir <path>]
 *   patch diff                         Show diff between backup and current files
 *     [--patches-dir <path>]
 *
 * Workflow Chainer Operations:
 *   workflow run <template>            Run a workflow template
 *     [--vars '{json}'] [--yolo]
 *     [--failure-strategy stop|continue|rollback]
 *     [--templates-dir <path>] [--state-dir <path>]
 *   workflow list                      List available workflow templates
 *     [--templates-dir <path>]
 *   workflow status [name]             Show workflow status (all or specific)
 *     [--state-dir <path>]
 *   workflow pause <name>              Pause a running workflow
 *     [--state-dir <path>]
 *   workflow resume <name>             Resume a paused workflow
 *     [--state-dir <path>]
 *   workflow rollback <name>           Rollback workflow to last checkpoint
 *     [--state-dir <path>]
 *
 * Pattern Discovery Operations (Phase 38-03):
 *   workflow discover                  Mine patterns from command history
 *     [--min-frequency N] [--min-quality N]
 *     [--min-success-rate N] [--min/max-length N]
 *     [--state-dir <path>]
 *   workflow recommend                 Get workflow recommendations
 *     [--phase N] [--recent-commands cmd1,cmd2]
 *     [--goal "..."] [--state-dir <path>]
 *   workflow optimize <name>           Optimize a workflow
 *     [--state-dir <path>]
 *   workflow analyze                   Analyze all workflows and patterns
 *     [--state-dir <path>]
 *   workflow export <pattern-id>       Export pattern as template
 *     [--output <path>] [--state-dir <path>]
 *
 * Knowledge Base Operations:
 *   knowledge extract <path>           Extract patterns from source files
 *     [--category <category>] [--knowledge-dir <path>]
 *   knowledge search <query>           Search knowledge base for patterns
 *     [--category <category>] [--limit N] [--knowledge-dir <path>]
 *   knowledge generate-skill <id>      Generate skill from pattern
 *     [--knowledge-dir <path>]
 *   knowledge list                     List all patterns in knowledge base
 *     [--category <category>] [--limit N] [--knowledge-dir <path>]
 *   knowledge stats                    Show knowledge base statistics
 *     [--knowledge-dir <path>]
 *
 * Multi-Type Artifact Generation (Phase 38-01):
 *   knowledge generate-all <id>        Generate ALL artifact types from pattern
 *     [--knowledge-dir <path>]
 *   knowledge generate <id> <type>     Generate specific artifact type
 *     [--knowledge-dir <path>]
 *   knowledge artifact-types           List available artifact types
 *   knowledge extract-generate <path>  Extract and generate artifacts in one op
 *     [--types type1,type2] [--category <cat>] [--knowledge-dir <path>]
 *   knowledge batch-generate <ids>     Generate artifacts for multiple patterns
 *     --types type1,type2 [--knowledge-dir <path>]
 *
 * Shorthand Commands (single artifact type):
 *   knowledge agent <id>               Generate agent from pattern
 *   knowledge feature <id>             Generate feature spec from pattern
 *   knowledge idea <id>                Generate idea doc from pattern
 *   knowledge logic <id>               Generate logic module from pattern
 *   knowledge function <id>            Generate function from pattern
 *   knowledge improvement <id>         Generate improvement suggestions
 *
 * Artifact Types: SKILL, AGENT, LOGIC, FUNCTION, FEATURE, IMPROVEMENT, IDEA
 *
 * Cognitive Flow Operations (Phase 38-04):
 *   cognitive flow <operation>         Execute with cognitive flow enhancement
 *     [--timeout N] [--phase PHASE] [--file PATH]
 *   cognitive status                   Show cognitive system status
 *   cognitive learn [operation]        Trigger learning capture
 *     [--phase PHASE]
 *   cognitive optimize                 Optimize cognitive settings
 *     [--reset-stats]
 *
 * Cognitive Phases: PREPARE, EXECUTE, REFLECT, LEARN
 */

const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');

// Pattern visualization module (try-exit for optional dependency)
let patternViz = null;
try {
  patternViz = require('../lib/pattern-learning/visualization');
} catch (e) {
  // Module not available yet
}

// ─── Model Profile Table ─────────────────────────────────────────────────────

const MODEL_PROFILES = {
  'GSI-planner':              { quality: 'opus', balanced: 'opus',   budget: 'sonnet' },
  'GSI-roadmapper':           { quality: 'opus', balanced: 'sonnet', budget: 'sonnet' },
  'GSI-executor':             { quality: 'opus', balanced: 'sonnet', budget: 'sonnet' },
  'GSI-phase-researcher':     { quality: 'opus', balanced: 'sonnet', budget: 'haiku' },
  'GSI-project-researcher':   { quality: 'opus', balanced: 'sonnet', budget: 'haiku' },
  'GSI-research-synthesizer': { quality: 'sonnet', balanced: 'sonnet', budget: 'haiku' },
  'GSI-debugger':             { quality: 'opus', balanced: 'sonnet', budget: 'sonnet' },
  'GSI-codebase-mapper':      { quality: 'sonnet', balanced: 'haiku', budget: 'haiku' },
  'GSI-verifier':             { quality: 'sonnet', balanced: 'sonnet', budget: 'haiku' },
  'GSI-plan-checker':         { quality: 'sonnet', balanced: 'sonnet', budget: 'haiku' },
  'GSI-integration-checker':  { quality: 'sonnet', balanced: 'sonnet', budget: 'haiku' },
};

// ─── Helpers ──────────────────────────────────────────────────────────────────

function parseIncludeFlag(args) {
  const includeIndex = args.indexOf('--include');
  if (includeIndex === -1) return new Set();
  const includeValue = args[includeIndex + 1];
  if (!includeValue) return new Set();
  return new Set(includeValue.split(',').map(s => s.trim()));
}

function safeReadFile(filePath) {
  try {
    return fs.readFileSync(filePath, 'utf-8');
  } catch {
    return null;
  }
}

function loadConfig(cwd) {
  const configPath = path.join(cwd, '.planning', 'config.json');
  const defaults = {
    model_profile: 'balanced',
    commit_docs: true,
    search_gitignored: false,
    branching_strategy: 'none',
    phase_branch_template: 'GSI/phase-{phase}-{slug}',
    milestone_branch_template: 'GSI/{milestone}-{slug}',
    research: true,
    plan_checker: true,
    verifier: true,
    parallelization: true,
    brave_search: false,
  };

  try {
    const raw = fs.readFileSync(configPath, 'utf-8');
    const parsed = JSON.parse(raw);

    const get = (key, nested) => {
      if (parsed[key] !== undefined) return parsed[key];
      if (nested && parsed[nested.section] && parsed[nested.section][nested.field] !== undefined) {
        return parsed[nested.section][nested.field];
      }
      return undefined;
    };

    const parallelization = (() => {
      const val = get('parallelization');
      if (typeof val === 'boolean') return val;
      if (typeof val === 'object' && val !== null && 'enabled' in val) return val.enabled;
      return defaults.parallelization;
    })();

    return {
      model_profile: get('model_profile') ?? defaults.model_profile,
      commit_docs: get('commit_docs', { section: 'planning', field: 'commit_docs' }) ?? defaults.commit_docs,
      search_gitignored: get('search_gitignored', { section: 'planning', field: 'search_gitignored' }) ?? defaults.search_gitignored,
      branching_strategy: get('branching_strategy', { section: 'git', field: 'branching_strategy' }) ?? defaults.branching_strategy,
      phase_branch_template: get('phase_branch_template', { section: 'git', field: 'phase_branch_template' }) ?? defaults.phase_branch_template,
      milestone_branch_template: get('milestone_branch_template', { section: 'git', field: 'milestone_branch_template' }) ?? defaults.milestone_branch_template,
      research: get('research', { section: 'workflow', field: 'research' }) ?? defaults.research,
      plan_checker: get('plan_checker', { section: 'workflow', field: 'plan_check' }) ?? defaults.plan_checker,
      verifier: get('verifier', { section: 'workflow', field: 'verifier' }) ?? defaults.verifier,
      parallelization,
      brave_search: get('brave_search') ?? defaults.brave_search,
    };
  } catch {
    return defaults;
  }
}

function isGitIgnored(cwd, targetPath) {
  try {
    execSync('git check-ignore -q -- ' + targetPath.replace(/[^a-zA-Z0-9._\-/]/g, ''), {
      cwd,
      stdio: 'pipe',
    });
    return true;
  } catch {
    return false;
  }
}

function execGit(cwd, args) {
  try {
    const escaped = args.map(a => {
      if (/^[a-zA-Z0-9._\-/=:@]+$/.test(a)) return a;
      return "'" + a.replace(/'/g, "'\\''") + "'";
    });
    const stdout = execSync('git ' + escaped.join(' '), {
      cwd,
      stdio: 'pipe',
      encoding: 'utf-8',
    });
    return { exitCode: 0, stdout: stdout.trim(), stderr: '' };
  } catch (err) {
    return {
      exitCode: err.status ?? 1,
      stdout: (err.stdout ?? '').toString().trim(),
      stderr: (err.stderr ?? '').toString().trim(),
    };
  }
}

function normalizePhaseName(phase) {
  const match = phase.match(/^(\d+(?:\.\d+)?)/);
  if (!match) return phase;
  const num = match[1];
  const parts = num.split('.');
  const padded = parts[0].padStart(2, '0');
  return parts.length > 1 ? `${padded}.${parts[1]}` : padded;
}

function extractFrontmatter(content) {
  const frontmatter = {};
  const match = content.match(/^---\n([\s\S]+?)\n---/);
  if (!match) return frontmatter;

  const yaml = match[1];
  const lines = yaml.split('\n');

  // Stack to track nested objects: [{obj, key, indent}]
  // obj = object to write to, key = current key collecting array items, indent = indentation level
  let stack = [{ obj: frontmatter, key: null, indent: -1 }];

  for (const line of lines) {
    // Skip empty lines
    if (line.trim() === '') continue;

    // Calculate indentation (number of leading spaces)
    const indentMatch = line.match(/^(\s*)/);
    const indent = indentMatch ? indentMatch[1].length : 0;

    // Pop stack back to appropriate level
    while (stack.length > 1 && indent <= stack[stack.length - 1].indent) {
      stack.pop();
    }

    const current = stack[stack.length - 1];

    // Check for key: value pattern
    const keyMatch = line.match(/^(\s*)([a-zA-Z0-9_-]+):\s*(.*)/);
    if (keyMatch) {
      const key = keyMatch[2];
      const value = keyMatch[3].trim();

      if (value === '' || value === '[') {
        // Key with no value or opening bracket — could be nested object or array
        // We'll determine based on next lines, for now create placeholder
        current.obj[key] = value === '[' ? [] : {};
        current.key = null;
        // Push new context for potential nested content
        stack.push({ obj: current.obj[key], key: null, indent });
      } else if (value.startsWith('[') && value.endsWith(']')) {
        // Inline array: key: [a, b, c]
        current.obj[key] = value.slice(1, -1).split(',').map(s => s.trim().replace(/^["']|["']$/g, '')).filter(Boolean);
        current.key = null;
      } else {
        // Simple key: value
        current.obj[key] = value.replace(/^["']|["']$/g, '');
        current.key = null;
      }
    } else if (line.trim().startsWith('- ')) {
      // Array item
      const itemValue = line.trim().slice(2).replace(/^["']|["']$/g, '');

      // If current context is an empty object, convert to array
      if (typeof current.obj === 'object' && !Array.isArray(current.obj) && Object.keys(current.obj).length === 0) {
        // Find the key in parent that points to this object and convert it
        const parent = stack.length > 1 ? stack[stack.length - 2] : null;
        if (parent) {
          for (const k of Object.keys(parent.obj)) {
            if (parent.obj[k] === current.obj) {
              parent.obj[k] = [itemValue];
              current.obj = parent.obj[k];
              break;
            }
          }
        }
      } else if (Array.isArray(current.obj)) {
        current.obj.push(itemValue);
      }
    }
  }

  return frontmatter;
}

function reconstructFrontmatter(obj) {
  const lines = [];
  for (const [key, value] of Object.entries(obj)) {
    if (value === null || value === undefined) continue;
    if (Array.isArray(value)) {
      if (value.length === 0) {
        lines.push(`${key}: []`);
      } else if (value.every(v => typeof v === 'string') && value.length <= 3 && value.join(', ').length < 60) {
        lines.push(`${key}: [${value.join(', ')}]`);
      } else {
        lines.push(`${key}:`);
        for (const item of value) {
          lines.push(`  - ${typeof item === 'string' && (item.includes(':') || item.includes('#')) ? `"${item}"` : item}`);
        }
      }
    } else if (typeof value === 'object') {
      lines.push(`${key}:`);
      for (const [subkey, subval] of Object.entries(value)) {
        if (subval === null || subval === undefined) continue;
        if (Array.isArray(subval)) {
          if (subval.length === 0) {
            lines.push(`  ${subkey}: []`);
          } else if (subval.every(v => typeof v === 'string') && subval.length <= 3 && subval.join(', ').length < 60) {
            lines.push(`  ${subkey}: [${subval.join(', ')}]`);
          } else {
            lines.push(`  ${subkey}:`);
            for (const item of subval) {
              lines.push(`    - ${typeof item === 'string' && (item.includes(':') || item.includes('#')) ? `"${item}"` : item}`);
            }
          }
        } else if (typeof subval === 'object') {
          lines.push(`  ${subkey}:`);
          for (const [subsubkey, subsubval] of Object.entries(subval)) {
            if (subsubval === null || subsubval === undefined) continue;
            if (Array.isArray(subsubval)) {
              if (subsubval.length === 0) {
                lines.push(`    ${subsubkey}: []`);
              } else {
                lines.push(`    ${subsubkey}:`);
                for (const item of subsubval) {
                  lines.push(`      - ${item}`);
                }
              }
            } else {
              lines.push(`    ${subsubkey}: ${subsubval}`);
            }
          }
        } else {
          const sv = String(subval);
          lines.push(`  ${subkey}: ${sv.includes(':') || sv.includes('#') ? `"${sv}"` : sv}`);
        }
      }
    } else {
      const sv = String(value);
      if (sv.includes(':') || sv.includes('#') || sv.startsWith('[') || sv.startsWith('{')) {
        lines.push(`${key}: "${sv}"`);
      } else {
        lines.push(`${key}: ${sv}`);
      }
    }
  }
  return lines.join('\n');
}

function spliceFrontmatter(content, newObj) {
  const yamlStr = reconstructFrontmatter(newObj);
  const match = content.match(/^---\n[\s\S]+?\n---/);
  if (match) {
    return `---\n${yamlStr}\n---` + content.slice(match[0].length);
  }
  return `---\n${yamlStr}\n---\n\n` + content;
}

function parseMustHavesBlock(content, blockName) {
  // Extract a specific block from must_haves in raw frontmatter YAML
  // Handles 3-level nesting: must_haves > artifacts/key_links > [{path, provides, ...}]
  const fmMatch = content.match(/^---\n([\s\S]+?)\n---/);
  if (!fmMatch) return [];

  const yaml = fmMatch[1];
  // Find the block (e.g., "truths:", "artifacts:", "key_links:")
  const blockPattern = new RegExp(`^\\s{4}${blockName}:\\s*$`, 'm');
  const blockStart = yaml.search(blockPattern);
  if (blockStart === -1) return [];

  const afterBlock = yaml.slice(blockStart);
  const blockLines = afterBlock.split('\n').slice(1); // skip the header line

  const items = [];
  let current = null;

  for (const line of blockLines) {
    // Stop at same or lower indent level (non-continuation)
    if (line.trim() === '') continue;
    const indent = line.match(/^(\s*)/)[1].length;
    if (indent <= 4 && line.trim() !== '') break; // back to must_haves level or higher

    if (line.match(/^\s{6}-\s+/)) {
      // New list item at 6-space indent
      if (current) items.push(current);
      current = {};
      // Check if it's a simple string item
      const simpleMatch = line.match(/^\s{6}-\s+"?([^"]+)"?\s*$/);
      if (simpleMatch && !line.includes(':')) {
        current = simpleMatch[1];
      } else {
        // Key-value on same line as dash: "- path: value"
        const kvMatch = line.match(/^\s{6}-\s+(\w+):\s*"?([^"]*)"?\s*$/);
        if (kvMatch) {
          current = {};
          current[kvMatch[1]] = kvMatch[2];
        }
      }
    } else if (current && typeof current === 'object') {
      // Continuation key-value at 8+ space indent
      const kvMatch = line.match(/^\s{8,}(\w+):\s*"?([^"]*)"?\s*$/);
      if (kvMatch) {
        const val = kvMatch[2];
        // Try to parse as number
        current[kvMatch[1]] = /^\d+$/.test(val) ? parseInt(val, 10) : val;
      }
      // Array items under a key
      const arrMatch = line.match(/^\s{10,}-\s+"?([^"]+)"?\s*$/);
      if (arrMatch) {
        // Find the last key added and convert to array
        const keys = Object.keys(current);
        const lastKey = keys[keys.length - 1];
        if (lastKey && !Array.isArray(current[lastKey])) {
          current[lastKey] = current[lastKey] ? [current[lastKey]] : [];
        }
        if (lastKey) current[lastKey].push(arrMatch[1]);
      }
    }
  }
  if (current) items.push(current);

  return items;
}

function output(result, raw, rawValue) {
  if (raw && rawValue !== undefined) {
    process.stdout.write(String(rawValue));
  } else {
    process.stdout.write(JSON.stringify(result, null, 2));
  }
  process.exit(0);
}

function error(message) {
  process.stderr.write('Error: ' + message + '\n');
  process.exit(1);
}

// ─── Commands ─────────────────────────────────────────────────────────────────

function cmdGenerateSlug(text, raw) {
  if (!text) {
    error('text required for slug generation');
  }

  const slug = text
    .toLowerCase()
    .replace(/[^a-z0-9]+/g, '-')
    .replace(/^-+|-+$/g, '');

  const result = { slug };
  output(result, raw, slug);
}

function cmdCurrentTimestamp(format, raw) {
  const now = new Date();
  let result;

  switch (format) {
    case 'date':
      result = now.toISOString().split('T')[0];
      break;
    case 'filename':
      result = now.toISOString().replace(/:/g, '-').replace(/\..+/, '');
      break;
    case 'full':
    default:
      result = now.toISOString();
      break;
  }

  output({ timestamp: result }, raw, result);
}

function cmdListTodos(cwd, area, raw) {
  const pendingDir = path.join(cwd, '.planning', 'todos', 'pending');

  let count = 0;
  const todos = [];

  try {
    const files = fs.readdirSync(pendingDir).filter(f => f.endsWith('.md'));

    for (const file of files) {
      try {
        const content = fs.readFileSync(path.join(pendingDir, file), 'utf-8');
        const createdMatch = content.match(/^created:\s*(.+)$/m);
        const titleMatch = content.match(/^title:\s*(.+)$/m);
        const areaMatch = content.match(/^area:\s*(.+)$/m);

        const todoArea = areaMatch ? areaMatch[1].trim() : 'general';

        // Apply area filter if specified
        if (area && todoArea !== area) continue;

        count++;
        todos.push({
          file,
          created: createdMatch ? createdMatch[1].trim() : 'unknown',
          title: titleMatch ? titleMatch[1].trim() : 'Untitled',
          area: todoArea,
          path: path.join('.planning', 'todos', 'pending', file),
        });
      } catch {}
    }
  } catch {}

  const result = { count, todos };
  output(result, raw, count.toString());
}

function cmdVerifyPathExists(cwd, targetPath, raw) {
  if (!targetPath) {
    error('path required for verification');
  }

  const fullPath = path.isAbsolute(targetPath) ? targetPath : path.join(cwd, targetPath);

  try {
    const stats = fs.statSync(fullPath);
    const type = stats.isDirectory() ? 'directory' : stats.isFile() ? 'file' : 'other';
    const result = { exists: true, type };
    output(result, raw, 'true');
  } catch {
    const result = { exists: false, type: null };
    output(result, raw, 'false');
  }
}

function cmdConfigEnsureSection(cwd, raw) {
  const configPath = path.join(cwd, '.planning', 'config.json');
  const planningDir = path.join(cwd, '.planning');

  // Ensure .planning directory exists
  try {
    if (!fs.existsSync(planningDir)) {
      fs.mkdirSync(planningDir, { recursive: true });
    }
  } catch (err) {
    error('Failed to create .planning directory: ' + err.message);
  }

  // Check if config already exists
  if (fs.existsSync(configPath)) {
    const result = { created: false, reason: 'already_exists' };
    output(result, raw, 'exists');
    return;
  }

  // Detect Brave Search API key availability
  const homedir = require('os').homedir();
  const braveKeyFile = path.join(homedir, '.GSI', 'brave_api_key');
  const hasBraveSearch = !!(process.env.BRAVE_API_KEY || fs.existsSync(braveKeyFile));

  // Create default config
  const defaults = {
    model_profile: 'balanced',
    commit_docs: true,
    search_gitignored: false,
    branching_strategy: 'none',
    phase_branch_template: 'GSI/phase-{phase}-{slug}',
    milestone_branch_template: 'GSI/{milestone}-{slug}',
    workflow: {
      research: true,
      plan_check: true,
      verifier: true,
    },
    parallelization: true,
    brave_search: hasBraveSearch,
  };

  try {
    fs.writeFileSync(configPath, JSON.stringify(defaults, null, 2), 'utf-8');
    const result = { created: true, path: '.planning/config.json' };
    output(result, raw, 'created');
  } catch (err) {
    error('Failed to create config.json: ' + err.message);
  }
}

function cmdConfigSet(cwd, keyPath, value, raw) {
  const configPath = path.join(cwd, '.planning', 'config.json');

  if (!keyPath) {
    error('Usage: config-set <key.path> <value>');
  }

  // Parse value (handle booleans and numbers)
  let parsedValue = value;
  if (value === 'true') parsedValue = true;
  else if (value === 'false') parsedValue = false;
  else if (!isNaN(value) && value !== '') parsedValue = Number(value);

  // Load existing config or start with empty object
  let config = {};
  try {
    if (fs.existsSync(configPath)) {
      config = JSON.parse(fs.readFileSync(configPath, 'utf-8'));
    }
  } catch (err) {
    error('Failed to read config.json: ' + err.message);
  }

  // Set nested value using dot notation (e.g., "workflow.research")
  const keys = keyPath.split('.');
  let current = config;
  for (let i = 0; i < keys.length - 1; i++) {
    const key = keys[i];
    if (current[key] === undefined || typeof current[key] !== 'object') {
      current[key] = {};
    }
    current = current[key];
  }
  current[keys[keys.length - 1]] = parsedValue;

  // Write back
  try {
    fs.writeFileSync(configPath, JSON.stringify(config, null, 2), 'utf-8');
    const result = { updated: true, key: keyPath, value: parsedValue };
    output(result, raw, `${keyPath}=${parsedValue}`);
  } catch (err) {
    error('Failed to write config.json: ' + err.message);
  }
}

function cmdHistoryDigest(cwd, raw) {
  const phasesDir = path.join(cwd, '.planning', 'phases');
  const digest = { phases: {}, decisions: [], tech_stack: new Set() };

  if (!fs.existsSync(phasesDir)) {
    digest.tech_stack = [];
    output(digest, raw);
    return;
  }

  try {
    const phaseDirs = fs.readdirSync(phasesDir, { withFileTypes: true })
      .filter(e => e.isDirectory())
      .map(e => e.name)
      .sort();

    for (const dir of phaseDirs) {
      const dirPath = path.join(phasesDir, dir);
      const summaries = fs.readdirSync(dirPath).filter(f => f.endsWith('-SUMMARY.md') || f === 'SUMMARY.md');

      for (const summary of summaries) {
        try {
          const content = fs.readFileSync(path.join(dirPath, summary), 'utf-8');
          const fm = extractFrontmatter(content);
          
          const phaseNum = fm.phase || dir.split('-')[0];
          
          if (!digest.phases[phaseNum]) {
            digest.phases[phaseNum] = {
              name: fm.name || dir.split('-').slice(1).join(' ') || 'Unknown',
              provides: new Set(),
              affects: new Set(),
              patterns: new Set(),
            };
          }

          // Merge provides
          if (fm['dependency-graph'] && fm['dependency-graph'].provides) {
            fm['dependency-graph'].provides.forEach(p => digest.phases[phaseNum].provides.add(p));
          } else if (fm.provides) {
            fm.provides.forEach(p => digest.phases[phaseNum].provides.add(p));
          }

          // Merge affects
          if (fm['dependency-graph'] && fm['dependency-graph'].affects) {
            fm['dependency-graph'].affects.forEach(a => digest.phases[phaseNum].affects.add(a));
          }

          // Merge patterns
          if (fm['patterns-established']) {
            fm['patterns-established'].forEach(p => digest.phases[phaseNum].patterns.add(p));
          }

          // Merge decisions
          if (fm['key-decisions']) {
            fm['key-decisions'].forEach(d => {
              digest.decisions.push({ phase: phaseNum, decision: d });
            });
          }

          // Merge tech stack
          if (fm['tech-stack'] && fm['tech-stack'].added) {
            fm['tech-stack'].added.forEach(t => digest.tech_stack.add(typeof t === 'string' ? t : t.name));
          }

        } catch (e) {
          // Skip malformed summaries
        }
      }
    }

    // Convert Sets to Arrays for JSON output
    Object.keys(digest.phases).forEach(p => {
      digest.phases[p].provides = [...digest.phases[p].provides];
      digest.phases[p].affects = [...digest.phases[p].affects];
      digest.phases[p].patterns = [...digest.phases[p].patterns];
    });
    digest.tech_stack = [...digest.tech_stack];

    output(digest, raw);
  } catch (e) {
    error('Failed to generate history digest: ' + e.message);
  }
}

function cmdPhasesList(cwd, options, raw) {
  const phasesDir = path.join(cwd, '.planning', 'phases');
  const { type, phase } = options;

  // If no phases directory, return empty
  if (!fs.existsSync(phasesDir)) {
    if (type) {
      output({ files: [], count: 0 }, raw, '');
    } else {
      output({ directories: [], count: 0 }, raw, '');
    }
    return;
  }

  try {
    // Get all phase directories
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    let dirs = entries.filter(e => e.isDirectory()).map(e => e.name);

    // Sort numerically (handles decimals: 01, 02, 02.1, 02.2, 03)
    dirs.sort((a, b) => {
      const aNum = parseFloat(a.match(/^(\d+(?:\.\d+)?)/)?.[1] || '0');
      const bNum = parseFloat(b.match(/^(\d+(?:\.\d+)?)/)?.[1] || '0');
      return aNum - bNum;
    });

    // If filtering by phase number
    if (phase) {
      const normalized = normalizePhaseName(phase);
      const match = dirs.find(d => d.startsWith(normalized));
      if (!match) {
        output({ files: [], count: 0, phase_dir: null, error: 'Phase not found' }, raw, '');
        return;
      }
      dirs = [match];
    }

    // If listing files of a specific type
    if (type) {
      const files = [];
      for (const dir of dirs) {
        const dirPath = path.join(phasesDir, dir);
        const dirFiles = fs.readdirSync(dirPath);

        let filtered;
        if (type === 'plans') {
          filtered = dirFiles.filter(f => f.endsWith('-PLAN.md') || f === 'PLAN.md');
        } else if (type === 'summaries') {
          filtered = dirFiles.filter(f => f.endsWith('-SUMMARY.md') || f === 'SUMMARY.md');
        } else {
          filtered = dirFiles;
        }

        files.push(...filtered.sort());
      }

      const result = {
        files,
        count: files.length,
        phase_dir: phase ? dirs[0].replace(/^\d+(?:\.\d+)?-?/, '') : null,
      };
      output(result, raw, files.join('\n'));
      return;
    }

    // Default: list directories
    output({ directories: dirs, count: dirs.length }, raw, dirs.join('\n'));
  } catch (e) {
    error('Failed to list phases: ' + e.message);
  }
}

function cmdRoadmapGetPhase(cwd, phaseNum, raw) {
  const roadmapPath = path.join(cwd, '.planning', 'ROADMAP.md');

  if (!fs.existsSync(roadmapPath)) {
    output({ found: false, error: 'ROADMAP.md not found' }, raw, '');
    return;
  }

  try {
    const content = fs.readFileSync(roadmapPath, 'utf-8');

    // Escape special regex chars in phase number, handle decimal
    const escapedPhase = phaseNum.replace(/\./g, '\\.');

    // Match "### Phase X:" or "### Phase X.Y:" with optional name
    const phasePattern = new RegExp(
      `###\\s*Phase\\s+${escapedPhase}:\\s*([^\\n]+)`,
      'i'
    );
    const headerMatch = content.match(phasePattern);

    if (!headerMatch) {
      output({ found: false, phase_number: phaseNum }, raw, '');
      return;
    }

    const phaseName = headerMatch[1].trim();
    const headerIndex = headerMatch.index;

    // Find the end of this section (next ### or end of file)
    const restOfContent = content.slice(headerIndex);
    const nextHeaderMatch = restOfContent.match(/\n###\s+Phase\s+\d/i);
    const sectionEnd = nextHeaderMatch
      ? headerIndex + nextHeaderMatch.index
      : content.length;

    const section = content.slice(headerIndex, sectionEnd).trim();

    // Extract goal if present
    const goalMatch = section.match(/\*\*Goal:\*\*\s*([^\n]+)/i);
    const goal = goalMatch ? goalMatch[1].trim() : null;

    output(
      {
        found: true,
        phase_number: phaseNum,
        phase_name: phaseName,
        goal,
        section,
      },
      raw,
      section
    );
  } catch (e) {
    error('Failed to read ROADMAP.md: ' + e.message);
  }
}

function cmdPhaseNextDecimal(cwd, basePhase, raw) {
  const phasesDir = path.join(cwd, '.planning', 'phases');
  const normalized = normalizePhaseName(basePhase);

  // Check if phases directory exists
  if (!fs.existsSync(phasesDir)) {
    output(
      {
        found: false,
        base_phase: normalized,
        next: `${normalized}.1`,
        existing: [],
      },
      raw,
      `${normalized}.1`
    );
    return;
  }

  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name);

    // Check if base phase exists
    const baseExists = dirs.some(d => d.startsWith(normalized + '-') || d === normalized);

    // Find existing decimal phases for this base
    const decimalPattern = new RegExp(`^${normalized}\\.(\\d+)`);
    const existingDecimals = [];

    for (const dir of dirs) {
      const match = dir.match(decimalPattern);
      if (match) {
        existingDecimals.push(`${normalized}.${match[1]}`);
      }
    }

    // Sort numerically
    existingDecimals.sort((a, b) => {
      const aNum = parseFloat(a);
      const bNum = parseFloat(b);
      return aNum - bNum;
    });

    // Calculate next decimal
    let nextDecimal;
    if (existingDecimals.length === 0) {
      nextDecimal = `${normalized}.1`;
    } else {
      const lastDecimal = existingDecimals[existingDecimals.length - 1];
      const lastNum = parseInt(lastDecimal.split('.')[1], 10);
      nextDecimal = `${normalized}.${lastNum + 1}`;
    }

    output(
      {
        found: baseExists,
        base_phase: normalized,
        next: nextDecimal,
        existing: existingDecimals,
      },
      raw,
      nextDecimal
    );
  } catch (e) {
    error('Failed to calculate next decimal phase: ' + e.message);
  }
}

function cmdStateLoad(cwd, raw) {
  const config = loadConfig(cwd);
  const planningDir = path.join(cwd, '.planning');

  let stateRaw = '';
  try {
    stateRaw = fs.readFileSync(path.join(planningDir, 'STATE.md'), 'utf-8');
  } catch {}

  const configExists = fs.existsSync(path.join(planningDir, 'config.json'));
  const roadmapExists = fs.existsSync(path.join(planningDir, 'ROADMAP.md'));
  const stateExists = stateRaw.length > 0;

  const result = {
    config,
    state_raw: stateRaw,
    state_exists: stateExists,
    roadmap_exists: roadmapExists,
    config_exists: configExists,
  };

  // For --raw, output a condensed key=value format
  if (raw) {
    const c = config;
    const lines = [
      `model_profile=${c.model_profile}`,
      `commit_docs=${c.commit_docs}`,
      `branching_strategy=${c.branching_strategy}`,
      `phase_branch_template=${c.phase_branch_template}`,
      `milestone_branch_template=${c.milestone_branch_template}`,
      `parallelization=${c.parallelization}`,
      `research=${c.research}`,
      `plan_checker=${c.plan_checker}`,
      `verifier=${c.verifier}`,
      `config_exists=${configExists}`,
      `roadmap_exists=${roadmapExists}`,
      `state_exists=${stateExists}`,
    ];
    process.stdout.write(lines.join('\n'));
    process.exit(0);
  }

  output(result);
}

function cmdStateGet(cwd, section, raw) {
  const statePath = path.join(cwd, '.planning', 'STATE.md');
  try {
    const content = fs.readFileSync(statePath, 'utf-8');
    
    if (!section) {
      output({ content }, raw, content);
      return;
    }

    // Try to find markdown section or field
    const fieldEscaped = section.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
    
    // Check for **field:** value
    const fieldPattern = new RegExp(`\\*\\*${fieldEscaped}:\\*\\*\\s*(.*)`, 'i');
    const fieldMatch = content.match(fieldPattern);
    if (fieldMatch) {
      output({ [section]: fieldMatch[1].trim() }, raw, fieldMatch[1].trim());
      return;
    }

    // Check for ## Section
    const sectionPattern = new RegExp(`##\\s*${fieldEscaped}\\s*\n([\\s\\S]*?)(?=\\n##|$)`, 'i');
    const sectionMatch = content.match(sectionPattern);
    if (sectionMatch) {
      output({ [section]: sectionMatch[1].trim() }, raw, sectionMatch[1].trim());
      return;
    }

    output({ error: `Section or field "${section}" not found` }, raw, '');
  } catch {
    error('STATE.md not found');
  }
}

function cmdStatePatch(cwd, patches, raw) {
  const statePath = path.join(cwd, '.planning', 'STATE.md');
  try {
    let content = fs.readFileSync(statePath, 'utf-8');
    const results = { updated: [], failed: [] };

    for (const [field, value] of Object.entries(patches)) {
      const fieldEscaped = field.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
      const pattern = new RegExp(`(\\*\\*${fieldEscaped}:\\*\\*\\s*)(.*)`, 'i');
      
      if (pattern.test(content)) {
        content = content.replace(pattern, `$1${value}`);
        results.updated.push(field);
      } else {
        results.failed.push(field);
      }
    }

    if (results.updated.length > 0) {
      fs.writeFileSync(statePath, content, 'utf-8');
    }

    output(results, raw, results.updated.length > 0 ? 'true' : 'false');
  } catch {
    error('STATE.md not found');
  }
}

function cmdStateUpdate(cwd, field, value) {
  if (!field || value === undefined) {
    error('field and value required for state update');
  }

  const statePath = path.join(cwd, '.planning', 'STATE.md');
  try {
    let content = fs.readFileSync(statePath, 'utf-8');
    const fieldEscaped = field.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
    const pattern = new RegExp(`(\\*\\*${fieldEscaped}:\\*\\*\\s*)(.*)`, 'i');
    if (pattern.test(content)) {
      content = content.replace(pattern, `$1${value}`);
      fs.writeFileSync(statePath, content, 'utf-8');
      output({ updated: true });
    } else {
      output({ updated: false, reason: `Field "${field}" not found in STATE.md` });
    }
  } catch {
    output({ updated: false, reason: 'STATE.md not found' });
  }
}

// ─── State Progression Engine ────────────────────────────────────────────────

function stateExtractField(content, fieldName) {
  const pattern = new RegExp(`\\*\\*${fieldName}:\\*\\*\\s*(.+)`, 'i');
  const match = content.match(pattern);
  return match ? match[1].trim() : null;
}

function stateReplaceField(content, fieldName, newValue) {
  const escaped = fieldName.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
  const pattern = new RegExp(`(\\*\\*${escaped}:\\*\\*\\s*)(.*)`, 'i');
  if (pattern.test(content)) {
    return content.replace(pattern, `$1${newValue}`);
  }
  return null;
}

function cmdStateAdvancePlan(cwd, raw) {
  const statePath = path.join(cwd, '.planning', 'STATE.md');
  if (!fs.existsSync(statePath)) { output({ error: 'STATE.md not found' }, raw); return; }

  let content = fs.readFileSync(statePath, 'utf-8');
  const currentPlan = parseInt(stateExtractField(content, 'Current Plan'), 10);
  const totalPlans = parseInt(stateExtractField(content, 'Total Plans in Phase'), 10);
  const today = new Date().toISOString().split('T')[0];

  if (isNaN(currentPlan) || isNaN(totalPlans)) {
    output({ error: 'Cannot parse Current Plan or Total Plans in Phase from STATE.md' }, raw);
    return;
  }

  if (currentPlan >= totalPlans) {
    content = stateReplaceField(content, 'Status', 'Phase complete — ready for verification') || content;
    content = stateReplaceField(content, 'Last Activity', today) || content;
    fs.writeFileSync(statePath, content, 'utf-8');
    output({ advanced: false, reason: 'last_plan', current_plan: currentPlan, total_plans: totalPlans, status: 'ready_for_verification' }, raw, 'false');
  } else {
    const newPlan = currentPlan + 1;
    content = stateReplaceField(content, 'Current Plan', String(newPlan)) || content;
    content = stateReplaceField(content, 'Status', 'Ready to execute') || content;
    content = stateReplaceField(content, 'Last Activity', today) || content;
    fs.writeFileSync(statePath, content, 'utf-8');
    output({ advanced: true, previous_plan: currentPlan, current_plan: newPlan, total_plans: totalPlans }, raw, 'true');
  }
}

function cmdStateRecordMetric(cwd, options, raw) {
  const statePath = path.join(cwd, '.planning', 'STATE.md');
  if (!fs.existsSync(statePath)) { output({ error: 'STATE.md not found' }, raw); return; }

  let content = fs.readFileSync(statePath, 'utf-8');
  const { phase, plan, duration, tasks, files } = options;

  if (!phase || !plan || !duration) {
    output({ error: 'phase, plan, and duration required' }, raw);
    return;
  }

  // Find Performance Metrics section and its table
  const metricsPattern = /(##\s*Performance Metrics[\s\S]*?\n\|[^\n]+\n\|[-|\s]+\n)([\s\S]*?)(?=\n##|\n$|$)/i;
  const metricsMatch = content.match(metricsPattern);

  if (metricsMatch) {
    const tableHeader = metricsMatch[1];
    let tableBody = metricsMatch[2].trimEnd();
    const newRow = `| Phase ${phase} P${plan} | ${duration} | ${tasks || '-'} tasks | ${files || '-'} files |`;

    if (tableBody.trim() === '' || tableBody.includes('None yet')) {
      tableBody = newRow;
    } else {
      tableBody = tableBody + '\n' + newRow;
    }

    content = content.replace(metricsPattern, `${tableHeader}${tableBody}\n`);
    fs.writeFileSync(statePath, content, 'utf-8');
    output({ recorded: true, phase, plan, duration }, raw, 'true');
  } else {
    output({ recorded: false, reason: 'Performance Metrics section not found in STATE.md' }, raw, 'false');
  }
}

function cmdStateUpdateProgress(cwd, raw) {
  const statePath = path.join(cwd, '.planning', 'STATE.md');
  if (!fs.existsSync(statePath)) { output({ error: 'STATE.md not found' }, raw); return; }

  let content = fs.readFileSync(statePath, 'utf-8');

  // Count summaries across all phases
  const phasesDir = path.join(cwd, '.planning', 'phases');
  let totalPlans = 0;
  let totalSummaries = 0;

  if (fs.existsSync(phasesDir)) {
    const phaseDirs = fs.readdirSync(phasesDir, { withFileTypes: true })
      .filter(e => e.isDirectory()).map(e => e.name);
    for (const dir of phaseDirs) {
      const files = fs.readdirSync(path.join(phasesDir, dir));
      totalPlans += files.filter(f => f.match(/-PLAN\.md$/i)).length;
      totalSummaries += files.filter(f => f.match(/-SUMMARY\.md$/i)).length;
    }
  }

  const percent = totalPlans > 0 ? Math.round(totalSummaries / totalPlans * 100) : 0;
  const barWidth = 10;
  const filled = Math.round(percent / 100 * barWidth);
  const bar = '\u2588'.repeat(filled) + '\u2591'.repeat(barWidth - filled);
  const progressStr = `[${bar}] ${percent}%`;

  const progressPattern = /(\*\*Progress:\*\*\s*).*/i;
  if (progressPattern.test(content)) {
    content = content.replace(progressPattern, `$1${progressStr}`);
    fs.writeFileSync(statePath, content, 'utf-8');
    output({ updated: true, percent, completed: totalSummaries, total: totalPlans, bar: progressStr }, raw, progressStr);
  } else {
    output({ updated: false, reason: 'Progress field not found in STATE.md' }, raw, 'false');
  }
}

function cmdStateAddDecision(cwd, options, raw) {
  const statePath = path.join(cwd, '.planning', 'STATE.md');
  if (!fs.existsSync(statePath)) { output({ error: 'STATE.md not found' }, raw); return; }

  const { phase, summary, rationale } = options;
  if (!summary) { output({ error: 'summary required' }, raw); return; }

  let content = fs.readFileSync(statePath, 'utf-8');
  const entry = `- [Phase ${phase || '?'}]: ${summary}${rationale ? ` — ${rationale}` : ''}`;

  // Find Decisions section (various heading patterns)
  const sectionPattern = /(###?\s*(?:Decisions|Decisions Made|Accumulated.*Decisions)\s*\n)([\s\S]*?)(?=\n###?|\n##[^#]|$)/i;
  const match = content.match(sectionPattern);

  if (match) {
    let sectionBody = match[2];
    // Remove placeholders
    sectionBody = sectionBody.replace(/None yet\.?\s*\n?/gi, '').replace(/No decisions yet\.?\s*\n?/gi, '');
    sectionBody = sectionBody.trimEnd() + '\n' + entry + '\n';
    content = content.replace(sectionPattern, `${match[1]}${sectionBody}`);
    fs.writeFileSync(statePath, content, 'utf-8');
    output({ added: true, decision: entry }, raw, 'true');
  } else {
    output({ added: false, reason: 'Decisions section not found in STATE.md' }, raw, 'false');
  }
}

function cmdStateAddBlocker(cwd, text, raw) {
  const statePath = path.join(cwd, '.planning', 'STATE.md');
  if (!fs.existsSync(statePath)) { output({ error: 'STATE.md not found' }, raw); return; }
  if (!text) { output({ error: 'text required' }, raw); return; }

  let content = fs.readFileSync(statePath, 'utf-8');
  const entry = `- ${text}`;

  const sectionPattern = /(###?\s*(?:Blockers|Blockers\/Concerns|Concerns)\s*\n)([\s\S]*?)(?=\n###?|\n##[^#]|$)/i;
  const match = content.match(sectionPattern);

  if (match) {
    let sectionBody = match[2];
    sectionBody = sectionBody.replace(/None\.?\s*\n?/gi, '').replace(/None yet\.?\s*\n?/gi, '');
    sectionBody = sectionBody.trimEnd() + '\n' + entry + '\n';
    content = content.replace(sectionPattern, `${match[1]}${sectionBody}`);
    fs.writeFileSync(statePath, content, 'utf-8');
    output({ added: true, blocker: text }, raw, 'true');
  } else {
    output({ added: false, reason: 'Blockers section not found in STATE.md' }, raw, 'false');
  }
}

function cmdStateResolveBlocker(cwd, text, raw) {
  const statePath = path.join(cwd, '.planning', 'STATE.md');
  if (!fs.existsSync(statePath)) { output({ error: 'STATE.md not found' }, raw); return; }
  if (!text) { output({ error: 'text required' }, raw); return; }

  let content = fs.readFileSync(statePath, 'utf-8');

  const sectionPattern = /(###?\s*(?:Blockers|Blockers\/Concerns|Concerns)\s*\n)([\s\S]*?)(?=\n###?|\n##[^#]|$)/i;
  const match = content.match(sectionPattern);

  if (match) {
    const sectionBody = match[2];
    const lines = sectionBody.split('\n');
    const filtered = lines.filter(line => {
      if (!line.startsWith('- ')) return true;
      return !line.toLowerCase().includes(text.toLowerCase());
    });

    let newBody = filtered.join('\n');
    // If section is now empty, add placeholder
    if (!newBody.trim() || !newBody.includes('- ')) {
      newBody = 'None\n';
    }

    content = content.replace(sectionPattern, `${match[1]}${newBody}`);
    fs.writeFileSync(statePath, content, 'utf-8');
    output({ resolved: true, blocker: text }, raw, 'true');
  } else {
    output({ resolved: false, reason: 'Blockers section not found in STATE.md' }, raw, 'false');
  }
}

function cmdStateRecordSession(cwd, options, raw) {
  const statePath = path.join(cwd, '.planning', 'STATE.md');
  if (!fs.existsSync(statePath)) { output({ error: 'STATE.md not found' }, raw); return; }

  let content = fs.readFileSync(statePath, 'utf-8');
  const now = new Date().toISOString();
  const updated = [];

  // Update Last session / Last Date
  let result = stateReplaceField(content, 'Last session', now);
  if (result) { content = result; updated.push('Last session'); }
  result = stateReplaceField(content, 'Last Date', now);
  if (result) { content = result; updated.push('Last Date'); }

  // Update Stopped at
  if (options.stopped_at) {
    result = stateReplaceField(content, 'Stopped At', options.stopped_at);
    if (!result) result = stateReplaceField(content, 'Stopped at', options.stopped_at);
    if (result) { content = result; updated.push('Stopped At'); }
  }

  // Update Resume file
  const resumeFile = options.resume_file || 'None';
  result = stateReplaceField(content, 'Resume File', resumeFile);
  if (!result) result = stateReplaceField(content, 'Resume file', resumeFile);
  if (result) { content = result; updated.push('Resume File'); }

  if (updated.length > 0) {
    fs.writeFileSync(statePath, content, 'utf-8');
    output({ recorded: true, updated }, raw, 'true');
  } else {
    output({ recorded: false, reason: 'No session fields found in STATE.md' }, raw, 'false');
  }
}

function cmdResolveModel(cwd, agentType, raw) {
  if (!agentType) {
    error('agent-type required');
  }

  const config = loadConfig(cwd);
  const profile = config.model_profile || 'balanced';

  const agentModels = MODEL_PROFILES[agentType];
  if (!agentModels) {
    const result = { model: 'sonnet', profile, unknown_agent: true };
    output(result, raw, 'sonnet');
    return;
  }

  const model = agentModels[profile] || agentModels['balanced'] || 'sonnet';
  const result = { model, profile };
  output(result, raw, model);
}

function cmdFindPhase(cwd, phase, raw) {
  if (!phase) {
    error('phase identifier required');
  }

  const phasesDir = path.join(cwd, '.planning', 'phases');
  const normalized = normalizePhaseName(phase);

  const notFound = { found: false, directory: null, phase_number: null, phase_name: null, plans: [], summaries: [] };

  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name).sort();

    const match = dirs.find(d => d.startsWith(normalized));
    if (!match) {
      output(notFound, raw, '');
      return;
    }

    const dirMatch = match.match(/^(\d+(?:\.\d+)?)-?(.*)/);
    const phaseNumber = dirMatch ? dirMatch[1] : normalized;
    const phaseName = dirMatch && dirMatch[2] ? dirMatch[2] : null;

    const phaseDir = path.join(phasesDir, match);
    const phaseFiles = fs.readdirSync(phaseDir);
    const plans = phaseFiles.filter(f => f.endsWith('-PLAN.md') || f === 'PLAN.md').sort();
    const summaries = phaseFiles.filter(f => f.endsWith('-SUMMARY.md') || f === 'SUMMARY.md').sort();

    const result = {
      found: true,
      directory: path.join('.planning', 'phases', match),
      phase_number: phaseNumber,
      phase_name: phaseName,
      plans,
      summaries,
    };

    output(result, raw, result.directory);
  } catch {
    output(notFound, raw, '');
  }
}

function cmdCommit(cwd, message, files, raw, amend) {
  if (!message && !amend) {
    error('commit message required');
  }

  const config = loadConfig(cwd);

  // Check commit_docs config
  if (!config.commit_docs) {
    const result = { committed: false, hash: null, reason: 'skipped_commit_docs_false' };
    output(result, raw, 'skipped');
    return;
  }

  // Check if .planning is gitignored
  if (isGitIgnored(cwd, '.planning')) {
    const result = { committed: false, hash: null, reason: 'skipped_gitignored' };
    output(result, raw, 'skipped');
    return;
  }

  // Stage files
  const filesToStage = files && files.length > 0 ? files : ['.planning/'];
  for (const file of filesToStage) {
    execGit(cwd, ['add', file]);
  }

  // Commit
  const commitArgs = amend ? ['commit', '--amend', '--no-edit'] : ['commit', '-m', message];
  const commitResult = execGit(cwd, commitArgs);
  if (commitResult.exitCode !== 0) {
    if (commitResult.stdout.includes('nothing to commit') || commitResult.stderr.includes('nothing to commit')) {
      const result = { committed: false, hash: null, reason: 'nothing_to_commit' };
      output(result, raw, 'nothing');
      return;
    }
    const result = { committed: false, hash: null, reason: 'nothing_to_commit', error: commitResult.stderr };
    output(result, raw, 'nothing');
    return;
  }

  // Get short hash
  const hashResult = execGit(cwd, ['rev-parse', '--short', 'HEAD']);
  const hash = hashResult.exitCode === 0 ? hashResult.stdout : null;
  const result = { committed: true, hash, reason: 'committed' };
  output(result, raw, hash || 'committed');
}

function cmdVerifySummary(cwd, summaryPath, checkFileCount, raw) {
  if (!summaryPath) {
    error('summary-path required');
  }

  const fullPath = path.join(cwd, summaryPath);
  const checkCount = checkFileCount || 2;

  // Check 1: Summary exists
  if (!fs.existsSync(fullPath)) {
    const result = {
      passed: false,
      checks: {
        summary_exists: false,
        files_created: { checked: 0, found: 0, missing: [] },
        commits_exist: false,
        self_check: 'not_found',
      },
      errors: ['SUMMARY.md not found'],
    };
    output(result, raw, 'failed');
    return;
  }

  const content = fs.readFileSync(fullPath, 'utf-8');
  const errors = [];

  // Check 2: Spot-check files mentioned in summary
  const mentionedFiles = new Set();
  const patterns = [
    /`([^`]+\.[a-zA-Z]+)`/g,
    /(?:Created|Modified|Added|Updated|Edited):\s*`?([^\s`]+\.[a-zA-Z]+)`?/gi,
  ];

  for (const pattern of patterns) {
    let m;
    while ((m = pattern.exec(content)) !== null) {
      const filePath = m[1];
      if (filePath && !filePath.startsWith('http') && filePath.includes('/')) {
        mentionedFiles.add(filePath);
      }
    }
  }

  const filesToCheck = Array.from(mentionedFiles).slice(0, checkCount);
  const missing = [];
  for (const file of filesToCheck) {
    if (!fs.existsSync(path.join(cwd, file))) {
      missing.push(file);
    }
  }

  // Check 3: Commits exist
  const commitHashPattern = /\b[0-9a-f]{7,40}\b/g;
  const hashes = content.match(commitHashPattern) || [];
  let commitsExist = false;
  if (hashes.length > 0) {
    for (const hash of hashes.slice(0, 3)) {
      const result = execGit(cwd, ['cat-file', '-t', hash]);
      if (result.exitCode === 0 && result.stdout === 'commit') {
        commitsExist = true;
        break;
      }
    }
  }

  // Check 4: Self-check section
  let selfCheck = 'not_found';
  const selfCheckPattern = /##\s*(?:Self[- ]?Check|Verification|Quality Check)/i;
  if (selfCheckPattern.test(content)) {
    const passPattern = /(?:all\s+)?(?:pass|✓|✅|complete|succeeded)/i;
    const failPattern = /(?:fail|✗|❌|incomplete|blocked)/i;
    const checkSection = content.slice(content.search(selfCheckPattern));
    if (failPattern.test(checkSection)) {
      selfCheck = 'failed';
    } else if (passPattern.test(checkSection)) {
      selfCheck = 'passed';
    }
  }

  if (missing.length > 0) errors.push('Missing files: ' + missing.join(', '));
  if (!commitsExist && hashes.length > 0) errors.push('Referenced commit hashes not found in git history');
  if (selfCheck === 'failed') errors.push('Self-check section indicates failure');

  const checks = {
    summary_exists: true,
    files_created: { checked: filesToCheck.length, found: filesToCheck.length - missing.length, missing },
    commits_exist: commitsExist,
    self_check: selfCheck,
  };

  const passed = missing.length === 0 && selfCheck !== 'failed';
  const result = { passed, checks, errors };
  output(result, raw, passed ? 'passed' : 'failed');
}

function cmdTemplateSelect(cwd, planPath, raw) {
  if (!planPath) {
    error('plan-path required');
  }

  try {
    const fullPath = path.join(cwd, planPath);
    const content = fs.readFileSync(fullPath, 'utf-8');
    
    // Simple heuristics
    const taskMatch = content.match(/###\s*Task\s*\d+/g) || [];
    const taskCount = taskMatch.length;
    
    const decisionMatch = content.match(/decision/gi) || [];
    const hasDecisions = decisionMatch.length > 0;
    
    // Count file mentions
    const fileMentions = new Set();
    const filePattern = /`([^`]+\.[a-zA-Z]+)`/g;
    let m;
    while ((m = filePattern.exec(content)) !== null) {
      if (m[1].includes('/') && !m[1].startsWith('http')) {
        fileMentions.add(m[1]);
      }
    }
    const fileCount = fileMentions.size;

    let template = 'templates/summary-standard.md';
    let type = 'standard';

    if (taskCount <= 2 && fileCount <= 3 && !hasDecisions) {
      template = 'templates/summary-minimal.md';
      type = 'minimal';
    } else if (hasDecisions || fileCount > 6 || taskCount > 5) {
      template = 'templates/summary-complex.md';
      type = 'complex';
    }

    const result = { template, type, taskCount, fileCount, hasDecisions };
    output(result, raw, template);
  } catch (e) {
    // Fallback to standard
    output({ template: 'templates/summary-standard.md', type: 'standard', error: e.message }, raw, 'templates/summary-standard.md');
  }
}

function cmdTemplateFill(cwd, templateType, options, raw) {
  if (!templateType) { error('template type required: summary, plan, or verification'); }
  if (!options.phase) { error('--phase required'); }

  const phaseInfo = findPhaseInternal(cwd, options.phase);
  if (!phaseInfo || !phaseInfo.found) { output({ error: 'Phase not found', phase: options.phase }, raw); return; }

  const padded = normalizePhaseName(options.phase);
  const today = new Date().toISOString().split('T')[0];
  const phaseName = options.name || phaseInfo.phase_name || 'Unnamed';
  const phaseSlug = phaseInfo.phase_slug || generateSlugInternal(phaseName);
  const phaseId = `${padded}-${phaseSlug}`;
  const planNum = (options.plan || '01').padStart(2, '0');
  const fields = options.fields || {};

  let frontmatter, body, fileName;

  switch (templateType) {
    case 'summary': {
      frontmatter = {
        phase: phaseId,
        plan: planNum,
        subsystem: '[primary category]',
        tags: [],
        provides: [],
        affects: [],
        'tech-stack': { added: [], patterns: [] },
        'key-files': { created: [], modified: [] },
        'key-decisions': [],
        'patterns-established': [],
        duration: '[X]min',
        completed: today,
        ...fields,
      };
      body = [
        `# Phase ${options.phase}: ${phaseName} Summary`,
        '',
        '**[Substantive one-liner describing outcome]**',
        '',
        '## Performance',
        '- **Duration:** [time]',
        '- **Tasks:** [count completed]',
        '- **Files modified:** [count]',
        '',
        '## Accomplishments',
        '- [Key outcome 1]',
        '- [Key outcome 2]',
        '',
        '## Task Commits',
        '1. **Task 1: [task name]** - `hash`',
        '',
        '## Files Created/Modified',
        '- `path/to/file.ts` - What it does',
        '',
        '## Decisions & Deviations',
        '[Key decisions or "None - followed plan as specified"]',
        '',
        '## Next Phase Readiness',
        '[What\'s ready for next phase]',
      ].join('\n');
      fileName = `${padded}-${planNum}-SUMMARY.md`;
      break;
    }
    case 'plan': {
      const planType = options.type || 'execute';
      const wave = parseInt(options.wave) || 1;
      frontmatter = {
        phase: phaseId,
        plan: planNum,
        type: planType,
        wave,
        depends_on: [],
        files_modified: [],
        autonomous: true,
        user_setup: [],
        must_haves: { truths: [], artifacts: [], key_links: [] },
        ...fields,
      };
      body = [
        `# Phase ${options.phase} Plan ${planNum}: [Title]`,
        '',
        '## Objective',
        '- **What:** [What this plan builds]',
        '- **Why:** [Why it matters for the phase goal]',
        '- **Output:** [Concrete deliverable]',
        '',
        '## Context',
        '@.planning/PROJECT.md',
        '@.planning/ROADMAP.md',
        '@.planning/STATE.md',
        '',
        '## Tasks',
        '',
        '<task type="code">',
        '  <name>[Task name]</name>',
        '  <files>[file paths]</files>',
        '  <action>[What to do]</action>',
        '  <verify>[How to verify]</verify>',
        '  <done>[Definition of done]</done>',
        '</task>',
        '',
        '## Verification',
        '[How to verify this plan achieved its objective]',
        '',
        '## Success Criteria',
        '- [ ] [Criterion 1]',
        '- [ ] [Criterion 2]',
      ].join('\n');
      fileName = `${padded}-${planNum}-PLAN.md`;
      break;
    }
    case 'verification': {
      frontmatter = {
        phase: phaseId,
        verified: new Date().toISOString(),
        status: 'pending',
        score: '0/0 must-haves verified',
        ...fields,
      };
      body = [
        `# Phase ${options.phase}: ${phaseName} — Verification`,
        '',
        '## Observable Truths',
        '| # | Truth | Status | Evidence |',
        '|---|-------|--------|----------|',
        '| 1 | [Truth] | pending | |',
        '',
        '## Required Artifacts',
        '| Artifact | Expected | Status | Details |',
        '|----------|----------|--------|---------|',
        '| [path] | [what] | pending | |',
        '',
        '## Key Link Verification',
        '| From | To | Via | Status | Details |',
        '|------|----|----|--------|---------|',
        '| [source] | [target] | [connection] | pending | |',
        '',
        '## Requirements Coverage',
        '| Requirement | Status | Blocking Issue |',
        '|-------------|--------|----------------|',
        '| [req] | pending | |',
        '',
        '## Result',
        '[Pending verification]',
      ].join('\n');
      fileName = `${padded}-VERIFICATION.md`;
      break;
    }
    default:
      error(`Unknown template type: ${templateType}. Available: summary, plan, verification`);
      return;
  }

  const fullContent = `---\n${reconstructFrontmatter(frontmatter)}\n---\n\n${body}\n`;
  const outPath = path.join(cwd, phaseInfo.directory, fileName);

  if (fs.existsSync(outPath)) {
    output({ error: 'File already exists', path: path.relative(cwd, outPath) }, raw);
    return;
  }

  fs.writeFileSync(outPath, fullContent, 'utf-8');
  const relPath = path.relative(cwd, outPath);
  output({ created: true, path: relPath, template: templateType }, raw, relPath);
}

function cmdPhasePlanIndex(cwd, phase, raw) {
  if (!phase) {
    error('phase required for phase-plan-index');
  }

  const phasesDir = path.join(cwd, '.planning', 'phases');
  const normalized = normalizePhaseName(phase);

  // Find phase directory
  let phaseDir = null;
  let phaseDirName = null;
  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name).sort();
    const match = dirs.find(d => d.startsWith(normalized));
    if (match) {
      phaseDir = path.join(phasesDir, match);
      phaseDirName = match;
    }
  } catch {
    // phases dir doesn't exist
  }

  if (!phaseDir) {
    output({ phase: normalized, error: 'Phase not found', plans: [], waves: {}, incomplete: [], has_checkpoints: false }, raw);
    return;
  }

  // Get all files in phase directory
  const phaseFiles = fs.readdirSync(phaseDir);
  const planFiles = phaseFiles.filter(f => f.endsWith('-PLAN.md') || f === 'PLAN.md').sort();
  const summaryFiles = phaseFiles.filter(f => f.endsWith('-SUMMARY.md') || f === 'SUMMARY.md');

  // Build set of plan IDs with summaries
  const completedPlanIds = new Set(
    summaryFiles.map(s => s.replace('-SUMMARY.md', '').replace('SUMMARY.md', ''))
  );

  const plans = [];
  const waves = {};
  const incomplete = [];
  let hasCheckpoints = false;

  for (const planFile of planFiles) {
    const planId = planFile.replace('-PLAN.md', '').replace('PLAN.md', '');
    const planPath = path.join(phaseDir, planFile);
    const content = fs.readFileSync(planPath, 'utf-8');
    const fm = extractFrontmatter(content);

    // Count tasks (## Task N patterns)
    const taskMatches = content.match(/##\s*Task\s*\d+/gi) || [];
    const taskCount = taskMatches.length;

    // Parse wave as integer
    const wave = parseInt(fm.wave, 10) || 1;

    // Parse autonomous (default true if not specified)
    let autonomous = true;
    if (fm.autonomous !== undefined) {
      autonomous = fm.autonomous === 'true' || fm.autonomous === true;
    }

    if (!autonomous) {
      hasCheckpoints = true;
    }

    // Parse files-modified
    let filesModified = [];
    if (fm['files-modified']) {
      filesModified = Array.isArray(fm['files-modified']) ? fm['files-modified'] : [fm['files-modified']];
    }

    const hasSummary = completedPlanIds.has(planId);
    if (!hasSummary) {
      incomplete.push(planId);
    }

    const plan = {
      id: planId,
      wave,
      autonomous,
      objective: fm.objective || null,
      files_modified: filesModified,
      task_count: taskCount,
      has_summary: hasSummary,
    };

    plans.push(plan);

    // Group by wave
    const waveKey = String(wave);
    if (!waves[waveKey]) {
      waves[waveKey] = [];
    }
    waves[waveKey].push(planId);
  }

  const result = {
    phase: normalized,
    plans,
    waves,
    incomplete,
    has_checkpoints: hasCheckpoints,
  };

  output(result, raw);
}

function cmdStateSnapshot(cwd, raw) {
  const statePath = path.join(cwd, '.planning', 'STATE.md');

  if (!fs.existsSync(statePath)) {
    output({ error: 'STATE.md not found' }, raw);
    return;
  }

  const content = fs.readFileSync(statePath, 'utf-8');

  // Helper to extract **Field:** value patterns
  const extractField = (fieldName) => {
    const pattern = new RegExp(`\\*\\*${fieldName}:\\*\\*\\s*(.+)`, 'i');
    const match = content.match(pattern);
    return match ? match[1].trim() : null;
  };

  // Extract basic fields
  const currentPhase = extractField('Current Phase');
  const currentPhaseName = extractField('Current Phase Name');
  const totalPhasesRaw = extractField('Total Phases');
  const currentPlan = extractField('Current Plan');
  const totalPlansRaw = extractField('Total Plans in Phase');
  const status = extractField('Status');
  const progressRaw = extractField('Progress');
  const lastActivity = extractField('Last Activity');
  const lastActivityDesc = extractField('Last Activity Description');
  const pausedAt = extractField('Paused At');

  // Parse numeric fields
  const totalPhases = totalPhasesRaw ? parseInt(totalPhasesRaw, 10) : null;
  const totalPlansInPhase = totalPlansRaw ? parseInt(totalPlansRaw, 10) : null;
  const progressPercent = progressRaw ? parseInt(progressRaw.replace('%', ''), 10) : null;

  // Extract decisions table
  const decisions = [];
  const decisionsMatch = content.match(/##\s*Decisions Made[\s\S]*?\n\|[^\n]+\n\|[-|\s]+\n([\s\S]*?)(?=\n##|\n$|$)/i);
  if (decisionsMatch) {
    const tableBody = decisionsMatch[1];
    const rows = tableBody.trim().split('\n').filter(r => r.includes('|'));
    for (const row of rows) {
      const cells = row.split('|').map(c => c.trim()).filter(Boolean);
      if (cells.length >= 3) {
        decisions.push({
          phase: cells[0],
          summary: cells[1],
          rationale: cells[2],
        });
      }
    }
  }

  // Extract blockers list
  const blockers = [];
  const blockersMatch = content.match(/##\s*Blockers\s*\n([\s\S]*?)(?=\n##|$)/i);
  if (blockersMatch) {
    const blockersSection = blockersMatch[1];
    const items = blockersSection.match(/^-\s+(.+)$/gm) || [];
    for (const item of items) {
      blockers.push(item.replace(/^-\s+/, '').trim());
    }
  }

  // Extract session info
  const session = {
    last_date: null,
    stopped_at: null,
    resume_file: null,
  };

  const sessionMatch = content.match(/##\s*Session\s*\n([\s\S]*?)(?=\n##|$)/i);
  if (sessionMatch) {
    const sessionSection = sessionMatch[1];
    const lastDateMatch = sessionSection.match(/\*\*Last Date:\*\*\s*(.+)/i);
    const stoppedAtMatch = sessionSection.match(/\*\*Stopped At:\*\*\s*(.+)/i);
    const resumeFileMatch = sessionSection.match(/\*\*Resume File:\*\*\s*(.+)/i);

    if (lastDateMatch) session.last_date = lastDateMatch[1].trim();
    if (stoppedAtMatch) session.stopped_at = stoppedAtMatch[1].trim();
    if (resumeFileMatch) session.resume_file = resumeFileMatch[1].trim();
  }

  const result = {
    current_phase: currentPhase,
    current_phase_name: currentPhaseName,
    total_phases: totalPhases,
    current_plan: currentPlan,
    total_plans_in_phase: totalPlansInPhase,
    status,
    progress_percent: progressPercent,
    last_activity: lastActivity,
    last_activity_desc: lastActivityDesc,
    decisions,
    blockers,
    paused_at: pausedAt,
    session,
  };

  output(result, raw);
}

function cmdSummaryExtract(cwd, summaryPath, fields, raw) {
  if (!summaryPath) {
    error('summary-path required for summary-extract');
  }

  const fullPath = path.join(cwd, summaryPath);

  if (!fs.existsSync(fullPath)) {
    output({ error: 'File not found', path: summaryPath }, raw);
    return;
  }

  const content = fs.readFileSync(fullPath, 'utf-8');
  const fm = extractFrontmatter(content);

  // Parse key-decisions into structured format
  const parseDecisions = (decisionsList) => {
    if (!decisionsList || !Array.isArray(decisionsList)) return [];
    return decisionsList.map(d => {
      const colonIdx = d.indexOf(':');
      if (colonIdx > 0) {
        return {
          summary: d.substring(0, colonIdx).trim(),
          rationale: d.substring(colonIdx + 1).trim(),
        };
      }
      return { summary: d, rationale: null };
    });
  };

  // Build full result
  const fullResult = {
    path: summaryPath,
    one_liner: fm['one-liner'] || null,
    key_files: fm['key-files'] || [],
    tech_added: (fm['tech-stack'] && fm['tech-stack'].added) || [],
    patterns: fm['patterns-established'] || [],
    decisions: parseDecisions(fm['key-decisions']),
  };

  // If fields specified, filter to only those fields
  if (fields && fields.length > 0) {
    const filtered = { path: summaryPath };
    for (const field of fields) {
      if (fullResult[field] !== undefined) {
        filtered[field] = fullResult[field];
      }
    }
    output(filtered, raw);
    return;
  }

  output(fullResult, raw);
}

// ─── Web Search (Brave API) ──────────────────────────────────────────────────

async function cmdWebsearch(query, options, raw) {
  const apiKey = process.env.BRAVE_API_KEY;

  if (!apiKey) {
    // No key = silent skip, agent falls back to built-in WebSearch
    output({ available: false, reason: 'BRAVE_API_KEY not set' }, raw, '');
    return;
  }

  if (!query) {
    output({ available: false, error: 'Query required' }, raw, '');
    return;
  }

  const params = new URLSearchParams({
    q: query,
    count: String(options.limit || 10),
    country: 'us',
    search_lang: 'en',
    text_decorations: 'false'
  });

  if (options.freshness) {
    params.set('freshness', options.freshness);
  }

  try {
    const response = await fetch(
      `https://api.search.brave.com/res/v1/web/search?${params}`,
      {
        headers: {
          'Accept': 'application/json',
          'X-Subscription-Token': apiKey
        }
      }
    );

    if (!response.ok) {
      output({ available: false, error: `API error: ${response.status}` }, raw, '');
      return;
    }

    const data = await response.json();

    const results = (data.web?.results || []).map(r => ({
      title: r.title,
      url: r.url,
      description: r.description,
      age: r.age || null
    }));

    output({
      available: true,
      query,
      count: results.length,
      results
    }, raw, results.map(r => `${r.title}\n${r.url}\n${r.description}`).join('\n\n'));
  } catch (err) {
    output({ available: false, error: err.message }, raw, '');
  }
}

// ─── Frontmatter CRUD ────────────────────────────────────────────────────────

function cmdFrontmatterGet(cwd, filePath, field, raw) {
  if (!filePath) { error('file path required'); }
  const fullPath = path.isAbsolute(filePath) ? filePath : path.join(cwd, filePath);
  const content = safeReadFile(fullPath);
  if (!content) { output({ error: 'File not found', path: filePath }, raw); return; }
  const fm = extractFrontmatter(content);
  if (field) {
    const value = fm[field];
    if (value === undefined) { output({ error: 'Field not found', field }, raw); return; }
    output({ [field]: value }, raw, JSON.stringify(value));
  } else {
    output(fm, raw);
  }
}

function cmdFrontmatterSet(cwd, filePath, field, value, raw) {
  if (!filePath || !field || value === undefined) { error('file, field, and value required'); }
  const fullPath = path.isAbsolute(filePath) ? filePath : path.join(cwd, filePath);
  if (!fs.existsSync(fullPath)) { output({ error: 'File not found', path: filePath }, raw); return; }
  const content = fs.readFileSync(fullPath, 'utf-8');
  const fm = extractFrontmatter(content);
  let parsedValue;
  try { parsedValue = JSON.parse(value); } catch { parsedValue = value; }
  fm[field] = parsedValue;
  const newContent = spliceFrontmatter(content, fm);
  fs.writeFileSync(fullPath, newContent, 'utf-8');
  output({ updated: true, field, value: parsedValue }, raw, 'true');
}

function cmdFrontmatterMerge(cwd, filePath, data, raw) {
  if (!filePath || !data) { error('file and data required'); }
  const fullPath = path.isAbsolute(filePath) ? filePath : path.join(cwd, filePath);
  if (!fs.existsSync(fullPath)) { output({ error: 'File not found', path: filePath }, raw); return; }
  const content = fs.readFileSync(fullPath, 'utf-8');
  const fm = extractFrontmatter(content);
  let mergeData;
  try { mergeData = JSON.parse(data); } catch { error('Invalid JSON for --data'); return; }
  Object.assign(fm, mergeData);
  const newContent = spliceFrontmatter(content, fm);
  fs.writeFileSync(fullPath, newContent, 'utf-8');
  output({ merged: true, fields: Object.keys(mergeData) }, raw, 'true');
}

const FRONTMATTER_SCHEMAS = {
  plan: { required: ['phase', 'plan', 'type', 'wave', 'depends_on', 'files_modified', 'autonomous', 'must_haves'] },
  summary: { required: ['phase', 'plan', 'subsystem', 'tags', 'duration', 'completed'] },
  verification: { required: ['phase', 'verified', 'status', 'score'] },
};

function cmdFrontmatterValidate(cwd, filePath, schemaName, raw) {
  if (!filePath || !schemaName) { error('file and schema required'); }
  const schema = FRONTMATTER_SCHEMAS[schemaName];
  if (!schema) { error(`Unknown schema: ${schemaName}. Available: ${Object.keys(FRONTMATTER_SCHEMAS).join(', ')}`); }
  const fullPath = path.isAbsolute(filePath) ? filePath : path.join(cwd, filePath);
  const content = safeReadFile(fullPath);
  if (!content) { output({ error: 'File not found', path: filePath }, raw); return; }
  const fm = extractFrontmatter(content);
  const missing = schema.required.filter(f => fm[f] === undefined);
  const present = schema.required.filter(f => fm[f] !== undefined);
  output({ valid: missing.length === 0, missing, present, schema: schemaName }, raw, missing.length === 0 ? 'valid' : 'invalid');
}

// ─── Verification Suite ──────────────────────────────────────────────────────

function cmdVerifyPlanStructure(cwd, filePath, raw) {
  if (!filePath) { error('file path required'); }
  const fullPath = path.isAbsolute(filePath) ? filePath : path.join(cwd, filePath);
  const content = safeReadFile(fullPath);
  if (!content) { output({ error: 'File not found', path: filePath }, raw); return; }

  const fm = extractFrontmatter(content);
  const errors = [];
  const warnings = [];

  // Check required frontmatter fields
  const required = ['phase', 'plan', 'type', 'wave', 'depends_on', 'files_modified', 'autonomous', 'must_haves'];
  for (const field of required) {
    if (fm[field] === undefined) errors.push(`Missing required frontmatter field: ${field}`);
  }

  // Parse and check task elements
  const taskPattern = /<task[^>]*>([\s\S]*?)<\/task>/g;
  const tasks = [];
  let taskMatch;
  while ((taskMatch = taskPattern.exec(content)) !== null) {
    const taskContent = taskMatch[1];
    const nameMatch = taskContent.match(/<name>([\s\S]*?)<\/name>/);
    const taskName = nameMatch ? nameMatch[1].trim() : 'unnamed';
    const hasFiles = /<files>/.test(taskContent);
    const hasAction = /<action>/.test(taskContent);
    const hasVerify = /<verify>/.test(taskContent);
    const hasDone = /<done>/.test(taskContent);

    if (!nameMatch) errors.push('Task missing <name> element');
    if (!hasAction) errors.push(`Task '${taskName}' missing <action>`);
    if (!hasVerify) warnings.push(`Task '${taskName}' missing <verify>`);
    if (!hasDone) warnings.push(`Task '${taskName}' missing <done>`);
    if (!hasFiles) warnings.push(`Task '${taskName}' missing <files>`);

    tasks.push({ name: taskName, hasFiles, hasAction, hasVerify, hasDone });
  }

  if (tasks.length === 0) warnings.push('No <task> elements found');

  // Wave/depends_on consistency
  if (fm.wave && parseInt(fm.wave) > 1 && (!fm.depends_on || (Array.isArray(fm.depends_on) && fm.depends_on.length === 0))) {
    warnings.push('Wave > 1 but depends_on is empty');
  }

  // Autonomous/checkpoint consistency
  const hasCheckpoints = /<task\s+type=["']?checkpoint/.test(content);
  if (hasCheckpoints && fm.autonomous !== 'false' && fm.autonomous !== false) {
    errors.push('Has checkpoint tasks but autonomous is not false');
  }

  output({
    valid: errors.length === 0,
    errors,
    warnings,
    task_count: tasks.length,
    tasks,
    frontmatter_fields: Object.keys(fm),
  }, raw, errors.length === 0 ? 'valid' : 'invalid');
}

function cmdVerifyPhaseCompleteness(cwd, phase, raw) {
  if (!phase) { error('phase required'); }
  const phaseInfo = findPhaseInternal(cwd, phase);
  if (!phaseInfo || !phaseInfo.found) {
    output({ error: 'Phase not found', phase }, raw);
    return;
  }

  const errors = [];
  const warnings = [];
  const phaseDir = path.join(cwd, phaseInfo.directory);

  // List plans and summaries
  let files;
  try { files = fs.readdirSync(phaseDir); } catch { output({ error: 'Cannot read phase directory' }, raw); return; }

  const plans = files.filter(f => f.match(/-PLAN\.md$/i));
  const summaries = files.filter(f => f.match(/-SUMMARY\.md$/i));

  // Extract plan IDs (everything before -PLAN.md)
  const planIds = new Set(plans.map(p => p.replace(/-PLAN\.md$/i, '')));
  const summaryIds = new Set(summaries.map(s => s.replace(/-SUMMARY\.md$/i, '')));

  // Plans without summaries
  const incompletePlans = [...planIds].filter(id => !summaryIds.has(id));
  if (incompletePlans.length > 0) {
    errors.push(`Plans without summaries: ${incompletePlans.join(', ')}`);
  }

  // Summaries without plans (orphans)
  const orphanSummaries = [...summaryIds].filter(id => !planIds.has(id));
  if (orphanSummaries.length > 0) {
    warnings.push(`Summaries without plans: ${orphanSummaries.join(', ')}`);
  }

  output({
    complete: errors.length === 0,
    phase: phaseInfo.phase_number,
    plan_count: plans.length,
    summary_count: summaries.length,
    incomplete_plans: incompletePlans,
    orphan_summaries: orphanSummaries,
    errors,
    warnings,
  }, raw, errors.length === 0 ? 'complete' : 'incomplete');
}

function cmdVerifyReferences(cwd, filePath, raw) {
  if (!filePath) { error('file path required'); }
  const fullPath = path.isAbsolute(filePath) ? filePath : path.join(cwd, filePath);
  const content = safeReadFile(fullPath);
  if (!content) { output({ error: 'File not found', path: filePath }, raw); return; }

  const found = [];
  const missing = [];

  // Find @-references: @path/to/file (must contain / to be a file path)
  const atRefs = content.match(/@([^\s\n,)]+\/[^\s\n,)]+)/g) || [];
  for (const ref of atRefs) {
    const cleanRef = ref.slice(1); // remove @
    const resolved = cleanRef.startsWith('~/')
      ? path.join(process.env.HOME || '', cleanRef.slice(2))
      : path.join(cwd, cleanRef);
    if (fs.existsSync(resolved)) {
      found.push(cleanRef);
    } else {
      missing.push(cleanRef);
    }
  }

  // Find backtick file paths that look like real paths (contain / and have extension)
  const backtickRefs = content.match(/`([^`]+\/[^`]+\.[a-zA-Z]{1,10})`/g) || [];
  for (const ref of backtickRefs) {
    const cleanRef = ref.slice(1, -1); // remove backticks
    if (cleanRef.startsWith('http') || cleanRef.includes('${') || cleanRef.includes('{{')) continue;
    if (found.includes(cleanRef) || missing.includes(cleanRef)) continue; // dedup
    const resolved = path.join(cwd, cleanRef);
    if (fs.existsSync(resolved)) {
      found.push(cleanRef);
    } else {
      missing.push(cleanRef);
    }
  }

  output({
    valid: missing.length === 0,
    found: found.length,
    missing,
    total: found.length + missing.length,
  }, raw, missing.length === 0 ? 'valid' : 'invalid');
}

function cmdVerifyCommits(cwd, hashes, raw) {
  if (!hashes || hashes.length === 0) { error('At least one commit hash required'); }

  const valid = [];
  const invalid = [];
  for (const hash of hashes) {
    const result = execGit(cwd, ['cat-file', '-t', hash]);
    if (result.exitCode === 0 && result.stdout.trim() === 'commit') {
      valid.push(hash);
    } else {
      invalid.push(hash);
    }
  }

  output({
    all_valid: invalid.length === 0,
    valid,
    invalid,
    total: hashes.length,
  }, raw, invalid.length === 0 ? 'valid' : 'invalid');
}

function cmdVerifyArtifacts(cwd, planFilePath, raw) {
  if (!planFilePath) { error('plan file path required'); }
  const fullPath = path.isAbsolute(planFilePath) ? planFilePath : path.join(cwd, planFilePath);
  const content = safeReadFile(fullPath);
  if (!content) { output({ error: 'File not found', path: planFilePath }, raw); return; }

  const artifacts = parseMustHavesBlock(content, 'artifacts');
  if (artifacts.length === 0) {
    output({ error: 'No must_haves.artifacts found in frontmatter', path: planFilePath }, raw);
    return;
  }

  const results = [];
  for (const artifact of artifacts) {
    if (typeof artifact === 'string') continue; // skip simple string items
    const artPath = artifact.path;
    if (!artPath) continue;

    const artFullPath = path.join(cwd, artPath);
    const exists = fs.existsSync(artFullPath);
    const check = { path: artPath, exists, issues: [], passed: false };

    if (exists) {
      const fileContent = safeReadFile(artFullPath) || '';
      const lineCount = fileContent.split('\n').length;

      if (artifact.min_lines && lineCount < artifact.min_lines) {
        check.issues.push(`Only ${lineCount} lines, need ${artifact.min_lines}`);
      }
      if (artifact.contains && !fileContent.includes(artifact.contains)) {
        check.issues.push(`Missing pattern: ${artifact.contains}`);
      }
      if (artifact.exports) {
        const exports = Array.isArray(artifact.exports) ? artifact.exports : [artifact.exports];
        for (const exp of exports) {
          if (!fileContent.includes(exp)) check.issues.push(`Missing export: ${exp}`);
        }
      }
      check.passed = check.issues.length === 0;
    } else {
      check.issues.push('File not found');
    }

    results.push(check);
  }

  const passed = results.filter(r => r.passed).length;
  output({
    all_passed: passed === results.length,
    passed,
    total: results.length,
    artifacts: results,
  }, raw, passed === results.length ? 'valid' : 'invalid');
}

function cmdVerifyKeyLinks(cwd, planFilePath, raw) {
  if (!planFilePath) { error('plan file path required'); }
  const fullPath = path.isAbsolute(planFilePath) ? planFilePath : path.join(cwd, planFilePath);
  const content = safeReadFile(fullPath);
  if (!content) { output({ error: 'File not found', path: planFilePath }, raw); return; }

  const keyLinks = parseMustHavesBlock(content, 'key_links');
  if (keyLinks.length === 0) {
    output({ error: 'No must_haves.key_links found in frontmatter', path: planFilePath }, raw);
    return;
  }

  const results = [];
  for (const link of keyLinks) {
    if (typeof link === 'string') continue;
    const check = { from: link.from, to: link.to, via: link.via || '', verified: false, detail: '' };

    const sourceContent = safeReadFile(path.join(cwd, link.from || ''));
    if (!sourceContent) {
      check.detail = 'Source file not found';
    } else if (link.pattern) {
      try {
        const regex = new RegExp(link.pattern);
        if (regex.test(sourceContent)) {
          check.verified = true;
          check.detail = 'Pattern found in source';
        } else {
          const targetContent = safeReadFile(path.join(cwd, link.to || ''));
          if (targetContent && regex.test(targetContent)) {
            check.verified = true;
            check.detail = 'Pattern found in target';
          } else {
            check.detail = `Pattern "${link.pattern}" not found in source or target`;
          }
        }
      } catch {
        check.detail = `Invalid regex pattern: ${link.pattern}`;
      }
    } else {
      // No pattern: just check source references target
      if (sourceContent.includes(link.to || '')) {
        check.verified = true;
        check.detail = 'Target referenced in source';
      } else {
        check.detail = 'Target not referenced in source';
      }
    }

    results.push(check);
  }

  const verified = results.filter(r => r.verified).length;
  output({
    all_verified: verified === results.length,
    verified,
    total: results.length,
    links: results,
  }, raw, verified === results.length ? 'valid' : 'invalid');
}

// ─── Roadmap Analysis ─────────────────────────────────────────────────────────

function cmdRoadmapAnalyze(cwd, raw) {
  const roadmapPath = path.join(cwd, '.planning', 'ROADMAP.md');

  if (!fs.existsSync(roadmapPath)) {
    output({ error: 'ROADMAP.md not found', milestones: [], phases: [], current_phase: null }, raw);
    return;
  }

  const content = fs.readFileSync(roadmapPath, 'utf-8');
  const phasesDir = path.join(cwd, '.planning', 'phases');

  // Extract all phase headings: ### Phase N: Name
  const phasePattern = /###\s*Phase\s+(\d+(?:\.\d+)?)\s*:\s*([^\n]+)/gi;
  const phases = [];
  let match;

  while ((match = phasePattern.exec(content)) !== null) {
    const phaseNum = match[1];
    const phaseName = match[2].replace(/\(INSERTED\)/i, '').trim();

    // Extract goal from the section
    const sectionStart = match.index;
    const restOfContent = content.slice(sectionStart);
    const nextHeader = restOfContent.match(/\n###\s+Phase\s+\d/i);
    const sectionEnd = nextHeader ? sectionStart + nextHeader.index : content.length;
    const section = content.slice(sectionStart, sectionEnd);

    const goalMatch = section.match(/\*\*Goal:\*\*\s*([^\n]+)/i);
    const goal = goalMatch ? goalMatch[1].trim() : null;

    const dependsMatch = section.match(/\*\*Depends on:\*\*\s*([^\n]+)/i);
    const depends_on = dependsMatch ? dependsMatch[1].trim() : null;

    // Check completion on disk
    const normalized = normalizePhaseName(phaseNum);
    let diskStatus = 'no_directory';
    let planCount = 0;
    let summaryCount = 0;
    let hasContext = false;
    let hasResearch = false;

    try {
      const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
      const dirs = entries.filter(e => e.isDirectory()).map(e => e.name);
      const dirMatch = dirs.find(d => d.startsWith(normalized + '-') || d === normalized);

      if (dirMatch) {
        const phaseFiles = fs.readdirSync(path.join(phasesDir, dirMatch));
        planCount = phaseFiles.filter(f => f.endsWith('-PLAN.md') || f === 'PLAN.md').length;
        summaryCount = phaseFiles.filter(f => f.endsWith('-SUMMARY.md') || f === 'SUMMARY.md').length;
        hasContext = phaseFiles.some(f => f.endsWith('-CONTEXT.md') || f === 'CONTEXT.md');
        hasResearch = phaseFiles.some(f => f.endsWith('-RESEARCH.md') || f === 'RESEARCH.md');

        if (summaryCount >= planCount && planCount > 0) diskStatus = 'complete';
        else if (summaryCount > 0) diskStatus = 'partial';
        else if (planCount > 0) diskStatus = 'planned';
        else if (hasResearch) diskStatus = 'researched';
        else if (hasContext) diskStatus = 'discussed';
        else diskStatus = 'empty';
      }
    } catch {}

    // Check ROADMAP checkbox status
    const checkboxPattern = new RegExp(`-\\s*\\[(x| )\\]\\s*.*Phase\\s+${phaseNum.replace('.', '\\.')}`, 'i');
    const checkboxMatch = content.match(checkboxPattern);
    const roadmapComplete = checkboxMatch ? checkboxMatch[1] === 'x' : false;

    phases.push({
      number: phaseNum,
      name: phaseName,
      goal,
      depends_on,
      plan_count: planCount,
      summary_count: summaryCount,
      has_context: hasContext,
      has_research: hasResearch,
      disk_status: diskStatus,
      roadmap_complete: roadmapComplete,
    });
  }

  // Extract milestone info
  const milestones = [];
  const milestonePattern = /##\s*(.*v(\d+\.\d+)[^(\n]*)/gi;
  let mMatch;
  while ((mMatch = milestonePattern.exec(content)) !== null) {
    milestones.push({
      heading: mMatch[1].trim(),
      version: 'v' + mMatch[2],
    });
  }

  // Find current and next phase
  const currentPhase = phases.find(p => p.disk_status === 'planned' || p.disk_status === 'partial') || null;
  const nextPhase = phases.find(p => p.disk_status === 'empty' || p.disk_status === 'no_directory' || p.disk_status === 'discussed' || p.disk_status === 'researched') || null;

  // Aggregated stats
  const totalPlans = phases.reduce((sum, p) => sum + p.plan_count, 0);
  const totalSummaries = phases.reduce((sum, p) => sum + p.summary_count, 0);
  const completedPhases = phases.filter(p => p.disk_status === 'complete').length;

  const result = {
    milestones,
    phases,
    phase_count: phases.length,
    completed_phases: completedPhases,
    total_plans: totalPlans,
    total_summaries: totalSummaries,
    progress_percent: totalPlans > 0 ? Math.round((totalSummaries / totalPlans) * 100) : 0,
    current_phase: currentPhase ? currentPhase.number : null,
    next_phase: nextPhase ? nextPhase.number : null,
  };

  output(result, raw);
}

// ─── Phase Add ────────────────────────────────────────────────────────────────

function cmdPhaseAdd(cwd, description, raw) {
  if (!description) {
    error('description required for phase add');
  }

  const roadmapPath = path.join(cwd, '.planning', 'ROADMAP.md');
  if (!fs.existsSync(roadmapPath)) {
    error('ROADMAP.md not found');
  }

  const content = fs.readFileSync(roadmapPath, 'utf-8');
  const slug = generateSlugInternal(description);

  // Find highest integer phase number
  const phasePattern = /###\s*Phase\s+(\d+)(?:\.\d+)?:/gi;
  let maxPhase = 0;
  let m;
  while ((m = phasePattern.exec(content)) !== null) {
    const num = parseInt(m[1], 10);
    if (num > maxPhase) maxPhase = num;
  }

  const newPhaseNum = maxPhase + 1;
  const paddedNum = String(newPhaseNum).padStart(2, '0');
  const dirName = `${paddedNum}-${slug}`;
  const dirPath = path.join(cwd, '.planning', 'phases', dirName);

  // Create directory
  fs.mkdirSync(dirPath, { recursive: true });

  // Build phase entry
  const phaseEntry = `\n### Phase ${newPhaseNum}: ${description}\n\n**Goal:** [To be planned]\n**Depends on:** Phase ${maxPhase}\n**Plans:** 0 plans\n\nPlans:\n- [ ] TBD (run /GSI:plan-phase ${newPhaseNum} to break down)\n`;

  // Find insertion point: before last "---" or at end
  let updatedContent;
  const lastSeparator = content.lastIndexOf('\n---');
  if (lastSeparator > 0) {
    updatedContent = content.slice(0, lastSeparator) + phaseEntry + content.slice(lastSeparator);
  } else {
    updatedContent = content + phaseEntry;
  }

  fs.writeFileSync(roadmapPath, updatedContent, 'utf-8');

  const result = {
    phase_number: newPhaseNum,
    padded: paddedNum,
    name: description,
    slug,
    directory: `.planning/phases/${dirName}`,
  };

  output(result, raw, paddedNum);
}

// ─── Phase Insert (Decimal) ──────────────────────────────────────────────────

function cmdPhaseInsert(cwd, afterPhase, description, raw) {
  if (!afterPhase || !description) {
    error('after-phase and description required for phase insert');
  }

  const roadmapPath = path.join(cwd, '.planning', 'ROADMAP.md');
  if (!fs.existsSync(roadmapPath)) {
    error('ROADMAP.md not found');
  }

  const content = fs.readFileSync(roadmapPath, 'utf-8');
  const slug = generateSlugInternal(description);

  // Verify target phase exists
  const afterPhaseEscaped = afterPhase.replace(/\./g, '\\.');
  const targetPattern = new RegExp(`###\\s*Phase\\s+${afterPhaseEscaped}:`, 'i');
  if (!targetPattern.test(content)) {
    error(`Phase ${afterPhase} not found in ROADMAP.md`);
  }

  // Calculate next decimal using existing logic
  const phasesDir = path.join(cwd, '.planning', 'phases');
  const normalizedBase = normalizePhaseName(afterPhase);
  let existingDecimals = [];

  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name);
    const decimalPattern = new RegExp(`^${normalizedBase}\\.(\\d+)`);
    for (const dir of dirs) {
      const dm = dir.match(decimalPattern);
      if (dm) existingDecimals.push(parseInt(dm[1], 10));
    }
  } catch {}

  const nextDecimal = existingDecimals.length === 0 ? 1 : Math.max(...existingDecimals) + 1;
  const decimalPhase = `${normalizedBase}.${nextDecimal}`;
  const dirName = `${decimalPhase}-${slug}`;
  const dirPath = path.join(cwd, '.planning', 'phases', dirName);

  // Create directory
  fs.mkdirSync(dirPath, { recursive: true });

  // Build phase entry
  const phaseEntry = `\n### Phase ${decimalPhase}: ${description} (INSERTED)\n\n**Goal:** [Urgent work - to be planned]\n**Depends on:** Phase ${afterPhase}\n**Plans:** 0 plans\n\nPlans:\n- [ ] TBD (run /GSI:plan-phase ${decimalPhase} to break down)\n`;

  // Insert after the target phase section
  const headerPattern = new RegExp(`(###\\s*Phase\\s+${afterPhaseEscaped}:[^\\n]*\\n)`, 'i');
  const headerMatch = content.match(headerPattern);
  if (!headerMatch) {
    error(`Could not find Phase ${afterPhase} header`);
  }

  const headerIdx = content.indexOf(headerMatch[0]);
  const afterHeader = content.slice(headerIdx + headerMatch[0].length);
  const nextPhaseMatch = afterHeader.match(/\n###\s+Phase\s+\d/i);

  let insertIdx;
  if (nextPhaseMatch) {
    insertIdx = headerIdx + headerMatch[0].length + nextPhaseMatch.index;
  } else {
    insertIdx = content.length;
  }

  const updatedContent = content.slice(0, insertIdx) + phaseEntry + content.slice(insertIdx);
  fs.writeFileSync(roadmapPath, updatedContent, 'utf-8');

  const result = {
    phase_number: decimalPhase,
    after_phase: afterPhase,
    name: description,
    slug,
    directory: `.planning/phases/${dirName}`,
  };

  output(result, raw, decimalPhase);
}

// ─── Phase Remove ─────────────────────────────────────────────────────────────

function cmdPhaseRemove(cwd, targetPhase, options, raw) {
  if (!targetPhase) {
    error('phase number required for phase remove');
  }

  const roadmapPath = path.join(cwd, '.planning', 'ROADMAP.md');
  const phasesDir = path.join(cwd, '.planning', 'phases');
  const force = options.force || false;

  if (!fs.existsSync(roadmapPath)) {
    error('ROADMAP.md not found');
  }

  // Normalize the target
  const normalized = normalizePhaseName(targetPhase);
  const isDecimal = targetPhase.includes('.');

  // Find and validate target directory
  let targetDir = null;
  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name).sort();
    targetDir = dirs.find(d => d.startsWith(normalized + '-') || d === normalized);
  } catch {}

  // Check for executed work (SUMMARY.md files)
  if (targetDir && !force) {
    const targetPath = path.join(phasesDir, targetDir);
    const files = fs.readdirSync(targetPath);
    const summaries = files.filter(f => f.endsWith('-SUMMARY.md') || f === 'SUMMARY.md');
    if (summaries.length > 0) {
      error(`Phase ${targetPhase} has ${summaries.length} executed plan(s). Use --force to remove anyway.`);
    }
  }

  // Delete target directory
  if (targetDir) {
    fs.rmSync(path.join(phasesDir, targetDir), { recursive: true, force: true });
  }

  // Renumber subsequent phases
  const renamedDirs = [];
  const renamedFiles = [];

  if (isDecimal) {
    // Decimal removal: renumber sibling decimals (e.g., removing 06.2 → 06.3 becomes 06.2)
    const baseParts = normalized.split('.');
    const baseInt = baseParts[0];
    const removedDecimal = parseInt(baseParts[1], 10);

    try {
      const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
      const dirs = entries.filter(e => e.isDirectory()).map(e => e.name).sort();

      // Find sibling decimals with higher numbers
      const decPattern = new RegExp(`^${baseInt}\\.(\\d+)-(.+)$`);
      const toRename = [];
      for (const dir of dirs) {
        const dm = dir.match(decPattern);
        if (dm && parseInt(dm[1], 10) > removedDecimal) {
          toRename.push({ dir, oldDecimal: parseInt(dm[1], 10), slug: dm[2] });
        }
      }

      // Sort descending to avoid conflicts
      toRename.sort((a, b) => b.oldDecimal - a.oldDecimal);

      for (const item of toRename) {
        const newDecimal = item.oldDecimal - 1;
        const oldPhaseId = `${baseInt}.${item.oldDecimal}`;
        const newPhaseId = `${baseInt}.${newDecimal}`;
        const newDirName = `${baseInt}.${newDecimal}-${item.slug}`;

        // Rename directory
        fs.renameSync(path.join(phasesDir, item.dir), path.join(phasesDir, newDirName));
        renamedDirs.push({ from: item.dir, to: newDirName });

        // Rename files inside
        const dirFiles = fs.readdirSync(path.join(phasesDir, newDirName));
        for (const f of dirFiles) {
          // Files may have phase prefix like "06.2-01-PLAN.md"
          if (f.includes(oldPhaseId)) {
            const newFileName = f.replace(oldPhaseId, newPhaseId);
            fs.renameSync(
              path.join(phasesDir, newDirName, f),
              path.join(phasesDir, newDirName, newFileName)
            );
            renamedFiles.push({ from: f, to: newFileName });
          }
        }
      }
    } catch {}

  } else {
    // Integer removal: renumber all subsequent integer phases
    const removedInt = parseInt(normalized, 10);

    try {
      const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
      const dirs = entries.filter(e => e.isDirectory()).map(e => e.name).sort();

      // Collect directories that need renumbering (integer phases > removed, and their decimals)
      const toRename = [];
      for (const dir of dirs) {
        const dm = dir.match(/^(\d+)(?:\.(\d+))?-(.+)$/);
        if (!dm) continue;
        const dirInt = parseInt(dm[1], 10);
        if (dirInt > removedInt) {
          toRename.push({
            dir,
            oldInt: dirInt,
            decimal: dm[2] ? parseInt(dm[2], 10) : null,
            slug: dm[3],
          });
        }
      }

      // Sort descending to avoid conflicts
      toRename.sort((a, b) => {
        if (a.oldInt !== b.oldInt) return b.oldInt - a.oldInt;
        return (b.decimal || 0) - (a.decimal || 0);
      });

      for (const item of toRename) {
        const newInt = item.oldInt - 1;
        const newPadded = String(newInt).padStart(2, '0');
        const oldPadded = String(item.oldInt).padStart(2, '0');
        const decimalSuffix = item.decimal !== null ? `.${item.decimal}` : '';
        const oldPrefix = `${oldPadded}${decimalSuffix}`;
        const newPrefix = `${newPadded}${decimalSuffix}`;
        const newDirName = `${newPrefix}-${item.slug}`;

        // Rename directory
        fs.renameSync(path.join(phasesDir, item.dir), path.join(phasesDir, newDirName));
        renamedDirs.push({ from: item.dir, to: newDirName });

        // Rename files inside
        const dirFiles = fs.readdirSync(path.join(phasesDir, newDirName));
        for (const f of dirFiles) {
          if (f.startsWith(oldPrefix)) {
            const newFileName = newPrefix + f.slice(oldPrefix.length);
            fs.renameSync(
              path.join(phasesDir, newDirName, f),
              path.join(phasesDir, newDirName, newFileName)
            );
            renamedFiles.push({ from: f, to: newFileName });
          }
        }
      }
    } catch {}
  }

  // Update ROADMAP.md
  let roadmapContent = fs.readFileSync(roadmapPath, 'utf-8');

  // Remove the target phase section
  const targetEscaped = targetPhase.replace(/\./g, '\\.');
  const sectionPattern = new RegExp(
    `\\n?###\\s*Phase\\s+${targetEscaped}\\s*:[\\s\\S]*?(?=\\n###\\s+Phase\\s+\\d|$)`,
    'i'
  );
  roadmapContent = roadmapContent.replace(sectionPattern, '');

  // Remove from phase list (checkbox)
  const checkboxPattern = new RegExp(`\\n?-\\s*\\[[ x]\\]\\s*.*Phase\\s+${targetEscaped}[:\\s][^\\n]*`, 'gi');
  roadmapContent = roadmapContent.replace(checkboxPattern, '');

  // Remove from progress table
  const tableRowPattern = new RegExp(`\\n?\\|\\s*${targetEscaped}\\.?\\s[^|]*\\|[^\\n]*`, 'gi');
  roadmapContent = roadmapContent.replace(tableRowPattern, '');

  // Renumber references in ROADMAP for subsequent phases
  if (!isDecimal) {
    const removedInt = parseInt(normalized, 10);

    // Collect all integer phases > removedInt
    const maxPhase = 99; // reasonable upper bound
    for (let oldNum = maxPhase; oldNum > removedInt; oldNum--) {
      const newNum = oldNum - 1;
      const oldStr = String(oldNum);
      const newStr = String(newNum);
      const oldPad = oldStr.padStart(2, '0');
      const newPad = newStr.padStart(2, '0');

      // Phase headings: ### Phase 18: → ### Phase 17:
      roadmapContent = roadmapContent.replace(
        new RegExp(`(###\\s*Phase\\s+)${oldStr}(\\s*:)`, 'gi'),
        `$1${newStr}$2`
      );

      // Checkbox items: - [ ] **Phase 18:** → - [ ] **Phase 17:**
      roadmapContent = roadmapContent.replace(
        new RegExp(`(Phase\\s+)${oldStr}([:\\s])`, 'g'),
        `$1${newStr}$2`
      );

      // Plan references: 18-01 → 17-01
      roadmapContent = roadmapContent.replace(
        new RegExp(`${oldPad}-(\\d{2})`, 'g'),
        `${newPad}-$1`
      );

      // Table rows: | 18. → | 17.
      roadmapContent = roadmapContent.replace(
        new RegExp(`(\\|\\s*)${oldStr}\\.\\s`, 'g'),
        `$1${newStr}. `
      );

      // Depends on references
      roadmapContent = roadmapContent.replace(
        new RegExp(`(Depends on:\\*\\*\\s*Phase\\s+)${oldStr}\\b`, 'gi'),
        `$1${newStr}`
      );
    }
  }

  fs.writeFileSync(roadmapPath, roadmapContent, 'utf-8');

  // Update STATE.md phase count
  const statePath = path.join(cwd, '.planning', 'STATE.md');
  if (fs.existsSync(statePath)) {
    let stateContent = fs.readFileSync(statePath, 'utf-8');
    // Update "Total Phases" field
    const totalPattern = /(\*\*Total Phases:\*\*\s*)(\d+)/;
    const totalMatch = stateContent.match(totalPattern);
    if (totalMatch) {
      const oldTotal = parseInt(totalMatch[2], 10);
      stateContent = stateContent.replace(totalPattern, `$1${oldTotal - 1}`);
    }
    // Update "Phase: X of Y" pattern
    const ofPattern = /(\bof\s+)(\d+)(\s*(?:\(|phases?))/i;
    const ofMatch = stateContent.match(ofPattern);
    if (ofMatch) {
      const oldTotal = parseInt(ofMatch[2], 10);
      stateContent = stateContent.replace(ofPattern, `$1${oldTotal - 1}$3`);
    }
    fs.writeFileSync(statePath, stateContent, 'utf-8');
  }

  const result = {
    removed: targetPhase,
    directory_deleted: targetDir || null,
    renamed_directories: renamedDirs,
    renamed_files: renamedFiles,
    roadmap_updated: true,
    state_updated: fs.existsSync(statePath),
  };

  output(result, raw);
}

// ─── Phase Complete (Transition) ──────────────────────────────────────────────

function cmdPhaseComplete(cwd, phaseNum, raw) {
  if (!phaseNum) {
    error('phase number required for phase complete');
  }

  const roadmapPath = path.join(cwd, '.planning', 'ROADMAP.md');
  const statePath = path.join(cwd, '.planning', 'STATE.md');
  const phasesDir = path.join(cwd, '.planning', 'phases');
  const normalized = normalizePhaseName(phaseNum);
  const today = new Date().toISOString().split('T')[0];

  // Verify phase info
  const phaseInfo = findPhaseInternal(cwd, phaseNum);
  if (!phaseInfo) {
    error(`Phase ${phaseNum} not found`);
  }

  const planCount = phaseInfo.plans.length;
  const summaryCount = phaseInfo.summaries.length;

  // Update ROADMAP.md: mark phase complete
  if (fs.existsSync(roadmapPath)) {
    let roadmapContent = fs.readFileSync(roadmapPath, 'utf-8');

    // Checkbox: - [ ] Phase N: → - [x] Phase N: (...completed DATE)
    const checkboxPattern = new RegExp(
      `(-\\s*\\[)[ ](\\]\\s*.*Phase\\s+${phaseNum.replace('.', '\\.')}[:\\s][^\\n]*)`,
      'i'
    );
    roadmapContent = roadmapContent.replace(checkboxPattern, `$1x$2 (completed ${today})`);

    // Progress table: update Status to Complete, add date
    const phaseEscaped = phaseNum.replace('.', '\\.');
    const tablePattern = new RegExp(
      `(\\|\\s*${phaseEscaped}\\.?\\s[^|]*\\|[^|]*\\|)\\s*[^|]*(\\|)\\s*[^|]*(\\|)`,
      'i'
    );
    roadmapContent = roadmapContent.replace(
      tablePattern,
      `$1 Complete    $2 ${today} $3`
    );

    // Update plan count in phase section
    const planCountPattern = new RegExp(
      `(###\\s*Phase\\s+${phaseEscaped}[\\s\\S]*?\\*\\*Plans:\\*\\*\\s*)[^\\n]+`,
      'i'
    );
    roadmapContent = roadmapContent.replace(
      planCountPattern,
      `$1${summaryCount}/${planCount} plans complete`
    );

    fs.writeFileSync(roadmapPath, roadmapContent, 'utf-8');
  }

  // Find next phase
  let nextPhaseNum = null;
  let nextPhaseName = null;
  let isLastPhase = true;

  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name).sort();
    const currentFloat = parseFloat(phaseNum);

    // Find the next phase directory after current
    for (const dir of dirs) {
      const dm = dir.match(/^(\d+(?:\.\d+)?)-?(.*)/);
      if (dm) {
        const dirFloat = parseFloat(dm[1]);
        if (dirFloat > currentFloat) {
          nextPhaseNum = dm[1];
          nextPhaseName = dm[2] || null;
          isLastPhase = false;
          break;
        }
      }
    }
  } catch {}

  // Update STATE.md
  if (fs.existsSync(statePath)) {
    let stateContent = fs.readFileSync(statePath, 'utf-8');

    // Update Current Phase
    stateContent = stateContent.replace(
      /(\*\*Current Phase:\*\*\s*).*/,
      `$1${nextPhaseNum || phaseNum}`
    );

    // Update Current Phase Name
    if (nextPhaseName) {
      stateContent = stateContent.replace(
        /(\*\*Current Phase Name:\*\*\s*).*/,
        `$1${nextPhaseName.replace(/-/g, ' ')}`
      );
    }

    // Update Status
    stateContent = stateContent.replace(
      /(\*\*Status:\*\*\s*).*/,
      `$1${isLastPhase ? 'Milestone complete' : 'Ready to plan'}`
    );

    // Update Current Plan
    stateContent = stateContent.replace(
      /(\*\*Current Plan:\*\*\s*).*/,
      `$1Not started`
    );

    // Update Last Activity
    stateContent = stateContent.replace(
      /(\*\*Last Activity:\*\*\s*).*/,
      `$1${today}`
    );

    // Update Last Activity Description
    stateContent = stateContent.replace(
      /(\*\*Last Activity Description:\*\*\s*).*/,
      `$1Phase ${phaseNum} complete${nextPhaseNum ? `, transitioned to Phase ${nextPhaseNum}` : ''}`
    );

    fs.writeFileSync(statePath, stateContent, 'utf-8');
  }

  const result = {
    completed_phase: phaseNum,
    phase_name: phaseInfo.phase_name,
    plans_executed: `${summaryCount}/${planCount}`,
    next_phase: nextPhaseNum,
    next_phase_name: nextPhaseName,
    is_last_phase: isLastPhase,
    date: today,
    roadmap_updated: fs.existsSync(roadmapPath),
    state_updated: fs.existsSync(statePath),
  };

  output(result, raw);
}

// ─── Milestone Complete ───────────────────────────────────────────────────────

function cmdMilestoneComplete(cwd, version, options, raw) {
  if (!version) {
    error('version required for milestone complete (e.g., v1.0)');
  }

  const roadmapPath = path.join(cwd, '.planning', 'ROADMAP.md');
  const reqPath = path.join(cwd, '.planning', 'REQUIREMENTS.md');
  const statePath = path.join(cwd, '.planning', 'STATE.md');
  const milestonesPath = path.join(cwd, '.planning', 'MILESTONES.md');
  const archiveDir = path.join(cwd, '.planning', 'milestones');
  const phasesDir = path.join(cwd, '.planning', 'phases');
  const today = new Date().toISOString().split('T')[0];
  const milestoneName = options.name || version;

  // Ensure archive directory exists
  fs.mkdirSync(archiveDir, { recursive: true });

  // Gather stats from phases
  let phaseCount = 0;
  let totalPlans = 0;
  let totalTasks = 0;
  const accomplishments = [];

  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name).sort();

    for (const dir of dirs) {
      phaseCount++;
      const phaseFiles = fs.readdirSync(path.join(phasesDir, dir));
      const plans = phaseFiles.filter(f => f.endsWith('-PLAN.md') || f === 'PLAN.md');
      const summaries = phaseFiles.filter(f => f.endsWith('-SUMMARY.md') || f === 'SUMMARY.md');
      totalPlans += plans.length;

      // Extract one-liners from summaries
      for (const s of summaries) {
        try {
          const content = fs.readFileSync(path.join(phasesDir, dir, s), 'utf-8');
          const fm = extractFrontmatter(content);
          if (fm['one-liner']) {
            accomplishments.push(fm['one-liner']);
          }
          // Count tasks
          const taskMatches = content.match(/##\s*Task\s*\d+/gi) || [];
          totalTasks += taskMatches.length;
        } catch {}
      }
    }
  } catch {}

  // Archive ROADMAP.md
  if (fs.existsSync(roadmapPath)) {
    const roadmapContent = fs.readFileSync(roadmapPath, 'utf-8');
    fs.writeFileSync(path.join(archiveDir, `${version}-ROADMAP.md`), roadmapContent, 'utf-8');
  }

  // Archive REQUIREMENTS.md
  if (fs.existsSync(reqPath)) {
    const reqContent = fs.readFileSync(reqPath, 'utf-8');
    const archiveHeader = `# Requirements Archive: ${version} ${milestoneName}\n\n**Archived:** ${today}\n**Status:** SHIPPED\n\nFor current requirements, see \`.planning/REQUIREMENTS.md\`.\n\n---\n\n`;
    fs.writeFileSync(path.join(archiveDir, `${version}-REQUIREMENTS.md`), archiveHeader + reqContent, 'utf-8');
  }

  // Archive audit file if exists
  const auditFile = path.join(cwd, '.planning', `${version}-MILESTONE-AUDIT.md`);
  if (fs.existsSync(auditFile)) {
    fs.renameSync(auditFile, path.join(archiveDir, `${version}-MILESTONE-AUDIT.md`));
  }

  // Create/append MILESTONES.md entry
  const accomplishmentsList = accomplishments.map(a => `- ${a}`).join('\n');
  const milestoneEntry = `## ${version} ${milestoneName} (Shipped: ${today})\n\n**Phases completed:** ${phaseCount} phases, ${totalPlans} plans, ${totalTasks} tasks\n\n**Key accomplishments:**\n${accomplishmentsList || '- (none recorded)'}\n\n---\n\n`;

  if (fs.existsSync(milestonesPath)) {
    const existing = fs.readFileSync(milestonesPath, 'utf-8');
    fs.writeFileSync(milestonesPath, existing + '\n' + milestoneEntry, 'utf-8');
  } else {
    fs.writeFileSync(milestonesPath, `# Milestones\n\n${milestoneEntry}`, 'utf-8');
  }

  // Update STATE.md
  if (fs.existsSync(statePath)) {
    let stateContent = fs.readFileSync(statePath, 'utf-8');
    stateContent = stateContent.replace(
      /(\*\*Status:\*\*\s*).*/,
      `$1${version} milestone complete`
    );
    stateContent = stateContent.replace(
      /(\*\*Last Activity:\*\*\s*).*/,
      `$1${today}`
    );
    stateContent = stateContent.replace(
      /(\*\*Last Activity Description:\*\*\s*).*/,
      `$1${version} milestone completed and archived`
    );
    fs.writeFileSync(statePath, stateContent, 'utf-8');
  }

  const result = {
    version,
    name: milestoneName,
    date: today,
    phases: phaseCount,
    plans: totalPlans,
    tasks: totalTasks,
    accomplishments,
    archived: {
      roadmap: fs.existsSync(path.join(archiveDir, `${version}-ROADMAP.md`)),
      requirements: fs.existsSync(path.join(archiveDir, `${version}-REQUIREMENTS.md`)),
      audit: fs.existsSync(path.join(archiveDir, `${version}-MILESTONE-AUDIT.md`)),
    },
    milestones_updated: true,
    state_updated: fs.existsSync(statePath),
  };

  output(result, raw);
}

// ─── Validate Consistency ─────────────────────────────────────────────────────

function cmdValidateConsistency(cwd, raw) {
  const roadmapPath = path.join(cwd, '.planning', 'ROADMAP.md');
  const phasesDir = path.join(cwd, '.planning', 'phases');
  const errors = [];
  const warnings = [];

  // Check for ROADMAP
  if (!fs.existsSync(roadmapPath)) {
    errors.push('ROADMAP.md not found');
    output({ passed: false, errors, warnings }, raw, 'failed');
    return;
  }

  const roadmapContent = fs.readFileSync(roadmapPath, 'utf-8');

  // Extract phases from ROADMAP
  const roadmapPhases = new Set();
  const phasePattern = /###\s*Phase\s+(\d+(?:\.\d+)?)\s*:/gi;
  let m;
  while ((m = phasePattern.exec(roadmapContent)) !== null) {
    roadmapPhases.add(m[1]);
  }

  // Get phases on disk
  const diskPhases = new Set();
  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name);
    for (const dir of dirs) {
      const dm = dir.match(/^(\d+(?:\.\d+)?)/);
      if (dm) diskPhases.add(dm[1]);
    }
  } catch {}

  // Check: phases in ROADMAP but not on disk
  for (const p of roadmapPhases) {
    if (!diskPhases.has(p) && !diskPhases.has(normalizePhaseName(p))) {
      warnings.push(`Phase ${p} in ROADMAP.md but no directory on disk`);
    }
  }

  // Check: phases on disk but not in ROADMAP
  for (const p of diskPhases) {
    const unpadded = String(parseInt(p, 10));
    if (!roadmapPhases.has(p) && !roadmapPhases.has(unpadded)) {
      warnings.push(`Phase ${p} exists on disk but not in ROADMAP.md`);
    }
  }

  // Check: sequential phase numbers (integers only)
  const integerPhases = [...diskPhases]
    .filter(p => !p.includes('.'))
    .map(p => parseInt(p, 10))
    .sort((a, b) => a - b);

  for (let i = 1; i < integerPhases.length; i++) {
    if (integerPhases[i] !== integerPhases[i - 1] + 1) {
      warnings.push(`Gap in phase numbering: ${integerPhases[i - 1]} → ${integerPhases[i]}`);
    }
  }

  // Check: plan numbering within phases
  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name).sort();

    for (const dir of dirs) {
      const phaseFiles = fs.readdirSync(path.join(phasesDir, dir));
      const plans = phaseFiles.filter(f => f.endsWith('-PLAN.md')).sort();

      // Extract plan numbers
      const planNums = plans.map(p => {
        const pm = p.match(/-(\d{2})-PLAN\.md$/);
        return pm ? parseInt(pm[1], 10) : null;
      }).filter(n => n !== null);

      for (let i = 1; i < planNums.length; i++) {
        if (planNums[i] !== planNums[i - 1] + 1) {
          warnings.push(`Gap in plan numbering in ${dir}: plan ${planNums[i - 1]} → ${planNums[i]}`);
        }
      }

      // Check: plans without summaries (completed plans)
      const summaries = phaseFiles.filter(f => f.endsWith('-SUMMARY.md'));
      const planIds = new Set(plans.map(p => p.replace('-PLAN.md', '')));
      const summaryIds = new Set(summaries.map(s => s.replace('-SUMMARY.md', '')));

      // Summary without matching plan is suspicious
      for (const sid of summaryIds) {
        if (!planIds.has(sid)) {
          warnings.push(`Summary ${sid}-SUMMARY.md in ${dir} has no matching PLAN.md`);
        }
      }
    }
  } catch {}

  // Check: frontmatter in plans has required fields
  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name);

    for (const dir of dirs) {
      const phaseFiles = fs.readdirSync(path.join(phasesDir, dir));
      const plans = phaseFiles.filter(f => f.endsWith('-PLAN.md'));

      for (const plan of plans) {
        const content = fs.readFileSync(path.join(phasesDir, dir, plan), 'utf-8');
        const fm = extractFrontmatter(content);

        if (!fm.wave) {
          warnings.push(`${dir}/${plan}: missing 'wave' in frontmatter`);
        }
      }
    }
  } catch {}

  const passed = errors.length === 0;
  output({ passed, errors, warnings, warning_count: warnings.length }, raw, passed ? 'passed' : 'failed');
}

// ─── Progress Render ──────────────────────────────────────────────────────────

function cmdProgressRender(cwd, format, raw) {
  const phasesDir = path.join(cwd, '.planning', 'phases');
  const roadmapPath = path.join(cwd, '.planning', 'ROADMAP.md');
  const milestone = getMilestoneInfo(cwd);

  const phases = [];
  let totalPlans = 0;
  let totalSummaries = 0;

  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name).sort((a, b) => {
      const aNum = parseFloat(a.match(/^(\d+(?:\.\d+)?)/)?.[1] || '0');
      const bNum = parseFloat(b.match(/^(\d+(?:\.\d+)?)/)?.[1] || '0');
      return aNum - bNum;
    });

    for (const dir of dirs) {
      const dm = dir.match(/^(\d+(?:\.\d+)?)-?(.*)/);
      const phaseNum = dm ? dm[1] : dir;
      const phaseName = dm && dm[2] ? dm[2].replace(/-/g, ' ') : '';
      const phaseFiles = fs.readdirSync(path.join(phasesDir, dir));
      const plans = phaseFiles.filter(f => f.endsWith('-PLAN.md') || f === 'PLAN.md').length;
      const summaries = phaseFiles.filter(f => f.endsWith('-SUMMARY.md') || f === 'SUMMARY.md').length;

      totalPlans += plans;
      totalSummaries += summaries;

      let status;
      if (plans === 0) status = 'Pending';
      else if (summaries >= plans) status = 'Complete';
      else if (summaries > 0) status = 'In Progress';
      else status = 'Planned';

      phases.push({ number: phaseNum, name: phaseName, plans, summaries, status });
    }
  } catch {}

  const percent = totalPlans > 0 ? Math.round((totalSummaries / totalPlans) * 100) : 0;

  if (format === 'table') {
    // Render markdown table
    const barWidth = 10;
    const filled = Math.round((percent / 100) * barWidth);
    const bar = '\u2588'.repeat(filled) + '\u2591'.repeat(barWidth - filled);
    let out = `# ${milestone.version} ${milestone.name}\n\n`;
    out += `**Progress:** [${bar}] ${totalSummaries}/${totalPlans} plans (${percent}%)\n\n`;
    out += `| Phase | Name | Plans | Status |\n`;
    out += `|-------|------|-------|--------|\n`;
    for (const p of phases) {
      out += `| ${p.number} | ${p.name} | ${p.summaries}/${p.plans} | ${p.status} |\n`;
    }
    output({ rendered: out }, raw, out);
  } else if (format === 'bar') {
    const barWidth = 20;
    const filled = Math.round((percent / 100) * barWidth);
    const bar = '\u2588'.repeat(filled) + '\u2591'.repeat(barWidth - filled);
    const text = `[${bar}] ${totalSummaries}/${totalPlans} plans (${percent}%)`;
    output({ bar: text, percent, completed: totalSummaries, total: totalPlans }, raw, text);
  } else {
    // JSON format
    output({
      milestone_version: milestone.version,
      milestone_name: milestone.name,
      phases,
      total_plans: totalPlans,
      total_summaries: totalSummaries,
      percent,
    }, raw);
  }
}

// ─── Progress Patterns (Pattern Learning Metrics) ─────────────────────────────

async function cmdProgressPatterns(cwd, raw) {
  try {
    const { getMetrics, getMetricsSummary } = require('../lib/pattern-learning/metrics');
    const metricsSummary = getMetricsSummary();

    if (raw) {
      process.stdout.write(metricsSummary);
    } else {
      const metrics = getMetrics();
      output(metrics, null, metricsSummary);
    }
  } catch (e) {
    error(`Failed to get pattern learning metrics: ${e.message}`);
  }
}

// ─── Todo Complete ────────────────────────────────────────────────────────────

function cmdTodoComplete(cwd, filename, raw) {
  if (!filename) {
    error('filename required for todo complete');
  }

  const pendingDir = path.join(cwd, '.planning', 'todos', 'pending');
  const completedDir = path.join(cwd, '.planning', 'todos', 'completed');
  const sourcePath = path.join(pendingDir, filename);

  if (!fs.existsSync(sourcePath)) {
    error(`Todo not found: ${filename}`);
  }

  // Ensure completed directory exists
  fs.mkdirSync(completedDir, { recursive: true });

  // Read, add completion timestamp, move
  let content = fs.readFileSync(sourcePath, 'utf-8');
  const today = new Date().toISOString().split('T')[0];
  content = `completed: ${today}\n` + content;

  fs.writeFileSync(path.join(completedDir, filename), content, 'utf-8');
  fs.unlinkSync(sourcePath);

  output({ completed: true, file: filename, date: today }, raw, 'completed');
}

// ─── Scaffold ─────────────────────────────────────────────────────────────────

function cmdScaffold(cwd, type, options, raw) {
  const { phase, name } = options;
  const padded = phase ? normalizePhaseName(phase) : '00';
  const today = new Date().toISOString().split('T')[0];

  // Find phase directory
  const phaseInfo = phase ? findPhaseInternal(cwd, phase) : null;
  const phaseDir = phaseInfo ? path.join(cwd, phaseInfo.directory) : null;

  if (phase && !phaseDir && type !== 'phase-dir') {
    error(`Phase ${phase} directory not found`);
  }

  let filePath, content;

  switch (type) {
    case 'context': {
      filePath = path.join(phaseDir, `${padded}-CONTEXT.md`);
      content = `---\nphase: "${padded}"\nname: "${name || phaseInfo?.phase_name || 'Unnamed'}"\ncreated: ${today}\n---\n\n# Phase ${phase}: ${name || phaseInfo?.phase_name || 'Unnamed'} — Context\n\n## Decisions\n\n_Decisions will be captured during /GSI:discuss-phase ${phase}_\n\n## Discretion Areas\n\n_Areas where the executor can use judgment_\n\n## Deferred Ideas\n\n_Ideas to consider later_\n`;
      break;
    }
    case 'uat': {
      filePath = path.join(phaseDir, `${padded}-UAT.md`);
      content = `---\nphase: "${padded}"\nname: "${name || phaseInfo?.phase_name || 'Unnamed'}"\ncreated: ${today}\nstatus: pending\n---\n\n# Phase ${phase}: ${name || phaseInfo?.phase_name || 'Unnamed'} — User Acceptance Testing\n\n## Test Results\n\n| # | Test | Status | Notes |\n|---|------|--------|-------|\n\n## Summary\n\n_Pending UAT_\n`;
      break;
    }
    case 'verification': {
      filePath = path.join(phaseDir, `${padded}-VERIFICATION.md`);
      content = `---\nphase: "${padded}"\nname: "${name || phaseInfo?.phase_name || 'Unnamed'}"\ncreated: ${today}\nstatus: pending\n---\n\n# Phase ${phase}: ${name || phaseInfo?.phase_name || 'Unnamed'} — Verification\n\n## Goal-Backward Verification\n\n**Phase Goal:** [From ROADMAP.md]\n\n## Checks\n\n| # | Requirement | Status | Evidence |\n|---|------------|--------|----------|\n\n## Result\n\n_Pending verification_\n`;
      break;
    }
    case 'phase-dir': {
      if (!phase || !name) {
        error('phase and name required for phase-dir scaffold');
      }
      const slug = generateSlugInternal(name);
      const dirName = `${padded}-${slug}`;
      const phasesParent = path.join(cwd, '.planning', 'phases');
      fs.mkdirSync(phasesParent, { recursive: true });
      const dirPath = path.join(phasesParent, dirName);
      fs.mkdirSync(dirPath, { recursive: true });
      output({ created: true, directory: `.planning/phases/${dirName}`, path: dirPath }, raw, dirPath);
      return;
    }
    default:
      error(`Unknown scaffold type: ${type}. Available: context, uat, verification, phase-dir`);
  }

  if (fs.existsSync(filePath)) {
    output({ created: false, reason: 'already_exists', path: filePath }, raw, 'exists');
    return;
  }

  fs.writeFileSync(filePath, content, 'utf-8');
  const relPath = path.relative(cwd, filePath);
  output({ created: true, path: relPath }, raw, relPath);
}

// ─── Compound Commands ────────────────────────────────────────────────────────

function resolveModelInternal(cwd, agentType) {
  const config = loadConfig(cwd);
  const profile = config.model_profile || 'balanced';
  const agentModels = MODEL_PROFILES[agentType];
  if (!agentModels) return 'sonnet';
  return agentModels[profile] || agentModels['balanced'] || 'sonnet';
}

function findPhaseInternal(cwd, phase) {
  if (!phase) return null;

  const phasesDir = path.join(cwd, '.planning', 'phases');
  const normalized = normalizePhaseName(phase);

  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name).sort();
    const match = dirs.find(d => d.startsWith(normalized));
    if (!match) return null;

    const dirMatch = match.match(/^(\d+(?:\.\d+)?)-?(.*)/);
    const phaseNumber = dirMatch ? dirMatch[1] : normalized;
    const phaseName = dirMatch && dirMatch[2] ? dirMatch[2] : null;
    const phaseDir = path.join(phasesDir, match);
    const phaseFiles = fs.readdirSync(phaseDir);

    const plans = phaseFiles.filter(f => f.endsWith('-PLAN.md') || f === 'PLAN.md').sort();
    const summaries = phaseFiles.filter(f => f.endsWith('-SUMMARY.md') || f === 'SUMMARY.md').sort();
    const hasResearch = phaseFiles.some(f => f.endsWith('-RESEARCH.md') || f === 'RESEARCH.md');
    const hasContext = phaseFiles.some(f => f.endsWith('-CONTEXT.md') || f === 'CONTEXT.md');
    const hasVerification = phaseFiles.some(f => f.endsWith('-VERIFICATION.md') || f === 'VERIFICATION.md');

    // Determine incomplete plans (plans without matching summaries)
    const completedPlanIds = new Set(
      summaries.map(s => s.replace('-SUMMARY.md', '').replace('SUMMARY.md', ''))
    );
    const incompletePlans = plans.filter(p => {
      const planId = p.replace('-PLAN.md', '').replace('PLAN.md', '');
      return !completedPlanIds.has(planId);
    });

    return {
      found: true,
      directory: path.join('.planning', 'phases', match),
      phase_number: phaseNumber,
      phase_name: phaseName,
      phase_slug: phaseName ? phaseName.toLowerCase().replace(/[^a-z0-9]+/g, '-').replace(/^-+|-+$/g, '') : null,
      plans,
      summaries,
      incomplete_plans: incompletePlans,
      has_research: hasResearch,
      has_context: hasContext,
      has_verification: hasVerification,
    };
  } catch {
    return null;
  }
}

function pathExistsInternal(cwd, targetPath) {
  const fullPath = path.isAbsolute(targetPath) ? targetPath : path.join(cwd, targetPath);
  try {
    fs.statSync(fullPath);
    return true;
  } catch {
    return false;
  }
}

function generateSlugInternal(text) {
  if (!text) return null;
  return text.toLowerCase().replace(/[^a-z0-9]+/g, '-').replace(/^-+|-+$/g, '');
}

function getMilestoneInfo(cwd) {
  try {
    const roadmap = fs.readFileSync(path.join(cwd, '.planning', 'ROADMAP.md'), 'utf-8');
    const versionMatch = roadmap.match(/v(\d+\.\d+)/);
    const nameMatch = roadmap.match(/## .*v\d+\.\d+[:\s]+([^\n(]+)/);
    return {
      version: versionMatch ? versionMatch[0] : 'v1.0',
      name: nameMatch ? nameMatch[1].trim() : 'milestone',
    };
  } catch {
    return { version: 'v1.0', name: 'milestone' };
  }
}

function cmdInitExecutePhase(cwd, phase, includes, raw) {
  if (!phase) {
    error('phase required for init execute-phase');
  }

  const config = loadConfig(cwd);
  const phaseInfo = findPhaseInternal(cwd, phase);
  const milestone = getMilestoneInfo(cwd);

  const result = {
    // Models
    executor_model: resolveModelInternal(cwd, 'GSI-executor'),
    verifier_model: resolveModelInternal(cwd, 'GSI-verifier'),

    // Config flags
    commit_docs: config.commit_docs,
    parallelization: config.parallelization,
    branching_strategy: config.branching_strategy,
    phase_branch_template: config.phase_branch_template,
    milestone_branch_template: config.milestone_branch_template,
    verifier_enabled: config.verifier,

    // Phase info
    phase_found: !!phaseInfo,
    phase_dir: phaseInfo?.directory || null,
    phase_number: phaseInfo?.phase_number || null,
    phase_name: phaseInfo?.phase_name || null,
    phase_slug: phaseInfo?.phase_slug || null,

    // Plan inventory
    plans: phaseInfo?.plans || [],
    summaries: phaseInfo?.summaries || [],
    incomplete_plans: phaseInfo?.incomplete_plans || [],
    plan_count: phaseInfo?.plans?.length || 0,
    incomplete_count: phaseInfo?.incomplete_plans?.length || 0,

    // Branch name (pre-computed)
    branch_name: config.branching_strategy === 'phase' && phaseInfo
      ? config.phase_branch_template
          .replace('{phase}', phaseInfo.phase_number)
          .replace('{slug}', phaseInfo.phase_slug || 'phase')
      : config.branching_strategy === 'milestone'
        ? config.milestone_branch_template
            .replace('{milestone}', milestone.version)
            .replace('{slug}', generateSlugInternal(milestone.name) || 'milestone')
        : null,

    // Milestone info
    milestone_version: milestone.version,
    milestone_name: milestone.name,
    milestone_slug: generateSlugInternal(milestone.name),

    // File existence
    state_exists: pathExistsInternal(cwd, '.planning/STATE.md'),
    roadmap_exists: pathExistsInternal(cwd, '.planning/ROADMAP.md'),
    config_exists: pathExistsInternal(cwd, '.planning/config.json'),
  };

  // Include file contents if requested via --include
  if (includes.has('state')) {
    result.state_content = safeReadFile(path.join(cwd, '.planning', 'STATE.md'));
  }
  if (includes.has('config')) {
    result.config_content = safeReadFile(path.join(cwd, '.planning', 'config.json'));
  }
  if (includes.has('roadmap')) {
    result.roadmap_content = safeReadFile(path.join(cwd, '.planning', 'ROADMAP.md'));
  }

  output(result, raw);
}

function cmdInitPlanPhase(cwd, phase, includes, raw) {
  if (!phase) {
    error('phase required for init plan-phase');
  }

  const config = loadConfig(cwd);
  const phaseInfo = findPhaseInternal(cwd, phase);

  const result = {
    // Models
    researcher_model: resolveModelInternal(cwd, 'GSI-phase-researcher'),
    planner_model: resolveModelInternal(cwd, 'GSI-planner'),
    checker_model: resolveModelInternal(cwd, 'GSI-plan-checker'),

    // Workflow flags
    research_enabled: config.research,
    plan_checker_enabled: config.plan_checker,
    commit_docs: config.commit_docs,

    // Phase info
    phase_found: !!phaseInfo,
    phase_dir: phaseInfo?.directory || null,
    phase_number: phaseInfo?.phase_number || null,
    phase_name: phaseInfo?.phase_name || null,
    phase_slug: phaseInfo?.phase_slug || null,
    padded_phase: phaseInfo?.phase_number?.padStart(2, '0') || null,

    // Existing artifacts
    has_research: phaseInfo?.has_research || false,
    has_context: phaseInfo?.has_context || false,
    has_plans: (phaseInfo?.plans?.length || 0) > 0,
    plan_count: phaseInfo?.plans?.length || 0,

    // Environment
    planning_exists: pathExistsInternal(cwd, '.planning'),
    roadmap_exists: pathExistsInternal(cwd, '.planning/ROADMAP.md'),
  };

  // Include file contents if requested via --include
  if (includes.has('state')) {
    result.state_content = safeReadFile(path.join(cwd, '.planning', 'STATE.md'));
  }
  if (includes.has('roadmap')) {
    result.roadmap_content = safeReadFile(path.join(cwd, '.planning', 'ROADMAP.md'));
  }
  if (includes.has('requirements')) {
    result.requirements_content = safeReadFile(path.join(cwd, '.planning', 'REQUIREMENTS.md'));
  }
  if (includes.has('context') && phaseInfo?.directory) {
    // Find *-CONTEXT.md in phase directory
    const phaseDirFull = path.join(cwd, phaseInfo.directory);
    try {
      const files = fs.readdirSync(phaseDirFull);
      const contextFile = files.find(f => f.endsWith('-CONTEXT.md') || f === 'CONTEXT.md');
      if (contextFile) {
        result.context_content = safeReadFile(path.join(phaseDirFull, contextFile));
      }
    } catch {}
  }
  if (includes.has('research') && phaseInfo?.directory) {
    // Find *-RESEARCH.md in phase directory
    const phaseDirFull = path.join(cwd, phaseInfo.directory);
    try {
      const files = fs.readdirSync(phaseDirFull);
      const researchFile = files.find(f => f.endsWith('-RESEARCH.md') || f === 'RESEARCH.md');
      if (researchFile) {
        result.research_content = safeReadFile(path.join(phaseDirFull, researchFile));
      }
    } catch {}
  }
  if (includes.has('verification') && phaseInfo?.directory) {
    // Find *-VERIFICATION.md in phase directory
    const phaseDirFull = path.join(cwd, phaseInfo.directory);
    try {
      const files = fs.readdirSync(phaseDirFull);
      const verificationFile = files.find(f => f.endsWith('-VERIFICATION.md') || f === 'VERIFICATION.md');
      if (verificationFile) {
        result.verification_content = safeReadFile(path.join(phaseDirFull, verificationFile));
      }
    } catch {}
  }
  if (includes.has('uat') && phaseInfo?.directory) {
    // Find *-UAT.md in phase directory
    const phaseDirFull = path.join(cwd, phaseInfo.directory);
    try {
      const files = fs.readdirSync(phaseDirFull);
      const uatFile = files.find(f => f.endsWith('-UAT.md') || f === 'UAT.md');
      if (uatFile) {
        result.uat_content = safeReadFile(path.join(phaseDirFull, uatFile));
      }
    } catch {}
  }

  output(result, raw);
}

function cmdInitNewProject(cwd, raw) {
  const config = loadConfig(cwd);

  // Detect Brave Search API key availability
  const homedir = require('os').homedir();
  const braveKeyFile = path.join(homedir, '.GSI', 'brave_api_key');
  const hasBraveSearch = !!(process.env.BRAVE_API_KEY || fs.existsSync(braveKeyFile));

  // Detect existing code
  let hasCode = false;
  let hasPackageFile = false;
  try {
    const files = execSync('find . -maxdepth 3 \\( -name "*.ts" -o -name "*.js" -o -name "*.py" -o -name "*.go" -o -name "*.rs" -o -name "*.swift" -o -name "*.java" \\) 2>/dev/null | grep -v node_modules | grep -v .git | head -5', {
      cwd,
      encoding: 'utf-8',
      stdio: ['pipe', 'pipe', 'pipe'],
    });
    hasCode = files.trim().length > 0;
  } catch {}

  hasPackageFile = pathExistsInternal(cwd, 'package.json') ||
                   pathExistsInternal(cwd, 'requirements.txt') ||
                   pathExistsInternal(cwd, 'Cargo.toml') ||
                   pathExistsInternal(cwd, 'go.mod') ||
                   pathExistsInternal(cwd, 'Package.swift');

  const result = {
    // Models
    researcher_model: resolveModelInternal(cwd, 'GSI-project-researcher'),
    synthesizer_model: resolveModelInternal(cwd, 'GSI-research-synthesizer'),
    roadmapper_model: resolveModelInternal(cwd, 'GSI-roadmapper'),

    // Config
    commit_docs: config.commit_docs,

    // Existing state
    project_exists: pathExistsInternal(cwd, '.planning/PROJECT.md'),
    has_codebase_map: pathExistsInternal(cwd, '.planning/codebase'),
    planning_exists: pathExistsInternal(cwd, '.planning'),

    // Brownfield detection
    has_existing_code: hasCode,
    has_package_file: hasPackageFile,
    is_brownfield: hasCode || hasPackageFile,
    needs_codebase_map: (hasCode || hasPackageFile) && !pathExistsInternal(cwd, '.planning/codebase'),

    // Git state
    has_git: pathExistsInternal(cwd, '.git'),

    // Enhanced search
    brave_search_available: hasBraveSearch,
  };

  output(result, raw);
}

function cmdInitNewMilestone(cwd, raw) {
  const config = loadConfig(cwd);
  const milestone = getMilestoneInfo(cwd);

  const result = {
    // Models
    researcher_model: resolveModelInternal(cwd, 'GSI-project-researcher'),
    synthesizer_model: resolveModelInternal(cwd, 'GSI-research-synthesizer'),
    roadmapper_model: resolveModelInternal(cwd, 'GSI-roadmapper'),

    // Config
    commit_docs: config.commit_docs,
    research_enabled: config.research,

    // Current milestone
    current_milestone: milestone.version,
    current_milestone_name: milestone.name,

    // File existence
    project_exists: pathExistsInternal(cwd, '.planning/PROJECT.md'),
    roadmap_exists: pathExistsInternal(cwd, '.planning/ROADMAP.md'),
    state_exists: pathExistsInternal(cwd, '.planning/STATE.md'),
  };

  output(result, raw);
}

function cmdInitQuick(cwd, description, raw) {
  const config = loadConfig(cwd);
  const now = new Date();
  const slug = description ? generateSlugInternal(description)?.substring(0, 40) : null;

  // Find next quick task number
  const quickDir = path.join(cwd, '.planning', 'quick');
  let nextNum = 1;
  try {
    const existing = fs.readdirSync(quickDir)
      .filter(f => /^\d+-/.test(f))
      .map(f => parseInt(f.split('-')[0], 10))
      .filter(n => !isNaN(n));
    if (existing.length > 0) {
      nextNum = Math.max(...existing) + 1;
    }
  } catch {}

  const result = {
    // Models
    planner_model: resolveModelInternal(cwd, 'GSI-planner'),
    executor_model: resolveModelInternal(cwd, 'GSI-executor'),

    // Config
    commit_docs: config.commit_docs,

    // Quick task info
    next_num: nextNum,
    slug: slug,
    description: description || null,

    // Timestamps
    date: now.toISOString().split('T')[0],
    timestamp: now.toISOString(),

    // Paths
    quick_dir: '.planning/quick',
    task_dir: slug ? `.planning/quick/${nextNum}-${slug}` : null,

    // File existence
    roadmap_exists: pathExistsInternal(cwd, '.planning/ROADMAP.md'),
    planning_exists: pathExistsInternal(cwd, '.planning'),
  };

  output(result, raw);
}

function cmdInitResume(cwd, raw) {
  const config = loadConfig(cwd);

  // Check for interrupted agent
  let interruptedAgentId = null;
  try {
    interruptedAgentId = fs.readFileSync(path.join(cwd, '.planning', 'current-agent-id.txt'), 'utf-8').trim();
  } catch {}

  const result = {
    // File existence
    state_exists: pathExistsInternal(cwd, '.planning/STATE.md'),
    roadmap_exists: pathExistsInternal(cwd, '.planning/ROADMAP.md'),
    project_exists: pathExistsInternal(cwd, '.planning/PROJECT.md'),
    planning_exists: pathExistsInternal(cwd, '.planning'),

    // Agent state
    has_interrupted_agent: !!interruptedAgentId,
    interrupted_agent_id: interruptedAgentId,

    // Config
    commit_docs: config.commit_docs,
  };

  output(result, raw);
}

function cmdInitVerifyWork(cwd, phase, raw) {
  if (!phase) {
    error('phase required for init verify-work');
  }

  const config = loadConfig(cwd);
  const phaseInfo = findPhaseInternal(cwd, phase);

  const result = {
    // Models
    planner_model: resolveModelInternal(cwd, 'GSI-planner'),
    checker_model: resolveModelInternal(cwd, 'GSI-plan-checker'),

    // Config
    commit_docs: config.commit_docs,

    // Phase info
    phase_found: !!phaseInfo,
    phase_dir: phaseInfo?.directory || null,
    phase_number: phaseInfo?.phase_number || null,
    phase_name: phaseInfo?.phase_name || null,

    // Existing artifacts
    has_verification: phaseInfo?.has_verification || false,
  };

  output(result, raw);
}

function cmdInitPhaseOp(cwd, phase, raw) {
  const config = loadConfig(cwd);
  const phaseInfo = findPhaseInternal(cwd, phase);

  const result = {
    // Config
    commit_docs: config.commit_docs,
    brave_search: config.brave_search,

    // Phase info
    phase_found: !!phaseInfo,
    phase_dir: phaseInfo?.directory || null,
    phase_number: phaseInfo?.phase_number || null,
    phase_name: phaseInfo?.phase_name || null,
    phase_slug: phaseInfo?.phase_slug || null,
    padded_phase: phaseInfo?.phase_number?.padStart(2, '0') || null,

    // Existing artifacts
    has_research: phaseInfo?.has_research || false,
    has_context: phaseInfo?.has_context || false,
    has_plans: (phaseInfo?.plans?.length || 0) > 0,
    has_verification: phaseInfo?.has_verification || false,
    plan_count: phaseInfo?.plans?.length || 0,

    // File existence
    roadmap_exists: pathExistsInternal(cwd, '.planning/ROADMAP.md'),
    planning_exists: pathExistsInternal(cwd, '.planning'),
  };

  output(result, raw);
}

function cmdInitTodos(cwd, area, raw) {
  const config = loadConfig(cwd);
  const now = new Date();

  // List todos (reuse existing logic)
  const pendingDir = path.join(cwd, '.planning', 'todos', 'pending');
  let count = 0;
  const todos = [];

  try {
    const files = fs.readdirSync(pendingDir).filter(f => f.endsWith('.md'));
    for (const file of files) {
      try {
        const content = fs.readFileSync(path.join(pendingDir, file), 'utf-8');
        const createdMatch = content.match(/^created:\s*(.+)$/m);
        const titleMatch = content.match(/^title:\s*(.+)$/m);
        const areaMatch = content.match(/^area:\s*(.+)$/m);
        const todoArea = areaMatch ? areaMatch[1].trim() : 'general';

        if (area && todoArea !== area) continue;

        count++;
        todos.push({
          file,
          created: createdMatch ? createdMatch[1].trim() : 'unknown',
          title: titleMatch ? titleMatch[1].trim() : 'Untitled',
          area: todoArea,
          path: path.join('.planning', 'todos', 'pending', file),
        });
      } catch {}
    }
  } catch {}

  const result = {
    // Config
    commit_docs: config.commit_docs,

    // Timestamps
    date: now.toISOString().split('T')[0],
    timestamp: now.toISOString(),

    // Todo inventory
    todo_count: count,
    todos,
    area_filter: area || null,

    // Paths
    pending_dir: '.planning/todos/pending',
    completed_dir: '.planning/todos/completed',

    // File existence
    planning_exists: pathExistsInternal(cwd, '.planning'),
    todos_dir_exists: pathExistsInternal(cwd, '.planning/todos'),
    pending_dir_exists: pathExistsInternal(cwd, '.planning/todos/pending'),
  };

  output(result, raw);
}

function cmdInitMilestoneOp(cwd, raw) {
  const config = loadConfig(cwd);
  const milestone = getMilestoneInfo(cwd);

  // Count phases
  let phaseCount = 0;
  let completedPhases = 0;
  const phasesDir = path.join(cwd, '.planning', 'phases');
  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name);
    phaseCount = dirs.length;

    // Count phases with summaries (completed)
    for (const dir of dirs) {
      try {
        const phaseFiles = fs.readdirSync(path.join(phasesDir, dir));
        const hasSummary = phaseFiles.some(f => f.endsWith('-SUMMARY.md') || f === 'SUMMARY.md');
        if (hasSummary) completedPhases++;
      } catch {}
    }
  } catch {}

  // Check archive
  const archiveDir = path.join(cwd, '.planning', 'archive');
  let archivedMilestones = [];
  try {
    archivedMilestones = fs.readdirSync(archiveDir, { withFileTypes: true })
      .filter(e => e.isDirectory())
      .map(e => e.name);
  } catch {}

  const result = {
    // Config
    commit_docs: config.commit_docs,

    // Current milestone
    milestone_version: milestone.version,
    milestone_name: milestone.name,
    milestone_slug: generateSlugInternal(milestone.name),

    // Phase counts
    phase_count: phaseCount,
    completed_phases: completedPhases,
    all_phases_complete: phaseCount > 0 && phaseCount === completedPhases,

    // Archive
    archived_milestones: archivedMilestones,
    archive_count: archivedMilestones.length,

    // File existence
    project_exists: pathExistsInternal(cwd, '.planning/PROJECT.md'),
    roadmap_exists: pathExistsInternal(cwd, '.planning/ROADMAP.md'),
    state_exists: pathExistsInternal(cwd, '.planning/STATE.md'),
    archive_exists: pathExistsInternal(cwd, '.planning/archive'),
    phases_dir_exists: pathExistsInternal(cwd, '.planning/phases'),
  };

  output(result, raw);
}

function cmdInitMapCodebase(cwd, raw) {
  const config = loadConfig(cwd);

  // Check for existing codebase maps
  const codebaseDir = path.join(cwd, '.planning', 'codebase');
  let existingMaps = [];
  try {
    existingMaps = fs.readdirSync(codebaseDir).filter(f => f.endsWith('.md'));
  } catch {}

  const result = {
    // Models
    mapper_model: resolveModelInternal(cwd, 'GSI-codebase-mapper'),

    // Config
    commit_docs: config.commit_docs,
    search_gitignored: config.search_gitignored,
    parallelization: config.parallelization,

    // Paths
    codebase_dir: '.planning/codebase',

    // Existing maps
    existing_maps: existingMaps,
    has_maps: existingMaps.length > 0,

    // File existence
    planning_exists: pathExistsInternal(cwd, '.planning'),
    codebase_dir_exists: pathExistsInternal(cwd, '.planning/codebase'),
  };

  output(result, raw);
}

function cmdInitProgress(cwd, includes, raw) {
  const config = loadConfig(cwd);
  const milestone = getMilestoneInfo(cwd);

  // Analyze phases
  const phasesDir = path.join(cwd, '.planning', 'phases');
  const phases = [];
  let currentPhase = null;
  let nextPhase = null;

  try {
    const entries = fs.readdirSync(phasesDir, { withFileTypes: true });
    const dirs = entries.filter(e => e.isDirectory()).map(e => e.name).sort();

    for (const dir of dirs) {
      const match = dir.match(/^(\d+(?:\.\d+)?)-?(.*)/);
      const phaseNumber = match ? match[1] : dir;
      const phaseName = match && match[2] ? match[2] : null;

      const phasePath = path.join(phasesDir, dir);
      const phaseFiles = fs.readdirSync(phasePath);

      const plans = phaseFiles.filter(f => f.endsWith('-PLAN.md') || f === 'PLAN.md');
      const summaries = phaseFiles.filter(f => f.endsWith('-SUMMARY.md') || f === 'SUMMARY.md');
      const hasResearch = phaseFiles.some(f => f.endsWith('-RESEARCH.md') || f === 'RESEARCH.md');

      const status = summaries.length >= plans.length && plans.length > 0 ? 'complete' :
                     plans.length > 0 ? 'in_progress' :
                     hasResearch ? 'researched' : 'pending';

      const phaseInfo = {
        number: phaseNumber,
        name: phaseName,
        directory: path.join('.planning', 'phases', dir),
        status,
        plan_count: plans.length,
        summary_count: summaries.length,
        has_research: hasResearch,
      };

      phases.push(phaseInfo);

      // Find current (first incomplete with plans) and next (first pending)
      if (!currentPhase && (status === 'in_progress' || status === 'researched')) {
        currentPhase = phaseInfo;
      }
      if (!nextPhase && status === 'pending') {
        nextPhase = phaseInfo;
      }
    }
  } catch {}

  // Check for paused work
  let pausedAt = null;
  try {
    const state = fs.readFileSync(path.join(cwd, '.planning', 'STATE.md'), 'utf-8');
    const pauseMatch = state.match(/\*\*Paused At:\*\*\s*(.+)/);
    if (pauseMatch) pausedAt = pauseMatch[1].trim();
  } catch {}

  const result = {
    // Models
    executor_model: resolveModelInternal(cwd, 'GSI-executor'),
    planner_model: resolveModelInternal(cwd, 'GSI-planner'),

    // Config
    commit_docs: config.commit_docs,

    // Milestone
    milestone_version: milestone.version,
    milestone_name: milestone.name,

    // Phase overview
    phases,
    phase_count: phases.length,
    completed_count: phases.filter(p => p.status === 'complete').length,
    in_progress_count: phases.filter(p => p.status === 'in_progress').length,

    // Current state
    current_phase: currentPhase,
    next_phase: nextPhase,
    paused_at: pausedAt,
    has_work_in_progress: !!currentPhase,

    // File existence
    project_exists: pathExistsInternal(cwd, '.planning/PROJECT.md'),
    roadmap_exists: pathExistsInternal(cwd, '.planning/ROADMAP.md'),
    state_exists: pathExistsInternal(cwd, '.planning/STATE.md'),
  };

  // Include file contents if requested via --include
  if (includes.has('state')) {
    result.state_content = safeReadFile(path.join(cwd, '.planning', 'STATE.md'));
  }
  if (includes.has('roadmap')) {
    result.roadmap_content = safeReadFile(path.join(cwd, '.planning', 'ROADMAP.md'));
  }
  if (includes.has('project')) {
    result.project_content = safeReadFile(path.join(cwd, '.planning', 'PROJECT.md'));
  }
  if (includes.has('config')) {
    result.config_content = safeReadFile(path.join(cwd, '.planning', 'config.json'));
  }

  output(result, raw);
}

// ─── Reflection Commands ───────────────────────────────────────────────────────

function cmdReflectionList(cwd, options, raw) {
  const ReflectionCapture = require('../lib/reflection/capture');
  const DebugThinkingIntegration = require('../lib/reflection/debug-integration');

  const capture = new ReflectionCapture();
  const debugIntegration = new DebugThinkingIntegration();

  // Get stats
  const captureStats = capture.getStats();
  const debugStats = debugIntegration.getStats();

  const result = {
    capture_stats: captureStats,
    debug_stats: debugStats,
    recent_reflections: capture.captureHistory.slice(-10).reverse()
  };

  if (raw) {
    const lines = [
      `Total reflections: ${debugStats.total}`,
      `By type: ${Object.entries(debugStats.byType).map(([k, v]) => `${k}: ${v}`).join(', ')}`,
      `Errors: ${debugStats.byType.ERROR || 0}`,
      `Success rate: ${debugStats.total > 0 ? ((debugStats.total - (debugStats.byType.ERROR || 0)) / debugStats.total * 100).toFixed(1) : 0}%`
    ];
    process.stdout.write(lines.join('\n'));
  } else {
    output(result, raw);
  }
}

function cmdReflectionPatterns(cwd, options, raw) {
  const PatternExtractor = require('../lib/reflection/patterns');
  const extractor = new PatternExtractor();

  const { minSuccess, minFrequency, type } = options;

  let patterns;
  if (type === 'anti') {
    patterns = extractor.getAntiPatterns(
      minSuccess || 0.3,
      minFrequency || 2
    );
  } else if (type === 'successful') {
    patterns = extractor.getSuccessfulPatterns(
      minSuccess || 0.7,
      minFrequency || 2
    );
  } else {
    patterns = extractor.patterns.slice(-20);
  }

  const result = {
    total: patterns.length,
    patterns: patterns.map(p => ({
      name: p.name,
      type: p.type,
      frequency: p.frequency,
      successRate: p.successRate.toFixed(2)
    }))
  };

  if (raw) {
    patterns.forEach(p => {
      process.stdout.write(`${p.name} (${p.type}): freq=${p.frequency}, success=${(p.successRate * 100).toFixed(0)}%\n`);
    });
  } else {
    output(result, raw);
  }
}

function cmdReflectionInsights(cwd, options, raw) {
  const InsightGenerator = require('../lib/reflection/insights');
  const generator = new InsightGenerator();

  const { type, impact, limit } = options;

  let insights;
  if (type) {
    insights = generator.getInsightsByType(type.toUpperCase());
  } else if (impact) {
    insights = generator.getInsightsByImpact(impact);
  } else {
    insights = generator.getTopInsights(limit || 10);
  }

  const result = {
    total: insights.length,
    insights: insights.map(i => ({
      title: i.title,
      type: i.type,
      impact: i.impact,
      priority: i.priority,
      applied: i.applied
    }))
  };

  if (raw) {
    insights.forEach(i => {
      process.stdout.write(`[${i.impact.toUpperCase()}] ${i.title} (priority: ${i.priority})\n`);
    });
  } else {
    output(result, raw);
  }
}

function cmdReflectionGraph(cwd, options, raw) {
  const DebugThinkingIntegration = require('../lib/reflection/debug-integration');
  const integration = new DebugThinkingIntegration();

  const stats = integration.getStats();

  const result = {
    total_observations: stats.total,
    by_type: stats.byType,
    by_tool: stats.byTool,
    graph_path: path.join(process.env.USERPROFILE || process.env.HOME || '', '.debug-thinking-mcp', 'reflections')
  };

  if (raw) {
    const lines = [
      `Total observations: ${result.total_observations}`,
      `By type: ${Object.entries(stats.byType).map(([k, v]) => `${k}: ${v}`).join(', ')}`,
      `Graph path: ${result.graph_path}`
    ];
    process.stdout.write(lines.join('\n'));
  } else {
    output(result, raw);
  }
}

// ─── Pattern Report Command ─────────────────────────────────────────────────────

async function cmdPatternReport(cwd, reportType, raw) {
  if (!patternViz) {
    error('Pattern learning module not available. Run from gsi repository root.');
  }

  try {
    let report;

    if (reportType === 'visualization' || reportType === 'viz') {
      report = await patternViz.generateVisualizationReport();
    } else {
      report = await patternViz.generatePatternReport();
    }

    if (raw) {
      process.stdout.write(report);
    } else {
      console.log(report);
    }

    // Optionally export to file
    const exportPath = path.join(cwd, '.planning', 'pattern-learning-report.md');
    patternViz.exportReport(exportPath, report);
    console.error(`\nReport exported to: ${exportPath}`);
  } catch (err) {
    error(`Failed to generate pattern report: ${err.message}`);
  }
}

// ─── Thinking Orchestrator Commands ─────────────────────────────────────────────

/**
 * Analyze command complexity and return recommended thinking configuration
 */
async function cmdThinkingAnalyze(cwd, commandDesc, options, raw) {
  try {
    // Dynamically import ThinkingOrchestrator (ES Module)
    const { ThinkingOrchestrator } = await import('../lib/workflow-modules/thinking-orchestrator.js');
    const orchestrator = new ThinkingOrchestrator();
    
    // Parse command description for analysis
    const analysis = orchestrator.analyzeCommand({
      description: commandDesc || '',
      allowedTools: options.tools ? options.tools.split(',') : [],
      process: options.process || ''
    });
    
    const result = {
      command: commandDesc,
      complexity: analysis.mode === 'NONE' ? 0 : 
                  analysis.mode === 'LIGHTWEIGHT' ? 4 :
                  analysis.mode === 'STANDARD' ? 10 : 15,
      mode: analysis.mode,
      servers: analysis.servers,
      bmad_enabled: analysis.bmad_enabled,
      timeout: analysis.timeout,
      rationale: analysis.rationale
    };
    
    if (raw) {
      console.log(`Complexity: ${result.complexity}`);
      console.log(`Mode: ${result.mode}`);
      console.log(`Servers: ${result.servers.join(', ')}`);
      console.log(`BMAD: ${result.bmad_enabled ? 'enabled' : 'disabled'}`);
      console.log(`Timeout: ${result.timeout}ms`);
      console.log(`Rationale: ${result.rationale}`);
    } else {
      output(result, options.json ? false : raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    if (raw) {
      console.error(`Analysis failed: ${err.message}`);
      process.exit(1);
    } else {
      output(result, raw);
    }
  }
}

/**
 * Generate optimal thinking configuration for a command
 */
async function cmdThinkingConfig(cwd, commandDesc, options, raw) {
  try {
    // Dynamically import ThinkingOrchestrator (ES Module)
    const { ThinkingOrchestrator } = await import('../lib/workflow-modules/thinking-orchestrator.js');
    const orchestrator = new ThinkingOrchestrator();
    
    // Load profile if specified
    let profile = null;
    if (options.profile) {
      const profilePath = path.join(__dirname, '..', 'profiles', `${options.profile}.json`);
      if (fs.existsSync(profilePath)) {
        profile = JSON.parse(fs.readFileSync(profilePath, 'utf-8'));
      }
    }
    
    // Analyze command or use profile
    let config;
    if (profile) {
      config = {
        mode: profile.mode,
        servers: profile.servers,
        bmad_enabled: options.bmad !== undefined ? options.bmad : profile.bmad_enabled,
        timeout: options.timeout || profile.baseTimeout,
        rationale: `Using ${options.profile} profile: ${profile.description}`
      };
    } else {
      config = orchestrator.analyzeCommand({
        description: commandDesc || '',
        allowedTools: options.tools ? options.tools.split(',') : [],
        process: options.process || ''
      });
      
      // Apply overrides
      if (options.timeout) {
        config.timeout = parseInt(options.timeout, 10);
      }
      if (options.bmad !== undefined) {
        config.bmad_enabled = options.bmad;
      }
    }
    
    // Generate frontmatter-style config
    const frontmatter = `thinking_phase:
  mode: ${config.mode}
  servers:
${config.servers.map(s => `    - ${s}`).join('\n')}
  bmad_enabled: ${config.bmad_enabled}
  timeout: ${config.timeout}
  rationale: "${config.rationale}"`;
    
    const result = {
      command: commandDesc,
      profile: options.profile || 'auto-detected',
      config: config,
      frontmatter: frontmatter
    };
    
    if (raw) {
      console.log(frontmatter);
    } else {
      output(result, options.json ? false : raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    if (raw) {
      console.error(`Config generation failed: ${err.message}`);
      process.exit(1);
    } else {
      output(result, raw);
    }
  }
}

/**
 * List available thinking servers
 */
async function cmdThinkingServers(cwd, options, raw) {
  const servers = [
    {
      name: 'sequential',
      endpoint: 'mcp__sequential-thinking__sequentialthinking',
      description: 'Sequential step planning and execution order',
      defaultMaxThoughts: 5
    },
    {
      name: 'tractatus',
      endpoint: 'mcp__tractatusthinking__tractatus_thinking',
      description: 'Structural analysis, relationships, and logical dependencies',
      defaultMaxThoughts: 5
    },
    {
      name: 'debug',
      endpoint: 'mcp__debug-thinking__debug_thinking',
      description: 'Problem detection, hypothesis generation, and solution verification',
      defaultMaxThoughts: 5
    }
  ];
  
  const result = {
    count: servers.length,
    servers: servers
  };
  
  if (raw || !options.json) {
    console.log('Available Thinking Servers:');
    for (const server of servers) {
      console.log(`- ${server.name}: ${server.endpoint}`);
      console.log(`  Description: ${server.description}`);
    }
  } else {
    output(result, false);
  }
}

/**
 * Test thinking server connections
 */
async function cmdThinkingTest(cwd, options, raw) {
  const { ThinkingOrchestrator } = await import('../lib/workflow-modules/thinking-orchestrator.js');
  const orchestrator = new ThinkingOrchestrator();
  
  const servers = options.server ? [options.server] : ['sequential', 'tractatus', 'debug'];
  const timeout = options.timeout || 5000;
  
  const results = [];
  
  for (const server of servers) {
    const startTime = Date.now();
    
    try {
      // Create a minimal test context
      const testConfig = {
        mode: 'LIGHTWEIGHT',
        servers: [server],
        bmad_enabled: false,
        timeout: timeout,
        rationale: 'Connection test'
      };
      
      const testContext = {
        command: 'test',
        description: 'Testing server connection'
      };
      
      // Attempt to invoke the thinking server
      const thinkingResults = await orchestrator.think(testConfig, testContext);
      const duration = Date.now() - startTime;
      
      const serverResult = thinkingResults.get(server);
      
      results.push({
        server: server,
        status: serverResult && serverResult.success ? 'connected' : 'error',
        duration: duration,
        thoughts: serverResult ? serverResult.thoughts.length : 0,
        error: serverResult ? serverResult.error : null
      });
    } catch (err) {
      results.push({
        server: server,
        status: 'error',
        duration: Date.now() - startTime,
        thoughts: 0,
        error: err.message
      });
    }
  }
  
  const result = {
    success: results.every(r => r.status === 'connected'),
    tested: servers.length,
    results: results
  };
  
  if (raw || !options.json) {
    console.log('Thinking Server Connection Test Results:');
    for (const r of results) {
      const status = r.status === 'connected' ? '✓' : '✗';
      console.log(`${status} ${r.server}: ${r.status} (${r.duration}ms)`);
      if (r.error) {
        console.log(`  Error: ${r.error}`);
      }
    }
  } else {
    output(result, false);
  }
}

/**
 * Apply thinking_phase to all GSI commands in a directory
 * Auto-generates and applies optimal thinking configurations
 */
async function cmdThinkingApplyAll(cwd, options, raw) {
  const { ThinkingOrchestrator } = await import('../lib/workflow-modules/thinking-orchestrator.js');
  const orchestrator = new ThinkingOrchestrator();
  
  const commandsDir = options.commandsDir || path.join(cwd, 'commands', 'gsi');
  const backupDir = options.backupDir || path.join(cwd, '.planning', 'thinking-backups');
  const dryRun = options.dryRun || false;
  const force = options.force || false;
  
  // Ensure backup directory exists
  if (!dryRun && !fs.existsSync(backupDir)) {
    fs.mkdirSync(backupDir, { recursive: true });
  }
  
  // Scan for command files
  const commandFiles = [];
  try {
    const files = fs.readdirSync(commandsDir).filter(f => f.endsWith('.md'));
    for (const file of files) {
      commandFiles.push(path.join(commandsDir, file));
    }
  } catch (err) {
    const result = { success: false, error: `Failed to read commands directory: ${err.message}` };
    output(result, raw);
    return;
  }
  
  const results = {
    scanned: commandFiles.length,
    processed: 0,
    skipped: 0,
    updated: 0,
    errors: 0,
    backups: [],
    changes: []
  };
  
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
  
  for (const filePath of commandFiles) {
    try {
      const content = fs.readFileSync(filePath, 'utf-8');
      const fm = extractFrontmatter(content);
      
      // Skip if already has thinking_phase and not forcing
      if (fm.thinking_phase && !force) {
        results.skipped++;
        results.changes.push({
          file: path.basename(filePath),
          action: 'skipped',
          reason: 'Already has thinking_phase'
        });
        continue;
      }
      
      // Extract command info for analysis
      const description = fm.description || fm.name || '';
      const allowedTools = fm['allowed-tools'] || [];
      
      // Extract process from content (between <process> tags)
      const processMatch = content.match(/<process>([\s\S]*?)<\/process>/);
      const process = processMatch ? processMatch[1] : '';
      
      // Extract objective
      const objectiveMatch = content.match(/<objective>([\s\S]*?)<\/objective>/);
      const objective = objectiveMatch ? objectiveMatch[1] : '';
      
      // Analyze and generate config
      const config = orchestrator.analyzeCommand({
        description,
        allowedTools,
        process,
        objective
      });
      
      // Validate the config
      const validation = orchestrator.validateConfig(config);
      if (!validation.valid) {
        results.errors++;
        results.changes.push({
          file: path.basename(filePath),
          action: 'error',
          reason: validation.errors.join('; ')
        });
        continue;
      }
      
      // Generate frontmatter string
      const thinkingFrontmatter = orchestrator.generateFrontmatter(config);
      
      // Create backup if not dry run
      if (!dryRun) {
        const backupPath = path.join(backupDir, `${path.basename(filePath)}.${timestamp}.bak`);
        fs.writeFileSync(backupPath, content, 'utf-8');
        results.backups.push(backupPath);
      }
      
      // Determine new content
      let newContent;
      if (fm.thinking_phase) {
        // Replace existing thinking_phase
        const thinkingBlockMatch = content.match(/thinking_phase:[\s\S]*?(?=\n[a-z_]+:|\n---|\n\n)/);
        if (thinkingBlockMatch) {
          newContent = content.replace(thinkingBlockMatch[0], thinkingFrontmatter);
        } else {
          // Fallback: insert after frontmatter
          newContent = spliceFrontmatter(content, { ...fm, thinking_phase: config });
        }
      } else {
        // Add thinking_phase to frontmatter
        const newFm = { ...fm, thinking_phase: config };
        newContent = spliceFrontmatter(content, newFm);
      }
      
      // Write if not dry run
      if (!dryRun) {
        fs.writeFileSync(filePath, newContent, 'utf-8');
      }
      
      results.updated++;
      results.processed++;
      results.changes.push({
        file: path.basename(filePath),
        action: fm.thinking_phase ? 'updated' : 'added',
        mode: config.mode,
        servers: config.servers,
        rationale: config.rationale
      });
      
    } catch (err) {
      results.errors++;
      results.changes.push({
        file: path.basename(filePath),
        action: 'error',
        reason: err.message
      });
    }
  }
  
  // Save backup metadata
  if (!dryRun && results.backups.length > 0) {
    const metaPath = path.join(backupDir, `apply-all-${timestamp}.json`);
    fs.writeFileSync(metaPath, JSON.stringify({
      timestamp,
      commandsDir,
      results: {
        scanned: results.scanned,
        processed: results.processed,
        updated: results.updated,
        skipped: results.skipped,
        errors: results.errors
      },
      backups: results.backups,
      changes: results.changes
    }, null, 2), 'utf-8');
  }
  
  const finalResult = {
    success: results.errors === 0,
    dry_run: dryRun,
    ...results
  };
  
  if (raw || !options.json) {
    console.log('=== Thinking Phase Apply-All Results ===\n');
    console.log(`Mode: ${dryRun ? 'DRY RUN (no changes made)' : 'LIVE'}`);
    console.log(`Commands scanned: ${results.scanned}`);
    console.log(`Processed: ${results.processed}`);
    console.log(`Updated: ${results.updated}`);
    console.log(`Skipped (already had config): ${results.skipped}`);
    console.log(`Errors: ${results.errors}`);
    
    if (results.changes.length > 0) {
      console.log('\nChanges:');
      for (const change of results.changes) {
        if (change.action === 'skipped') {
          console.log(`  [SKIP] ${change.file}: ${change.reason}`);
        } else if (change.action === 'error') {
          console.log(`  [ERROR] ${change.file}: ${change.reason}`);
        } else {
          console.log(`  [${change.action.toUpperCase()}] ${change.file}: ${change.mode} (${change.servers.join(', ')})`);
        }
      }
    }
    
    if (!dryRun && results.backups.length > 0) {
      console.log(`\nBackups saved to: ${backupDir}`);
    }
  } else {
    output(finalResult, false);
  }
}

/**
 * Validate thinking_phase configurations in command files
 */
async function cmdThinkingValidate(cwd, options, raw) {
  const { ThinkingOrchestrator } = await import('../lib/workflow-modules/thinking-orchestrator.js');
  const orchestrator = new ThinkingOrchestrator();
  
  const commandsDir = options.commandsDir || path.join(cwd, 'commands', 'gsi');
  const strictMode = options.strict || false;
  
  // Scan for command files
  const commandFiles = [];
  try {
    const files = fs.readdirSync(commandsDir).filter(f => f.endsWith('.md'));
    for (const file of files) {
      commandFiles.push(path.join(commandsDir, file));
    }
  } catch (err) {
    const result = { success: false, error: `Failed to read commands directory: ${err.message}` };
    output(result, raw);
    return;
  }
  
  const results = {
    scanned: commandFiles.length,
    valid: 0,
    invalid: 0,
    missing: 0,
    warnings: 0,
    files: []
  };
  
  for (const filePath of commandFiles) {
    try {
      const content = fs.readFileSync(filePath, 'utf-8');
      const fm = extractFrontmatter(content);
      
      const fileResult = {
        file: path.basename(filePath),
        status: 'valid',
        errors: [],
        warnings: []
      };
      
      // Check if thinking_phase exists
      if (!fm.thinking_phase) {
        fileResult.status = 'missing';
        fileResult.warnings.push('No thinking_phase configuration found');
        results.missing++;
        results.files.push(fileResult);
        continue;
      }
      
      // Parse thinking_phase configuration
      const config = {
        mode: fm.thinking_phase.mode || 'NONE',
        servers: fm.thinking_phase.servers || [],
        bmad_enabled: fm.thinking_phase.bmad_enabled || false,
        timeout: fm.thinking_phase.timeout || 0,
        rationale: fm.thinking_phase.rationale || ''
      };
      
      // Validate
      const validation = orchestrator.validateConfig(config);
      
      if (!validation.valid) {
        fileResult.status = 'invalid';
        fileResult.errors = validation.errors;
        results.invalid++;
      } else {
        results.valid++;
      }
      
      if (validation.warnings.length > 0) {
        fileResult.warnings = validation.warnings;
        results.warnings++;
        
        // In strict mode, warnings become errors
        if (strictMode && fileResult.status === 'valid') {
          fileResult.status = 'warning';
        }
      }
      
      results.files.push(fileResult);
      
    } catch (err) {
      results.invalid++;
      results.files.push({
        file: path.basename(filePath),
        status: 'error',
        errors: [err.message],
        warnings: []
      });
    }
  }
  
  const finalResult = {
    success: results.invalid === 0 && (!strictMode || results.warnings === 0),
    strict_mode: strictMode,
    ...results,
    summary: {
      total: results.scanned,
      valid: `${results.valid} (${Math.round(results.valid / results.scanned * 100)}%)`,
      invalid: results.invalid,
      missing: results.missing,
      with_warnings: results.warnings
    }
  };
  
  if (raw || !options.json) {
    console.log('=== Thinking Phase Validation Results ===\n');
    console.log(`Strict Mode: ${strictMode ? 'ON' : 'off'}`);
    console.log(`Files scanned: ${results.scanned}`);
    console.log(`Valid: ${results.valid}`);
    console.log(`Invalid: ${results.invalid}`);
    console.log(`Missing: ${results.missing}`);
    console.log(`With warnings: ${results.warnings}`);
    
    if (results.invalid > 0 || results.missing > 0 || results.warnings > 0) {
      console.log('\nDetails:');
      for (const f of results.files) {
        if (f.status !== 'valid') {
          console.log(`\n  [${f.status.toUpperCase()}] ${f.file}`);
          if (f.errors.length > 0) {
            f.errors.forEach(e => console.log(`    ERROR: ${e}`));
          }
          if (f.warnings.length > 0) {
            f.warnings.forEach(w => console.log(`    WARNING: ${w}`));
          }
        }
      }
    }
    
    console.log(`\n${finalResult.success ? '✓ All validations passed' : '✗ Validation failed'}`);
  } else {
    output(finalResult, false);
  }
}

/**
 * Rollback thinking_phase changes from a backup
 */
async function cmdThinkingRollback(cwd, options, raw) {
  const backupDir = options.backupDir || path.join(cwd, '.planning', 'thinking-backups');
  const commandsDir = options.commandsDir || path.join(cwd, 'commands', 'gsi');
  
  // Find the most recent apply-all backup metadata
  let backupMeta = null;
  let backupMetaPath = null;
  
  try {
    const files = fs.readdirSync(backupDir)
      .filter(f => f.startsWith('apply-all-') && f.endsWith('.json'))
      .sort()
      .reverse();
    
    if (files.length === 0) {
      const result = { success: false, error: 'No backup found to rollback' };
      output(result, raw);
      return;
    }
    
    // Use the most recent backup
    backupMetaPath = path.join(backupDir, files[0]);
    backupMeta = JSON.parse(fs.readFileSync(backupMetaPath, 'utf-8'));
    
  } catch (err) {
    const result = { success: false, error: `Failed to find backup: ${err.message}` };
    output(result, raw);
    return;
  }
  
  const results = {
    restored: 0,
    failed: 0,
    files: []
  };
  
  // Restore each backup file
  for (const backupPath of backupMeta.backups) {
    try {
      const backupFileName = path.basename(backupPath);
      // Extract original filename (remove timestamp and .bak)
      const originalName = backupFileName.replace(/\.\d{4}-\d{2}-\d{2}T[\d\-]+Z\.bak$/, '');
      const targetPath = path.join(commandsDir, originalName);
      
      if (!fs.existsSync(backupPath)) {
        results.failed++;
        results.files.push({
          backup: backupFileName,
          target: originalName,
          status: 'error',
          reason: 'Backup file not found'
        });
        continue;
      }
      
      // Restore the file
      const backupContent = fs.readFileSync(backupPath, 'utf-8');
      fs.writeFileSync(targetPath, backupContent, 'utf-8');
      
      results.restored++;
      results.files.push({
        backup: backupFileName,
        target: originalName,
        status: 'restored'
      });
      
    } catch (err) {
      results.failed++;
      results.files.push({
        backup: path.basename(backupPath),
        target: 'unknown',
        status: 'error',
        reason: err.message
      });
    }
  }
  
  const finalResult = {
    success: results.failed === 0,
    backup_timestamp: backupMeta.timestamp,
    ...results
  };
  
  if (raw || !options.json) {
    console.log('=== Thinking Phase Rollback Results ===\n');
    console.log(`Backup timestamp: ${backupMeta.timestamp}`);
    console.log(`Restored: ${results.restored}`);
    console.log(`Failed: ${results.failed}`);
    
    if (results.files.length > 0) {
      console.log('\nFiles:');
      for (const f of results.files) {
        const status = f.status === 'restored' ? '✓' : '✗';
        console.log(`  ${status} ${f.target}: ${f.status}`);
        if (f.reason) {
          console.log(`    Reason: ${f.reason}`);
        }
      }
    }
  } else {
    output(finalResult, false);
  }
}

/**
 * Show complexity analysis factors documentation
 */
async function cmdThinkingFactors(cwd, options, raw) {
  const { ThinkingOrchestrator } = await import('../lib/workflow-modules/thinking-orchestrator.js');
  const orchestrator = new ThinkingOrchestrator();
  
  const factors = orchestrator.getComplexityFactorDescriptions();
  const thresholds = orchestrator.getModeThresholds();
  
  const result = {
    factors,
    thresholds
  };
  
  if (raw || !options.json) {
    console.log('=== Thinking Complexity Factors (25 total) ===\n');
    
    // Group by category
    const categories = {};
    for (const [name, info] of Object.entries(factors)) {
      if (!categories[info.category]) {
        categories[info.category] = [];
      }
      categories[info.category].push({ name, ...info });
    }
    
    for (const [category, items] of Object.entries(categories)) {
      console.log(`\n## ${category} Factors (${items.length})`);
      for (const item of items) {
        console.log(`  - ${item.name}: ${item.description} (range: ${item.range})`);
      }
    }
    
    console.log('\n=== Mode Thresholds ===\n');
    for (const [mode, info] of Object.entries(thresholds)) {
      console.log(`${mode}: score ${info.min}-${info.max}`);
      console.log(`  ${info.description}`);
    }
  } else {
    output(result, false);
  }
}

// ─── Patch Manager Commands ─────────────────────────────────────────────────────

/**
 * Backup local modifications before GSI package update
 */
async function cmdPatchBackup(cwd, options, raw) {
  const patchesDir = options.patchesDir || path.join(process.env.USERPROFILE || process.env.HOME || '', '.claude', 'GSI-local-patches');
  
  try {
    // Dynamically import PatchManager (ES Module)
    const { PatchManager } = await import('../lib/workflow-modules/patch-manager.js');
    const manager = new PatchManager(patchesDir);
    
    console.log('Backing up local modifications...');
    const metadata = await manager.backup();
    
    const result = {
      success: true,
      version: metadata.version,
      timestamp: metadata.timestamp,
      files_backed_up: metadata.files.length,
      patches: metadata.patches.map(p => ({
        file: p.file,
        type: p.type,
        description: p.description
      })),
      backup_location: patchesDir
    };
    
    if (raw) {
      console.log(`Backed up ${metadata.files.length} files from version ${metadata.version}`);
      console.log(`Backup location: ${patchesDir}`);
    } else {
      output(result, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    if (raw) {
      console.error(`Backup failed: ${err.message}`);
      process.exit(1);
    } else {
      output(result, raw);
    }
  }
}

/**
 * Restore backed-up modifications after GSI package update
 */
async function cmdPatchRestore(cwd, options, raw) {
  const patchesDir = options.patchesDir || path.join(process.env.USERPROFILE || process.env.HOME || '', '.claude', 'GSI-local-patches');
  
  try {
    // Dynamically import PatchManager (ES Module)
    const { PatchManager } = await import('../lib/workflow-modules/patch-manager.js');
    const manager = new PatchManager(patchesDir);
    
    console.log('Restoring local modifications...');
    const results = await manager.restore();
    
    const mergedFiles = [];
    const conflictedFiles = [];
    
    for (const [filePath, mergeResult] of results) {
      if (mergeResult.success) {
        mergedFiles.push(filePath);
      } else {
        conflictedFiles.push({
          file: filePath,
          conflicts: mergeResult.conflicts
        });
      }
    }
    
    const result = {
      success: conflictedFiles.length === 0,
      files_restored: mergedFiles.length,
      files_with_conflicts: conflictedFiles.length,
      merged_files: mergedFiles,
      conflicted_files: conflictedFiles,
      backup_location: patchesDir
    };
    
    if (raw) {
      console.log(`Restored ${mergedFiles.length} files`);
      if (conflictedFiles.length > 0) {
        console.log(`Conflicts in ${conflictedFiles.length} files:`);
        conflictedFiles.forEach(f => console.log(`  - ${f.file}`));
      }
    } else {
      output(result, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    if (raw) {
      console.error(`Restore failed: ${err.message}`);
      process.exit(1);
    } else {
      output(result, raw);
    }
  }
}

/**
 * Show status of local modifications
 */
async function cmdPatchStatus(cwd, options, raw) {
  const patchesDir = options.patchesDir || path.join(process.env.USERPROFILE || process.env.HOME || '', '.claude', 'GSI-local-patches');
  const metadataPath = path.join(patchesDir, 'backup-meta.json');
  
  try {
    // Check if backup exists
    if (!fs.existsSync(metadataPath)) {
      const result = {
        has_backup: false,
        message: 'No backup found. Run "gsi patch backup" first.'
      };
      output(result, raw);
      return;
    }
    
    // Read backup metadata
    const metadata = JSON.parse(fs.readFileSync(metadataPath, 'utf-8'));
    
    const result = {
      has_backup: true,
      backup_version: metadata.version,
      backup_timestamp: metadata.timestamp,
      files_count: metadata.files.length,
      patches: metadata.patches,
      backup_location: patchesDir
    };
    
    if (raw) {
      console.log(`Backup exists for version ${metadata.version}`);
      console.log(`Created: ${metadata.timestamp}`);
      console.log(`Files: ${metadata.files.length}`);
      console.log(`Location: ${patchesDir}`);
    } else {
      output(result, raw);
    }
  } catch (err) {
    const result = { has_backup: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Show diff between backup and current files
 */
async function cmdPatchDiff(cwd, options, raw) {
  const patchesDir = options.patchesDir || path.join(process.env.USERPROFILE || process.env.HOME || '', '.claude', 'GSI-local-patches');
  const metadataPath = path.join(patchesDir, 'backup-meta.json');
  const gsiInstallDir = detectGSIInstallDir();
  
  try {
    // Check if backup exists
    if (!fs.existsSync(metadataPath)) {
      const result = {
        has_backup: false,
        message: 'No backup found. Run "gsi patch backup" first.'
      };
      output(result, raw);
      return;
    }
    
    const metadata = JSON.parse(fs.readFileSync(metadataPath, 'utf-8'));
    const diffs = [];
    
    for (const file of metadata.files) {
      const backupPath = path.join(patchesDir, file.path);
      const currentPath = path.join(gsiInstallDir, file.path);
      
      if (!fs.existsSync(backupPath) || !fs.existsSync(currentPath)) {
        continue;
      }
      
      const backupContent = fs.readFileSync(backupPath, 'utf-8');
      const currentContent = fs.readFileSync(currentPath, 'utf-8');
      
      const backupHash = createHash('sha256').update(backupContent).digest('hex');
      const currentHash = createHash('sha256').update(currentContent).digest('hex');
      
      if (backupHash !== currentHash) {
        diffs.push({
          file: file.path,
          backup_hash: backupHash.substring(0, 8),
          current_hash: currentHash.substring(0, 8),
          modified_since_backup: true
        });
      }
    }
    
    const result = {
      backup_version: metadata.version,
      backup_timestamp: metadata.timestamp,
      files_checked: metadata.files.length,
      files_different: diffs.length,
      diffs
    };
    
    if (raw) {
      if (diffs.length === 0) {
        console.log('No differences found between backup and current files.');
      } else {
        console.log(`Found ${diffs.length} files with differences:`);
        diffs.forEach(d => console.log(`  - ${d.file}`));
      }
    } else {
      output(result, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Detect GSI installation directory
 */
function detectGSIInstallDir() {
  // Check for global installation
  const globalPath = path.join(
    process.env.APPDATA || '',
    'npm',
    'node_modules',
    'get-shit-indexed-cc'
  );
  if (fs.existsSync(globalPath)) {
    return globalPath;
  }

  // Check for local installation
  const localPath = path.join(process.cwd(), 'node_modules', 'get-shit-indexed-cc');
  if (fs.existsSync(localPath)) {
    return localPath;
  }

  // Return current directory as fallback
  return process.cwd();
}

/**
 * Create hash helper for diff command
 */
function createHash(algorithm) {
  const crypto = require('crypto');
  return crypto.createHash(algorithm);
}

// ─── Workflow Chainer Commands ───────────────────────────────────────────────────

/**
 * Run a workflow chain
 */
async function cmdWorkflowRun(cwd, templateName, variables, options, raw) {
  const { WorkflowChainer } = require('../lib/workflow-modules/index.js');
  
  if (!templateName) {
    error('Template name required. Usage: gsi workflow run <template>');
  }
  
  const stateDir = options.stateDir || path.join(cwd, '.planning');
  const chainer = new WorkflowChainer(stateDir);
  
  // Load custom templates if templatesDir specified
  if (options.templatesDir) {
    const templatesPath = path.join(options.templatesDir, `${templateName}.json`);
    if (fs.existsSync(templatesPath)) {
      const templateDef = JSON.parse(fs.readFileSync(templatesPath, 'utf-8'));
      chainer.createChain(templateDef);
    }
  }
  
  try {
    const result = await chainer.run(templateName, variables, {
      failureStrategy: options.failureStrategy,
      yoloMode: options.yolo
    });
    
    if (raw) {
      console.log(`Workflow ${templateName}: ${result.success ? 'SUCCESS' : 'FAILED'}`);
      console.log(`Completed steps: ${result.completedSteps.length}`);
      console.log(`Duration: ${result.duration}ms`);
      if (result.error) {
        console.log(`Error: ${result.error}`);
      }
    }
    
    output(result, raw);
  } catch (err) {
    const result = { success: false, error: err.message, template: templateName };
    output(result, raw);
  }
}

/**
 * List available workflow templates
 */
async function cmdWorkflowList(cwd, options, raw) {
  const { WorkflowChainer } = require('../lib/workflow-modules/index.js');
  
  const stateDir = options.stateDir || path.join(cwd, '.planning');
  const chainer = new WorkflowChainer(stateDir);
  
  // Load custom templates from templates directory
  if (options.templatesDir && fs.existsSync(options.templatesDir)) {
    const templateFiles = fs.readdirSync(options.templatesDir).filter(f => f.endsWith('.json'));
    for (const file of templateFiles) {
      try {
        const templatePath = path.join(options.templatesDir, file);
        const templateDef = JSON.parse(fs.readFileSync(templatePath, 'utf-8'));
        chainer.createChain(templateDef);
      } catch (e) {
        // Skip invalid template files
      }
    }
  }
  
  const templates = chainer.listTemplates();
  
  const result = {
    count: templates.length,
    templates: templates.map(t => ({
      name: t.name,
      description: t.description,
      steps: t.chain.length,
      parallel_groups: t.parallel?.length || 0,
      checkpoint_strategy: t.checkpoint,
      rollback_enabled: t.rollback
    }))
  };
  
  if (raw) {
    console.log('Available workflow templates:');
    templates.forEach(t => {
      console.log(`  - ${t.name}: ${t.description}`);
      console.log(`    Steps: ${t.chain.length}, Checkpoint: ${t.checkpoint}`);
    });
  }
  
  output(result, raw);
}

/**
 * Get workflow status
 */
async function cmdWorkflowStatus(cwd, workflowName, options, raw) {
  const { WorkflowChainer } = require('../lib/workflow-modules/index.js');
  
  const stateDir = options.stateDir || path.join(cwd, '.planning');
  const chainer = new WorkflowChainer(stateDir);
  
  try {
    const status = chainer.getStatus(workflowName || undefined);
    
    if (raw) {
      if (Array.isArray(status)) {
        console.log(`Active workflows: ${status.length}`);
        status.forEach(s => {
          console.log(`  - ${s.chain}: ${s.status}`);
          console.log(`    Completed: ${s.completed.length}, Pending: ${s.pending.length}`);
        });
      } else {
        console.log(`Workflow: ${status.chain}`);
        console.log(`Status: ${status.status}`);
        console.log(`Started: ${status.startTime}`);
        console.log(`Completed: ${status.completed.length}`);
        console.log(`Pending: ${status.pending.length}`);
        if (status.current) {
          console.log(`Current: ${status.current}`);
        }
        if (status.checkpoint) {
          console.log(`Last checkpoint: ${status.checkpoint.timestamp}`);
        }
      }
    }
    
    output(status, raw);
  } catch (err) {
    const result = { error: err.message };
    output(result, raw);
  }
}

/**
 * Pause a running workflow
 */
async function cmdWorkflowPause(cwd, workflowName, options, raw) {
  const { WorkflowChainer } = require('../lib/workflow-modules/index.js');
  
  if (!workflowName) {
    error('Workflow name required. Usage: gsi workflow pause <name>');
  }
  
  const stateDir = options.stateDir || path.join(cwd, '.planning');
  const chainer = new WorkflowChainer(stateDir);
  
  try {
    await chainer.pause(workflowName);
    const result = { success: true, workflow: workflowName, status: 'paused' };
    
    if (raw) {
      console.log(`Workflow '${workflowName}' paused.`);
    }
    
    output(result, raw);
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Resume a paused workflow
 */
async function cmdWorkflowResume(cwd, workflowName, options, raw) {
  const { WorkflowChainer } = require('../lib/workflow-modules/index.js');
  
  if (!workflowName) {
    error('Workflow name required. Usage: gsi workflow resume <name>');
  }
  
  const stateDir = options.stateDir || path.join(cwd, '.planning');
  const chainer = new WorkflowChainer(stateDir);
  
  try {
    const result = await chainer.resume(workflowName);
    result.workflow = workflowName;
    
    if (raw) {
      console.log(`Workflow '${workflowName}' resumed.`);
      console.log(`Status: ${result.success ? 'SUCCESS' : 'FAILED'}`);
    }
    
    output(result, raw);
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Rollback a workflow to last checkpoint
 */
async function cmdWorkflowRollback(cwd, workflowName, options, raw) {
  const { WorkflowChainer } = require('../lib/workflow-modules/index.js');
  
  if (!workflowName) {
    error('Workflow name required. Usage: gsi workflow rollback <name>');
  }
  
  const stateDir = options.stateDir || path.join(cwd, '.planning');
  const chainer = new WorkflowChainer(stateDir);
  
  try {
    await chainer.rollback(workflowName);
    const result = { success: true, workflow: workflowName, status: 'rolled_back' };
    
    if (raw) {
      console.log(`Workflow '${workflowName}' rolled back to last checkpoint.`);
    }
    
    output(result, raw);
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

// ─── Pattern Discovery Commands (Phase 38-03) ───────────────────────────────────

/**
 * Mine patterns from command history
 */
async function cmdWorkflowDiscover(cwd, options, raw) {
  const { PatternMiner } = await import('../lib/workflow-modules/pattern-miner.js');
  
  const stateDir = options.stateDir || path.join(cwd, '.planning');
  const miner = new PatternMiner(stateDir);
  
  const miningOptions = {
    minFrequency: options.minFrequency || 2,
    minSuccessRate: options.minSuccessRate || 0.5,
    minLength: options.minLength || 2,
    maxLength: options.maxLength || 10
  };
  
  try {
    console.log('Mining patterns from command history...');
    const patterns = miner.minePatterns(miningOptions);
    
    // Generate templates for high-quality patterns
    const minQuality = options.minQuality || 50;
    const templatesGenerated = [];
    
    for (const pattern of patterns) {
      if (pattern.qualityScore >= minQuality) {
        const template = miner.generateTemplate(pattern.id);
        if (template) {
          const templatePath = miner.saveTemplate(template);
          templatesGenerated.push({ pattern_id: pattern.id, template_path: templatePath });
        }
      }
    }
    
    const result = {
      success: true,
      patterns_discovered: patterns.length,
      templates_generated: templatesGenerated.length,
      patterns: patterns.map(p => ({
        id: p.id,
        name: p.name,
        sequence: p.sequence,
        frequency: p.frequency,
        success_rate: Math.round(p.successRate * 100),
        quality_score: Math.round(p.qualityScore),
        avg_duration_ms: Math.round(p.avgDuration)
      })),
      templates: templatesGenerated
    };
    
    if (raw) {
      console.log(`Discovered ${patterns.length} patterns`);
      console.log(`Generated ${templatesGenerated.length} templates (quality >= ${minQuality})`);
      console.log('\nTop patterns:');
      patterns.slice(0, 5).forEach(p => {
        console.log(`  - ${p.name}: freq=${p.frequency}, success=${Math.round(p.successRate * 100)}%, quality=${Math.round(p.qualityScore)}`);
      });
    } else {
      output(result, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Get workflow recommendations based on current context
 */
async function cmdWorkflowRecommend(cwd, options, raw) {
  const { PatternMiner } = await import('../lib/workflow-modules/pattern-miner.js');
  
  const stateDir = options.stateDir || path.join(cwd, '.planning');
  const miner = new PatternMiner(stateDir);
  
  const context = {
    currentPhase: options.phase,
    recentCommands: options.recentCommands ? options.recentCommands.split(',') : [],
    workflowGoal: options.goal
  };
  
  try {
    const recommendations = miner.getRecommendations(context);
    
    const result = {
      success: true,
      context,
      recommendations_count: recommendations.length,
      recommendations: recommendations.map(r => ({
        pattern_id: r.pattern.id,
        pattern_name: r.pattern.name,
        relevance_score: Math.round(r.relevanceScore * 100),
        reason: r.reason,
        suggested_variables: r.suggestedVariables,
        sequence: r.pattern.sequence
      }))
    };
    
    if (raw) {
      if (recommendations.length === 0) {
        console.log('No recommendations found for the current context.');
        console.log('Try running some commands first or use "gsi workflow discover" to mine patterns.');
      } else {
        console.log(`Found ${recommendations.length} recommendations:\n`);
        recommendations.forEach((r, i) => {
          console.log(`${i + 1}. ${r.pattern.name} (${Math.round(r.relevanceScore * 100)}% relevant)`);
          console.log(`   ${r.reason}`);
          console.log(`   Sequence: ${r.pattern.sequence.join(' -> ')}`);
          if (Object.keys(r.suggestedVariables).length > 0) {
            console.log(`   Suggested vars: ${JSON.stringify(r.suggestedVariables)}`);
          }
          console.log('');
        });
      }
    } else {
      output(result, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Optimize a workflow by analyzing for improvements
 */
async function cmdWorkflowOptimize(cwd, workflowName, options, raw) {
  const { PatternMiner } = await import('../lib/workflow-modules/pattern-miner.js');
  
  if (!workflowName) {
    error('Workflow name required. Usage: gsi workflow optimize <name>');
  }
  
  const stateDir = options.stateDir || path.join(cwd, '.planning');
  const miner = new PatternMiner(stateDir);
  
  try {
    const optimizations = miner.analyzeOptimizations(workflowName);
    
    // Group by type
    const grouped = {
      parallel: optimizations.filter(o => o.type === 'parallel'),
      skip: optimizations.filter(o => o.type === 'skip'),
      reorder: optimizations.filter(o => o.type === 'reorder'),
      merge: optimizations.filter(o => o.type === 'merge')
    };
    
    const totalTimeSavings = optimizations.reduce((sum, o) => sum + o.estimatedTimeSavings, 0);
    
    const result = {
      success: true,
      workflow: workflowName,
      total_optimizations: optimizations.length,
      estimated_time_savings_ms: Math.round(totalTimeSavings),
      by_type: {
        parallel: grouped.parallel.length,
        skip: grouped.skip.length,
        reorder: grouped.reorder.length,
        merge: grouped.merge.length
      },
      optimizations: optimizations.map(o => ({
        type: o.type,
        steps: o.steps,
        description: o.description,
        estimated_savings_ms: Math.round(o.estimatedTimeSavings),
        risk_level: o.riskLevel
      }))
    };
    
    if (raw) {
      console.log(`Optimization analysis for '${workflowName}':`);
      console.log(`Total optimizations found: ${optimizations.length}`);
      console.log(`Estimated time savings: ${Math.round(totalTimeSavings / 1000)}s\n`);
      
      if (grouped.parallel.length > 0) {
        console.log('Parallel opportunities:');
        grouped.parallel.forEach(o => {
          console.log(`  - ${o.description}`);
          console.log(`    Savings: ${Math.round(o.estimatedTimeSavings / 1000)}s, Risk: ${o.riskLevel}`);
        });
        console.log('');
      }
      
      if (grouped.skip.length > 0) {
        console.log('Redundant steps to skip:');
        grouped.skip.forEach(o => {
          console.log(`  - ${o.description}`);
        });
        console.log('');
      }
      
      if (grouped.reorder.length > 0) {
        console.log('Reorder suggestions:');
        grouped.reorder.forEach(o => {
          console.log(`  - ${o.description}`);
        });
        console.log('');
      }
      
      if (grouped.merge.length > 0) {
        console.log('Merge opportunities:');
        grouped.merge.forEach(o => {
          console.log(`  - ${o.description}`);
        });
      }
    } else {
      output(result, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Analyze all workflows and patterns
 */
async function cmdWorkflowAnalyze(cwd, options, raw) {
  const { PatternMiner } = await import('../lib/workflow-modules/pattern-miner.js');
  
  const stateDir = options.stateDir || path.join(cwd, '.planning');
  const miner = new PatternMiner(stateDir);
  
  try {
    const analysis = miner.analyzeWorkflows();
    const stats = miner.getStats();
    
    const result = {
      success: true,
      stats: {
        total_executions: stats.totalExecutions,
        total_sequences: stats.totalSequences,
        successful_executions: stats.successfulExecutions,
        failed_executions: stats.failedExecutions,
        avg_execution_time_ms: Math.round(stats.avgExecutionTime),
        patterns_discovered: stats.patternsDiscovered,
        most_used_commands: stats.mostUsedCommands.slice(0, 10)
      },
      patterns: {
        total: analysis.patterns.length,
        top_patterns: analysis.topPatterns.map(p => ({
          id: p.id,
          name: p.name,
          quality_score: Math.round(p.qualityScore),
          frequency: p.frequency,
          success_rate: Math.round(p.successRate * 100)
        }))
      },
      optimization_opportunities: analysis.optimizationOpportunities,
      recommendations_count: analysis.recommendations.length
    };
    
    if (raw) {
      console.log('=== Workflow Analysis ===\n');
      console.log('Statistics:');
      console.log(`  Total executions: ${stats.totalExecutions}`);
      console.log(`  Total sequences: ${stats.totalSequences}`);
      console.log(`  Success rate: ${stats.totalExecutions > 0 ? Math.round(stats.successfulExecutions / stats.totalExecutions * 100) : 0}%`);
      console.log(`  Avg execution time: ${Math.round(stats.avgExecutionTime)}ms`);
      console.log(`  Patterns discovered: ${stats.patternsDiscovered}\n`);
      
      console.log('Most used commands:');
      stats.mostUsedCommands.slice(0, 5).forEach(c => {
        console.log(`  - ${c.command}: ${c.count} times`);
      });
      
      console.log('\nTop patterns by quality:');
      analysis.topPatterns.slice(0, 5).forEach(p => {
        console.log(`  - ${p.name}: quality=${Math.round(p.qualityScore)}, freq=${p.frequency}`);
      });
      
      console.log(`\nOptimization opportunities: ${analysis.optimizationOpportunities}`);
    } else {
      output(result, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Export a pattern as a workflow template
 */
async function cmdWorkflowExport(cwd, patternId, options, raw) {
  const { PatternMiner } = await import('../lib/workflow-modules/pattern-miner.js');
  
  if (!patternId) {
    error('Pattern ID required. Usage: gsi workflow export <pattern-id>');
  }
  
  const stateDir = options.stateDir || path.join(cwd, '.planning');
  const miner = new PatternMiner(stateDir);
  
  const outputPath = options.output;
  
  try {
    // Get pattern
    const pattern = miner.getPattern(patternId);
    if (!pattern) {
      const result = { success: false, error: `Pattern not found: ${patternId}` };
      output(result, raw);
      return;
    }
    
    // Generate template
    const template = miner.generateTemplate(patternId);
    if (!template) {
      const result = { success: false, error: 'Failed to generate template from pattern' };
      output(result, raw);
      return;
    }
    
    // Save template
    const templatePath = miner.saveTemplate(template);
    
    // Also export to stdout or file if output specified
    const templateJson = JSON.stringify(template, null, 2);
    
    if (outputPath) {
      fs.writeFileSync(outputPath, templateJson);
    }
    
    const result = {
      success: true,
      pattern_id: patternId,
      template_name: template.name,
      template_path: templatePath,
      output_path: outputPath || null,
      template: template
    };
    
    if (raw) {
      console.log(`Exported pattern '${patternId}' as template '${template.name}'`);
      console.log(`Template saved to: ${templatePath}`);
      if (outputPath) {
        console.log(`Also exported to: ${outputPath}`);
      }
      console.log('\nTemplate JSON:');
      console.log(templateJson);
    } else {
      output(result, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

// ─── Knowledge Base Commands ───────────────────────────────────────────────────

/**
 * Extract patterns from source files
 */
async function cmdKnowledgeExtract(cwd, sourcePath, options, raw) {
  const { KnowledgeBase } = await import('../lib/workflow-modules/knowledge-base.js');
  
  const knowledgeDir = options.knowledgeDir || path.join(cwd, '.planning', 'knowledge');
  const kb = new KnowledgeBase(knowledgeDir);
  
  if (!sourcePath) {
    error('Source path required. Usage: gsi knowledge extract <path> [--category <category>]');
  }
  
  try {
    const result = await kb.extract(sourcePath, options.category);
    
    if (raw) {
      console.log(`Extracted ${result.patternsExtracted.length} patterns from ${result.patternsFound} files`);
      console.log(`Templates: ${result.templatesGenerated.length}`);
      console.log(`Best Practices: ${result.bestPractices.length}`);
    } else {
      output({
        success: true,
        files_scanned: result.patternsFound,
        patterns_extracted: result.patternsExtracted.length,
        templates_generated: result.templatesGenerated.length,
        best_practices: result.bestPractices.length,
        patterns: result.patternsExtracted.map(p => ({
          id: p.id,
          name: p.name,
          category: p.category
        }))
      }, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Search knowledge base for patterns
 */
async function cmdKnowledgeSearch(cwd, query, options, raw) {
  const { KnowledgeBase } = await import('../lib/workflow-modules/knowledge-base.js');
  
  const knowledgeDir = options.knowledgeDir || path.join(cwd, '.planning', 'knowledge');
  const kb = new KnowledgeBase(knowledgeDir);
  
  if (!query) {
    error('Search query required. Usage: gsi knowledge search <query> [--category <category>] [--limit N]');
  }
  
  try {
    const results = kb.search(query, options.category);
    const limited = results.slice(0, options.limit || 20);
    
    if (raw) {
      console.log(`Found ${results.length} patterns (showing ${limited.length}):`);
      limited.forEach(p => {
        console.log(`\n[${p.id}] ${p.name}`);
        console.log(`  Category: ${p.category}`);
        console.log(`  Effectiveness: ${(p.effectiveness * 100).toFixed(0)}%`);
        console.log(`  ${p.description}`);
      });
    } else {
      output({
        success: true,
        query: query,
        total_matches: results.length,
        returned: limited.length,
        patterns: limited.map(p => ({
          id: p.id,
          name: p.name,
          category: p.category,
          description: p.description,
          effectiveness: p.effectiveness,
          uses: p.uses
        }))
      }, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Generate a skill from a pattern
 */
async function cmdKnowledgeGenerateSkill(cwd, patternId, options, raw) {
  const { KnowledgeBase } = await import('../lib/workflow-modules/knowledge-base.js');
  
  const knowledgeDir = options.knowledgeDir || path.join(cwd, '.planning', 'knowledge');
  const kb = new KnowledgeBase(knowledgeDir);
  
  if (!patternId) {
    error('Pattern ID required. Usage: gsi knowledge generate-skill <pattern-id>');
  }
  
  try {
    const skillPath = await kb.generateSkill(patternId);
    
    if (raw) {
      console.log(`Skill generated: ${skillPath}`);
    } else {
      output({
        success: true,
        pattern_id: patternId,
        skill_path: skillPath
      }, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * List all patterns in the knowledge base
 */
async function cmdKnowledgeList(cwd, options, raw) {
  const { KnowledgeBase } = await import('../lib/workflow-modules/knowledge-base.js');
  const fs = require('fs');
  
  const knowledgeDir = options.knowledgeDir || path.join(cwd, '.planning', 'knowledge');
  const patternsDir = path.join(knowledgeDir, 'patterns');
  const kb = new KnowledgeBase(knowledgeDir);
  
  try {
    const patterns = [];
    
    if (fs.existsSync(patternsDir)) {
      const categories = fs.readdirSync(patternsDir, { withFileTypes: true })
        .filter(d => d.isDirectory())
        .map(d => d.name);
      
      for (const category of categories) {
        const categoryDir = path.join(patternsDir, category);
        const files = fs.readdirSync(categoryDir).filter(f => f.endsWith('.json'));
        
        for (const file of files) {
          try {
            const pattern = JSON.parse(fs.readFileSync(path.join(categoryDir, file), 'utf-8'));
            patterns.push({
              id: pattern.id,
              name: pattern.name,
              category: pattern.category,
              effectiveness: pattern.effectiveness,
              uses: pattern.uses
            });
          } catch (e) {
            // Skip malformed files
          }
        }
      }
    }
    
    // Filter by category if specified
    const filtered = options.category 
      ? patterns.filter(p => p.category === options.category)
      : patterns;
    
    // Sort by effectiveness
    filtered.sort((a, b) => b.effectiveness - a.effectiveness);
    
    // Apply limit
    const limited = filtered.slice(0, options.limit || 50);
    
    if (raw) {
      console.log(`Knowledge Base: ${filtered.length} patterns`);
      limited.forEach(p => {
        console.log(`  [${p.category}] ${p.id}: ${p.name} (${(p.effectiveness * 100).toFixed(0)}%)`);
      });
    } else {
      output({
        success: true,
        total: filtered.length,
        returned: limited.length,
        patterns: limited
      }, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Show knowledge base statistics
 */
async function cmdKnowledgeStats(cwd, options, raw) {
  const { KnowledgeBase } = await import('../lib/workflow-modules/knowledge-base.js');
  const fs = require('fs');
  
  const knowledgeDir = options.knowledgeDir || path.join(cwd, '.planning', 'knowledge');
  const patternsDir = path.join(knowledgeDir, 'patterns');
  const templatesDir = path.join(knowledgeDir, 'templates');
  const practicesDir = path.join(knowledgeDir, 'best-practices');
  const indexFile = path.join(knowledgeDir, 'index.json');
  
  try {
    const stats = {
      knowledge_dir: knowledgeDir,
      exists: fs.existsSync(knowledgeDir),
      patterns: { total: 0, by_category: {} },
      templates: { total: 0 },
      best_practices: { total: 0 },
      artifacts: { total: 0, by_type: {} },
      index: null
    };
    
    // Count patterns by category
    if (fs.existsSync(patternsDir)) {
      const categories = fs.readdirSync(patternsDir, { withFileTypes: true })
        .filter(d => d.isDirectory())
        .map(d => d.name);
      
      for (const category of categories) {
        const categoryDir = path.join(patternsDir, category);
        const files = fs.readdirSync(categoryDir).filter(f => f.endsWith('.json'));
        stats.patterns.by_category[category] = files.length;
        stats.patterns.total += files.length;
      }
    }
    
    // Count templates
    if (fs.existsSync(templatesDir)) {
      stats.templates.total = fs.readdirSync(templatesDir).filter(f => f.endsWith('.json')).length;
    }
    
    // Count best practices
    if (fs.existsSync(practicesDir)) {
      stats.best_practices.total = fs.readdirSync(practicesDir).filter(f => f.endsWith('.md')).length;
    }
    
    // Count generated artifacts by type
    const artifactTypes = ['skills', 'agents', 'logic', 'functions', 'features', 'improvements', 'ideas'];
    for (const type of artifactTypes) {
      const typeDir = path.join(knowledgeDir, type);
      if (fs.existsSync(typeDir)) {
        const count = fs.readdirSync(typeDir).length;
        stats.artifacts.by_type[type] = count;
        stats.artifacts.total += count;
      }
    }
    
    // Load index if exists
    if (fs.existsSync(indexFile)) {
      stats.index = JSON.parse(fs.readFileSync(indexFile, 'utf-8'));
    }
    
    if (raw) {
      console.log('=== Knowledge Base Statistics ===');
      console.log(`Directory: ${stats.knowledge_dir}`);
      console.log(`Exists: ${stats.exists}`);
      console.log(`\nPatterns: ${stats.patterns.total}`);
      for (const [cat, count] of Object.entries(stats.patterns.by_category)) {
        console.log(`  ${cat}: ${count}`);
      }
      console.log(`\nTemplates: ${stats.templates.total}`);
      console.log(`Best Practices: ${stats.best_practices.total}`);
      console.log(`\nGenerated Artifacts: ${stats.artifacts.total}`);
      for (const [type, count] of Object.entries(stats.artifacts.by_type)) {
        console.log(`  ${type}: ${count}`);
      }
      if (stats.index) {
        console.log(`\nLast Updated: ${stats.index.lastUpdated}`);
      }
    } else {
      output(stats, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

// ─── Multi-Type Artifact Generation Commands (Phase 38-01) ────────────────────

/**
 * Generate all artifact types from a pattern
 */
async function cmdKnowledgeGenerateAll(cwd, patternId, options, raw) {
  const { KnowledgeBase } = await import('../lib/workflow-modules/knowledge-base.js');
  
  const knowledgeDir = options.knowledgeDir || path.join(cwd, '.planning', 'knowledge');
  const kb = new KnowledgeBase(knowledgeDir);
  
  if (!patternId) {
    error('Pattern ID required. Usage: gsi knowledge generate-all <pattern-id>');
  }
  
  try {
    const result = await kb.generateAllArtifacts(patternId);
    
    if (raw) {
      console.log(`Generated ${result.artifacts.length} artifacts for pattern ${patternId}:`);
      result.artifacts.forEach(a => {
        console.log(`  - ${a.type}: ${a.file_path}`);
      });
      if (result.errors.length > 0) {
        console.log('\nErrors:');
        result.errors.forEach(e => console.log(`  - ${e}`));
      }
    } else {
      output({
        success: result.success,
        pattern_id: patternId,
        artifacts_generated: result.artifacts.length,
        artifacts: result.artifacts.map(a => ({
          type: a.type,
          id: a.id,
          name: a.name,
          file_path: a.file_path
        })),
        errors: result.errors
      }, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Generate a specific artifact type from a pattern
 */
async function cmdKnowledgeGenerateArtifact(cwd, patternId, artifactType, options, raw) {
  const { KnowledgeBase } = await import('../lib/workflow-modules/knowledge-base.js');
  
  const knowledgeDir = options.knowledgeDir || path.join(cwd, '.planning', 'knowledge');
  const kb = new KnowledgeBase(knowledgeDir);
  
  if (!patternId) {
    error('Pattern ID required. Usage: gsi knowledge generate <pattern-id> <type>');
  }
  
  if (!artifactType) {
    error('Artifact type required. Available types: skill, agent, logic, function, feature, improvement, idea');
  }
  
  // Normalize type to uppercase
  const type = artifactType.toUpperCase();
  const validTypes = ['SKILL', 'AGENT', 'LOGIC', 'FUNCTION', 'FEATURE', 'IMPROVEMENT', 'IDEA'];
  
  if (!validTypes.includes(type)) {
    error(`Invalid artifact type: ${artifactType}. Valid types: ${validTypes.map(t => t.toLowerCase()).join(', ')}`);
  }
  
  try {
    const artifact = await kb.generateArtifact(patternId, type);
    
    if (raw) {
      console.log(`Generated ${type} artifact:`);
      console.log(`  ID: ${artifact.id}`);
      console.log(`  Name: ${artifact.name}`);
      console.log(`  Path: ${artifact.file_path}`);
    } else {
      output({
        success: true,
        type: artifact.type,
        id: artifact.id,
        name: artifact.name,
        description: artifact.description,
        file_path: artifact.file_path,
        created_at: artifact.created_at,
        metadata: artifact.metadata
      }, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * List available artifact types
 */
async function cmdKnowledgeArtifactTypes(cwd, options, raw) {
  const types = [
    { type: 'SKILL', description: 'Claude Code skill for reuse' },
    { type: 'AGENT', description: 'GSI agent definition with thinking config' },
    { type: 'LOGIC', description: 'TypeScript logic module with interfaces' },
    { type: 'FUNCTION', description: 'Reusable TypeScript function' },
    { type: 'FEATURE', description: 'Feature specification document' },
    { type: 'IMPROVEMENT', description: 'Improvement suggestions with rationale' },
    { type: 'IDEA', description: 'Visionary idea and concept proposal' }
  ];
  
  if (raw) {
    console.log('Available Artifact Types:');
    types.forEach(t => {
      console.log(`  ${t.type.toLowerCase()}: ${t.description}`);
    });
  } else {
    output({ types }, raw);
  }
}

/**
 * Extract patterns and generate artifacts in one operation
 */
async function cmdKnowledgeExtractGenerate(cwd, sourcePath, options, raw) {
  const { KnowledgeBase } = await import('../lib/workflow-modules/knowledge-base.js');
  
  const knowledgeDir = options.knowledgeDir || path.join(cwd, '.planning', 'knowledge');
  const kb = new KnowledgeBase(knowledgeDir);
  
  if (!sourcePath) {
    error('Source path required. Usage: gsi knowledge extract-generate <path> [--types type1,type2]');
  }
  
  // Parse artifact types if specified
  let artifactTypes = null;
  if (options.types) {
    artifactTypes = options.types.split(',').map(t => t.trim().toUpperCase());
  }
  
  try {
    const result = await kb.extractAndGenerate(sourcePath, options.category, artifactTypes);
    
    // Count total artifacts
    let totalArtifacts = 0;
    result.generations.forEach(g => totalArtifacts += g.artifacts.length);
    
    if (raw) {
      console.log(`Extracted ${result.extraction.patternsExtracted.length} patterns`);
      console.log(`Generated ${totalArtifacts} artifacts`);
      
      result.generations.forEach(g => {
        console.log(`\nPattern: ${g.pattern?.id || 'unknown'}`);
        g.artifacts.forEach(a => {
          console.log(`  - ${a.type}: ${a.file_path}`);
        });
      });
    } else {
      output({
        success: true,
        extraction: {
          files_scanned: result.extraction.patternsFound,
          patterns_extracted: result.extraction.patternsExtracted.length,
          patterns: result.extraction.patternsExtracted.map(p => ({
            id: p.id,
            name: p.name,
            category: p.category
          }))
        },
        generation: {
          total_artifacts: totalArtifacts,
          patterns_processed: result.generations.length,
          generations: result.generations.map(g => ({
            pattern_id: g.pattern?.id,
            artifacts: g.artifacts.map(a => ({
              type: a.type,
              file_path: a.file_path
            })),
            success: g.success,
            errors: g.errors
          }))
        }
      }, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Batch generate artifacts for multiple patterns
 */
async function cmdKnowledgeBatchGenerate(cwd, patternIds, options, raw) {
  const { KnowledgeBase } = await import('../lib/workflow-modules/knowledge-base.js');
  
  const knowledgeDir = options.knowledgeDir || path.join(cwd, '.planning', 'knowledge');
  const kb = new KnowledgeBase(knowledgeDir);
  
  if (!patternIds || patternIds.length === 0) {
    error('Pattern IDs required. Usage: gsi knowledge batch-generate <id1,id2,...> --types type1,type2');
  }
  
  // Parse types
  const types = options.types 
    ? options.types.split(',').map(t => t.trim().toUpperCase())
    : ['SKILL', 'AGENT', 'FEATURE', 'IDEA'];
  
  try {
    const results = await kb.batchGenerate(patternIds, types);
    
    // Aggregate stats
    let totalArtifacts = 0;
    let successCount = 0;
    let failCount = 0;
    
    results.forEach((result, id) => {
      totalArtifacts += result.artifacts.length;
      if (result.success) successCount++;
      else failCount++;
    });
    
    if (raw) {
      console.log(`Batch generation complete:`);
      console.log(`  Patterns: ${results.size}`);
      console.log(`  Successful: ${successCount}`);
      console.log(`  Failed: ${failCount}`);
      console.log(`  Total artifacts: ${totalArtifacts}`);
      
      results.forEach((result, id) => {
        console.log(`\n${id}: ${result.success ? 'SUCCESS' : 'FAILED'}`);
        result.artifacts.forEach(a => {
          console.log(`  - ${a.type}: ${a.file_path}`);
        });
        if (result.errors.length > 0) {
          result.errors.forEach(e => console.log(`  ERROR: ${e}`));
        }
      });
    } else {
      const output_results = {};
      results.forEach((result, id) => {
        output_results[id] = {
          success: result.success,
          artifacts: result.artifacts.map(a => ({
            type: a.type,
            file_path: a.file_path
          })),
          errors: result.errors
        };
      });
      
      output({
        success: failCount === 0,
        summary: {
          total_patterns: results.size,
          successful: successCount,
          failed: failCount,
          total_artifacts: totalArtifacts
        },
        types_generated: types,
        results: output_results
      }, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

// ─── GSD Integration Commands ───────────────────────────────────────────────────

async function cmdCheckGSDUpdates(cwd, options, raw) {
  const { hasUpdateAvailable } = require('../lib/gsi-integration/version-checker');
  const { downloadGSDPackage, cleanupDownload } = require('../lib/gsi-integration/downloader');
  const { analyzeChanges } = require('../lib/gsi-integration/change-analyzer');
  const { categorizeChanges, assessChanges } = require('../lib/gsi-integration/change-analyzer');
  const { suggestIntegrations, generateIntegrationPlan } = require('../lib/gsi-integration/suggester');
  const { recordUpdate } = require('../lib/gsi-integration/tracker');

  try {
    console.log('Checking for GSD updates...');
    const updateInfo = await hasUpdateAvailable();

    if (updateInfo.cached) {
      console.log(`(Using cached check from ${new Date(updateInfo.lastCheck).toLocaleString()})`);
    }

    if (!updateInfo.hasUpdate) {
      console.log('No updates available.');
      console.log(`Current: ${updateInfo.installedVersion || 'unknown'}`);
      console.log(`Latest: ${updateInfo.latestVersion}`);
      return;
    }

    console.log(`Update available!`);
    console.log(`Current: ${updateInfo.installedVersion || 'unknown'}`);
    console.log(`Latest: ${updateInfo.latestVersion}`);

    // Download and analyze
    console.log('\nDownloading package...');
    const { packageDir, tempDir } = await downloadGSDPackage(updateInfo.latestVersion);

    try {
      console.log('Analyzing changes...');
      const changes = await analyzeChanges(cwd, packageDir);
      const categorized = categorizeChanges(changes);
      const impact = await assessChanges(changes, cwd);

      // Record detection
      await recordUpdate(updateInfo.latestVersion, changes);

      // Display summary
      console.log('\n=== Change Summary ===');
      console.log(`Total changes: ${changes.total}`);
      console.log(`  Added: ${changes.added.length}`);
      console.log(`  Removed: ${changes.removed.length}`);
      console.log(`  Modified: ${changes.modified.length}`);

      console.log('\n=== Categories ===');
      for (const [category, items] of Object.entries(categorized)) {
        if (items.length > 0) {
          console.log(`${category}: ${items.length}`);
        }
      }

      // Generate suggestions
      const suggestions = suggestIntegrations(categorized, impact);
      if (suggestions.length > 0) {
        console.log(`\n=== Integratable Changes (${suggestions.length}) ===`);
        suggestions.slice(0, 10).forEach(s => {
          console.log(`  [${s.priority}] ${s.description}`);
        });

        if (suggestions.length > 10) {
          console.log(`  ... and ${suggestions.length - 10} more`);
        }

        console.log(`\nRun 'gsi integrate-gsd-change <id>' to integrate a specific change`);
      }

      // Generate plan
      const plan = generateIntegrationPlan(suggestions);
      console.log(`\n=== Integration Plan ===`);
      console.log(`Estimated effort: ${plan.estimatedEffort}`);
      console.log(`Phases: ${plan.steps.length}`);
      plan.steps.forEach(step => {
        console.log(`  - ${step.phase}: ${step.changes.length} changes`);
      });

      if (plan.warnings.length > 0) {
        console.log(`\nWarnings:`);
        plan.warnings.forEach(w => console.log(`  ⚠️  ${w}`));
      }

    } finally {
      await cleanupDownload(tempDir);
    }

  } catch (error) {
    console.error(`Error checking for updates: ${error.message}`);
    process.exit(1);
  }
}

function cmdIntegrateGSDChange(cwd, changeId, raw) {
  const { getUpdateHistory } = require('../lib/gsi-integration/tracker');
  const { recordIntegration } = require('../lib/gsi-integration/tracker');
  const { downloadGSDPackage, cleanupDownload } = require('../lib/gsi-integration/downloader');
  const { analyzeChanges, categorizeChanges, assessChanges } = require('../lib/gsi-integration/change-analyzer');
  const { suggestIntegrations, createMergeStrategy } = require('../lib/gsi-integration/suggester');
  const fs = require('fs').promises;
  const path = require('path');

  (async () => {
    try {
      // Find change in recent history
      const history = await getUpdateHistory(5);
      let targetChange = null;
      let targetVersion = null;

      for (const entry of history) {
        // This is simplified - in reality we'd need to store suggestions
        // For now, just show a message
        console.log(`Checking version ${entry.version}...`);
      }

      console.log(`Change integration not yet implemented.`);
      console.log(`Change ID: ${changeId}`);
      console.log(`\nThis would:`);
      console.log(`1. Locate the change in the downloaded package`);
      console.log(`2. Apply the merge strategy`);
      console.log(`3. Update tracking file`);
      console.log(`4. Commit the integration`);

    } catch (error) {
      console.error(`Error integrating change: ${error.message}`);
      process.exit(1);
    }
  })();
}

async function cmdGSDUpdateHistory(cwd, options, raw) {
  const { getUpdateHistory, getIntegratedChanges, getDeferredChanges, getIntegrationStats } = require('../lib/gsi-integration/tracker');

  try {
    const history = await getUpdateHistory(20);
    const integrated = await getIntegratedChanges();
    const deferred = await getDeferredChanges();
    const stats = await getIntegrationStats();

    const result = {
      stats,
      recent_detections: history,
      integrations: integrated.slice(-20),
      deferred: deferred.slice(-20)
    };

    if (raw) {
      console.log(`=== GSD Update History ===`);
      console.log(`\nStatistics:`);
      console.log(`  Versions detected: ${stats.totalDetected}`);
      console.log(`  Changes integrated: ${stats.totalIntegrated}`);
      console.log(`  Changes deferred: ${stats.totalDeferred}`);
      console.log(`  Integration rate: ${stats.integrationRate}%`);

      if (history.length > 0) {
        console.log(`\nRecent detections:`);
        history.forEach(h => {
          console.log(`  ${h.version} (${new Date(h.detectedAt).toLocaleDateString()}): ${h.changes.total} changes`);
        });
      }

      if (integrated.length > 0) {
        console.log(`\nRecent integrations:`);
        integrated.slice(-10).forEach(i => {
          console.log(`  ${i.changeId} (${i.version}): ${i.status}`);
        });
      }
    } else {
      output(result, raw);
    }

  } catch (error) {
    console.error(`Error getting history: ${error.message}`);
    process.exit(1);
  }
}

// ─── Install Detection Commands ───────────────────────────────────────────────

function cmdInstallInfo(cwd, options, raw) {
  const { forceGlobal, forceProject } = options;
  
  try {
    const { detectInstallLocation, getGlobalInstallPath } = require('../lib/context/install-detector');
    const { getAllDataPaths, getPlanningPath } = require('../lib/context/path-resolver');
    
    const location = detectInstallLocation({
      cwd,
      forceGlobal,
      forceProject,
      noCache: true // Always detect fresh for info command
    });
    
    const dataPaths = getAllDataPaths({ cwd, forceGlobal, forceProject });
    
    const result = {
      type: location.type,
      basePath: location.basePath,
      globalPath: getGlobalInstallPath(),
      indicators: location.indicators,
      dataPaths,
      cwd
    };
    
    if (!raw) {
      console.log('=== GSI Install Context ===\n');
      console.log(`Install Type: ${location.type.toUpperCase()}`);
      console.log(`Base Path: ${location.basePath}`);
      console.log(`Global Path: ${getGlobalInstallPath()}`);
      console.log(`Current Directory: ${cwd}`);
      console.log(`\nDetection Indicators:`);
      location.indicators.forEach(i => console.log(`  - ${i}`));
      console.log(`\nData Paths:`);
      for (const [type, p] of Object.entries(dataPaths)) {
        if (typeof p === 'string') {
          console.log(`  ${type}: ${p}`);
        } else {
          console.log(`  ${type}: ERROR - ${p.error}`);
        }
      }
      console.log(`\nPlanning Path: ${getPlanningPath({ cwd, forceGlobal, forceProject })}`);
    } else {
      output(result, raw);
    }
  } catch (error) {
    console.error(`Error detecting install info: ${error.message}`);
    process.exit(1);
  }
}

// ─── CLI Router ───────────────────────────────────────────────────────────────

async function main() {
  const args = process.argv.slice(2);
  const rawIndex = args.indexOf('--raw');
  const raw = rawIndex !== -1;
  if (rawIndex !== -1) args.splice(rawIndex, 1);

  const command = args[0];
  const cwd = process.cwd();

  if (!command) {
    error('Usage: GSI-tools <command> [args] [--raw]\nCommands: state, install-info, resolve-model, find-phase, commit, verify-summary, verify, frontmatter, template, generate-slug, current-timestamp, list-todos, verify-path-exists, config-ensure-section, reflection, check-gsd-updates, integrate-gsd-change, gsd-update-history, init');
  }

  switch (command) {
    case 'install-info': {
      const forceGlobal = args.includes('--force-global');
      const forceProject = args.includes('--force-project');
      cmdInstallInfo(cwd, { forceGlobal, forceProject }, raw);
      break;
    }

    case 'state': {
      const subcommand = args[1];
      if (subcommand === 'update') {
        cmdStateUpdate(cwd, args[2], args[3]);
      } else if (subcommand === 'get') {
        cmdStateGet(cwd, args[2], raw);
      } else if (subcommand === 'patch') {
        const patches = {};
        for (let i = 2; i < args.length; i += 2) {
          const key = args[i].replace(/^--/, '');
          const value = args[i + 1];
          if (key && value !== undefined) {
            patches[key] = value;
          }
        }
        cmdStatePatch(cwd, patches, raw);
      } else if (subcommand === 'advance-plan') {
        cmdStateAdvancePlan(cwd, raw);
      } else if (subcommand === 'record-metric') {
        const phaseIdx = args.indexOf('--phase');
        const planIdx = args.indexOf('--plan');
        const durationIdx = args.indexOf('--duration');
        const tasksIdx = args.indexOf('--tasks');
        const filesIdx = args.indexOf('--files');
        cmdStateRecordMetric(cwd, {
          phase: phaseIdx !== -1 ? args[phaseIdx + 1] : null,
          plan: planIdx !== -1 ? args[planIdx + 1] : null,
          duration: durationIdx !== -1 ? args[durationIdx + 1] : null,
          tasks: tasksIdx !== -1 ? args[tasksIdx + 1] : null,
          files: filesIdx !== -1 ? args[filesIdx + 1] : null,
        }, raw);
      } else if (subcommand === 'update-progress') {
        cmdStateUpdateProgress(cwd, raw);
      } else if (subcommand === 'add-decision') {
        const phaseIdx = args.indexOf('--phase');
        const summaryIdx = args.indexOf('--summary');
        const rationaleIdx = args.indexOf('--rationale');
        cmdStateAddDecision(cwd, {
          phase: phaseIdx !== -1 ? args[phaseIdx + 1] : null,
          summary: summaryIdx !== -1 ? args[summaryIdx + 1] : null,
          rationale: rationaleIdx !== -1 ? args[rationaleIdx + 1] : '',
        }, raw);
      } else if (subcommand === 'add-blocker') {
        const textIdx = args.indexOf('--text');
        cmdStateAddBlocker(cwd, textIdx !== -1 ? args[textIdx + 1] : null, raw);
      } else if (subcommand === 'resolve-blocker') {
        const textIdx = args.indexOf('--text');
        cmdStateResolveBlocker(cwd, textIdx !== -1 ? args[textIdx + 1] : null, raw);
      } else if (subcommand === 'record-session') {
        const stoppedIdx = args.indexOf('--stopped-at');
        const resumeIdx = args.indexOf('--resume-file');
        cmdStateRecordSession(cwd, {
          stopped_at: stoppedIdx !== -1 ? args[stoppedIdx + 1] : null,
          resume_file: resumeIdx !== -1 ? args[resumeIdx + 1] : 'None',
        }, raw);
      } else {
        cmdStateLoad(cwd, raw);
      }
      break;
    }

    case 'resolve-model': {
      cmdResolveModel(cwd, args[1], raw);
      break;
    }

    case 'find-phase': {
      cmdFindPhase(cwd, args[1], raw);
      break;
    }

    case 'commit': {
      const amend = args.includes('--amend');
      const message = args[1];
      // Parse --files flag (collect args after --files, stopping at other flags)
      const filesIndex = args.indexOf('--files');
      const files = filesIndex !== -1 ? args.slice(filesIndex + 1).filter(a => !a.startsWith('--')) : [];
      cmdCommit(cwd, message, files, raw, amend);
      break;
    }

    case 'verify-summary': {
      const summaryPath = args[1];
      const countIndex = args.indexOf('--check-count');
      const checkCount = countIndex !== -1 ? parseInt(args[countIndex + 1], 10) : 2;
      cmdVerifySummary(cwd, summaryPath, checkCount, raw);
      break;
    }

    case 'template': {
      const subcommand = args[1];
      if (subcommand === 'select') {
        cmdTemplateSelect(cwd, args[2], raw);
      } else if (subcommand === 'fill') {
        const templateType = args[2];
        const phaseIdx = args.indexOf('--phase');
        const planIdx = args.indexOf('--plan');
        const nameIdx = args.indexOf('--name');
        const typeIdx = args.indexOf('--type');
        const waveIdx = args.indexOf('--wave');
        const fieldsIdx = args.indexOf('--fields');
        cmdTemplateFill(cwd, templateType, {
          phase: phaseIdx !== -1 ? args[phaseIdx + 1] : null,
          plan: planIdx !== -1 ? args[planIdx + 1] : null,
          name: nameIdx !== -1 ? args[nameIdx + 1] : null,
          type: typeIdx !== -1 ? args[typeIdx + 1] : 'execute',
          wave: waveIdx !== -1 ? args[waveIdx + 1] : '1',
          fields: fieldsIdx !== -1 ? JSON.parse(args[fieldsIdx + 1]) : {},
        }, raw);
      } else {
        error('Unknown template subcommand. Available: select, fill');
      }
      break;
    }

    case 'frontmatter': {
      const subcommand = args[1];
      const file = args[2];
      if (subcommand === 'get') {
        const fieldIdx = args.indexOf('--field');
        cmdFrontmatterGet(cwd, file, fieldIdx !== -1 ? args[fieldIdx + 1] : null, raw);
      } else if (subcommand === 'set') {
        const fieldIdx = args.indexOf('--field');
        const valueIdx = args.indexOf('--value');
        cmdFrontmatterSet(cwd, file, fieldIdx !== -1 ? args[fieldIdx + 1] : null, valueIdx !== -1 ? args[valueIdx + 1] : undefined, raw);
      } else if (subcommand === 'merge') {
        const dataIdx = args.indexOf('--data');
        cmdFrontmatterMerge(cwd, file, dataIdx !== -1 ? args[dataIdx + 1] : null, raw);
      } else if (subcommand === 'validate') {
        const schemaIdx = args.indexOf('--schema');
        cmdFrontmatterValidate(cwd, file, schemaIdx !== -1 ? args[schemaIdx + 1] : null, raw);
      } else {
        error('Unknown frontmatter subcommand. Available: get, set, merge, validate');
      }
      break;
    }

    case 'verify': {
      const subcommand = args[1];
      if (subcommand === 'plan-structure') {
        cmdVerifyPlanStructure(cwd, args[2], raw);
      } else if (subcommand === 'phase-completeness') {
        cmdVerifyPhaseCompleteness(cwd, args[2], raw);
      } else if (subcommand === 'references') {
        cmdVerifyReferences(cwd, args[2], raw);
      } else if (subcommand === 'commits') {
        cmdVerifyCommits(cwd, args.slice(2), raw);
      } else if (subcommand === 'artifacts') {
        cmdVerifyArtifacts(cwd, args[2], raw);
      } else if (subcommand === 'key-links') {
        cmdVerifyKeyLinks(cwd, args[2], raw);
      } else {
        error('Unknown verify subcommand. Available: plan-structure, phase-completeness, references, commits, artifacts, key-links');
      }
      break;
    }

    case 'generate-slug': {
      cmdGenerateSlug(args[1], raw);
      break;
    }

    case 'current-timestamp': {
      cmdCurrentTimestamp(args[1] || 'full', raw);
      break;
    }

    case 'list-todos': {
      cmdListTodos(cwd, args[1], raw);
      break;
    }

    case 'verify-path-exists': {
      cmdVerifyPathExists(cwd, args[1], raw);
      break;
    }

    case 'config-ensure-section': {
      cmdConfigEnsureSection(cwd, raw);
      break;
    }

    case 'config-set': {
      cmdConfigSet(cwd, args[1], args[2], raw);
      break;
    }

    case 'history-digest': {
      cmdHistoryDigest(cwd, raw);
      break;
    }

    case 'phases': {
      const subcommand = args[1];
      if (subcommand === 'list') {
        const typeIndex = args.indexOf('--type');
        const phaseIndex = args.indexOf('--phase');
        const options = {
          type: typeIndex !== -1 ? args[typeIndex + 1] : null,
          phase: phaseIndex !== -1 ? args[phaseIndex + 1] : null,
        };
        cmdPhasesList(cwd, options, raw);
      } else {
        error('Unknown phases subcommand. Available: list');
      }
      break;
    }

    case 'roadmap': {
      const subcommand = args[1];
      if (subcommand === 'get-phase') {
        cmdRoadmapGetPhase(cwd, args[2], raw);
      } else if (subcommand === 'analyze') {
        cmdRoadmapAnalyze(cwd, raw);
      } else {
        error('Unknown roadmap subcommand. Available: get-phase, analyze');
      }
      break;
    }

    case 'phase': {
      const subcommand = args[1];
      if (subcommand === 'next-decimal') {
        cmdPhaseNextDecimal(cwd, args[2], raw);
      } else if (subcommand === 'add') {
        cmdPhaseAdd(cwd, args.slice(2).join(' '), raw);
      } else if (subcommand === 'insert') {
        cmdPhaseInsert(cwd, args[2], args.slice(3).join(' '), raw);
      } else if (subcommand === 'remove') {
        const forceFlag = args.includes('--force');
        cmdPhaseRemove(cwd, args[2], { force: forceFlag }, raw);
      } else if (subcommand === 'complete') {
        cmdPhaseComplete(cwd, args[2], raw);
      } else {
        error('Unknown phase subcommand. Available: next-decimal, add, insert, remove, complete');
      }
      break;
    }

    case 'milestone': {
      const subcommand = args[1];
      if (subcommand === 'complete') {
        const nameIndex = args.indexOf('--name');
        const milestoneName = nameIndex !== -1 ? args.slice(nameIndex + 1).join(' ') : null;
        cmdMilestoneComplete(cwd, args[2], { name: milestoneName }, raw);
      } else {
        error('Unknown milestone subcommand. Available: complete');
      }
      break;
    }

    case 'validate': {
      const subcommand = args[1];
      if (subcommand === 'consistency') {
        cmdValidateConsistency(cwd, raw);
      } else {
        error('Unknown validate subcommand. Available: consistency');
      }
      break;
    }

    case 'progress': {
      const subcommand = args[1] || 'json';
      if (subcommand === 'pattern-learning' || subcommand === 'patterns') {
        await cmdProgressPatterns(cwd, raw);
      } else {
        cmdProgressRender(cwd, subcommand, raw);
      }
      break;
    }

    case 'todo': {
      const subcommand = args[1];
      if (subcommand === 'complete') {
        cmdTodoComplete(cwd, args[2], raw);
      } else {
        error('Unknown todo subcommand. Available: complete');
      }
      break;
    }

    case 'scaffold': {
      const scaffoldType = args[1];
      const phaseIndex = args.indexOf('--phase');
      const nameIndex = args.indexOf('--name');
      const scaffoldOptions = {
        phase: phaseIndex !== -1 ? args[phaseIndex + 1] : null,
        name: nameIndex !== -1 ? args.slice(nameIndex + 1).join(' ') : null,
      };
      cmdScaffold(cwd, scaffoldType, scaffoldOptions, raw);
      break;
    }

    case 'init': {
      const workflow = args[1];
      const includes = parseIncludeFlag(args);
      switch (workflow) {
        case 'execute-phase':
          cmdInitExecutePhase(cwd, args[2], includes, raw);
          break;
        case 'plan-phase':
          cmdInitPlanPhase(cwd, args[2], includes, raw);
          break;
        case 'new-project':
          cmdInitNewProject(cwd, raw);
          break;
        case 'new-milestone':
          cmdInitNewMilestone(cwd, raw);
          break;
        case 'quick':
          cmdInitQuick(cwd, args.slice(2).join(' '), raw);
          break;
        case 'resume':
          cmdInitResume(cwd, raw);
          break;
        case 'verify-work':
          cmdInitVerifyWork(cwd, args[2], raw);
          break;
        case 'phase-op':
          cmdInitPhaseOp(cwd, args[2], raw);
          break;
        case 'todos':
          cmdInitTodos(cwd, args[2], raw);
          break;
        case 'milestone-op':
          cmdInitMilestoneOp(cwd, raw);
          break;
        case 'map-codebase':
          cmdInitMapCodebase(cwd, raw);
          break;
        case 'progress':
          cmdInitProgress(cwd, includes, raw);
          break;
        default:
          error(`Unknown init workflow: ${workflow}\nAvailable: execute-phase, plan-phase, new-project, new-milestone, quick, resume, verify-work, phase-op, todos, milestone-op, map-codebase, progress`);
      }
      break;
    }

    case 'phase-plan-index': {
      cmdPhasePlanIndex(cwd, args[1], raw);
      break;
    }

    case 'state-snapshot': {
      cmdStateSnapshot(cwd, raw);
      break;
    }

    case 'summary-extract': {
      const summaryPath = args[1];
      const fieldsIndex = args.indexOf('--fields');
      const fields = fieldsIndex !== -1 ? args[fieldsIndex + 1].split(',') : null;
      cmdSummaryExtract(cwd, summaryPath, fields, raw);
      break;
    }

    case 'reflection': {
      const subcommand = args[1];
      if (subcommand === 'list') {
        const toolIdx = args.indexOf('--tool');
        const typeIdx = args.indexOf('--type');
        cmdReflectionList(cwd, {
          tool: toolIdx !== -1 ? args[toolIdx + 1] : null,
          type: typeIdx !== -1 ? args[typeIdx + 1] : null
        }, raw);
      } else if (subcommand === 'patterns') {
        const successIdx = args.indexOf('--min-success');
        const freqIdx = args.indexOf('--min-freq');
        const typeIdx = args.indexOf('--type');
        cmdReflectionPatterns(cwd, {
          minSuccess: successIdx !== -1 ? parseFloat(args[successIdx + 1]) : null,
          minFrequency: freqIdx !== -1 ? parseInt(args[freqIdx + 1], 10) : null,
          type: typeIdx !== -1 ? args[typeIdx + 1] : null
        }, raw);
      } else if (subcommand === 'insights') {
        const typeIdx = args.indexOf('--type');
        const impactIdx = args.indexOf('--impact');
        const limitIdx = args.indexOf('--limit');
        cmdReflectionInsights(cwd, {
          type: typeIdx !== -1 ? args[typeIdx + 1] : null,
          impact: impactIdx !== -1 ? args[impactIdx + 1] : null,
          limit: limitIdx !== -1 ? parseInt(args[limitIdx + 1], 10) : 10
        }, raw);
      } else if (subcommand === 'graph') {
        cmdReflectionGraph(cwd, {}, raw);
      } else {
        error('Unknown reflection subcommand. Available: list, patterns, insights, graph');
      }
      break;
    }

    case 'check-gsd-updates': {
      await cmdCheckGSDUpdates(cwd, {}, raw);
      break;
    }

    case 'integrate-gsd-change': {
      const changeId = args[1];
      if (!changeId) {
        error('Usage: gsi integrate-gsd-change <change-id>');
      }
      cmdIntegrateGSDChange(cwd, changeId, raw);
      break;
    }

    case 'gsd-update-history': {
      await cmdGSDUpdateHistory(cwd, {}, raw);
      break;
    }

    case 'websearch': {
      const query = args[1];
      const limitIdx = args.indexOf('--limit');
      const freshnessIdx = args.indexOf('--freshness');
      await cmdWebsearch(query, {
        limit: limitIdx !== -1 ? parseInt(args[limitIdx + 1], 10) : 10,
        freshness: freshnessIdx !== -1 ? args[freshnessIdx + 1] : null,
      }, raw);
      break;
    }

    case 'pattern-report': {
      await cmdPatternReport(cwd, args[1], raw);
      break;
    }

    case 'thinking': {
      const subcommand = args[1];
      const jsonFlag = args.includes('--json');
      const profileIdx = args.indexOf('--profile');
      const timeoutIdx = args.indexOf('--timeout');
      const serverIdx = args.indexOf('--server');
      const toolsIdx = args.indexOf('--tools');
      const processIdx = args.indexOf('--process');
      const commandsDirIdx = args.indexOf('--commands-dir');
      const backupDirIdx = args.indexOf('--backup-dir');
      
      const thinkingOptions = {
        json: jsonFlag,
        profile: profileIdx !== -1 ? args[profileIdx + 1] : null,
        timeout: timeoutIdx !== -1 ? args[timeoutIdx + 1] : null,
        server: serverIdx !== -1 ? args[serverIdx + 1] : null,
        tools: toolsIdx !== -1 ? args[toolsIdx + 1] : null,
        process: processIdx !== -1 ? args[processIdx + 1] : null,
        bmad: args.includes('--bmad') ? true : (args.includes('--no-bmad') ? false : undefined),
        commandsDir: commandsDirIdx !== -1 ? args[commandsDirIdx + 1] : null,
        backupDir: backupDirIdx !== -1 ? args[backupDirIdx + 1] : null,
        dryRun: args.includes('--dry-run'),
        force: args.includes('--force'),
        strict: args.includes('--strict')
      };
      
      if (subcommand === 'analyze') {
        const commandDesc = args.slice(2).find(a => !a.startsWith('--')) || '';
        await cmdThinkingAnalyze(cwd, commandDesc, thinkingOptions, raw);
      } else if (subcommand === 'config') {
        const commandDesc = args.slice(2).find(a => !a.startsWith('--')) || '';
        await cmdThinkingConfig(cwd, commandDesc, thinkingOptions, raw);
      } else if (subcommand === 'servers') {
        await cmdThinkingServers(cwd, thinkingOptions, raw);
      } else if (subcommand === 'test') {
        await cmdThinkingTest(cwd, thinkingOptions, raw);
      } else if (subcommand === 'apply-all') {
        await cmdThinkingApplyAll(cwd, thinkingOptions, raw);
      } else if (subcommand === 'validate') {
        await cmdThinkingValidate(cwd, thinkingOptions, raw);
      } else if (subcommand === 'rollback') {
        await cmdThinkingRollback(cwd, thinkingOptions, raw);
      } else if (subcommand === 'factors') {
        await cmdThinkingFactors(cwd, thinkingOptions, raw);
      } else {
        error('Unknown thinking subcommand. Available: analyze, config, servers, test, apply-all, validate, rollback, factors');
      }
      break;
    }

    case 'patch': {
      const subcommand = args[1];
      const patchesDirIdx = args.indexOf('--patches-dir');
      const patchesDir = patchesDirIdx !== -1 ? args[patchesDirIdx + 1] : null;
      
      if (subcommand === 'backup') {
        await cmdPatchBackup(cwd, { patchesDir }, raw);
      } else if (subcommand === 'restore') {
        await cmdPatchRestore(cwd, { patchesDir }, raw);
      } else if (subcommand === 'status') {
        await cmdPatchStatus(cwd, { patchesDir }, raw);
      } else if (subcommand === 'diff') {
        await cmdPatchDiff(cwd, { patchesDir }, raw);
      } else {
        error('Unknown patch subcommand. Available: backup, restore, status, diff');
      }
      break;
    }

    case 'workflow': {
      const subcommand = args[1];
      const templatesDirIdx = args.indexOf('--templates-dir');
      const templatesDir = templatesDirIdx !== -1 ? args[templatesDirIdx + 1] : null;
      const stateDirIdx = args.indexOf('--state-dir');
      const stateDir = stateDirIdx !== -1 ? args[stateDirIdx + 1] : null;
      const yoloIdx = args.indexOf('--yolo');
      const failureIdx = args.indexOf('--failure-strategy');
      
      // Pattern discovery options
      const minFreqIdx = args.indexOf('--min-frequency');
      const minSuccessIdx = args.indexOf('--min-success-rate');
      const minLenIdx = args.indexOf('--min-length');
      const maxLenIdx = args.indexOf('--max-length');
      const minQualityIdx = args.indexOf('--min-quality');
      const phaseIdx = args.indexOf('--phase');
      const recentIdx = args.indexOf('--recent-commands');
      const goalIdx = args.indexOf('--goal');
      const outputIdx = args.indexOf('--output');
      
      const workflowOptions = {
        templatesDir,
        stateDir,
        yolo: yoloIdx !== -1,
        failureStrategy: failureIdx !== -1 ? args[failureIdx + 1] : 'stop-on-error',
        // Pattern discovery options
        minFrequency: minFreqIdx !== -1 ? parseInt(args[minFreqIdx + 1], 10) : 2,
        minSuccessRate: minSuccessIdx !== -1 ? parseFloat(args[minSuccessIdx + 1]) : 0.5,
        minLength: minLenIdx !== -1 ? parseInt(args[minLenIdx + 1], 10) : 2,
        maxLength: maxLenIdx !== -1 ? parseInt(args[maxLenIdx + 1], 10) : 10,
        minQuality: minQualityIdx !== -1 ? parseInt(args[minQualityIdx + 1], 10) : 50,
        phase: phaseIdx !== -1 ? args[phaseIdx + 1] : null,
        recentCommands: recentIdx !== -1 ? args[recentIdx + 1] : null,
        goal: goalIdx !== -1 ? args[goalIdx + 1] : null,
        output: outputIdx !== -1 ? args[outputIdx + 1] : null
      };
      
      if (subcommand === 'run') {
        const templateName = args[2];
        const varsIdx = args.indexOf('--vars');
        const vars = varsIdx !== -1 ? JSON.parse(args[varsIdx + 1]) : {};
        await cmdWorkflowRun(cwd, templateName, vars, workflowOptions, raw);
      } else if (subcommand === 'list') {
        await cmdWorkflowList(cwd, workflowOptions, raw);
      } else if (subcommand === 'status') {
        const workflowName = args[2];
        await cmdWorkflowStatus(cwd, workflowName, workflowOptions, raw);
      } else if (subcommand === 'pause') {
        const workflowName = args[2];
        await cmdWorkflowPause(cwd, workflowName, workflowOptions, raw);
      } else if (subcommand === 'resume') {
        const workflowName = args[2];
        await cmdWorkflowResume(cwd, workflowName, workflowOptions, raw);
      } else if (subcommand === 'rollback') {
        const workflowName = args[2];
        await cmdWorkflowRollback(cwd, workflowName, workflowOptions, raw);
      } else if (subcommand === 'discover') {
        // Phase 38-03: Mine patterns from history
        await cmdWorkflowDiscover(cwd, workflowOptions, raw);
      } else if (subcommand === 'recommend') {
        // Phase 38-03: Get workflow recommendations
        await cmdWorkflowRecommend(cwd, workflowOptions, raw);
      } else if (subcommand === 'optimize') {
        // Phase 38-03: Optimize a workflow
        const workflowName = args[2];
        await cmdWorkflowOptimize(cwd, workflowName, workflowOptions, raw);
      } else if (subcommand === 'analyze') {
        // Phase 38-03: Analyze all workflows
        await cmdWorkflowAnalyze(cwd, workflowOptions, raw);
      } else if (subcommand === 'export') {
        // Phase 38-03: Export pattern as template
        const patternId = args[2];
        await cmdWorkflowExport(cwd, patternId, workflowOptions, raw);
      } else {
        error(`Unknown workflow subcommand. Available:
  run <template> - Run a workflow template
  list - List available templates
  status [name] - Show workflow status
  pause <name> - Pause a running workflow
  resume <name> - Resume a paused workflow
  rollback <name> - Rollback to last checkpoint
  discover - Mine patterns from history (Phase 38-03)
  recommend - Get workflow recommendations (Phase 38-03)
  optimize <name> - Optimize a workflow (Phase 38-03)
  analyze - Analyze all workflows (Phase 38-03)
  export <pattern-id> - Export pattern as template (Phase 38-03)`);
      }
      break;
    }

    case 'knowledge': {
      const subcommand = args[1];
      const knowledgeDirIdx = args.indexOf('--knowledge-dir');
      const knowledgeDir = knowledgeDirIdx !== -1 ? args[knowledgeDirIdx + 1] : null;
      const categoryIdx = args.indexOf('--category');
      const category = categoryIdx !== -1 ? args[categoryIdx + 1] : null;
      const limitIdx = args.indexOf('--limit');
      const limit = limitIdx !== -1 ? parseInt(args[limitIdx + 1], 10) : 20;
      const typesIdx = args.indexOf('--types');
      const types = typesIdx !== -1 ? args[typesIdx + 1] : null;
      
      const knowledgeOptions = {
        knowledgeDir,
        category,
        limit,
        types
      };
      
      if (subcommand === 'extract') {
        const sourcePath = args[2];
        cmdKnowledgeExtract(cwd, sourcePath, knowledgeOptions, raw);
      } else if (subcommand === 'search') {
        const query = args.slice(2).find(a => !a.startsWith('--')) || '';
        cmdKnowledgeSearch(cwd, query, knowledgeOptions, raw);
      } else if (subcommand === 'generate-skill') {
        const patternId = args[2];
        cmdKnowledgeGenerateSkill(cwd, patternId, knowledgeOptions, raw);
      } else if (subcommand === 'list') {
        cmdKnowledgeList(cwd, knowledgeOptions, raw);
      } else if (subcommand === 'stats') {
        cmdKnowledgeStats(cwd, knowledgeOptions, raw);
      } else if (subcommand === 'generate-all') {
        // Generate all artifact types from a pattern
        const patternId = args[2];
        cmdKnowledgeGenerateAll(cwd, patternId, knowledgeOptions, raw);
      } else if (subcommand === 'generate') {
        // Generate specific artifact type: gsi knowledge generate <pattern-id> <type>
        const patternId = args[2];
        const artifactType = args[3];
        cmdKnowledgeGenerateArtifact(cwd, patternId, artifactType, knowledgeOptions, raw);
      } else if (subcommand === 'artifact-types') {
        // List available artifact types
        cmdKnowledgeArtifactTypes(cwd, knowledgeOptions, raw);
      } else if (subcommand === 'extract-generate') {
        // Extract and generate in one operation
        const sourcePath = args[2];
        cmdKnowledgeExtractGenerate(cwd, sourcePath, knowledgeOptions, raw);
      } else if (subcommand === 'batch-generate') {
        // Batch generate for multiple patterns
        const idsArg = args[2];
        const patternIds = idsArg ? idsArg.split(',') : [];
        cmdKnowledgeBatchGenerate(cwd, patternIds, knowledgeOptions, raw);
      } else if (subcommand === 'agent') {
        // Shorthand: generate agent
        const patternId = args[2];
        cmdKnowledgeGenerateArtifact(cwd, patternId, 'AGENT', knowledgeOptions, raw);
      } else if (subcommand === 'feature') {
        // Shorthand: generate feature
        const patternId = args[2];
        cmdKnowledgeGenerateArtifact(cwd, patternId, 'FEATURE', knowledgeOptions, raw);
      } else if (subcommand === 'idea') {
        // Shorthand: generate idea
        const patternId = args[2];
        cmdKnowledgeGenerateArtifact(cwd, patternId, 'IDEA', knowledgeOptions, raw);
      } else if (subcommand === 'logic') {
        // Shorthand: generate logic
        const patternId = args[2];
        cmdKnowledgeGenerateArtifact(cwd, patternId, 'LOGIC', knowledgeOptions, raw);
      } else if (subcommand === 'function') {
        // Shorthand: generate function
        const patternId = args[2];
        cmdKnowledgeGenerateArtifact(cwd, patternId, 'FUNCTION', knowledgeOptions, raw);
      } else if (subcommand === 'improvement') {
        // Shorthand: generate improvement
        const patternId = args[2];
        cmdKnowledgeGenerateArtifact(cwd, patternId, 'IMPROVEMENT', knowledgeOptions, raw);
      } else {
        error(`Unknown knowledge subcommand. Available: 
  extract <path> - Extract patterns from source files
  search <query> - Search knowledge base
  generate-skill <id> - Generate skill from pattern
  list - List all patterns
  stats - Show knowledge base statistics
  generate-all <id> - Generate all artifact types from pattern
  generate <id> <type> - Generate specific artifact type
  artifact-types - List available artifact types
  extract-generate <path> - Extract and generate in one operation
  batch-generate <ids> - Batch generate for multiple patterns
  agent <id> - Generate agent from pattern
  feature <id> - Generate feature from pattern
  idea <id> - Generate idea from pattern
  logic <id> - Generate logic from pattern
  function <id> - Generate function from pattern
  improvement <id> - Generate improvement from pattern`);
      }
      break;
    }

    case 'cognitive': {
      const subcommand = args[1];
      const timeoutIdx = args.indexOf('--timeout');
      const phaseIdx = args.indexOf('--phase');
      const fileIdx = args.indexOf('--file');
      const resetIdx = args.indexOf('--reset-stats');
      
      const cognitiveOptions = {
        timeout: timeoutIdx !== -1 ? parseInt(args[timeoutIdx + 1], 10) : 10000,
        phase: phaseIdx !== -1 ? args[phaseIdx + 1] : null,
        file: fileIdx !== -1 ? args[fileIdx + 1] : null,
        resetStats: resetIdx !== -1
      };
      
      if (subcommand === 'flow') {
        const operation = args[2];
        await cmdCognitiveFlow(cwd, operation, cognitiveOptions, raw);
      } else if (subcommand === 'status') {
        await cmdCognitiveStatus(cwd, cognitiveOptions, raw);
      } else if (subcommand === 'learn') {
        const operation = args[2];
        await cmdCognitiveLearn(cwd, operation, cognitiveOptions, raw);
      } else if (subcommand === 'optimize') {
        await cmdCognitiveOptimize(cwd, cognitiveOptions, raw);
      } else {
        error(`Unknown cognitive subcommand. Available:
  flow <operation> - Execute with cognitive flow
    [--timeout N] [--phase PHASE] [--file PATH]
  status - Show cognitive system status
  learn [operation] - Trigger learning capture
    [--phase PHASE]
  optimize - Optimize cognitive settings
    [--reset-stats]`);
      }
      break;
    }

    default:
      error(`Unknown command: ${command}`);
  }
}

// ─── Cognitive Flow Commands (Phase 38-04) ─────────────────────────────────────

/**
 * Execute an operation with cognitive flow
 */
async function cmdCognitiveFlow(cwd, operation, options, raw) {
  try {
    const { getOrchestrator, CognitivePhase } = await import('../lib/cognitive-flow/index.js');
    
    if (!operation) {
      error('Operation required. Usage: gsi cognitive flow <operation> [--file PATH] [--phase PHASE]');
    }
    
    const orchestrator = getOrchestrator();
    
    // Build context
    const phase = options.phase ? CognitivePhase[options.phase.toUpperCase()] : CognitivePhase.PREPARE;
    const targetPath = options.file ? path.resolve(cwd, options.file) : null;
    
    const result = await orchestrator.quickExecute(operation, {}, {
      targetPath,
      timeout: options.timeout
    });
    
    // Set phase after creation
    result.phase = phase;
    
    if (raw) {
      console.log(`Cognitive Flow: ${operation}`);
      console.log(`Status: ${result.success ? 'SUCCESS' : (result.degraded ? 'DEGRADED' : 'FAILED')}`);
      console.log(`Duration: ${result.duration}ms`);
      console.log(`Tokens: ${result.totalTokens}`);
      console.log(`\nPhases executed: ${result.phases.size}`);
      
      for (const [phaseName, phaseResult] of result.phases) {
        console.log(`\n${phaseName}:`);
        console.log(`  Status: ${phaseResult.success ? 'OK' : 'FAILED'}`);
        console.log(`  Duration: ${phaseResult.duration}ms`);
        console.log(`  Thinking results: ${phaseResult.thinkingResults.length}`);
        console.log(`  Tool results: ${phaseResult.toolResults.length}`);
        if (phaseResult.insights.length > 0) {
          console.log(`  Insights: ${phaseResult.insights.length}`);
        }
      }
      
      if (result.errors.length > 0) {
        console.log(`\nErrors:`);
        result.errors.forEach(e => console.log(`  - ${e}`));
      }
    } else {
      output({
        success: result.success,
        operation: result.operation,
        duration: result.duration,
        tokens: result.totalTokens,
        degraded: result.degraded,
        phases: Array.from(result.phases.entries()).map(([name, pr]) => ({
          phase: name,
          success: pr.success,
          duration: pr.duration,
          insights: pr.insights.length,
          learnings: pr.learnings.length
        })),
        insights: result.insights,
        errors: result.errors
      }, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Show cognitive system status
 */
async function cmdCognitiveStatus(cwd, options, raw) {
  try {
    const { getOrchestrator } = await import('../lib/cognitive-flow/index.js');
    
    const orchestrator = getOrchestrator();
    const status = orchestrator.getStatus();
    
    if (raw) {
      console.log('=== Cognitive System Status ===\n');
      
      console.log('Server Pool:');
      console.log(`  Total calls: ${status.serverPool.totalCalls}`);
      console.log(`  Avg latency: ${Math.round(status.serverPool.avgLatency)}ms`);
      
      for (const [server, stats] of status.serverPool.serverStats) {
        console.log(`\n  ${server}:`);
        console.log(`    Calls: ${stats.calls}`);
        console.log(`    Avg latency: ${Math.round(stats.avgLatency)}ms`);
        console.log(`    Errors: ${stats.errors}`);
        console.log(`    Availability: ${stats.availability}%`);
      }
      
      console.log('\nTool Optimizer:');
      console.log(`  Total calls: ${status.toolOptimizer.totalCalls}`);
      console.log(`  Tokens used: ${status.toolOptimizer.totalTokensUsed}`);
      console.log(`  Tokens saved: ${status.toolOptimizer.totalTokensSaved}`);
      
      console.log('\nFlow Status:');
      console.log(`  Active flows: ${status.activeFlows}`);
      console.log(`  Learning buffer: ${status.learningBufferSize}`);
      
      console.log('\nConfiguration:');
      console.log(`  Enabled phases: ${status.config.enabledPhases.join(', ')}`);
      console.log(`  Learning: ${status.config.learningEnabled ? 'ON' : 'OFF'}`);
      console.log(`  Parallel tools: ${status.config.parallelTools ? 'ON' : 'OFF'}`);
      console.log(`  BMAD enhancement: ${status.config.bmadEnhancement ? 'ON' : 'OFF'}`);
    } else {
      output({
        success: true,
        serverPool: {
          totalCalls: status.serverPool.totalCalls,
          avgLatency: Math.round(status.serverPool.avgLatency),
          servers: Object.fromEntries(status.serverPool.serverStats)
        },
        toolOptimizer: {
          totalCalls: status.toolOptimizer.totalCalls,
          tokensUsed: status.toolOptimizer.totalTokensUsed,
          tokensSaved: status.toolOptimizer.totalTokensSaved
        },
        activeFlows: status.activeFlows,
        learningBufferSize: status.learningBufferSize,
        config: {
          enabledPhases: status.config.enabledPhases,
          learningEnabled: status.config.learningEnabled,
          parallelTools: status.config.parallelTools
        }
      }, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Trigger learning capture
 */
async function cmdCognitiveLearn(cwd, operation, options, raw) {
  try {
    const { getOrchestrator, CognitivePhase } = await import('../lib/cognitive-flow/index.js');
    
    const orchestrator = getOrchestrator();
    
    // Create a minimal learning context
    const operationName = operation || 'manual-capture';
    const phase = options.phase ? CognitivePhase[options.phase.toUpperCase()] : CognitivePhase.LEARN;
    
    // Execute a quick flow to trigger learning
    const result = await orchestrator.quickExecute(operationName, { capture: true }, {
      timeout: 5000
    });
    
    if (raw) {
      console.log(`Learning capture triggered for: ${operationName}`);
      console.log(`Learnings captured: ${result.learnings.length}`);
      if (result.learnings.length > 0) {
        console.log('\nCaptured learnings:');
        result.learnings.forEach((l, i) => console.log(`  ${i + 1}. ${l}`));
      }
      console.log(`\nInsights: ${result.insights.length}`);
      console.log(`Duration: ${result.duration}ms`);
    } else {
      output({
        success: result.success,
        operation: operationName,
        learnings: result.learnings,
        insights: result.insights,
        duration: result.duration
      }, raw);
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

/**
 * Optimize cognitive settings
 */
async function cmdCognitiveOptimize(cwd, options, raw) {
  try {
    const { getOrchestrator } = await import('../lib/cognitive-flow/index.js');
    
    const orchestrator = getOrchestrator();
    
    if (options.resetStats) {
      // Reset statistics
      const status = orchestrator.getStatus();
      
      if (raw) {
        console.log('Cognitive statistics reset.');
        console.log('Previous stats:');
        console.log(`  Server calls: ${status.serverPool.totalCalls}`);
        console.log(`  Tool calls: ${status.toolOptimizer.totalCalls}`);
        console.log(`  Tokens saved: ${status.toolOptimizer.totalTokensSaved}`);
      }
      
      output({
        success: true,
        action: 'reset-stats',
        previousStats: {
          serverCalls: status.serverPool.totalCalls,
          toolCalls: status.toolOptimizer.totalCalls,
          tokensSaved: status.toolOptimizer.totalTokensSaved
        }
      }, raw);
    } else {
      // Show optimization recommendations
      const status = orchestrator.getStatus();
      const recommendations = [];
      
      // Check server health
      for (const [server, stats] of status.serverPool.serverStats) {
        if (stats.errors > 5) {
          recommendations.push({
            type: 'server-health',
            server,
            message: `Server ${server} has high error count (${stats.errors}). Consider checking MCP server status.`
          });
        }
        if (stats.availability < 90) {
          recommendations.push({
            type: 'availability',
            server,
            message: `Server ${server} availability is low (${stats.availability}%). Check server health.`
          });
        }
      }
      
      // Check token efficiency
      const tokenEfficiency = status.toolOptimizer.totalTokensSaved / 
        Math.max(1, status.toolOptimizer.totalTokensUsed) * 100;
      
      if (tokenEfficiency < 50) {
        recommendations.push({
          type: 'token-efficiency',
          message: `Token efficiency is ${Math.round(tokenEfficiency)}%. Consider using more MCP tools for better savings.`
        });
      }
      
      if (raw) {
        console.log('=== Cognitive Optimization Analysis ===\n');
        
        if (recommendations.length === 0) {
          console.log('No optimization issues detected. System is running optimally.');
        } else {
          console.log(`Found ${recommendations.length} optimization opportunities:\n`);
          recommendations.forEach((r, i) => {
            console.log(`${i + 1}. [${r.type}] ${r.message}`);
          });
        }
        
        console.log('\nCurrent efficiency:');
        console.log(`  Token savings: ${Math.round(tokenEfficiency)}%`);
        console.log(`  Active flows: ${status.activeFlows}`);
        console.log(`  Learning buffer: ${status.learningBufferSize}`);
      } else {
        output({
          success: true,
          recommendations,
          efficiency: {
            tokenSavings: Math.round(tokenEfficiency),
            activeFlows: status.activeFlows,
            learningBuffer: status.learningBufferSize
          }
        }, raw);
      }
    }
  } catch (err) {
    const result = { success: false, error: err.message };
    output(result, raw);
  }
}

main();

</document_content>
</document>
<document index="3">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\bin\gsi-tools.test.js</source>
<document_content>
/**
 * GSI Tools Tests
 */

const { test, describe, beforeEach, afterEach } = require('node:test');
const assert = require('node:assert');
const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');

const TOOLS_PATH = path.join(__dirname, 'GSI-tools.js');

// Helper to run GSI-tools command
function runGSITools(args, cwd = process.cwd()) {
  try {
    const result = execSync(`node "${TOOLS_PATH}" ${args}`, {
      cwd,
      encoding: 'utf-8',
      stdio: ['pipe', 'pipe', 'pipe'],
    });
    return { success: true, output: result.trim() };
  } catch (err) {
    return {
      success: false,
      output: err.stdout?.toString().trim() || '',
      error: err.stderr?.toString().trim() || err.message,
    };
  }
}

// Create temp directory structure
function createTempProject() {
  const tmpDir = fs.mkdtempSync(path.join(require('os').tmpdir(), 'GSI-test-'));
  fs.mkdirSync(path.join(tmpDir, '.planning', 'phases'), { recursive: true });
  return tmpDir;
}

function cleanup(tmpDir) {
  fs.rmSync(tmpDir, { recursive: true, force: true });
}

describe('history-digest command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('empty phases directory returns valid schema', () => {
    const result = runGSITools('history-digest', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const digest = JSON.parse(result.output);

    assert.deepStrictEqual(digest.phases, {}, 'phases should be empty object');
    assert.deepStrictEqual(digest.decisions, [], 'decisions should be empty array');
    assert.deepStrictEqual(digest.tech_stack, [], 'tech_stack should be empty array');
  });

  test('nested frontmatter fields extracted correctly', () => {
    // Create phase directory with SUMMARY containing nested frontmatter
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '01-foundation');
    fs.mkdirSync(phaseDir, { recursive: true });

    const summaryContent = `---
phase: "01"
name: "Foundation Setup"
dependency-graph:
  provides:
    - "Database schema"
    - "Auth system"
  affects:
    - "API layer"
tech-stack:
  added:
    - "prisma"
    - "jose"
patterns-established:
  - "Repository pattern"
  - "JWT auth flow"
key-decisions:
  - "Use Prisma over Drizzle"
  - "JWT in httpOnly cookies"
---

# Summary content here
`;

    fs.writeFileSync(path.join(phaseDir, '01-01-SUMMARY.md'), summaryContent);

    const result = runGSITools('history-digest', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const digest = JSON.parse(result.output);

    // Check nested dependency-graph.provides
    assert.ok(digest.phases['01'], 'Phase 01 should exist');
    assert.deepStrictEqual(
      digest.phases['01'].provides.sort(),
      ['Auth system', 'Database schema'],
      'provides should contain nested values'
    );

    // Check nested dependency-graph.affects
    assert.deepStrictEqual(
      digest.phases['01'].affects,
      ['API layer'],
      'affects should contain nested values'
    );

    // Check nested tech-stack.added
    assert.deepStrictEqual(
      digest.tech_stack.sort(),
      ['jose', 'prisma'],
      'tech_stack should contain nested values'
    );

    // Check patterns-established (flat array)
    assert.deepStrictEqual(
      digest.phases['01'].patterns.sort(),
      ['JWT auth flow', 'Repository pattern'],
      'patterns should be extracted'
    );

    // Check key-decisions
    assert.strictEqual(digest.decisions.length, 2, 'Should have 2 decisions');
    assert.ok(
      digest.decisions.some(d => d.decision === 'Use Prisma over Drizzle'),
      'Should contain first decision'
    );
  });

  test('multiple phases merged into single digest', () => {
    // Create phase 01
    const phase01Dir = path.join(tmpDir, '.planning', 'phases', '01-foundation');
    fs.mkdirSync(phase01Dir, { recursive: true });
    fs.writeFileSync(
      path.join(phase01Dir, '01-01-SUMMARY.md'),
      `---
phase: "01"
name: "Foundation"
provides:
  - "Database"
patterns-established:
  - "Pattern A"
key-decisions:
  - "Decision 1"
---
`
    );

    // Create phase 02
    const phase02Dir = path.join(tmpDir, '.planning', 'phases', '02-api');
    fs.mkdirSync(phase02Dir, { recursive: true });
    fs.writeFileSync(
      path.join(phase02Dir, '02-01-SUMMARY.md'),
      `---
phase: "02"
name: "API"
provides:
  - "REST endpoints"
patterns-established:
  - "Pattern B"
key-decisions:
  - "Decision 2"
tech-stack:
  added:
    - "zod"
---
`
    );

    const result = runGSITools('history-digest', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const digest = JSON.parse(result.output);

    // Both phases present
    assert.ok(digest.phases['01'], 'Phase 01 should exist');
    assert.ok(digest.phases['02'], 'Phase 02 should exist');

    // Decisions merged
    assert.strictEqual(digest.decisions.length, 2, 'Should have 2 decisions total');

    // Tech stack merged
    assert.deepStrictEqual(digest.tech_stack, ['zod'], 'tech_stack should have zod');
  });

  test('malformed SUMMARY.md skipped gracefully', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '01-test');
    fs.mkdirSync(phaseDir, { recursive: true });

    // Valid summary
    fs.writeFileSync(
      path.join(phaseDir, '01-01-SUMMARY.md'),
      `---
phase: "01"
provides:
  - "Valid feature"
---
`
    );

    // Malformed summary (no frontmatter)
    fs.writeFileSync(
      path.join(phaseDir, '01-02-SUMMARY.md'),
      `# Just a heading
No frontmatter here
`
    );

    // Another malformed summary (broken YAML)
    fs.writeFileSync(
      path.join(phaseDir, '01-03-SUMMARY.md'),
      `---
broken: [unclosed
---
`
    );

    const result = runGSITools('history-digest', tmpDir);
    assert.ok(result.success, `Command should succeed despite malformed files: ${result.error}`);

    const digest = JSON.parse(result.output);
    assert.ok(digest.phases['01'], 'Phase 01 should exist');
    assert.ok(
      digest.phases['01'].provides.includes('Valid feature'),
      'Valid feature should be extracted'
    );
  });

  test('flat provides field still works (backward compatibility)', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '01-test');
    fs.mkdirSync(phaseDir, { recursive: true });

    fs.writeFileSync(
      path.join(phaseDir, '01-01-SUMMARY.md'),
      `---
phase: "01"
provides:
  - "Direct provides"
---
`
    );

    const result = runGSITools('history-digest', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const digest = JSON.parse(result.output);
    assert.deepStrictEqual(
      digest.phases['01'].provides,
      ['Direct provides'],
      'Direct provides should work'
    );
  });

  test('inline array syntax supported', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '01-test');
    fs.mkdirSync(phaseDir, { recursive: true });

    fs.writeFileSync(
      path.join(phaseDir, '01-01-SUMMARY.md'),
      `---
phase: "01"
provides: [Feature A, Feature B]
patterns-established: ["Pattern X", "Pattern Y"]
---
`
    );

    const result = runGSITools('history-digest', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const digest = JSON.parse(result.output);
    assert.deepStrictEqual(
      digest.phases['01'].provides.sort(),
      ['Feature A', 'Feature B'],
      'Inline array should work'
    );
    assert.deepStrictEqual(
      digest.phases['01'].patterns.sort(),
      ['Pattern X', 'Pattern Y'],
      'Inline quoted array should work'
    );
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// phases list command
// ─────────────────────────────────────────────────────────────────────────────

describe('phases list command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('empty phases directory returns empty array', () => {
    const result = runGSITools('phases list', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.deepStrictEqual(output.directories, [], 'directories should be empty');
    assert.strictEqual(output.count, 0, 'count should be 0');
  });

  test('lists phase directories sorted numerically', () => {
    // Create out-of-order directories
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '10-final'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '02-api'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '01-foundation'), { recursive: true });

    const result = runGSITools('phases list', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.count, 3, 'should have 3 directories');
    assert.deepStrictEqual(
      output.directories,
      ['01-foundation', '02-api', '10-final'],
      'should be sorted numerically'
    );
  });

  test('handles decimal phases in sort order', () => {
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '02-api'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '02.1-hotfix'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '02.2-patch'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '03-ui'), { recursive: true });

    const result = runGSITools('phases list', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.deepStrictEqual(
      output.directories,
      ['02-api', '02.1-hotfix', '02.2-patch', '03-ui'],
      'decimal phases should sort correctly between whole numbers'
    );
  });

  test('--type plans lists only PLAN.md files', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '01-test');
    fs.mkdirSync(phaseDir, { recursive: true });
    fs.writeFileSync(path.join(phaseDir, '01-01-PLAN.md'), '# Plan 1');
    fs.writeFileSync(path.join(phaseDir, '01-02-PLAN.md'), '# Plan 2');
    fs.writeFileSync(path.join(phaseDir, '01-01-SUMMARY.md'), '# Summary');
    fs.writeFileSync(path.join(phaseDir, 'RESEARCH.md'), '# Research');

    const result = runGSITools('phases list --type plans', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.deepStrictEqual(
      output.files.sort(),
      ['01-01-PLAN.md', '01-02-PLAN.md'],
      'should list only PLAN files'
    );
  });

  test('--type summaries lists only SUMMARY.md files', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '01-test');
    fs.mkdirSync(phaseDir, { recursive: true });
    fs.writeFileSync(path.join(phaseDir, '01-01-PLAN.md'), '# Plan');
    fs.writeFileSync(path.join(phaseDir, '01-01-SUMMARY.md'), '# Summary 1');
    fs.writeFileSync(path.join(phaseDir, '01-02-SUMMARY.md'), '# Summary 2');

    const result = runGSITools('phases list --type summaries', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.deepStrictEqual(
      output.files.sort(),
      ['01-01-SUMMARY.md', '01-02-SUMMARY.md'],
      'should list only SUMMARY files'
    );
  });

  test('--phase filters to specific phase directory', () => {
    const phase01 = path.join(tmpDir, '.planning', 'phases', '01-foundation');
    const phase02 = path.join(tmpDir, '.planning', 'phases', '02-api');
    fs.mkdirSync(phase01, { recursive: true });
    fs.mkdirSync(phase02, { recursive: true });
    fs.writeFileSync(path.join(phase01, '01-01-PLAN.md'), '# Plan');
    fs.writeFileSync(path.join(phase02, '02-01-PLAN.md'), '# Plan');

    const result = runGSITools('phases list --type plans --phase 01', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.deepStrictEqual(output.files, ['01-01-PLAN.md'], 'should only list phase 01 plans');
    assert.strictEqual(output.phase_dir, 'foundation', 'should report phase name without number prefix');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// roadmap get-phase command
// ─────────────────────────────────────────────────────────────────────────────

describe('roadmap get-phase command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('extracts phase section from ROADMAP.md', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap v1.0

## Phases

### Phase 1: Foundation
**Goal:** Set up project infrastructure
**Plans:** 2 plans

Some description here.

### Phase 2: API
**Goal:** Build REST API
**Plans:** 3 plans
`
    );

    const result = runGSITools('roadmap get-phase 1', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.found, true, 'phase should be found');
    assert.strictEqual(output.phase_number, '1', 'phase number correct');
    assert.strictEqual(output.phase_name, 'Foundation', 'phase name extracted');
    assert.strictEqual(output.goal, 'Set up project infrastructure', 'goal extracted');
  });

  test('returns not found for missing phase', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap v1.0

### Phase 1: Foundation
**Goal:** Set up project
`
    );

    const result = runGSITools('roadmap get-phase 5', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.found, false, 'phase should not be found');
  });

  test('handles decimal phase numbers', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap

### Phase 2: Main
**Goal:** Main work

### Phase 2.1: Hotfix
**Goal:** Emergency fix
`
    );

    const result = runGSITools('roadmap get-phase 2.1', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.found, true, 'decimal phase should be found');
    assert.strictEqual(output.phase_name, 'Hotfix', 'phase name correct');
    assert.strictEqual(output.goal, 'Emergency fix', 'goal extracted');
  });

  test('extracts full section content', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap

### Phase 1: Setup
**Goal:** Initialize everything

This phase covers:
- Database setup
- Auth configuration
- CI/CD pipeline

### Phase 2: Build
**Goal:** Build features
`
    );

    const result = runGSITools('roadmap get-phase 1', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.ok(output.section.includes('Database setup'), 'section includes description');
    assert.ok(output.section.includes('CI/CD pipeline'), 'section includes all bullets');
    assert.ok(!output.section.includes('Phase 2'), 'section does not include next phase');
  });

  test('handles missing ROADMAP.md gracefully', () => {
    const result = runGSITools('roadmap get-phase 1', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.found, false, 'should return not found');
    assert.strictEqual(output.error, 'ROADMAP.md not found', 'should explain why');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// phase next-decimal command
// ─────────────────────────────────────────────────────────────────────────────

describe('phase next-decimal command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('returns X.1 when no decimal phases exist', () => {
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '06-feature'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '07-next'), { recursive: true });

    const result = runGSITools('phase next-decimal 06', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.next, '06.1', 'should return 06.1');
    assert.deepStrictEqual(output.existing, [], 'no existing decimals');
  });

  test('increments from existing decimal phases', () => {
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '06-feature'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '06.1-hotfix'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '06.2-patch'), { recursive: true });

    const result = runGSITools('phase next-decimal 06', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.next, '06.3', 'should return 06.3');
    assert.deepStrictEqual(output.existing, ['06.1', '06.2'], 'lists existing decimals');
  });

  test('handles gaps in decimal sequence', () => {
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '06-feature'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '06.1-first'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '06.3-third'), { recursive: true });

    const result = runGSITools('phase next-decimal 06', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    // Should take next after highest, not fill gap
    assert.strictEqual(output.next, '06.4', 'should return 06.4, not fill gap at 06.2');
  });

  test('handles single-digit phase input', () => {
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '06-feature'), { recursive: true });

    const result = runGSITools('phase next-decimal 6', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.next, '06.1', 'should normalize to 06.1');
    assert.strictEqual(output.base_phase, '06', 'base phase should be padded');
  });

  test('returns error if base phase does not exist', () => {
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '01-start'), { recursive: true });

    const result = runGSITools('phase next-decimal 06', tmpDir);
    assert.ok(result.success, `Command should succeed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.found, false, 'base phase not found');
    assert.strictEqual(output.next, '06.1', 'should still suggest 06.1');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// phase-plan-index command
// ─────────────────────────────────────────────────────────────────────────────

describe('phase-plan-index command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('empty phase directory returns empty plans array', () => {
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '03-api'), { recursive: true });

    const result = runGSITools('phase-plan-index 03', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.phase, '03', 'phase number correct');
    assert.deepStrictEqual(output.plans, [], 'plans should be empty');
    assert.deepStrictEqual(output.waves, {}, 'waves should be empty');
    assert.deepStrictEqual(output.incomplete, [], 'incomplete should be empty');
    assert.strictEqual(output.has_checkpoints, false, 'no checkpoints');
  });

  test('extracts single plan with frontmatter', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '03-api');
    fs.mkdirSync(phaseDir, { recursive: true });

    fs.writeFileSync(
      path.join(phaseDir, '03-01-PLAN.md'),
      `---
wave: 1
autonomous: true
objective: Set up database schema
files-modified: [prisma/schema.prisma, src/lib/db.ts]
---

## Task 1: Create schema
## Task 2: Generate client
`
    );

    const result = runGSITools('phase-plan-index 03', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.plans.length, 1, 'should have 1 plan');
    assert.strictEqual(output.plans[0].id, '03-01', 'plan id correct');
    assert.strictEqual(output.plans[0].wave, 1, 'wave extracted');
    assert.strictEqual(output.plans[0].autonomous, true, 'autonomous extracted');
    assert.strictEqual(output.plans[0].objective, 'Set up database schema', 'objective extracted');
    assert.deepStrictEqual(output.plans[0].files_modified, ['prisma/schema.prisma', 'src/lib/db.ts'], 'files extracted');
    assert.strictEqual(output.plans[0].task_count, 2, 'task count correct');
    assert.strictEqual(output.plans[0].has_summary, false, 'no summary yet');
  });

  test('groups multiple plans by wave', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '03-api');
    fs.mkdirSync(phaseDir, { recursive: true });

    fs.writeFileSync(
      path.join(phaseDir, '03-01-PLAN.md'),
      `---
wave: 1
autonomous: true
objective: Database setup
---

## Task 1: Schema
`
    );

    fs.writeFileSync(
      path.join(phaseDir, '03-02-PLAN.md'),
      `---
wave: 1
autonomous: true
objective: Auth setup
---

## Task 1: JWT
`
    );

    fs.writeFileSync(
      path.join(phaseDir, '03-03-PLAN.md'),
      `---
wave: 2
autonomous: false
objective: API routes
---

## Task 1: Routes
`
    );

    const result = runGSITools('phase-plan-index 03', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.plans.length, 3, 'should have 3 plans');
    assert.deepStrictEqual(output.waves['1'], ['03-01', '03-02'], 'wave 1 has 2 plans');
    assert.deepStrictEqual(output.waves['2'], ['03-03'], 'wave 2 has 1 plan');
  });

  test('detects incomplete plans (no matching summary)', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '03-api');
    fs.mkdirSync(phaseDir, { recursive: true });

    // Plan with summary
    fs.writeFileSync(path.join(phaseDir, '03-01-PLAN.md'), `---\nwave: 1\n---\n## Task 1`);
    fs.writeFileSync(path.join(phaseDir, '03-01-SUMMARY.md'), `# Summary`);

    // Plan without summary
    fs.writeFileSync(path.join(phaseDir, '03-02-PLAN.md'), `---\nwave: 2\n---\n## Task 1`);

    const result = runGSITools('phase-plan-index 03', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.plans[0].has_summary, true, 'first plan has summary');
    assert.strictEqual(output.plans[1].has_summary, false, 'second plan has no summary');
    assert.deepStrictEqual(output.incomplete, ['03-02'], 'incomplete list correct');
  });

  test('detects checkpoints (autonomous: false)', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '03-api');
    fs.mkdirSync(phaseDir, { recursive: true });

    fs.writeFileSync(
      path.join(phaseDir, '03-01-PLAN.md'),
      `---
wave: 1
autonomous: false
objective: Manual review needed
---

## Task 1: Review
`
    );

    const result = runGSITools('phase-plan-index 03', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.has_checkpoints, true, 'should detect checkpoint');
    assert.strictEqual(output.plans[0].autonomous, false, 'plan marked non-autonomous');
  });

  test('phase not found returns error', () => {
    const result = runGSITools('phase-plan-index 99', tmpDir);
    assert.ok(result.success, `Command should succeed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.error, 'Phase not found', 'should report phase not found');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// state-snapshot command
// ─────────────────────────────────────────────────────────────────────────────

describe('state-snapshot command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('missing STATE.md returns error', () => {
    const result = runGSITools('state-snapshot', tmpDir);
    assert.ok(result.success, `Command should succeed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.error, 'STATE.md not found', 'should report missing file');
  });

  test('extracts basic fields from STATE.md', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'STATE.md'),
      `# Project State

**Current Phase:** 03
**Current Phase Name:** API Layer
**Total Phases:** 6
**Current Plan:** 03-02
**Total Plans in Phase:** 3
**Status:** In progress
**Progress:** 45%
**Last Activity:** 2024-01-15
**Last Activity Description:** Completed 03-01-PLAN.md
`
    );

    const result = runGSITools('state-snapshot', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.current_phase, '03', 'current phase extracted');
    assert.strictEqual(output.current_phase_name, 'API Layer', 'phase name extracted');
    assert.strictEqual(output.total_phases, 6, 'total phases extracted');
    assert.strictEqual(output.current_plan, '03-02', 'current plan extracted');
    assert.strictEqual(output.total_plans_in_phase, 3, 'total plans extracted');
    assert.strictEqual(output.status, 'In progress', 'status extracted');
    assert.strictEqual(output.progress_percent, 45, 'progress extracted');
    assert.strictEqual(output.last_activity, '2024-01-15', 'last activity date extracted');
  });

  test('extracts decisions table', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'STATE.md'),
      `# Project State

**Current Phase:** 01

## Decisions Made

| Phase | Decision | Rationale |
|-------|----------|-----------|
| 01 | Use Prisma | Better DX than raw SQL |
| 02 | JWT auth | Stateless authentication |
`
    );

    const result = runGSITools('state-snapshot', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.decisions.length, 2, 'should have 2 decisions');
    assert.strictEqual(output.decisions[0].phase, '01', 'first decision phase');
    assert.strictEqual(output.decisions[0].summary, 'Use Prisma', 'first decision summary');
    assert.strictEqual(output.decisions[0].rationale, 'Better DX than raw SQL', 'first decision rationale');
  });

  test('extracts blockers list', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'STATE.md'),
      `# Project State

**Current Phase:** 03

## Blockers

- Waiting for API credentials
- Need design review for dashboard
`
    );

    const result = runGSITools('state-snapshot', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.deepStrictEqual(output.blockers, [
      'Waiting for API credentials',
      'Need design review for dashboard',
    ], 'blockers extracted');
  });

  test('extracts session continuity info', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'STATE.md'),
      `# Project State

**Current Phase:** 03

## Session

**Last Date:** 2024-01-15
**Stopped At:** Phase 3, Plan 2, Task 1
**Resume File:** .planning/phases/03-api/03-02-PLAN.md
`
    );

    const result = runGSITools('state-snapshot', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.session.last_date, '2024-01-15', 'session date extracted');
    assert.strictEqual(output.session.stopped_at, 'Phase 3, Plan 2, Task 1', 'stopped at extracted');
    assert.strictEqual(output.session.resume_file, '.planning/phases/03-api/03-02-PLAN.md', 'resume file extracted');
  });

  test('handles paused_at field', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'STATE.md'),
      `# Project State

**Current Phase:** 03
**Paused At:** Phase 3, Plan 1, Task 2 - mid-implementation
`
    );

    const result = runGSITools('state-snapshot', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.paused_at, 'Phase 3, Plan 1, Task 2 - mid-implementation', 'paused_at extracted');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// summary-extract command
// ─────────────────────────────────────────────────────────────────────────────

describe('summary-extract command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('missing file returns error', () => {
    const result = runGSITools('summary-extract .planning/phases/01-test/01-01-SUMMARY.md', tmpDir);
    assert.ok(result.success, `Command should succeed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.error, 'File not found', 'should report missing file');
  });

  test('extracts all fields from SUMMARY.md', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '01-foundation');
    fs.mkdirSync(phaseDir, { recursive: true });

    fs.writeFileSync(
      path.join(phaseDir, '01-01-SUMMARY.md'),
      `---
one-liner: Set up Prisma with User and Project models
key-files:
  - prisma/schema.prisma
  - src/lib/db.ts
tech-stack:
  added:
    - prisma
    - zod
patterns-established:
  - Repository pattern
  - Dependency injection
key-decisions:
  - Use Prisma over Drizzle: Better DX and ecosystem
  - Single database: Start simple, shard later
---

# Summary

Full summary content here.
`
    );

    const result = runGSITools('summary-extract .planning/phases/01-foundation/01-01-SUMMARY.md', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.path, '.planning/phases/01-foundation/01-01-SUMMARY.md', 'path correct');
    assert.strictEqual(output.one_liner, 'Set up Prisma with User and Project models', 'one-liner extracted');
    assert.deepStrictEqual(output.key_files, ['prisma/schema.prisma', 'src/lib/db.ts'], 'key files extracted');
    assert.deepStrictEqual(output.tech_added, ['prisma', 'zod'], 'tech added extracted');
    assert.deepStrictEqual(output.patterns, ['Repository pattern', 'Dependency injection'], 'patterns extracted');
    assert.strictEqual(output.decisions.length, 2, 'decisions extracted');
  });

  test('selective extraction with --fields', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '01-foundation');
    fs.mkdirSync(phaseDir, { recursive: true });

    fs.writeFileSync(
      path.join(phaseDir, '01-01-SUMMARY.md'),
      `---
one-liner: Set up database
key-files:
  - prisma/schema.prisma
tech-stack:
  added:
    - prisma
patterns-established:
  - Repository pattern
key-decisions:
  - Use Prisma: Better DX
---
`
    );

    const result = runGSITools('summary-extract .planning/phases/01-foundation/01-01-SUMMARY.md --fields one_liner,key_files', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.one_liner, 'Set up database', 'one_liner included');
    assert.deepStrictEqual(output.key_files, ['prisma/schema.prisma'], 'key_files included');
    assert.strictEqual(output.tech_added, undefined, 'tech_added excluded');
    assert.strictEqual(output.patterns, undefined, 'patterns excluded');
    assert.strictEqual(output.decisions, undefined, 'decisions excluded');
  });

  test('handles missing frontmatter fields gracefully', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '01-foundation');
    fs.mkdirSync(phaseDir, { recursive: true });

    fs.writeFileSync(
      path.join(phaseDir, '01-01-SUMMARY.md'),
      `---
one-liner: Minimal summary
---

# Summary
`
    );

    const result = runGSITools('summary-extract .planning/phases/01-foundation/01-01-SUMMARY.md', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.one_liner, 'Minimal summary', 'one-liner extracted');
    assert.deepStrictEqual(output.key_files, [], 'key_files defaults to empty');
    assert.deepStrictEqual(output.tech_added, [], 'tech_added defaults to empty');
    assert.deepStrictEqual(output.patterns, [], 'patterns defaults to empty');
    assert.deepStrictEqual(output.decisions, [], 'decisions defaults to empty');
  });

  test('parses key-decisions with rationale', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '01-foundation');
    fs.mkdirSync(phaseDir, { recursive: true });

    fs.writeFileSync(
      path.join(phaseDir, '01-01-SUMMARY.md'),
      `---
key-decisions:
  - Use Prisma: Better DX than alternatives
  - JWT tokens: Stateless auth for scalability
---
`
    );

    const result = runGSITools('summary-extract .planning/phases/01-foundation/01-01-SUMMARY.md', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.decisions[0].summary, 'Use Prisma', 'decision summary parsed');
    assert.strictEqual(output.decisions[0].rationale, 'Better DX than alternatives', 'decision rationale parsed');
    assert.strictEqual(output.decisions[1].summary, 'JWT tokens', 'second decision summary');
    assert.strictEqual(output.decisions[1].rationale, 'Stateless auth for scalability', 'second decision rationale');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// init --include flag tests
// ─────────────────────────────────────────────────────────────────────────────

describe('init commands with --include flag', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('init execute-phase includes state and config content', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '03-api');
    fs.mkdirSync(phaseDir, { recursive: true });
    fs.writeFileSync(path.join(phaseDir, '03-01-PLAN.md'), '# Plan');
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'STATE.md'),
      '# State\n\n**Current Phase:** 03\n**Status:** In progress'
    );
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'config.json'),
      JSON.stringify({ model_profile: 'balanced' })
    );

    const result = runGSITools('init execute-phase 03 --include state,config', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.ok(output.state_content, 'state_content should be included');
    assert.ok(output.state_content.includes('Current Phase'), 'state content correct');
    assert.ok(output.config_content, 'config_content should be included');
    assert.ok(output.config_content.includes('model_profile'), 'config content correct');
  });

  test('init execute-phase without --include omits content', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '03-api');
    fs.mkdirSync(phaseDir, { recursive: true });
    fs.writeFileSync(path.join(phaseDir, '03-01-PLAN.md'), '# Plan');
    fs.writeFileSync(path.join(tmpDir, '.planning', 'STATE.md'), '# State');

    const result = runGSITools('init execute-phase 03', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.state_content, undefined, 'state_content should be omitted');
    assert.strictEqual(output.config_content, undefined, 'config_content should be omitted');
  });

  test('init plan-phase includes multiple file contents', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '03-api');
    fs.mkdirSync(phaseDir, { recursive: true });
    fs.writeFileSync(path.join(tmpDir, '.planning', 'STATE.md'), '# Project State');
    fs.writeFileSync(path.join(tmpDir, '.planning', 'ROADMAP.md'), '# Roadmap v1.0');
    fs.writeFileSync(path.join(tmpDir, '.planning', 'REQUIREMENTS.md'), '# Requirements');
    fs.writeFileSync(path.join(phaseDir, '03-CONTEXT.md'), '# Phase Context');
    fs.writeFileSync(path.join(phaseDir, '03-RESEARCH.md'), '# Research Findings');

    const result = runGSITools('init plan-phase 03 --include state,roadmap,requirements,context,research', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.ok(output.state_content, 'state_content included');
    assert.ok(output.state_content.includes('Project State'), 'state content correct');
    assert.ok(output.roadmap_content, 'roadmap_content included');
    assert.ok(output.roadmap_content.includes('Roadmap v1.0'), 'roadmap content correct');
    assert.ok(output.requirements_content, 'requirements_content included');
    assert.ok(output.context_content, 'context_content included');
    assert.ok(output.research_content, 'research_content included');
  });

  test('init plan-phase includes verification and uat content', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '03-api');
    fs.mkdirSync(phaseDir, { recursive: true });
    fs.writeFileSync(path.join(phaseDir, '03-VERIFICATION.md'), '# Verification Results');
    fs.writeFileSync(path.join(phaseDir, '03-UAT.md'), '# UAT Findings');

    const result = runGSITools('init plan-phase 03 --include verification,uat', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.ok(output.verification_content, 'verification_content included');
    assert.ok(output.verification_content.includes('Verification Results'), 'verification content correct');
    assert.ok(output.uat_content, 'uat_content included');
    assert.ok(output.uat_content.includes('UAT Findings'), 'uat content correct');
  });

  test('init progress includes state, roadmap, project, config', () => {
    fs.writeFileSync(path.join(tmpDir, '.planning', 'STATE.md'), '# State');
    fs.writeFileSync(path.join(tmpDir, '.planning', 'ROADMAP.md'), '# Roadmap');
    fs.writeFileSync(path.join(tmpDir, '.planning', 'PROJECT.md'), '# Project');
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'config.json'),
      JSON.stringify({ model_profile: 'quality' })
    );

    const result = runGSITools('init progress --include state,roadmap,project,config', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.ok(output.state_content, 'state_content included');
    assert.ok(output.roadmap_content, 'roadmap_content included');
    assert.ok(output.project_content, 'project_content included');
    assert.ok(output.config_content, 'config_content included');
  });

  test('missing files return null in content fields', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '03-api');
    fs.mkdirSync(phaseDir, { recursive: true });
    fs.writeFileSync(path.join(phaseDir, '03-01-PLAN.md'), '# Plan');

    const result = runGSITools('init execute-phase 03 --include state,config', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.state_content, null, 'missing state returns null');
    assert.strictEqual(output.config_content, null, 'missing config returns null');
  });

  test('partial includes work correctly', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '03-api');
    fs.mkdirSync(phaseDir, { recursive: true });
    fs.writeFileSync(path.join(phaseDir, '03-01-PLAN.md'), '# Plan');
    fs.writeFileSync(path.join(tmpDir, '.planning', 'STATE.md'), '# State');
    fs.writeFileSync(path.join(tmpDir, '.planning', 'ROADMAP.md'), '# Roadmap');

    // Only request state, not roadmap
    const result = runGSITools('init execute-phase 03 --include state', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.ok(output.state_content, 'state_content included');
    assert.strictEqual(output.roadmap_content, undefined, 'roadmap_content not requested, should be undefined');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// roadmap analyze command
// ─────────────────────────────────────────────────────────────────────────────

describe('roadmap analyze command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('missing ROADMAP.md returns error', () => {
    const result = runGSITools('roadmap analyze', tmpDir);
    assert.ok(result.success, `Command should succeed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.error, 'ROADMAP.md not found');
  });

  test('parses phases with goals and disk status', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap v1.0

### Phase 1: Foundation
**Goal:** Set up infrastructure

### Phase 2: Authentication
**Goal:** Add user auth

### Phase 3: Features
**Goal:** Build core features
`
    );

    // Create phase dirs with varying completion
    const p1 = path.join(tmpDir, '.planning', 'phases', '01-foundation');
    fs.mkdirSync(p1, { recursive: true });
    fs.writeFileSync(path.join(p1, '01-01-PLAN.md'), '# Plan');
    fs.writeFileSync(path.join(p1, '01-01-SUMMARY.md'), '# Summary');

    const p2 = path.join(tmpDir, '.planning', 'phases', '02-authentication');
    fs.mkdirSync(p2, { recursive: true });
    fs.writeFileSync(path.join(p2, '02-01-PLAN.md'), '# Plan');

    const result = runGSITools('roadmap analyze', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.phase_count, 3, 'should find 3 phases');
    assert.strictEqual(output.phases[0].disk_status, 'complete', 'phase 1 complete');
    assert.strictEqual(output.phases[1].disk_status, 'planned', 'phase 2 planned');
    assert.strictEqual(output.phases[2].disk_status, 'no_directory', 'phase 3 no directory');
    assert.strictEqual(output.completed_phases, 1, '1 phase complete');
    assert.strictEqual(output.total_plans, 2, '2 total plans');
    assert.strictEqual(output.total_summaries, 1, '1 total summary');
    assert.strictEqual(output.progress_percent, 50, '50% complete');
    assert.strictEqual(output.current_phase, '2', 'current phase is 2');
  });

  test('extracts goals and dependencies', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap

### Phase 1: Setup
**Goal:** Initialize project
**Depends on:** Nothing

### Phase 2: Build
**Goal:** Build features
**Depends on:** Phase 1
`
    );

    const result = runGSITools('roadmap analyze', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.phases[0].goal, 'Initialize project');
    assert.strictEqual(output.phases[0].depends_on, 'Nothing');
    assert.strictEqual(output.phases[1].goal, 'Build features');
    assert.strictEqual(output.phases[1].depends_on, 'Phase 1');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// phase add command
// ─────────────────────────────────────────────────────────────────────────────

describe('phase add command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('adds phase after highest existing', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap v1.0

### Phase 1: Foundation
**Goal:** Setup

### Phase 2: API
**Goal:** Build API

---
`
    );

    const result = runGSITools('phase add User Dashboard', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.phase_number, 3, 'should be phase 3');
    assert.strictEqual(output.slug, 'user-dashboard');

    // Verify directory created
    assert.ok(
      fs.existsSync(path.join(tmpDir, '.planning', 'phases', '03-user-dashboard')),
      'directory should be created'
    );

    // Verify ROADMAP updated
    const roadmap = fs.readFileSync(path.join(tmpDir, '.planning', 'ROADMAP.md'), 'utf-8');
    assert.ok(roadmap.includes('### Phase 3: User Dashboard'), 'roadmap should include new phase');
    assert.ok(roadmap.includes('**Depends on:** Phase 2'), 'should depend on previous');
  });

  test('handles empty roadmap', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap v1.0\n`
    );

    const result = runGSITools('phase add Initial Setup', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.phase_number, 1, 'should be phase 1');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// phase insert command
// ─────────────────────────────────────────────────────────────────────────────

describe('phase insert command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('inserts decimal phase after target', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap

### Phase 1: Foundation
**Goal:** Setup

### Phase 2: API
**Goal:** Build API
`
    );
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '01-foundation'), { recursive: true });

    const result = runGSITools('phase insert 1 Fix Critical Bug', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.phase_number, '01.1', 'should be 01.1');
    assert.strictEqual(output.after_phase, '1');

    // Verify directory
    assert.ok(
      fs.existsSync(path.join(tmpDir, '.planning', 'phases', '01.1-fix-critical-bug')),
      'decimal phase directory should be created'
    );

    // Verify ROADMAP
    const roadmap = fs.readFileSync(path.join(tmpDir, '.planning', 'ROADMAP.md'), 'utf-8');
    assert.ok(roadmap.includes('Phase 01.1: Fix Critical Bug (INSERTED)'), 'roadmap should include inserted phase');
  });

  test('increments decimal when siblings exist', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap

### Phase 1: Foundation
**Goal:** Setup

### Phase 2: API
**Goal:** Build API
`
    );
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '01-foundation'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '01.1-hotfix'), { recursive: true });

    const result = runGSITools('phase insert 1 Another Fix', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.phase_number, '01.2', 'should be 01.2');
  });

  test('rejects missing phase', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap\n### Phase 1: Test\n**Goal:** Test\n`
    );

    const result = runGSITools('phase insert 99 Fix Something', tmpDir);
    assert.ok(!result.success, 'should fail for missing phase');
    assert.ok(result.error.includes('not found'), 'error mentions not found');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// phase remove command
// ─────────────────────────────────────────────────────────────────────────────

describe('phase remove command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('removes phase directory and renumbers subsequent', () => {
    // Setup 3 phases
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap

### Phase 1: Foundation
**Goal:** Setup
**Depends on:** Nothing

### Phase 2: Auth
**Goal:** Authentication
**Depends on:** Phase 1

### Phase 3: Features
**Goal:** Core features
**Depends on:** Phase 2
`
    );

    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '01-foundation'), { recursive: true });
    const p2 = path.join(tmpDir, '.planning', 'phases', '02-auth');
    fs.mkdirSync(p2, { recursive: true });
    fs.writeFileSync(path.join(p2, '02-01-PLAN.md'), '# Plan');
    const p3 = path.join(tmpDir, '.planning', 'phases', '03-features');
    fs.mkdirSync(p3, { recursive: true });
    fs.writeFileSync(path.join(p3, '03-01-PLAN.md'), '# Plan');
    fs.writeFileSync(path.join(p3, '03-02-PLAN.md'), '# Plan 2');

    // Remove phase 2
    const result = runGSITools('phase remove 2', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.removed, '2');
    assert.strictEqual(output.directory_deleted, '02-auth');

    // Phase 3 should be renumbered to 02
    assert.ok(
      fs.existsSync(path.join(tmpDir, '.planning', 'phases', '02-features')),
      'phase 3 should be renumbered to 02-features'
    );
    assert.ok(
      !fs.existsSync(path.join(tmpDir, '.planning', 'phases', '03-features')),
      'old 03-features should not exist'
    );

    // Files inside should be renamed
    assert.ok(
      fs.existsSync(path.join(tmpDir, '.planning', 'phases', '02-features', '02-01-PLAN.md')),
      'plan file should be renumbered to 02-01'
    );
    assert.ok(
      fs.existsSync(path.join(tmpDir, '.planning', 'phases', '02-features', '02-02-PLAN.md')),
      'plan 2 should be renumbered to 02-02'
    );

    // ROADMAP should be updated
    const roadmap = fs.readFileSync(path.join(tmpDir, '.planning', 'ROADMAP.md'), 'utf-8');
    assert.ok(!roadmap.includes('Phase 2: Auth'), 'removed phase should not be in roadmap');
    assert.ok(roadmap.includes('Phase 2: Features'), 'phase 3 should be renumbered to 2');
  });

  test('rejects removal of phase with summaries unless --force', () => {
    const p1 = path.join(tmpDir, '.planning', 'phases', '01-test');
    fs.mkdirSync(p1, { recursive: true });
    fs.writeFileSync(path.join(p1, '01-01-PLAN.md'), '# Plan');
    fs.writeFileSync(path.join(p1, '01-01-SUMMARY.md'), '# Summary');
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap\n### Phase 1: Test\n**Goal:** Test\n`
    );

    // Should fail without --force
    const result = runGSITools('phase remove 1', tmpDir);
    assert.ok(!result.success, 'should fail without --force');
    assert.ok(result.error.includes('executed plan'), 'error mentions executed plans');

    // Should succeed with --force
    const forceResult = runGSITools('phase remove 1 --force', tmpDir);
    assert.ok(forceResult.success, `Force remove failed: ${forceResult.error}`);
  });

  test('removes decimal phase and renumbers siblings', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap\n### Phase 6: Main\n**Goal:** Main\n### Phase 6.1: Fix A\n**Goal:** Fix A\n### Phase 6.2: Fix B\n**Goal:** Fix B\n### Phase 6.3: Fix C\n**Goal:** Fix C\n`
    );

    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '06-main'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '06.1-fix-a'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '06.2-fix-b'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '06.3-fix-c'), { recursive: true });

    const result = runGSITools('phase remove 6.2', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    // 06.3 should become 06.2
    assert.ok(
      fs.existsSync(path.join(tmpDir, '.planning', 'phases', '06.2-fix-c')),
      '06.3 should be renumbered to 06.2'
    );
    assert.ok(
      !fs.existsSync(path.join(tmpDir, '.planning', 'phases', '06.3-fix-c')),
      'old 06.3 should not exist'
    );
  });

  test('updates STATE.md phase count', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap\n### Phase 1: A\n**Goal:** A\n### Phase 2: B\n**Goal:** B\n`
    );
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'STATE.md'),
      `# State\n\n**Current Phase:** 1\n**Total Phases:** 2\n`
    );
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '01-a'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '02-b'), { recursive: true });

    runGSITools('phase remove 2', tmpDir);

    const state = fs.readFileSync(path.join(tmpDir, '.planning', 'STATE.md'), 'utf-8');
    assert.ok(state.includes('**Total Phases:** 1'), 'total phases should be decremented');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// phase complete command
// ─────────────────────────────────────────────────────────────────────────────

describe('phase complete command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('marks phase complete and transitions to next', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap

- [ ] Phase 1: Foundation
- [ ] Phase 2: API

### Phase 1: Foundation
**Goal:** Setup
**Plans:** 1 plans

### Phase 2: API
**Goal:** Build API
`
    );
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'STATE.md'),
      `# State\n\n**Current Phase:** 01\n**Current Phase Name:** Foundation\n**Status:** In progress\n**Current Plan:** 01-01\n**Last Activity:** 2025-01-01\n**Last Activity Description:** Working on phase 1\n`
    );

    const p1 = path.join(tmpDir, '.planning', 'phases', '01-foundation');
    fs.mkdirSync(p1, { recursive: true });
    fs.writeFileSync(path.join(p1, '01-01-PLAN.md'), '# Plan');
    fs.writeFileSync(path.join(p1, '01-01-SUMMARY.md'), '# Summary');
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '02-api'), { recursive: true });

    const result = runGSITools('phase complete 1', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.completed_phase, '1');
    assert.strictEqual(output.plans_executed, '1/1');
    assert.strictEqual(output.next_phase, '02');
    assert.strictEqual(output.is_last_phase, false);

    // Verify STATE.md updated
    const state = fs.readFileSync(path.join(tmpDir, '.planning', 'STATE.md'), 'utf-8');
    assert.ok(state.includes('**Current Phase:** 02'), 'should advance to phase 02');
    assert.ok(state.includes('**Status:** Ready to plan'), 'status should be ready to plan');
    assert.ok(state.includes('**Current Plan:** Not started'), 'plan should be reset');

    // Verify ROADMAP checkbox
    const roadmap = fs.readFileSync(path.join(tmpDir, '.planning', 'ROADMAP.md'), 'utf-8');
    assert.ok(roadmap.includes('[x]'), 'phase should be checked off');
    assert.ok(roadmap.includes('completed'), 'completion date should be added');
  });

  test('detects last phase in milestone', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap\n### Phase 1: Only Phase\n**Goal:** Everything\n`
    );
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'STATE.md'),
      `# State\n\n**Current Phase:** 01\n**Status:** In progress\n**Current Plan:** 01-01\n**Last Activity:** 2025-01-01\n**Last Activity Description:** Working\n`
    );

    const p1 = path.join(tmpDir, '.planning', 'phases', '01-only-phase');
    fs.mkdirSync(p1, { recursive: true });
    fs.writeFileSync(path.join(p1, '01-01-PLAN.md'), '# Plan');
    fs.writeFileSync(path.join(p1, '01-01-SUMMARY.md'), '# Summary');

    const result = runGSITools('phase complete 1', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.is_last_phase, true, 'should detect last phase');
    assert.strictEqual(output.next_phase, null, 'no next phase');

    const state = fs.readFileSync(path.join(tmpDir, '.planning', 'STATE.md'), 'utf-8');
    assert.ok(state.includes('Milestone complete'), 'status should be milestone complete');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// milestone complete command
// ─────────────────────────────────────────────────────────────────────────────

describe('milestone complete command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('archives roadmap, requirements, creates MILESTONES.md', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap v1.0 MVP\n\n### Phase 1: Foundation\n**Goal:** Setup\n`
    );
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'REQUIREMENTS.md'),
      `# Requirements\n\n- [ ] User auth\n- [ ] Dashboard\n`
    );
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'STATE.md'),
      `# State\n\n**Status:** In progress\n**Last Activity:** 2025-01-01\n**Last Activity Description:** Working\n`
    );

    const p1 = path.join(tmpDir, '.planning', 'phases', '01-foundation');
    fs.mkdirSync(p1, { recursive: true });
    fs.writeFileSync(
      path.join(p1, '01-01-SUMMARY.md'),
      `---\none-liner: Set up project infrastructure\n---\n# Summary\n`
    );

    const result = runGSITools('milestone complete v1.0 --name MVP Foundation', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.version, 'v1.0');
    assert.strictEqual(output.phases, 1);
    assert.ok(output.archived.roadmap, 'roadmap should be archived');
    assert.ok(output.archived.requirements, 'requirements should be archived');

    // Verify archive files exist
    assert.ok(
      fs.existsSync(path.join(tmpDir, '.planning', 'milestones', 'v1.0-ROADMAP.md')),
      'archived roadmap should exist'
    );
    assert.ok(
      fs.existsSync(path.join(tmpDir, '.planning', 'milestones', 'v1.0-REQUIREMENTS.md')),
      'archived requirements should exist'
    );

    // Verify MILESTONES.md created
    assert.ok(
      fs.existsSync(path.join(tmpDir, '.planning', 'MILESTONES.md')),
      'MILESTONES.md should be created'
    );
    const milestones = fs.readFileSync(path.join(tmpDir, '.planning', 'MILESTONES.md'), 'utf-8');
    assert.ok(milestones.includes('v1.0 MVP Foundation'), 'milestone entry should contain name');
    assert.ok(milestones.includes('Set up project infrastructure'), 'accomplishments should be listed');
  });

  test('appends to existing MILESTONES.md', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'MILESTONES.md'),
      `# Milestones\n\n## v0.9 Alpha (Shipped: 2025-01-01)\n\n---\n\n`
    );
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap v1.0\n`
    );
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'STATE.md'),
      `# State\n\n**Status:** In progress\n**Last Activity:** 2025-01-01\n**Last Activity Description:** Working\n`
    );

    const result = runGSITools('milestone complete v1.0 --name Beta', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const milestones = fs.readFileSync(path.join(tmpDir, '.planning', 'MILESTONES.md'), 'utf-8');
    assert.ok(milestones.includes('v0.9 Alpha'), 'existing entry should be preserved');
    assert.ok(milestones.includes('v1.0 Beta'), 'new entry should be appended');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// validate consistency command
// ─────────────────────────────────────────────────────────────────────────────

describe('validate consistency command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('passes for consistent project', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap\n### Phase 1: A\n### Phase 2: B\n### Phase 3: C\n`
    );
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '01-a'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '02-b'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '03-c'), { recursive: true });

    const result = runGSITools('validate consistency', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.passed, true, 'should pass');
    assert.strictEqual(output.warning_count, 0, 'no warnings');
  });

  test('warns about phase on disk but not in roadmap', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap\n### Phase 1: A\n`
    );
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '01-a'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '02-orphan'), { recursive: true });

    const result = runGSITools('validate consistency', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.ok(output.warning_count > 0, 'should have warnings');
    assert.ok(
      output.warnings.some(w => w.includes('disk but not in ROADMAP')),
      'should warn about orphan directory'
    );
  });

  test('warns about gaps in phase numbering', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap\n### Phase 1: A\n### Phase 3: C\n`
    );
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '01-a'), { recursive: true });
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '03-c'), { recursive: true });

    const result = runGSITools('validate consistency', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.ok(
      output.warnings.some(w => w.includes('Gap in phase numbering')),
      'should warn about gap'
    );
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// progress command
// ─────────────────────────────────────────────────────────────────────────────

describe('progress command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('renders JSON progress', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap v1.0 MVP\n`
    );
    const p1 = path.join(tmpDir, '.planning', 'phases', '01-foundation');
    fs.mkdirSync(p1, { recursive: true });
    fs.writeFileSync(path.join(p1, '01-01-PLAN.md'), '# Plan');
    fs.writeFileSync(path.join(p1, '01-01-SUMMARY.md'), '# Done');
    fs.writeFileSync(path.join(p1, '01-02-PLAN.md'), '# Plan 2');

    const result = runGSITools('progress json', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.total_plans, 2, '2 total plans');
    assert.strictEqual(output.total_summaries, 1, '1 summary');
    assert.strictEqual(output.percent, 50, '50%');
    assert.strictEqual(output.phases.length, 1, '1 phase');
    assert.strictEqual(output.phases[0].status, 'In Progress', 'phase in progress');
  });

  test('renders bar format', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap v1.0\n`
    );
    const p1 = path.join(tmpDir, '.planning', 'phases', '01-test');
    fs.mkdirSync(p1, { recursive: true });
    fs.writeFileSync(path.join(p1, '01-01-PLAN.md'), '# Plan');
    fs.writeFileSync(path.join(p1, '01-01-SUMMARY.md'), '# Done');

    const result = runGSITools('progress bar --raw', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);
    assert.ok(result.output.includes('1/1'), 'should include count');
    assert.ok(result.output.includes('100%'), 'should include 100%');
  });

  test('renders table format', () => {
    fs.writeFileSync(
      path.join(tmpDir, '.planning', 'ROADMAP.md'),
      `# Roadmap v1.0 MVP\n`
    );
    const p1 = path.join(tmpDir, '.planning', 'phases', '01-foundation');
    fs.mkdirSync(p1, { recursive: true });
    fs.writeFileSync(path.join(p1, '01-01-PLAN.md'), '# Plan');

    const result = runGSITools('progress table --raw', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);
    assert.ok(result.output.includes('Phase'), 'should have table header');
    assert.ok(result.output.includes('foundation'), 'should include phase name');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// todo complete command
// ─────────────────────────────────────────────────────────────────────────────

describe('todo complete command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('moves todo from pending to completed', () => {
    const pendingDir = path.join(tmpDir, '.planning', 'todos', 'pending');
    fs.mkdirSync(pendingDir, { recursive: true });
    fs.writeFileSync(
      path.join(pendingDir, 'add-dark-mode.md'),
      `title: Add dark mode\narea: ui\ncreated: 2025-01-01\n`
    );

    const result = runGSITools('todo complete add-dark-mode.md', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.completed, true);

    // Verify moved
    assert.ok(
      !fs.existsSync(path.join(tmpDir, '.planning', 'todos', 'pending', 'add-dark-mode.md')),
      'should be removed from pending'
    );
    assert.ok(
      fs.existsSync(path.join(tmpDir, '.planning', 'todos', 'completed', 'add-dark-mode.md')),
      'should be in completed'
    );

    // Verify completion timestamp added
    const content = fs.readFileSync(
      path.join(tmpDir, '.planning', 'todos', 'completed', 'add-dark-mode.md'),
      'utf-8'
    );
    assert.ok(content.startsWith('completed:'), 'should have completed timestamp');
  });

  test('fails for nonexistent todo', () => {
    const result = runGSITools('todo complete nonexistent.md', tmpDir);
    assert.ok(!result.success, 'should fail');
    assert.ok(result.error.includes('not found'), 'error mentions not found');
  });
});

// ─────────────────────────────────────────────────────────────────────────────
// scaffold command
// ─────────────────────────────────────────────────────────────────────────────

describe('scaffold command', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = createTempProject();
  });

  afterEach(() => {
    cleanup(tmpDir);
  });

  test('scaffolds context file', () => {
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '03-api'), { recursive: true });

    const result = runGSITools('scaffold context --phase 3', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.created, true);

    // Verify file content
    const content = fs.readFileSync(
      path.join(tmpDir, '.planning', 'phases', '03-api', '03-CONTEXT.md'),
      'utf-8'
    );
    assert.ok(content.includes('Phase 3'), 'should reference phase number');
    assert.ok(content.includes('Decisions'), 'should have decisions section');
    assert.ok(content.includes('Discretion Areas'), 'should have discretion section');
  });

  test('scaffolds UAT file', () => {
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '03-api'), { recursive: true });

    const result = runGSITools('scaffold uat --phase 3', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.created, true);

    const content = fs.readFileSync(
      path.join(tmpDir, '.planning', 'phases', '03-api', '03-UAT.md'),
      'utf-8'
    );
    assert.ok(content.includes('User Acceptance Testing'), 'should have UAT heading');
    assert.ok(content.includes('Test Results'), 'should have test results section');
  });

  test('scaffolds verification file', () => {
    fs.mkdirSync(path.join(tmpDir, '.planning', 'phases', '03-api'), { recursive: true });

    const result = runGSITools('scaffold verification --phase 3', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.created, true);

    const content = fs.readFileSync(
      path.join(tmpDir, '.planning', 'phases', '03-api', '03-VERIFICATION.md'),
      'utf-8'
    );
    assert.ok(content.includes('Goal-Backward Verification'), 'should have verification heading');
  });

  test('scaffolds phase directory', () => {
    const result = runGSITools('scaffold phase-dir --phase 5 --name User Dashboard', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.created, true);
    assert.ok(
      fs.existsSync(path.join(tmpDir, '.planning', 'phases', '05-user-dashboard')),
      'directory should be created'
    );
  });

  test('does not overwrite existing files', () => {
    const phaseDir = path.join(tmpDir, '.planning', 'phases', '03-api');
    fs.mkdirSync(phaseDir, { recursive: true });
    fs.writeFileSync(path.join(phaseDir, '03-CONTEXT.md'), '# Existing content');

    const result = runGSITools('scaffold context --phase 3', tmpDir);
    assert.ok(result.success, `Command failed: ${result.error}`);

    const output = JSON.parse(result.output);
    assert.strictEqual(output.created, false, 'should not overwrite');
    assert.strictEqual(output.reason, 'already_exists');
  });
});

</document_content>
</document>
<document index="4">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\docs\cognitive-flow.md</source>
<document_content>
# Cognitive-Flow Orchestration Layer

> Unified orchestration for thinking servers, MCP tools, and claudeception modules.

## Overview

The Cognitive-Flow Orchestration Layer provides a unified interface for coordinating multiple cognitive services:

- **Thinking Servers**: Sequential, Tractatus, Debug thinking
- **MCP Tools**: File operations, code search, process management, documentation
- **Claudeception Modules**: Knowledge extraction, pattern learning, reflection capture

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                  Cognitive Orchestrator                      │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐        │
│  │ PREPARE │→ │ EXECUTE │→ │ REFLECT │→ │  LEARN  │        │
│  └────┬────┘  └────┬────┘  └────┬────┘  └────┬────┘        │
│       │            │            │            │              │
│  ┌────▼────────────▼────────────▼────────────▼────┐        │
│  │              Server Pool                        │        │
│  │  ┌───────────┐ ┌───────────┐ ┌───────────┐    │        │
│  │  │ Sequential│ │ Tractatus │ │   Debug   │    │        │
│  │  └───────────┘ └───────────┘ └───────────┘    │        │
│  └─────────────────────────────────────────────────┘        │
│                                                              │
│  ┌─────────────────────────────────────────────────┐        │
│  │              Tool Optimizer                      │        │
│  │  • Tool Selection Matrix                         │        │
│  │  • Token Cost Estimation                         │        │
│  │  • Batch Optimization                            │        │
│  │  • Parallel Execution Planner                    │        │
│  └─────────────────────────────────────────────────┘        │
└─────────────────────────────────────────────────────────────┘
```

## Four-Phase Flow

### Phase 1: PREPARE
**Purpose**: Structure analysis and planning
**Thinking Server**: Tractatus (primary), Sequential (secondary)
**Operations**:
- Analyze file structure
- Identify dependencies
- Plan execution approach

### Phase 2: EXECUTE
**Purpose**: Step-by-step execution
**Thinking Server**: Sequential (primary), Tractatus (secondary)
**Operations**:
- Execute planned steps
- Process files
- Apply changes

### Phase 3: REFLECT
**Purpose**: Problem analysis and verification
**Thinking Server**: Debug (primary), Tractatus (secondary)
**Operations**:
- Analyze results
- Detect issues
- Generate insights

### Phase 4: LEARN
**Purpose**: Knowledge capture and storage
**Thinking Server**: Debug (primary), Sequential (secondary)
**Operations**:
- Capture patterns
- Store in knowledge base
- Update effectiveness metrics

## Server Selection Algorithm

The server pool uses a scoring system to select the best thinking server:

### Scoring Factors

| Factor | Points | Description |
|--------|--------|-------------|
| Health | 0-20 | Server availability and error count |
| Latency | 0-15 | Response time (lower is better) |
| Capability Match | 0-15 | How well capabilities match the operation |
| Phase Affinity | 0-10 | Server's suitability for current phase |
| Load Balance | -10-0 | Penalize overloaded servers |

### Phase Affinity Matrix

| Phase | Primary Server | Secondary Server |
|-------|---------------|------------------|
| PREPARE | Tractatus | Sequential |
| EXECUTE | Sequential | Tractatus |
| REFLECT | Debug | Tractatus |
| LEARN | Debug | Sequential |

### Fallback Chain

Default: `sequential` → `tractatus` → `debug`

## Tool Optimization

### Tool Selection Matrix

| Operation | Preferred Tool | Token Savings |
|-----------|---------------|---------------|
| read-file | mcp__desktop-commander__read_file | 50% |
| write-file | mcp__desktop-commander__write_file | 50% |
| edit-file | mcp__desktop-commander__edit_block | 60% |
| search-code | mcp__code-index-mcp__search_code_advanced | 75% |
| get-symbol | mcp__code-index-mcp__get_symbol_body | 90% |
| get-library-docs | mcp__context7__get-library-docs | 70% |

### Batch Optimization

The tool optimizer can batch multiple operations for efficiency:

```typescript
const optimizer = new ToolOptimizer();

const calls = [
  { server: 'desktop-commander', tool: 'read_file', params: { path: 'a.ts' } },
  { server: 'desktop-commander', tool: 'read_file', params: { path: 'b.ts' } },
  { server: 'desktop-commander', tool: 'read_file', params: { path: 'c.ts' } }
];

const optimization = optimizer.optimizeBatch(calls);
// Result: Batches calls, estimates 85% token savings
```

## API Reference

### CognitiveOrchestrator

```typescript
import { CognitiveOrchestrator, CognitivePhase } from 'cognitive-flow';

// Create orchestrator
const orchestrator = new CognitiveOrchestrator({
  learningEnabled: true,
  parallelTools: true,
  tokenBudget: 50000
});

// Build context
const context = CognitiveOrchestrator.context('analyze-code')
  .withPhase(CognitivePhase.PREPARE)
  .withTargetPath('/path/to/file.ts')
  .withTimeout(10000)
  .build();

// Execute flow
const result = await orchestrator.execute(context);

// Check results
console.log(result.success);
console.log(result.insights);
console.log(result.totalTokens);
```

### ServerPool

```typescript
import { ServerPool } from 'cognitive-flow';

const pool = new ServerPool({
  healthCheckInterval: 30000,
  maxRetries: 3
});

// Start health monitoring
pool.startHealthChecks();

// Select server
const selection = pool.selectServer(context);
console.log(selection.server);      // 'tractatus'
console.log(selection.confidence);  // 0.85
console.log(selection.alternatives); // ['sequential']

// Get stats
const stats = pool.getStats();
```

### ToolOptimizer

```typescript
import { ToolOptimizer } from 'cognitive-flow';

const optimizer = new ToolOptimizer();

// Select tool
const selection = optimizer.selectTool('read-file');
console.log(selection.preferredTool);    // 'mcp__desktop-commander__read_file'
console.log(selection.tokenSavings);     // 50

// Estimate costs
const cost = optimizer.estimateTokenCost('mcp__desktop-commander__read_file');

// Optimize batch
const optimization = optimizer.optimizeBatch(calls);
```

### Quick Execute

```typescript
import { quickCognitiveFlow } from 'cognitive-flow';

const result = await quickCognitiveFlow(
  'analyze-code',
  { filePath: '/path/to/file.ts' },
  { targetPath: '/path/to/file.ts' }
);
```

## CLI Commands

### gsi cognitive flow

Execute a command with cognitive flow enhancement.

```bash
gsi cognitive flow analyze --file path/to/file.ts
```

### gsi cognitive status

Show cognitive system status.

```bash
gsi cognitive status
```

Output:
```json
{
  "serverPool": {
    "totalCalls": 150,
    "avgLatency": 45,
    "serverStats": {
      "sequential": { "calls": 50, "errors": 0 },
      "tractatus": { "calls": 75, "errors": 1 },
      "debug": { "calls": 25, "errors": 0 }
    }
  },
  "toolOptimizer": {
    "totalCalls": 200,
    "totalTokensSaved": 15000
  },
  "activeFlows": 0,
  "learningBufferSize": 5
}
```

### gsi cognitive learn

Trigger learning capture.

```bash
gsi cognitive learn --operation analyze-code
```

### gsi cognitive optimize

Optimize cognitive settings.

```bash
gsi cognitive optimize --reset-stats
gsi cognitive optimize --set-timeout PREPARE=3000
```

## Configuration

### Default Configuration

```typescript
const DEFAULT_FLOW_CONFIG = {
  enabledPhases: ['PREPARE', 'EXECUTE', 'REFLECT', 'LEARN'],
  phaseTimeouts: {
    PREPARE: 5000,
    EXECUTE: 15000,
    REFLECT: 5000,
    LEARN: 3000
  },
  serverPool: {
    healthCheckInterval: 30000,
    maxRetries: 3,
    retryDelay: 1000,
    timeout: 10000,
    fallbackChain: ['sequential', 'tractatus', 'debug']
  },
  learningEnabled: true,
  parallelTools: true,
  maxParallelTools: 5,
  tokenBudget: 50000,
  bmadEnhancement: true,
  verbose: false
};
```

### Custom Configuration

```typescript
const orchestrator = new CognitiveOrchestrator({
  enabledPhases: ['PREPARE', 'EXECUTE'],  // Skip REFLECT and LEARN
  phaseTimeouts: new Map([
    [CognitivePhase.PREPARE, 3000],
    [CognitivePhase.EXECUTE, 20000]
  ]),
  learningEnabled: false,  // Disable learning
  tokenBudget: 100000     // Increase token budget
});
```

## Events

The orchestrator emits events for monitoring and debugging:

```typescript
orchestrator.on('flow:start', (event) => {
  console.log('Flow started:', event.data);
});

orchestrator.on('phase:complete', (event) => {
  console.log(`Phase ${event.phase} completed:`, event.data);
});

orchestrator.on('server:select', (event) => {
  console.log(`Selected server: ${event.server}`);
});

orchestrator.on('learning:capture', (event) => {
  console.log('Learning captured:', event.data);
});
```

### Event Types

| Event | Description |
|-------|-------------|
| `flow:start` | Flow execution started |
| `flow:complete` | Flow execution completed |
| `phase:start` | Phase execution started |
| `phase:complete` | Phase execution completed |
| `phase:error` | Phase execution failed |
| `server:select` | Server selection made |
| `server:call` | Server call initiated |
| `server:result` | Server result received |
| `tool:select` | Tool selection made |
| `tool:call` | Tool call initiated |
| `tool:result` | Tool result received |
| `learning:capture` | Learning entry captured |
| `error` | General error |

## Integration Points

### Thinking Orchestrator Integration

```typescript
import { ThinkingOrchestrator } from '../workflow-modules/thinking-orchestrator.js';
import { CognitiveOrchestrator } from './cognitive-flow.js';

// Use cognitive orchestrator for enhanced thinking
const cognitive = new CognitiveOrchestrator();
const thinking = new ThinkingOrchestrator();

// Cognitive flow enhances thinking with phases
const result = await cognitive.execute(
  CognitiveOrchestrator.context('analyze')
    .withPhase(CognitivePhase.PREPARE)
    .build()
);
```

### Workflow Chainer Integration

```typescript
import { WorkflowChainer } from '../workflow-modules/workflow-chainer.js';
import { CognitiveOrchestrator } from './cognitive-flow.js';

const chainer = new WorkflowChainer();
const cognitive = new CognitiveOrchestrator();

// Add cognitive enhancement to workflow steps
chainer.createChain({
  name: 'cognitive-enhanced',
  chain: [
    { command: 'gsi:plan-phase', cognitive: true },
    { command: 'gsi:execute-phase', cognitive: true },
    { command: 'gsi:verify-work', cognitive: true }
  ]
});
```

### Knowledge Base Integration

```typescript
import { KnowledgeBase } from '../workflow-modules/knowledge-base.js';
import { CognitiveOrchestrator, CognitivePhase } from './cognitive-flow.js';

const knowledge = new KnowledgeBase();
const cognitive = new CognitiveOrchestrator({
  learningEnabled: true
});

// Learning phase stores patterns in knowledge base
cognitive.on('learning:capture', async (event) => {
  const entry = event.data;
  // Store in knowledge base
  await knowledge.storePattern({
    id: entry.id,
    name: `Pattern: ${entry.operation}`,
    category: 'cognitive-patterns',
    description: `Learned from ${entry.operation}`,
    // ...
  });
});
```

## Best Practices

1. **Use Context Builders**: Always use the fluent API for building contexts
2. **Handle Degradation**: Check `result.degraded` and handle gracefully
3. **Monitor Events**: Subscribe to events for debugging and monitoring
4. **Configure Timeouts**: Set appropriate timeouts for each phase
5. **Enable Learning**: Keep learning enabled for continuous improvement
6. **Check Server Health**: Monitor server pool statistics
7. **Optimize Tools**: Use tool optimizer for batch operations

## Troubleshooting

### Phase Timeout

If phases are timing out:
- Increase phase timeout in configuration
- Check server health with `gsi cognitive status`
- Verify MCP servers are running

### High Token Usage

If token usage is high:
- Enable batch optimization
- Use `get_file_summary` instead of reading entire files
- Check tool selection matrix for better alternatives

### Server Unavailable

If servers are marked unavailable:
- Check MCP server logs
- Verify network connectivity
- Use `gsi cognitive optimize --reset-stats` to reset error counts

## Version History

- **1.0.0**: Initial release
  - Four-phase cognitive flow
  - Server pool with health checking
  - Tool optimizer with batch processing
  - Learning capture and storage
  - CLI commands for cognitive operations

</document_content>
</document>
<document index="5">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\docs\knowledge-base.md</source>
<document_content>
# Knowledge Base Module

The Knowledge Base module extracts patterns, principles, and reusable knowledge from the GSI codebase to create new skills, improve existing commands, and build a searchable knowledge index.

## Overview

This module implements the knowledge extraction capabilities identified during the Claudeception analysis of GSI. It enables GSI to learn from its own codebase and generate reusable artifacts.

**Phase 38-01 Enhancement**: The Knowledge Base now supports multi-type artifact generation, allowing patterns to be transformed into 7 different artifact types:
- **SKILL**: Claude Code skills for reuse
- **AGENT**: GSI agent definitions with thinking configurations
- **LOGIC**: TypeScript logic modules with interfaces
- **FUNCTION**: Reusable TypeScript functions
- **FEATURE**: Feature specification documents
- **IMPROVEMENT**: Improvement suggestions with rationale
- **IDEA**: Visionary ideas and concept proposals

## CLI Commands

### `gsi knowledge extract <path>`

Extract patterns from source files.

```bash
# Extract patterns from GSI commands
gsi knowledge extract ./commands

# Extract specific category
gsi knowledge extract ./workflows --category workflows

# Extract to custom knowledge directory
gsi knowledge extract ./agents --knowledge-dir ~/.gsi-knowledge
```

**Options:**
- `--category <category>` - Filter extraction to specific category
- `--knowledge-dir <path>` - Custom knowledge base directory

**Categories:**
- `command-patterns` - GSI command structures
- `thinking-configs` - Thinking phase configurations
- `workflows` - Multi-step workflow patterns
- `agents` - Agent definitions
- `error-handling` - Error handling patterns
- `optimization` - Performance optimization patterns

### `gsi knowledge search <query>`

Search the knowledge base for matching patterns.

```bash
# Search all patterns
gsi knowledge search "planning"

# Search within category
gsi knowledge search "debug" --category error-handling

# Limit results
gsi knowledge search "workflow" --limit 10
```

**Options:**
- `--category <category>` - Filter by category
- `--limit N` - Maximum results to return (default: 20)
- `--knowledge-dir <path>` - Custom knowledge base directory

### `gsi knowledge generate-skill <pattern-id>`

Generate a Claude skill file from a stored pattern.

```bash
gsi knowledge generate-skill pattern-command-add-phase
```

**Output:**
Creates a skill file at `~/.claude/skills/generated-<pattern-id>/skill.md`

### `gsi knowledge list`

List all patterns in the knowledge base.

```bash
# List all patterns
gsi knowledge list

# List patterns in specific category
gsi knowledge list --category command-patterns

# Limit output
gsi knowledge list --limit 30
```

**Options:**
- `--category <category>` - Filter by category
- `--limit N` - Maximum results (default: 50)
- `--knowledge-dir <path>` - Custom knowledge base directory

### `gsi knowledge stats`

Show knowledge base statistics.

```bash
gsi knowledge stats
```

**Output:**
```json
{
  "knowledge_dir": ".planning/knowledge",
  "exists": true,
  "patterns": {
    "total": 45,
    "by_category": {
      "command-patterns": 20,
      "thinking-configs": 10,
      "workflows": 15
    }
  },
  "templates": { "total": 5 },
  "best_practices": { "total": 8 },
  "artifacts": {
    "total": 12,
    "by_type": {
      "skills": 3,
      "agents": 2,
      "features": 4,
      "ideas": 3
    }
  }
}
```

## Multi-Type Artifact Generation (Phase 38-01)

### `gsi knowledge generate-all <pattern-id>`

Generate ALL artifact types from a pattern in one operation.

```bash
gsi knowledge generate-all pattern-command-add-phase
```

**Output:**
Creates 7 artifacts:
- `knowledge/skills/<pattern-name>.md` - Skill definition
- `knowledge/agents/gsi-<pattern-name>.md` - Agent with thinking config
- `knowledge/logic/<pattern-name>.ts` - TypeScript logic module
- `knowledge/functions/<pattern-name>.ts` - Reusable function
- `knowledge/features/<pattern-name>-feature.md` - Feature specification
- `knowledge/improvements/<pattern-name>-improvement.md` - Improvement suggestions
- `knowledge/ideas/<pattern-name>-idea.md` - Visionary ideas

### `gsi knowledge generate <pattern-id> <type>`

Generate a specific artifact type from a pattern.

```bash
# Generate an agent
gsi knowledge generate pattern-workflow-execute AGENT

# Generate a feature specification
gsi knowledge generate pattern-command-debug FEATURE

# Generate an idea document
gsi knowledge generate pattern-thinking-comprehensive IDEA
```

**Valid Types:**
- `SKILL` - Claude Code skill
- `AGENT` - GSI agent definition
- `LOGIC` - TypeScript logic module
- `FUNCTION` - Reusable TypeScript function
- `FEATURE` - Feature specification
- `IMPROVEMENT` - Improvement suggestions
- `IDEA` - Visionary idea document

### `gsi knowledge artifact-types`

List all available artifact types with descriptions.

```bash
gsi knowledge artifact-types
```

**Output:**
```
Available Artifact Types:
  skill: Claude Code skill for reuse
  agent: GSI agent definition with thinking config
  logic: TypeScript logic module with interfaces
  function: Reusable TypeScript function
  feature: Feature specification document
  improvement: Improvement suggestions with rationale
  idea: Visionary idea and concept proposal
```

### `gsi knowledge extract-generate <path>`

Extract patterns AND generate artifacts in one operation.

```bash
# Extract and generate all artifact types
gsi knowledge extract-generate ./commands

# Extract and generate only agents and features
gsi knowledge extract-generate ./workflows --types AGENT,FEATURE

# Extract specific category and generate
gsi knowledge extract-generate ./agents --category agents --types AGENT,IDEA
```

**Options:**
- `--types <types>` - Comma-separated artifact types to generate
- `--category <category>` - Filter extraction to specific category
- `--knowledge-dir <path>` - Custom knowledge base directory

### `gsi knowledge batch-generate <pattern-ids>`

Generate artifacts for multiple patterns at once.

```bash
# Generate agents and features for multiple patterns
gsi knowledge batch-generate pattern-1,pattern-2,pattern-3 --types AGENT,FEATURE
```

**Options:**
- `--types <types>` - Comma-separated artifact types to generate (default: SKILL,AGENT,FEATURE,IDEA)
- `--knowledge-dir <path>` - Custom knowledge base directory

## Shorthand Commands

For convenience, shorthand commands exist for single artifact type generation:

### `gsi knowledge agent <pattern-id>`
Generate an agent from a pattern.

```bash
gsi knowledge agent pattern-command-debug
```

### `gsi knowledge feature <pattern-id>`
Generate a feature specification from a pattern.

```bash
gsi knowledge feature pattern-workflow-execute
```

### `gsi knowledge idea <pattern-id>`
Generate an idea document from a pattern.

```bash
gsi knowledge idea pattern-thinking-comprehensive
```

### `gsi knowledge logic <pattern-id>`
Generate a logic module from a pattern.

```bash
gsi knowledge logic pattern-command-add-phase
```

### `gsi knowledge function <pattern-id>`
Generate a function from a pattern.

```bash
gsi knowledge function pattern-optimization-cache
```

### `gsi knowledge improvement <pattern-id>`
Generate improvement suggestions from a pattern.

```bash
gsi knowledge improvement pattern-error-handling
```

## Pattern Storage Structure

The knowledge base stores data in the following structure:

```
.planning/knowledge/
├── patterns/
│   ├── command-patterns/
│   │   ├── pattern-command-add-phase.json
│   │   └── pattern-command-debug.json
│   ├── thinking-configs/
│   │   └── pattern-thinking-comprehensive.json
│   ├── workflows/
│   │   └── pattern-workflow-execute.json
│   ├── agents/
│   ├── error-handling/
│   └── optimization/
├── templates/
│   ├── gsi-command-1234567890.json
│   └── thinking-config-1234567891.json
├── best-practices/
│   └── practice-execute-phase-0.md
├── skills/                          # Generated skills
│   └── pattern-name.md
├── agents/                          # Generated agents
│   └── gsi-pattern-name.md
├── logic/                           # Generated logic modules
│   └── pattern-name.ts
├── functions/                       # Generated functions
│   └── pattern-name.ts
├── features/                        # Generated feature specs
│   └── pattern-name-feature.md
├── improvements/                    # Generated improvements
│   └── pattern-name-improvement.md
├── ideas/                           # Generated ideas
│   └── pattern-name-idea.md
└── index.json
```

### Pattern File Format

Each pattern is stored as JSON:

```json
{
  "id": "pattern-command-add-phase",
  "name": "add-phase Command Pattern",
  "category": "command-patterns",
  "description": "Pattern for add-phase command with 5 tools",
  "source": "commands/GSI/add-phase.md",
  "whenToUse": [
    "When implementing a command similar to add-phase",
    "When 5 tools are needed",
    "When the command has similar complexity"
  ],
  "howToApply": [
    "1. Copy the command structure",
    "2. Modify description and objective",
    "3. Adjust allowed-tools list",
    "4. Update process section"
  ],
  "variations": [
    {
      "name": "Simplified",
      "description": "Remove non-essential tools",
      "context": "When simpler version is needed"
    }
  ],
  "examples": [
    {
      "name": "Basic usage",
      "code": "...",
      "explanation": "Command description"
    }
  ],
  "effectiveness": 1.0,
  "uses": 0
}
```

### Index File Format

The `index.json` file tracks overall statistics:

```json
{
  "lastUpdated": "2025-02-18T12:00:00.000Z",
  "patterns": 45,
  "templates": 5,
  "practices": 8,
  "categories": ["command-patterns", "thinking-configs", "workflows"]
}
```

## Programmatic API

### Import and Initialize

```javascript
import { KnowledgeBase } from 'get-shit-indexed/lib/workflow-modules/knowledge-base.js';

const kb = new KnowledgeBase('./.planning/knowledge');
```

### Extract Patterns

```javascript
const result = await kb.extract('./commands', 'command-patterns');
console.log(`Extracted ${result.patternsExtracted.length} patterns`);
```

### Search Patterns

```javascript
const patterns = kb.search('planning', 'workflows');
patterns.forEach(p => console.log(p.name, p.effectiveness));
```

### Generate Skill

```javascript
const skillPath = await kb.generateSkill('pattern-command-add-phase');
console.log(`Skill created at: ${skillPath}`);
```

### Multi-Type Artifact Generation

```javascript
// Generate all artifact types
const result = await kb.generateAllArtifacts('pattern-command-add-phase');
console.log(`Generated ${result.artifacts.length} artifacts`);

// Generate specific types
const partial = await kb.generateArtifactTypes('pattern-command-add-phase', ['AGENT', 'FEATURE']);

// Generate single artifact
const agent = await kb.generateAgent('pattern-command-add-phase');
const feature = await kb.generateFeature('pattern-workflow-execute');
const idea = await kb.generateIdea('pattern-thinking-comprehensive');

// Extract and generate in one operation
const combined = await kb.extractAndGenerate('./commands', 'command-patterns', ['AGENT', 'FEATURE']);

// Batch generate for multiple patterns
const batchResults = await kb.batchGenerate(
  ['pattern-1', 'pattern-2', 'pattern-3'],
  ['AGENT', 'FEATURE', 'IDEA']
);
```

### Track Effectiveness

```javascript
// After successful use of a pattern
kb.trackEffectiveness('pattern-command-add-phase', true);

// After failed use
kb.trackEffectiveness('pattern-command-add-phase', false);
```

## Artifact Generator Module

The `artifact-generator.ts` module provides the multi-type generation capabilities:

```javascript
import { ArtifactGeneratorManager } from 'get-shit-indexed/lib/workflow-modules/artifact-generator.js';

const generator = new ArtifactGeneratorManager('./.planning/knowledge');

// Get available types
const types = generator.getAvailableTypes();
// ['SKILL', 'AGENT', 'LOGIC', 'FUNCTION', 'FEATURE', 'IMPROVEMENT', 'IDEA']

// Generate all types
const artifacts = await generator.generateAll(pattern);

// Generate specific types
const selected = await generator.generateTypes(pattern, ['AGENT', 'FEATURE']);

// Generate single type
const agent = await generator.generate(pattern, 'AGENT');
```

### Individual Generators

Each artifact type has its own generator class:

- `SkillGenerator` - Creates Claude Code skill files
- `AgentGenerator` - Creates GSI agent definitions with auto-generated thinking configs
- `LogicGenerator` - Creates TypeScript logic modules with interfaces
- `FunctionGenerator` - Creates reusable TypeScript functions
- `FeatureGenerator` - Creates feature specification documents
- `ImprovementGenerator` - Creates improvement suggestion documents
- `IdeaGenerator` - Creates visionary idea documents

## Use Cases

### 1. Command Development

When creating a new GSI command, search for similar patterns:

```bash
gsi knowledge search "phase" --category command-patterns
```

### 2. Agent Generation

Generate an agent from a proven command pattern:

```bash
gsi knowledge agent pattern-command-debug
```

The generated agent includes:
- Appropriate thinking configuration
- Inferred allowed tools
- Process steps from pattern
- Examples and variations

### 3. Feature Specification

Create a detailed feature specification from a workflow pattern:

```bash
gsi knowledge feature pattern-workflow-execute
```

### 4. Idea Generation

Explore innovative concepts from patterns:

```bash
gsi knowledge idea pattern-thinking-comprehensive
```

### 5. Batch Processing

Generate multiple artifacts for all patterns in a category:

```bash
gsi knowledge batch-generate $(gsi knowledge list --category workflows --raw | cut -d' ' -f2) --types AGENT,FEATURE
```

## Integration with Other Modules

### Thinking Orchestrator

The Knowledge Base can suggest thinking configurations based on extracted patterns:

```javascript
const pattern = kb.search('complex planning')[0];
// Use pattern to configure thinking orchestrator
```

The Agent generator automatically creates appropriate thinking configs based on pattern complexity.

### Workflow Chainer

Workflow patterns can be converted to workflow templates:

```javascript
const workflowPatterns = kb.search('', 'workflows');
// Convert to WorkflowChainer templates
```

## Best Practices

1. **Extract Regularly**: Run `gsi knowledge extract` after completing major features
2. **Track Effectiveness**: Use `trackEffectiveness()` to improve pattern rankings
3. **Generate Multiple Types**: Use `generate-all` to explore all artifact possibilities
4. **Search First**: Before creating new commands, search for existing patterns
5. **Review Stats**: Check `gsi knowledge stats` to monitor knowledge base growth
6. **Use Shorthands**: Use `gsi knowledge agent`, `gsi knowledge feature` for quick generation

## Related Documentation

- [Thinking Orchestrator](./thinking-orchestrator.md) - Thinking server coordination
- [Workflow Chainer](./workflow-chainer.md) - Workflow execution
- [Patch Manager](./patch-manager.md) - Local modification management
- [Artifact Generator](./artifact-generator.md) - Multi-type artifact generation details

</document_content>
</document>
<document index="6">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\docs\patch-manager.md</source>
<document_content>
# GSI Patch Manager

## Overview

The Patch Manager module handles backup and restoration of local modifications across GSI package updates. It was extracted from the v1.18.0 to v1.23.0 migration session where 28 files were patched.

## Purpose

When updating the GSI npm package, local modifications (such as custom thinking_phase configurations, allowed-tools additions, or other customizations) would normally be lost. The Patch Manager:

1. **Backs up** local modifications before an update
2. **Restores** those modifications after the update
3. **Merges** changes intelligently to handle conflicts
4. **Tracks** modification metadata for audit trails

## CLI Commands

### `gsi patch backup`

Backs up all local modifications before a GSI package update.

```bash
gsi patch backup [--patches-dir <path>]
```

**Options:**
- `--patches-dir <path>`: Custom directory for storing backups (default: `~/.claude/GSI-local-patches`)

**Output:**
- Creates backup files in the patches directory
- Generates `backup-meta.json` with metadata about the backup

**Example:**
```bash
# Before updating GSI
gsi patch backup

# Output:
# Backing up local modifications...
# Backed up 28 files from version 1.23.0
# Backup location: ~/.claude/GSI-local-patches
```

### `gsi patch restore`

Restores backed-up modifications to the new GSI version after an update.

```bash
gsi patch restore [--patches-dir <path>]
```

**Options:**
- `--patches-dir <path>`: Custom directory containing backups (default: `~/.claude/GSI-local-patches`)

**Behavior:**
- Reads `backup-meta.json` to identify backed-up files
- Merges modifications with current version files
- Reports any conflicts that require manual resolution

**Example:**
```bash
# After updating GSI
gsi patch restore

# Output:
# Restoring local modifications...
# Restored 28 files
# Conflicts in 2 files:
#   - commands/gsi/debug.md
#   - commands/gsi/execute-phase.md
```

### `gsi patch status`

Shows the status of local modifications backup.

```bash
gsi patch status [--patches-dir <path>]
```

**Options:**
- `--patches-dir <path>`: Custom directory for backups (default: `~/.claude/GSI-local-patches`)

**Output:**
- Backup existence and validity
- Version the backup was created from
- Timestamp of backup creation
- Number of files backed up
- List of patches by type

**Example:**
```bash
gsi patch status

# Output:
# Backup exists for version 1.23.0
# Created: 2025-02-18T10:30:00.000Z
# Files: 28
# Location: ~/.claude/GSI-local-patches
```

### `gsi patch diff`

Shows differences between backup and current files.

```bash
gsi patch diff [--patches-dir <path>]
```

**Options:**
- `--patches-dir <path>`: Custom directory for backups (default: `~/.claude/GSI-local-patches`)

**Output:**
- Files that have changed since backup
- Hash comparison for quick identification
- Summary of modifications

**Example:**
```bash
gsi patch diff

# Output:
# Found 5 files with differences:
#   - commands/gsi/add-phase.md
#   - commands/gsi/debug.md
#   - hooks/pre-tool-use/thinking-invoke.js
#   - lib/thinking/orchestrator.js
#   - workflows/execute-phase.md
```

## Typical Workflow

### Before Updating GSI

```bash
# 1. Check current status
gsi patch status

# 2. Create backup
gsi patch backup

# 3. Verify backup was created
gsi patch status
```

### After Updating GSI

```bash
# 1. Check for differences
gsi patch diff

# 2. Restore modifications
gsi patch restore

# 3. Handle any conflicts manually
# (conflicted files are listed in output)

# 4. Verify modifications applied
gsi patch diff
```

## Modification Types

The Patch Manager categorizes modifications by type:

| Type | Description |
|------|-------------|
| `thinking_phase` | Custom thinking_phase configurations added to commands |
| `allowed_tools` | Modifications to allowed-tools lists |
| `content` | General content modifications |
| `mixed` | Multiple types of modifications in one file |

## Conflict Resolution

When conflicts occur during restore:

1. **Automatic Merge**: Most modifications are merged automatically
2. **Conflict Report**: Files with unmergeable conflicts are listed
3. **Manual Resolution**: Open conflicted files and resolve manually

### Conflict Structure

```json
{
  "section": "thinking_phase",
  "userVersion": "{\"mode\":\"sequential\",\"server\":\"sequential-thinking\"}",
  "upstreamVersion": "{\"mode\":\"enhanced\",\"server\":\"7bmad\"}",
  "resolution": "user | upstream | merged"
}
```

## Programmatic Usage

The Patch Manager can also be used programmatically:

```javascript
import { PatchManager } from 'get-shit-indexed-cc/lib/workflow-modules/patch-manager.js';

const manager = new PatchManager('/custom/patches/dir');

// Backup
const metadata = await manager.backup();
console.log(`Backed up ${metadata.files.length} files`);

// Restore
const results = await manager.restore();
for (const [file, result] of results) {
  if (!result.success) {
    console.log(`Conflicts in ${file}:`, result.conflicts);
  }
}
```

## API Reference

### `PatchManager`

#### Constructor

```typescript
constructor(patchesDir?: string)
```

Creates a new PatchManager instance.

**Parameters:**
- `patchesDir` (optional): Directory for storing patches. Default: `~/.claude/GSI-local-patches`

#### Methods

##### `backup(): Promise<PatchMetadata>`

Backs up all local modifications.

**Returns:** Promise resolving to backup metadata

##### `restore(): Promise<Map<string, MergeResult>>`

Restores modifications from backup.

**Returns:** Promise resolving to map of file paths to merge results

### Types

```typescript
interface PatchMetadata {
  version: string;
  timestamp: string;
  files: PatchFile[];
  patches: PatchSummary[];
}

interface PatchFile {
  path: string;
  hash: string;
  modified: boolean;
}

interface PatchSummary {
  file: string;
  type: 'thinking_phase' | 'allowed_tools' | 'content' | 'mixed';
  description: string;
}

interface MergeResult {
  success: boolean;
  conflicts: Conflict[];
  mergedContent: string;
}

interface Conflict {
  section: string;
  userVersion: string;
  upstreamVersion: string;
  resolution?: 'user' | 'upstream' | 'merged';
}
```

## File Locations

| Path | Description |
|------|-------------|
| `~/.claude/GSI-local-patches/` | Default backup directory |
| `~/.claude/GSI-local-patches/backup-meta.json` | Backup metadata file |
| `~/.claude/GSI-local-patches/commands/gsi/*.md` | Backed up command files |

## Troubleshooting

### "No backup found"

Run `gsi patch backup` before attempting restore or diff operations.

### "GSI installation not found"

Ensure GSI is installed globally (`npm install -g get-shit-indexed-cc`) or locally in the current project.

### Conflicts After Restore

1. Check the conflict report in the restore output
2. Open each conflicted file
3. Look for conflict markers or compare with backup
4. Manually merge the changes
5. Commit the resolved files

## Version History

- **v1.23.0**: Initial release of Patch Manager
- Extracted from v1.18.0 -> v1.23.0 migration (28 files patched)

</document_content>
</document>
<document index="7">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\docs\thinking-orchestrator.md</source>
<document_content>
# Thinking Orchestrator Module

## Overview

The Thinking Orchestrator module coordinates MCP thinking servers (Sequential, Tractatus, Debug) based on `thinking_phase` configurations in GSI commands. It provides automatic complexity analysis, server selection, and timeout calculation for optimal thinking orchestration.

## Module Location

```
get-shit-indexed/lib/workflow-modules/thinking-orchestrator.ts
```

## Exports

### Types

```typescript
type ThinkingMode = 'NONE' | 'LIGHTWEIGHT' | 'STANDARD' | 'COMPREHENSIVE';
type ThinkingServer = 'sequential' | 'tractatus' | 'debug';

interface ThinkingPhaseConfig {
  mode: ThinkingMode;
  servers: ThinkingServer[];
  bmad_enabled: boolean;
  timeout: number;
  rationale: string;
}

interface ThinkingContext {
  command: string;
  description: string;
  objective?: string;
  process?: string;
  additionalContext?: Record<string, any>;
}

interface ThinkingResult {
  server: ThinkingServer;
  thoughts: ThinkingThought[];
  duration: number;
  success: boolean;
  error?: string;
}

interface ThinkingThought {
  thoughtNumber: number;
  totalThoughts: number;
  thought: string;
  nextThoughtNeeded: boolean;
  isRevision?: boolean;
  revisesThought?: number;
  branchFromThought?: number;
  branchId?: string;
  needsMoreThoughts?: boolean;
}

interface ComplexityFactor {
  name: string;
  score: number;
  description?: string;
}

interface ComplexityAnalysis {
  totalScore: number;
  mode: ThinkingMode;
  factors: ComplexityFactor[];
  breakdown: Record<string, number>;
}
```

### Class: ThinkingOrchestrator

```typescript
import { ThinkingOrchestrator } from 'get-shit-indexed';
```

## CLI Commands

### `gsi thinking analyze <command>`

Analyze a command's complexity and get recommended thinking configuration.

**Usage:**
```bash
gsi thinking analyze "execute-phase 20-01"
gsi thinking analyze "debug --complex"
gsi thinking analyze "plan-phase 21" --json
```

**Output:**
```json
{
  "complexity": 8,
  "mode": "STANDARD",
  "servers": ["sequential", "tractatus"],
  "bmad_enabled": true,
  "timeout": 7000,
  "rationale": "Planning task requiring step sequencing (Sequential) and structural analysis (Tractatus)"
}
```

### `gsi thinking config <command>`

Generate optimal thinking configuration for a command.

**Usage:**
```bash
gsi thinking config "execute-phase 20-01"
gsi thinking config "quick status" --profile quick
gsi thinking config "debug issue" --timeout 10000
```

**Options:**
- `--profile <name>` - Use specific profile (quick, standard, comprehensive)
- `--timeout <ms>` - Override calculated timeout
- `--bmad` - Enable BMAD integration
- `--no-bmad` - Disable BMAD integration

### `gsi thinking servers`

List available thinking servers and their status.

**Usage:**
```bash
gsi thinking servers
gsi thinking servers --json
```

**Output:**
```
Available Thinking Servers:
- sequential: mcp__sequential-thinking__sequentialthinking
- tractatus: mcp__tractatusthinking__tractatus_thinking
- debug: mcp__debug-thinking__debug_thinking
```

### `gsi thinking test`

Test connections to thinking servers.

**Usage:**
```bash
gsi thinking test
gsi thinking test --server sequential
gsi thinking test --timeout 5000
```

### `gsi thinking apply-all` (NEW)

Apply thinking_phase configurations to all GSI commands in a directory.

**Usage:**
```bash
gsi thinking apply-all
gsi thinking apply-all --dry-run
gsi thinking apply-all --force
gsi thinking apply-all --commands-dir ./commands/gsi
```

**Options:**
- `--commands-dir <path>` - Directory containing command files (default: `commands/gsi/`)
- `--backup-dir <path>` - Directory for backups (default: `.planning/thinking-backups/`)
- `--dry-run` - Show what would be changed without making changes
- `--force` - Overwrite existing thinking_phase configurations

**Output:**
```
=== Thinking Phase Apply-All Results ===

Mode: LIVE
Commands scanned: 30
Processed: 25
Updated: 20
Skipped (already had config): 5
Errors: 0

Changes:
  [ADDED] help.md: NONE (sequential)
  [ADDED] progress.md: LIGHTWEIGHT (sequential)
  [UPDATED] execute-phase.md: STANDARD (sequential, tractatus)
  [ADDED] debug.md: COMPREHENSIVE (sequential, tractatus, debug)

Backups saved to: .planning/thinking-backups/
```

### `gsi thinking validate` (NEW)

Validate thinking_phase configurations in command files.

**Usage:**
```bash
gsi thinking validate
gsi thinking validate --strict
gsi thinking validate --commands-dir ./commands/gsi
```

**Options:**
- `--commands-dir <path>` - Directory containing command files
- `--strict` - Treat warnings as errors

**Output:**
```
=== Thinking Phase Validation Results ===

Strict Mode: off
Files scanned: 30
Valid: 25
Invalid: 0
Missing: 5
With warnings: 3

Details:

  [MISSING] help.md
    WARNING: No thinking_phase configuration found

  [WARNING] execute-phase.md
    WARNING: Timeout seems low for STANDARD mode: 3000ms (expected ~5000ms)

✓ All validations passed
```

### `gsi thinking rollback` (NEW)

Rollback thinking_phase changes from the most recent backup.

**Usage:**
```bash
gsi thinking rollback
gsi thinking rollback --backup-dir ./backups
```

**Output:**
```
=== Thinking Phase Rollback Results ===

Backup timestamp: 2024-02-18T10:30:00.000Z
Restored: 20
Failed: 0

Files:
  ✓ help.md: restored
  ✓ progress.md: restored
  ✓ execute-phase.md: restored
```

### `gsi thinking factors` (NEW)

Show complexity factor documentation.

**Usage:**
```bash
gsi thinking factors
gsi thinking factors --json
```

**Output:**
```
=== Thinking Complexity Factors (25 total) ===

## Tool-Based Factors (10)
  - tool_count: Number of allowed tools (range: 0-15+)
  - execution_tools: Tools for executing commands (range: 0-6)
  - delegation: Task/subagent delegation tools (range: 0-3)
  ...

## Keyword-Based Factors (8)
  - debug_keywords: Debug/troubleshoot operation (range: 0-4)
  - analysis_keywords: Analysis/research operation (range: 0-3)
  ...

## Workflow Factors (4)
  - workflow_steps: Number of workflow steps (range: 0-5)
  - workflow_branching: Branching/conditional points (range: 0-3)
  ...

## Error Handling Factors (3)
  - error_recovery: Error handling points (range: 0-3)
  - validation_gates: Validation gates (range: 0-2)
  - rollback_capability: Rollback capability (range: 0-2)

=== Mode Thresholds ===

NONE: score 0-2
  Simple display commands, status checks
LIGHTWEIGHT: score 3-6
  Quick operations, single-step modifications
STANDARD: score 7-12
  Planning operations, multi-step workflows
COMPREHENSIVE: score 13-100
  Complex debugging, architecture design
```

## Complexity Algorithm (Enhanced - 25 Factors)

The complexity score is calculated based on 25 factors across 4 categories:

### Category 1: Tool-Based Factors (10 factors)

| Factor | Range | Description |
|--------|-------|-------------|
| `tool_count` | 0-15+ | Number of allowed tools |
| `execution_tools` | 0-6 | Tools for executing commands (Bash, start_process) |
| `delegation` | 0-3 | Task/subagent delegation tools |
| `web_integration` | 0-6 | Web/API integration tools |
| `file_modification` | 0-5 | File modification tools (Write, Edit) |
| `code_analysis` | 0-3 | Code analysis/indexing tools |
| `tool_combination` | 0-5 | Multiple tool categories combined |
| `mcp_dependency` | 0-3 | MCP server dependencies beyond 3 |
| `dc_comprehensive` | 0-2 | Comprehensive Desktop Commander usage |
| `parallel_potential` | 0-2 | High parallel execution potential |

### Category 2: Keyword-Based Factors (8 factors)

| Factor | Range | Description |
|--------|-------|-------------|
| `debug_keywords` | 0-4 | debug, troubleshoot, fix, resolve |
| `analysis_keywords` | 0-3 | analyze, research, investigate, explore |
| `planning_keywords` | 0-3 | plan, design, architect, structure |
| `integration_keywords` | 0-3 | integrate, migrate, refactor, transform |
| `verification_keywords` | 0-2 | verify, test, validate, check |
| `simplicity_keywords` | -3-0 | quick, simple, display, show (negative factor) |
| `critical_keywords` | 0-3 | critical, urgent, production, breaking |
| `multi_component` | 0-2 | Multi-component operation indicators |

### Category 3: Workflow Factors (4 factors)

| Factor | Range | Description |
|--------|-------|-------------|
| `workflow_steps` | 0-5 | Number of workflow steps (capped at 5) |
| `workflow_branching` | 0-3 | Branching/conditional logic points |
| `workflow_checkpoints` | 0-2 | Checkpoint/pause points |
| `workflow_parallel` | 0-2 | Parallel execution indicators |

### Category 4: Error Handling Factors (3 factors)

| Factor | Range | Description |
|--------|-------|-------------|
| `error_recovery` | 0-3 | Error handling patterns |
| `validation_gates` | 0-2 | Validation gate patterns |
| `rollback_capability` | 0-2 | Rollback capability indicators |

### Mode Thresholds

| Score Range | Mode | Max Thoughts | Description |
|-------------|------|--------------|-------------|
| 0-2 | NONE | 0 | Simple display commands |
| 3-6 | LIGHTWEIGHT | 3 | Quick operations |
| 7-12 | STANDARD | 5 | Multi-step workflows |
| 13+ | COMPREHENSIVE | 10 | Complex operations |

## Server Selection Logic

### Sequential Server (Always Selected)

The sequential thinking server is always included as it provides fundamental step planning.

### Tractatus Server (Conditional)

Selected when:
- Command contains: analyze, structure, architecture, design, plan, research
- Tools include: code-index-mcp

### Debug Server (Conditional)

Selected when:
- Command contains: debug, troubleshoot, fix, verify, test, resolve, investigate

## Thinking Templates

Templates are located in `templates/thinking/`:

### NONE.yaml
- **Use for:** Display commands, status checks
- **Complexity:** 0-2
- **Servers:** None
- **BMAD:** Disabled

### LIGHTWEIGHT.yaml
- **Use for:** Quick operations, simple modifications
- **Complexity:** 3-6
- **Servers:** sequential only
- **BMAD:** Disabled

### STANDARD.yaml
- **Use for:** Planning, execution, research
- **Complexity:** 7-12
- **Servers:** sequential, tractatus
- **BMAD:** Enabled

### COMPREHENSIVE.yaml
- **Use for:** Debugging, architecture, integration
- **Complexity:** 13+
- **Servers:** sequential, tractatus, debug
- **BMAD:** Enabled
- **Parallel Execution:** Enabled

## Thinking Profiles

### Quick Profile (`profiles/quick.json`)

```json
{
  "mode": "LIGHTWEIGHT",
  "servers": ["sequential"],
  "bmad_enabled": false,
  "maxThoughts": 3,
  "complexityThreshold": { "min": 3, "max": 6 }
}
```

**Use Cases:**
- Simple display operations
- Status checks
- Quick lookups
- Single-step operations

### Standard Profile (`profiles/standard.json`)

```json
{
  "mode": "STANDARD",
  "servers": ["sequential", "tractatus"],
  "bmad_enabled": true,
  "maxThoughts": 5,
  "complexityThreshold": { "min": 7, "max": 12 }
}
```

**Use Cases:**
- Planning operations
- Phase execution
- Code analysis
- Multi-step workflows

### Comprehensive Profile (`profiles/comprehensive.json`)

```json
{
  "mode": "COMPREHENSIVE",
  "servers": ["sequential", "tractatus", "debug"],
  "bmad_enabled": true,
  "maxThoughts": 10,
  "complexityThreshold": { "min": 13, "max": 100 }
}
```

**Use Cases:**
- Complex debugging
- Architecture design
- Multi-phase integration
- Critical path operations

## Usage Examples

### Programmatic Usage

```typescript
import { ThinkingOrchestrator } from 'get-shit-indexed';

const orchestrator = new ThinkingOrchestrator();

// Analyze a command with full complexity breakdown
const analysis = orchestrator.analyzeComplexity({
  description: 'Execute phase 20-01: Add thinking orchestrator',
  allowedTools: ['Read', 'Write', 'Edit', 'Bash'],
  process: '1. Read existing files\n2. Analyze structure\n3. Implement changes'
});

console.log(analysis);
// {
//   totalScore: 10,
//   mode: 'STANDARD',
//   factors: [...],
//   breakdown: { tools: 4, execution: 2, fileMod: 2, workflowSteps: 2 }
// }

// Get config for a command
const config = orchestrator.analyzeCommand({
  description: 'Execute phase 20-01: Add thinking orchestrator',
  allowedTools: ['Read', 'Write', 'Edit', 'Bash'],
  process: '1. Read existing files\n2. Analyze structure\n3. Implement changes'
});

// Generate frontmatter string
const frontmatter = orchestrator.generateFrontmatter(config);
console.log(frontmatter);

// Validate a config
const validation = orchestrator.validateConfig(config);
if (!validation.valid) {
  console.error('Errors:', validation.errors);
}
if (validation.warnings.length > 0) {
  console.warn('Warnings:', validation.warnings);
}

// Get factor documentation
const factors = orchestrator.getComplexityFactorDescriptions();
const thresholds = orchestrator.getModeThresholds();
```

### Integration with GSI Commands

```yaml
# In a GSI command frontmatter
---
thinking_phase:
  mode: STANDARD
  servers:
    - sequential
    - tractatus
  bmad_enabled: true
  timeout: 5000
  rationale: "Planning task requiring step sequencing and structural analysis"
---
```

## Timeout Calculation

Timeout is calculated based on mode and tool count:

```
baseTimeout = {
  NONE: 0,
  LIGHTWEIGHT: 2000,
  STANDARD: 5000,
  COMPREHENSIVE: 9000
}

calculated = baseTimeout[mode] + (toolCount * 500)
final = min(calculated, 15000)  // Cap at 15 seconds
```

## BMAD Integration

When `bmad_enabled` is true, the thinking orchestrator applies 7-BMAD methodology principles:

1. **Method Circle** - Implementation correctness checks
2. **Mad Circle** - Integration completeness verification
3. **Model Circle** - Architecture alignment validation
4. **Mode Circle** - Pattern consistency checks
5. **Mod Circle** - Maintainability standards
6. **Modd Circle** - Extensibility verification
7. **Methodd Circle** - Documentation quality

## Error Handling

The orchestrator handles errors gracefully:

- Server connection failures return partial results
- Individual server errors don't block other servers
- Errors are included in result objects for debugging

```typescript
const result = results.get('sequential');
if (!result.success) {
  console.error(`Sequential thinking failed: ${result.error}`);
}
```

## Batch Processing

### Auto-Application Workflow

1. **Scan** commands directory for `.md` files
2. **Parse** frontmatter and content
3. **Analyze** complexity using 25 factors
4. **Generate** optimal thinking_phase
5. **Backup** original files
6. **Apply** changes to frontmatter
7. **Report** all changes

### Backup Strategy

- Backups stored in `.planning/thinking-backups/`
- Filename format: `{original}.{timestamp}.bak`
- Metadata stored in `apply-all-{timestamp}.json`
- Supports rollback to previous state

## Version History

- **v1.24.0** - Enhanced complexity algorithm (25 factors)
  - Added tool combination analysis
  - Added workflow step analysis
  - Added error handling complexity
  - Added MCP server dependency analysis
  - Added apply-all command with batch processing
  - Added validate command
  - Added rollback command
  - Added factors documentation command
  - Added thinking templates (YAML)
  
- **v1.23.0** - Initial module extraction
  - Analyzed 28 commands with thinking configurations
  - Implemented complexity scoring algorithm (15 factors)
  - Added three thinking profiles (quick, standard, comprehensive)

</document_content>
</document>
<document index="8">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\docs\workflow-chainer.md</source>
<document_content>
# Workflow Chainer

The Workflow Chainer module chains multiple GSI commands into unified workflows with automatic dependency resolution and parallel execution support.

## Overview

Workflows automate common GSI command sequences, enabling:

- **Automated sequences**: Run multiple commands in order
- **Checkpoint/rollback**: Save state and revert on failure
- **Parallel execution**: Run independent steps concurrently
- **Variable substitution**: Parameterize workflows with variables

## CLI Commands

### gsi workflow run

Run a workflow template.

```bash
gsi workflow run <template> [options]
```

**Arguments:**
- `<template>` - Name of the workflow template to run

**Options:**
- `--vars '{json}'` - Variables to substitute in the workflow (JSON format)
- `--yolo` - Enable YOLO mode (skip confirmations)
- `--failure-strategy <strategy>` - How to handle failures:
  - `stop-on-error` (default) - Stop immediately on error
  - `continue-on-error` - Continue with next step
  - `rollback-on-error` - Rollback to last checkpoint
- `--templates-dir <path>` - Custom templates directory
- `--state-dir <path>` - Custom state directory (default: `.planning`)

**Examples:**

```bash
# Run full development cycle for phase 01
gsi workflow run full-cycle --vars '{"phase": "01"}'

# Run quick fix with rollback on error
gsi workflow run quick-fix --vars '{"phase": "01.01"}' --failure-strategy rollback-on-error

# Run with YOLO mode
gsi workflow run full-cycle --vars '{"phase": "02"}' --yolo
```

### gsi workflow list

List available workflow templates.

```bash
gsi workflow list [options]
```

**Options:**
- `--templates-dir <path>` - Custom templates directory

**Example:**

```bash
gsi workflow list
```

**Output:**
```
Available workflow templates:
  - full-cycle: Research -> Plan -> Execute -> Verify
    Steps: 4, Checkpoint: after-each
  - quick-fix: Plan -> Execute -> Verify (skip research)
    Steps: 3, Checkpoint: before-execute
  - project-setup: Initialize new project with all phases
    Steps: 4, Checkpoint: after-phase
  - milestone-complete: Complete milestone and prepare next
    Steps: 4, Checkpoint: manual
```

### gsi workflow status

Show status of workflows (all or specific).

```bash
gsi workflow status [name] [options]
```

**Arguments:**
- `[name]` - Optional workflow name to show specific status

**Options:**
- `--state-dir <path>` - Custom state directory

**Examples:**

```bash
# Show all active workflows
gsi workflow status

# Show specific workflow status
gsi workflow status full-cycle
```

**Output:**
```
Workflow: full-cycle
Status: running
Started: 2025-02-18T10:30:00.000Z
Completed: 2
Pending: 2
Current: gsi:execute-phase
Last checkpoint: 2025-02-18T10:45:00.000Z
```

### gsi workflow pause

Pause a running workflow.

```bash
gsi workflow pause <name> [options]
```

**Arguments:**
- `<name>` - Name of the workflow to pause

**Options:**
- `--state-dir <path>` - Custom state directory

**Example:**

```bash
gsi workflow pause full-cycle
```

### gsi workflow resume

Resume a paused workflow.

```bash
gsi workflow resume <name> [options]
```

**Arguments:**
- `<name>` - Name of the workflow to resume

**Options:**
- `--state-dir <path>` - Custom state directory

**Example:**

```bash
gsi workflow resume full-cycle
```

### gsi workflow rollback

Rollback a workflow to the last checkpoint.

```bash
gsi workflow rollback <name> [options]
```

**Arguments:**
- `<name>` - Name of the workflow to rollback

**Options:**
- `--state-dir <path>` - Custom state directory

**Example:**

```bash
gsi workflow rollback full-cycle
```

## Built-in Templates

### full-cycle

Complete development cycle with all phases.

**Steps:**
1. `gsi:research-phase` - Research phase requirements
2. `gsi:plan-phase` - Create execution plan
3. `gsi:execute-phase` - Execute the plan
4. `gsi:verify-work` - Verify implementation

**Checkpoint:** After each step
**Rollback:** Enabled

**Use when:** Starting a new feature or significant change requiring full analysis.

### quick-fix

Fast fix cycle skipping the research phase.

**Steps:**
1. `gsi:plan-phase --skip-research` - Create plan (no research)
2. `gsi:execute-phase` - Execute the fix
3. `gsi:verify-work` - Verify the fix

**Checkpoint:** Before execute
**Rollback:** Enabled

**Use when:** Requirements are already known and you need a quick fix.

### project-setup

Initialize a new GSI-managed project.

**Steps:**
1. `gsi:new-project` - Initialize project structure
2. `gsi:map-codebase` - Analyze existing codebase
3. `gsi:add-phase "Foundation"` - Create first phase
4. `gsi:plan-phase 01` - Plan foundation phase

**Parallel Groups:**
- `status-check`: Runs `gsi:check-todos` and `gsi:progress` in parallel

**Checkpoint:** After each phase
**Rollback:** Disabled (new project)

**Use when:** Starting a new GSI-managed project.

### milestone-complete

Complete current milestone and prepare next.

**Steps:**
1. `gsi:audit-milestone` - Audit milestone completeness
2. `gsi:verify-work --all` - Verify all phases complete
3. `gsi:complete-milestone` - Archive current milestone
4. `gsi:new-milestone` - Create next milestone

**Checkpoint:** Manual only
**Rollback:** Enabled

**Use when:** Finishing a milestone and preparing for the next.

## Custom Templates

Create custom workflow templates in JSON format.

### Template Format

```json
{
  "name": "my-workflow",
  "description": "Description of what this workflow does",
  "chain": [
    {
      "command": "gsi:command-name",
      "args": "${variable}",
      "description": "Step description",
      "condition": "optional condition",
      "checkpoint": true
    }
  ],
  "parallel": [
    {
      "name": "parallel-group-name",
      "steps": [
        { "command": "gsi:command1" },
        { "command": "gsi:command2" }
      ]
    }
  ],
  "checkpoint": "after-each|after-phase|before-execute|manual",
  "rollback": true,
  "dependencies": {
    "gsi:command2": ["gsi:command1"]
  },
  "metadata": {
    "category": "custom",
    "estimated_duration": "1 hour",
    "use_case": "When to use this workflow"
  }
}
```

### Template Properties

| Property | Type | Description |
|----------|------|-------------|
| `name` | string | Unique template identifier |
| `description` | string | Human-readable description |
| `chain` | array | Sequential steps to execute |
| `parallel` | array | Groups of parallel steps |
| `checkpoint` | string | Checkpoint strategy |
| `rollback` | boolean | Enable rollback on failure |
| `dependencies` | object | Step dependencies |
| `metadata` | object | Additional metadata |

### Step Properties

| Property | Type | Description |
|----------|------|-------------|
| `command` | string | GSI command to execute |
| `args` | string | Command arguments (supports variables) |
| `description` | string | Step description |
| `condition` | string | Optional execution condition |
| `checkpoint` | boolean | Force checkpoint after this step |

### Checkpoint Strategies

| Strategy | Description |
|----------|-------------|
| `after-each` | Create checkpoint after every step |
| `after-phase` | Create checkpoint after phase-related commands |
| `before-execute` | Create checkpoint before execute commands |
| `manual` | Only checkpoint steps marked with `checkpoint: true` |

### Variable Substitution

Use `${variable}` syntax in args to substitute variables passed via `--vars`:

```bash
gsi workflow run my-template --vars '{"phase": "01", "name": "feature-x"}'
```

In template:
```json
{
  "args": "${phase} --name ${name}"
}
```

### Custom Template Location

Store custom templates in:
- Default: `get-shit-indexed/workflow-templates/`
- Custom: Specified via `--templates-dir`

## Workflow State

Workflows maintain state in `.planning/workflow-state.json`:

```json
{
  "full-cycle": {
    "chain": "full-cycle",
    "variables": { "phase": "01" },
    "completed": ["gsi:research-phase", "gsi:plan-phase"],
    "current": "gsi:execute-phase",
    "pending": ["gsi:verify-work"],
    "checkpoint": {
      "timestamp": "2025-02-18T10:45:00.000Z",
      "filesChanged": [],
      "stateSnapshot": { ... }
    },
    "startTime": "2025-02-18T10:30:00.000Z",
    "status": "running"
  }
}
```

## API Usage

For programmatic use, import the WorkflowChainer class:

```javascript
import { WorkflowChainer } from 'get-shit-indexed/lib/workflow-modules/index.js';

const chainer = new WorkflowChainer('.planning');

// Run a workflow
const result = await chainer.run('full-cycle', { phase: '01' }, {
  failureStrategy: 'stop-on-error',
  yoloMode: false
});

console.log(result.success);
console.log(result.completedSteps);
console.log(result.duration);

// List templates
const templates = chainer.listTemplates();

// Create custom chain
chainer.createChain({
  name: 'custom',
  description: 'Custom workflow',
  chain: [...],
  checkpoint: 'after-each',
  rollback: true
});

// Pause/resume/rollback
await chainer.pause('full-cycle');
await chainer.resume('full-cycle');
await chainer.rollback('full-cycle');

// Get status
const status = chainer.getStatus('full-cycle');
```

## Error Handling

Workflows handle errors based on the failure strategy:

### stop-on-error (default)

Stops immediately when a step fails:

```
Step 1: SUCCESS
Step 2: FAILED
Workflow: STOPPED
```

### continue-on-error

Continues to next step on failure:

```
Step 1: SUCCESS
Step 2: FAILED (logged)
Step 3: SUCCESS
Workflow: COMPLETED (with errors)
```

### rollback-on-error

Rolls back to last checkpoint on failure:

```
Step 1: SUCCESS
Checkpoint saved
Step 2: FAILED
Rolling back to checkpoint...
Workflow: ROLLED BACK
```

## Best Practices

1. **Use appropriate checkpoints**: More checkpoints = more recovery options but slower execution
2. **Enable rollback for critical workflows**: Prevents partial state on failure
3. **Use variables for reusable templates**: Parameterize phase numbers, names, etc.
4. **Start with built-in templates**: They cover common use cases
5. **Test custom templates**: Run with `--failure-strategy continue-on-error` first

## Troubleshooting

### Workflow stuck in "running" state

```bash
# Pause and resume
gsi workflow pause <name>
gsi workflow resume <name>

# Or rollback and restart
gsi workflow rollback <name>
gsi workflow run <name> --vars '...'
```

### Checkpoint not found

Ensure the workflow was run with a checkpoint strategy other than `manual`, or that steps have `checkpoint: true` set.

### Template not found

Check template name and location:
```bash
gsi workflow list --templates-dir ./custom-templates
```

## See Also

- [Patch Manager](./patch-manager.md) - Backup/restore local modifications
- [Thinking Orchestrator](./thinking-orchestrator.md) - Coordinate thinking servers
- [Knowledge Base](./knowledge-base.md) - Extract patterns from work

---

# Pattern Discovery (Phase 38-03)

The Workflow Chainer includes automatic pattern discovery capabilities that analyze command history to identify reusable workflow patterns.

## Overview

Pattern Discovery enables:

- **Automatic pattern mining**: Discover common command sequences from history
- **Template generation**: Convert high-quality patterns into reusable templates
- **Smart recommendations**: Get context-aware workflow suggestions
- **Workflow optimization**: Identify opportunities to improve workflow efficiency
- **Usage analytics**: Understand how workflows are being used

## CLI Commands

### gsi workflow discover

Mine patterns from command history and generate templates.

```bash
gsi workflow discover [options]
```

**Options:**
- `--min-frequency N` - Minimum occurrences to consider a pattern (default: 2)
- `--min-quality N` - Minimum quality score to generate template (default: 50)
- `--min-success-rate N` - Minimum success rate (0.0-1.0, default: 0.5)
- `--min-length N` - Minimum pattern length (default: 2)
- `--max-length N` - Maximum pattern length (default: 10)
- `--state-dir <path>` - Custom state directory

**Example:**

```bash
# Discover patterns with default settings
gsi workflow discover

# Only generate templates for high-quality patterns
gsi workflow discover --min-quality 75 --min-frequency 5

# Discover shorter patterns
gsi workflow discover --min-length 2 --max-length 5
```

**Output:**
```
Mining patterns from command history...
Discovered 12 patterns
Generated 4 templates (quality >= 50)

Top patterns:
  - research-plan-execute: freq=8, success=87%, quality=78
  - plan-execute-verify: freq=15, success=93%, quality=85
  - quick-fix-cycle: freq=6, success=75%, quality=62
  - milestone-complete: freq=4, success=100%, quality=71
```

### gsi workflow recommend

Get workflow recommendations based on current context.

```bash
gsi workflow recommend [options]
```

**Options:**
- `--phase N` - Current phase number for context
- `--recent-commands cmd1,cmd2` - Recently executed commands
- `--goal "..."` - Current workflow goal
- `--state-dir <path>` - Custom state directory

**Example:**

```bash
# Get recommendations for current phase
gsi workflow recommend --phase 01

# Get recommendations based on recent work
gsi workflow recommend --recent-commands "gsi:plan-phase,gsi:execute-phase"

# Get recommendations for a specific goal
gsi workflow recommend --goal "complete milestone"
```

**Output:**
```
Found 3 recommendations:

1. plan-execute-verify (85% relevant)
   Continues from gsi:plan-phase with gsi:execute-phase -> gsi:verify-work
   Sequence: gsi:plan-phase -> gsi:execute-phase -> gsi:verify-work
   Suggested vars: {"phase": "01"}

2. full-cycle (72% relevant)
   Frequently used pattern for phase operations (15 times)
   Sequence: gsi:research-phase -> gsi:plan-phase -> gsi:execute-phase -> gsi:verify-work
   Suggested vars: {"phase": "01"}

3. quick-fix (45% relevant)
   High-quality pattern with 93% success rate
   Sequence: gsi:plan-phase -> gsi:execute-phase -> gsi:verify-work
```

### gsi workflow optimize

Analyze a workflow for optimization opportunities.

```bash
gsi workflow optimize <name> [options]
```

**Arguments:**
- `<name>` - Name of the workflow to optimize

**Options:**
- `--state-dir <path>` - Custom state directory

**Example:**

```bash
gsi workflow optimize full-cycle
```

**Output:**
```
Optimization analysis for 'full-cycle':
Total optimizations found: 5
Estimated time savings: 45s

Parallel opportunities:
  - gsi:check-todos and gsi:progress can run in parallel
    Savings: 15s, Risk: low
  - gsi:research-phase and gsi:map-codebase can run in parallel
    Savings: 20s, Risk: low

Reorder suggestions:
  - Move fast step gsi:verify-references before slow step gsi:execute-phase
```

### gsi workflow analyze

Analyze all workflows and patterns with comprehensive statistics.

```bash
gsi workflow analyze [options]
```

**Options:**
- `--state-dir <path>` - Custom state directory

**Example:**

```bash
gsi workflow analyze
```

**Output:**
```
=== Workflow Analysis ===

Statistics:
  Total executions: 234
  Total sequences: 45
  Success rate: 89%
  Avg execution time: 12500ms
  Patterns discovered: 12

Most used commands:
  - gsi:plan-phase: 45 times
  - gsi:execute-phase: 42 times
  - gsi:verify-work: 38 times
  - gsi:research-phase: 28 times
  - gsi:progress: 25 times

Top patterns by quality:
  - full-cycle: quality=85, freq=15
  - quick-fix: quality=78, freq=8
  - milestone-complete: quality=71, freq=4

Optimization opportunities: 23
```

### gsi workflow export

Export a pattern as a reusable workflow template.

```bash
gsi workflow export <pattern-id> [options]
```

**Arguments:**
- `<pattern-id>` - ID of the pattern to export

**Options:**
- `--output <path>` - Output file path for the template
- `--state-dir <path>` - Custom state directory

**Example:**

```bash
# Export pattern to default location
gsi workflow export pattern-abc123

# Export to specific file
gsi workflow export pattern-abc123 --output ./my-workflow.json
```

**Output:**
```
Exported pattern 'pattern-abc123' as template 'research-plan-execute'
Template saved to: .planning/workflow-templates/discovered/research-plan-execute.json

Template JSON:
{
  "name": "research-plan-execute",
  "description": "Discovered pattern: gsi:research-phase -> gsi:plan-phase -> gsi:execute-phase",
  "chain": [...],
  "checkpoint": "after-phase",
  "rollback": true,
  "metadata": {
    "pattern_id": "pattern-abc123",
    "frequency": 8,
    "success_rate": 0.87,
    "quality_score": 78,
    "auto_generated": true
  }
}
```

## Pattern Quality Scoring

Patterns are scored on a 0-100 scale based on multiple factors:

| Factor | Weight | Description |
|--------|--------|-------------|
| Frequency | 25% | How often the pattern occurs (capped at 10) |
| Success Rate | 35% | Percentage of successful executions |
| Time Savings | 25% | Potential efficiency gains (capped at 1 minute) |
| Length | 15% | Pattern complexity (capped at 5 steps) |

### Quality Score Interpretation

| Score | Quality | Action |
|-------|---------|--------|
| 80-100 | Excellent | Highly recommended for automation |
| 60-79 | Good | Suitable for templates |
| 40-59 | Fair | Consider for manual workflows |
| 0-39 | Poor | Not recommended |

## Optimization Types

### Parallel Execution

Commands that don't depend on each other can run concurrently:

```
Before: cmd1 (10s) -> cmd2 (10s) -> cmd3 (5s) = 25s
After:  cmd1 (10s) + cmd2 (10s) -> cmd3 (5s) = 15s
Savings: 10s (40%)
```

**Risk Level:** Low (for independent commands)

### Skip Redundant Steps

Duplicate or unnecessary commands can be removed:

```
Before: cmd1 -> cmd2 -> cmd1 -> cmd3
After:  cmd1 -> cmd2 -> cmd3
```

**Risk Level:** Medium (verify command is truly redundant)

### Reorder Steps

Fast commands can be moved before slow ones:

```
Before: slow-cmd (30s) -> fast-cmd (2s)
After:  fast-cmd (2s) -> slow-cmd (30s)
Benefits: Earlier feedback, better UX
```

**Risk Level:** Medium (ensure no dependencies)

### Merge Steps

Similar commands can be combined:

```
Before: gsi:plan-phase 01 -> gsi:plan-phase 02
After:  gsi:plan-phases 01,02
```

**Risk Level:** High (requires command support)

## Data Storage

### workflow-history.json

Stores all tracked command executions and sequences:

```json
{
  "executions": [
    {
      "command": "gsi:plan-phase",
      "args": "01",
      "timestamp": "2025-02-18T10:30:00.000Z",
      "success": true,
      "duration": 5000
    }
  ],
  "sequences": [
    {
      "id": "seq-abc123",
      "commands": [...],
      "startTime": "2025-02-18T10:30:00.000Z",
      "endTime": "2025-02-18T10:45:00.000Z",
      "successRate": 1.0,
      "source": "workflow"
    }
  ],
  "patterns": [...],
  "stats": {...}
}
```

### workflow-templates/discovered/

Auto-generated templates from discovered patterns:

```
discovered/
├── README.md
├── .gitkeep
├── research-plan-execute.json
├── quick-fix-cycle.json
└── milestone-complete.json
```

## Programmatic API

```javascript
import { PatternMiner } from 'get-shit-indexed/lib/workflow-modules/pattern-miner.js';

const miner = new PatternMiner('.planning');

// Track command execution
miner.trackExecution({
  command: 'gsi:plan-phase',
  args: '01',
  timestamp: new Date().toISOString(),
  success: true,
  duration: 5000
});

// Track a sequence
const seqId = miner.startSequence('workflow');
miner.addToSequence(seqId, execution1);
miner.addToSequence(seqId, execution2);
miner.completeSequence(seqId);

// Mine patterns
const patterns = miner.minePatterns({
  minFrequency: 2,
  minSuccessRate: 0.5,
  minQuality: 50
});

// Get recommendations
const recommendations = miner.getRecommendations({
  currentPhase: '01',
  recentCommands: ['gsi:plan-phase'],
  workflowGoal: 'complete feature'
});

// Analyze optimizations
const optimizations = miner.analyzeOptimizations('full-cycle');

// Export pattern as template
const template = miner.generateTemplate('pattern-abc123');
miner.saveTemplate(template);
```

## Best Practices for Pattern Discovery

1. **Run discover regularly**: Keep patterns up-to-date with your workflow habits
2. **Set appropriate thresholds**: Use `--min-quality` to control template generation
3. **Review recommendations**: Don't blindly follow suggestions, verify context
4. **Export valuable patterns**: Save high-quality patterns before clearing history
5. **Monitor optimization**: Run `analyze` periodically to find efficiency opportunities

## Troubleshooting Pattern Discovery

### No patterns discovered

- Ensure you have command history (run some commands first)
- Lower `--min-frequency` threshold
- Lower `--min-quality` threshold

### Low quality patterns

- Increase `--min-frequency` to find more reliable patterns
- Increase `--min-success-rate` to filter out unreliable patterns
- Review execution history for failures

### Irrelevant recommendations

- Provide more context via `--phase`, `--recent-commands`, or `--goal`
- Clear old history that doesn't match current workflow patterns
- Run `discover` again after major workflow changes

</document_content>
</document>
<document index="9">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\cognitive-flow\index.ts</source>
<document_content>
/**
 * Cognitive-Flow Orchestration Layer
 *
 * Unified orchestration for thinking servers, MCP tools, and claudeception modules.
 *
 * ## Quick Start
 *
 * ```typescript
 * import { CognitiveOrchestrator, CognitivePhase } from 'cognitive-flow';
 *
 * const orchestrator = new CognitiveOrchestrator();
 *
 * const context = CognitiveOrchestrator.context('analyze-code')
 *   .withPhase(CognitivePhase.PREPARE)
 *   .withTargetPath('/path/to/file.ts')
 *   .build();
 *
 * const result = await orchestrator.execute(context);
 * ```
 *
 * ## Four-Phase Flow
 *
 * 1. **PREPARE**: Structure analysis using Tractatus thinking
 * 2. **EXECUTE**: Step-by-step execution using Sequential thinking
 * 3. **REFLECT**: Problem analysis using Debug thinking
 * 4. **LEARN**: Knowledge capture and storage
 *
 * @module cognitive-flow
 */

// Types
export {
  // Phases
  CognitivePhase,

  // Context
  CognitiveContext,
  CognitiveContextBuilder,

  // Results
  CognitiveResult,
  PhaseResult,
  ThinkingResult,
  ThinkingThought,
  MCPToolResult,

  // Server Types
  ThinkingServer,
  ServerHealth,
  ServerPoolConfig,
  ServerSelection,

  // Tool Types
  MCPToolCategory,
  MCPToolInfo,
  ToolSelectionEntry,
  BatchOptimization,
  MCPToolCall,

  // Learning Types
  LearningEntry,
  CognitivePattern,
  PatternTrigger,
  PatternAction,

  // Configuration
  CognitiveFlowConfig,
  DEFAULT_FLOW_CONFIG,

  // Events
  CognitiveEventType,
  CognitiveEvent,
  CognitiveEventHandler
} from './types.js';

// Orchestrator
export {
  CognitiveOrchestrator,
  getOrchestrator,
  executeCognitiveFlow
} from './orchestrator.js';

// Server Pool
export { ServerPool } from './server-pool.js';

// Tool Optimizer
export { ToolOptimizer } from './tool-optimizer.js';

// Version
export const COGNITIVE_FLOW_VERSION = '1.0.0';

/**
 * Initialize cognitive-flow with default configuration.
 */
export function initializeCognitiveFlow(config?: Partial<import('./types.js').CognitiveFlowConfig>): CognitiveOrchestrator {
  return new CognitiveOrchestrator(config);
}

/**
 * Quick cognitive flow execution.
 */
export async function quickCognitiveFlow(
  operation: string,
  input: any,
  options?: {
    targetPath?: string;
    command?: string;
    timeout?: number;
  }
): Promise<import('./types.js').CognitiveResult> {
  const orchestrator = getOrchestrator();
  return orchestrator.quickExecute(operation, input, options);
}

</document_content>
</document>
<document index="10">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\cognitive-flow\orchestrator.ts</source>
<document_content>
/**
 * Cognitive Flow Orchestrator
 *
 * Unified orchestration layer that coordinates thinking servers, MCP tools,
 * and claudeception modules for intelligent cognitive operations.
 *
 * Four-Phase Flow:
 * 1. PREPARE: Structure analysis using Tractatus thinking
 * 2. EXECUTE: Step-by-step execution using Sequential thinking
 * 3. REFLECT: Problem analysis using Debug thinking
 * 4. LEARN: Knowledge capture and storage
 *
 * @module cognitive-flow/orchestrator
 */

import {
  CognitivePhase,
  CognitiveContext,
  CognitiveResult,
  CognitiveFlowConfig,
  CognitiveContextBuilder,
  CognitiveEvent,
  CognitiveEventType,
  CognitiveEventHandler,
  PhaseResult,
  ThinkingResult,
  ThinkingThought,
  MCPToolResult,
  DEFAULT_FLOW_CONFIG,
  LearningEntry
} from './types.js';

import { ServerPool } from './server-pool.js';
import { ToolOptimizer, MCPToolCall } from './tool-optimizer.js';

/**
 * Main cognitive orchestrator class.
 */
export class CognitiveOrchestrator {
  private config: CognitiveFlowConfig;
  private serverPool: ServerPool;
  private toolOptimizer: ToolOptimizer;
  private eventHandlers: Map<CognitiveEventType, CognitiveEventHandler[]>;
  private learningBuffer: LearningEntry[];
  private activeFlows: Map<string, CognitiveResult>;

  constructor(config: Partial<CognitiveFlowConfig> = {}) {
    this.config = { ...DEFAULT_FLOW_CONFIG, ...config };
    this.serverPool = new ServerPool(this.config.serverPool);
    this.toolOptimizer = new ToolOptimizer();
    this.eventHandlers = new Map();
    this.learningBuffer = [];
    this.activeFlows = new Map();

    // Start server health checks
    this.serverPool.startHealthChecks();
  }

  /**
   * Execute a cognitive flow.
   */
  async execute(context: CognitiveContext): Promise<CognitiveResult> {
    const startTime = Date.now();
    const flowId = `${context.operation}-${Date.now()}`;

    this.emit('flow:start', { phase: context.phase, data: { flowId, context } });

    const result: CognitiveResult = {
      success: false,
      operation: context.operation,
      phases: new Map(),
      duration: 0,
      totalTokens: 0,
      insights: [],
      learnings: [],
      nextSteps: [],
      errors: [],
      degraded: false,
      timestamp: new Date()
    };

    try {
      // Execute each enabled phase
      for (const phase of this.config.enabledPhases) {
        const phaseTimeout = this.config.phaseTimeouts.get(phase) || 5000;

        this.emit('phase:start', { phase });

        try {
          const phaseResult = await this.executePhaseWithTimeout(
            phase,
            context,
            phaseTimeout
          );

          result.phases.set(phase, phaseResult);

          if (!phaseResult.success) {
            result.degraded = true;
          }

          // Aggregate insights and learnings
          result.insights.push(...phaseResult.insights);
          result.learnings.push(...phaseResult.learnings);

          // Calculate tokens
          for (const toolResult of phaseResult.toolResults) {
            result.totalTokens += toolResult.tokensUsed;
          }

          this.emit('phase:complete', { phase, data: phaseResult });
        } catch (error) {
          result.degraded = true;
          result.errors.push(`Phase ${phase} failed: ${error}`);

          this.emit('phase:error', { phase, error: error as Error });
        }
      }

      result.success = !result.degraded || result.phases.size > 0;

      // Store learning if enabled
      if (this.config.learningEnabled) {
        await this.captureLearning(context, result);
      }

    } catch (error) {
      result.errors.push(`Flow failed: ${error}`);
      this.emit('error', { error: error as Error });
    }

    result.duration = Date.now() - startTime;
    this.activeFlows.set(flowId, result);

    this.emit('flow:complete', { data: result });

    return result;
  }

  /**
   * Execute a single phase with timeout.
   */
  private async executePhaseWithTimeout(
    phase: CognitivePhase,
    context: CognitiveContext,
    timeout: number
  ): Promise<PhaseResult> {
    return new Promise(async (resolve, reject) => {
      const timeoutId = setTimeout(() => {
        reject(new Error(`Phase ${phase} timed out after ${timeout}ms`));
      }, timeout);

      try {
        const result = await this.executePhase(phase, context);
        clearTimeout(timeoutId);
        resolve(result);
      } catch (error) {
        clearTimeout(timeoutId);
        reject(error);
      }
    });
  }

  /**
   * Execute a single cognitive phase.
   */
  private async executePhase(
    phase: CognitivePhase,
    context: CognitiveContext
  ): Promise<PhaseResult> {
    const startTime = Date.now();
    const phaseContext: CognitiveContext = {
      ...context,
      phase
    };

    const thinkingResults: ThinkingResult[] = [];
    const toolResults: MCPToolResult[] = [];
    const insights: string[] = [];
    const learnings: string[] = [];

    // Execute thinking for this phase
    const thinkingResult = await this.executeThinking(phase, phaseContext);
    if (thinkingResult) {
      thinkingResults.push(thinkingResult);
      insights.push(...this.extractInsights(thinkingResult));
    }

    // Execute tools for this phase
    const toolsToExecute = this.selectToolsForPhase(phase, phaseContext);
    for (const toolCall of toolsToExecute) {
      const toolResult = await this.executeTool(toolCall);
      toolResults.push(toolResult);
    }

    const duration = Date.now() - startTime;

    return {
      phase,
      thinkingResults,
      toolResults,
      success: thinkingResults.some(r => r.success) || toolResults.some(r => r.success),
      duration,
      insights,
      learnings,
      nextPhase: this.determineNextPhase(phase, thinkingResults)
    };
  }

  /**
   * Execute thinking server for a phase.
   */
  private async executeThinking(
    phase: CognitivePhase,
    context: CognitiveContext
  ): Promise<ThinkingResult | null> {
    const selection = this.serverPool.selectServer(context);

    this.emit('server:select', { server: selection.server, data: selection });

    const startTime = Date.now();

    try {
      this.emit('server:call', { server: selection.server, phase });

      // Simulate thinking execution
      // In real implementation, would call the MCP server
      const thoughts = await this.simulateThinking(selection.server, context);

      const duration = Date.now() - startTime;

      this.serverPool.recordCall(selection.server, duration, true);

      const result: ThinkingResult = {
        server: selection.server,
        phase,
        thoughts,
        duration,
        success: true,
        metadata: { selection }
      };

      this.emit('server:result', { server: selection.server, data: result });

      return result;
    } catch (error) {
      const duration = Date.now() - startTime;
      this.serverPool.recordCall(selection.server, duration, false);

      return {
        server: selection.server,
        phase,
        thoughts: [],
        duration,
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error'
      };
    }
  }

  /**
   * Simulate thinking execution.
   * In production, this would call the actual MCP server.
   */
  private async simulateThinking(
    server: string,
    context: CognitiveContext
  ): Promise<ThinkingThought[]> {
    const thoughts: ThinkingThought[] = [];
    const maxThoughts = this.getMaxThoughtsForPhase(context.phase);

    for (let i = 1; i <= maxThoughts; i++) {
      thoughts.push({
        thoughtNumber: i,
        totalThoughts: maxThoughts,
        thought: `[${server}] Processing ${context.operation} - Step ${i}/${maxThoughts}`,
        nextThoughtNeeded: i < maxThoughts
      });
    }

    return thoughts;
  }

  /**
   * Get max thoughts for a phase.
   */
  private getMaxThoughtsForPhase(phase: CognitivePhase): number {
    switch (phase) {
      case CognitivePhase.PREPARE:
        return 3;
      case CognitivePhase.EXECUTE:
        return 5;
      case CognitivePhase.REFLECT:
        return 4;
      case CognitivePhase.LEARN:
        return 2;
      default:
        return 3;
    }
  }

  /**
   * Select tools for a phase.
   */
  private selectToolsForPhase(phase: CognitivePhase, context: CognitiveContext): MCPToolCall[] {
    const tools: MCPToolCall[] = [];

    switch (phase) {
      case CognitivePhase.PREPARE:
        // Structure analysis tools
        if (context.targetPath) {
          tools.push({
            server: 'code-index-mcp',
            tool: 'get_file_summary',
            params: { file_path: context.targetPath }
          });
        }
        break;

      case CognitivePhase.EXECUTE:
        // Execution tools based on operation
        if (context.targetPath) {
          tools.push({
            server: 'desktop-commander',
            tool: 'read_file',
            params: { path: context.targetPath }
          });
        }
        break;

      case CognitivePhase.REFLECT:
        // Analysis tools
        tools.push({
          server: 'code-index-mcp',
          tool: 'search_code_advanced',
          params: { pattern: context.operation, max_results: 5 }
        });
        break;

      case CognitivePhase.LEARN:
        // Learning capture tools
        // Learning is handled separately
        break;
    }

    return tools;
  }

  /**
   * Execute a tool.
   */
  private async executeTool(call: MCPToolCall): Promise<MCPToolResult> {
    const startTime = Date.now();
    const tokenCost = this.toolOptimizer.estimateTokenCost(
      `${call.server}__${call.tool}`,
      call.params
    );

    this.emit('tool:call', { tool: call.tool, data: call });

    try {
      // Simulate tool execution
      // In production, would call the actual MCP server
      await new Promise(resolve => setTimeout(resolve, 50));

      const duration = Date.now() - startTime;

      const result: MCPToolResult = {
        tool: call.tool,
        server: call.server,
        success: true,
        result: { simulated: true },
        duration,
        tokensUsed: tokenCost
      };

      this.emit('tool:result', { tool: call.tool, data: result });

      this.toolOptimizer.recordCall(call, result);

      return result;
    } catch (error) {
      const duration = Date.now() - startTime;

      return {
        tool: call.tool,
        server: call.server,
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
        duration,
        tokensUsed: tokenCost
      };
    }
  }

  /**
   * Extract insights from thinking results.
   */
  private extractInsights(result: ThinkingResult): string[] {
    const insights: string[] = [];

    for (const thought of result.thoughts) {
      // Extract key insights from thoughts
      if (thought.thought.includes('pattern')) {
        insights.push(`Pattern detected: ${thought.thought.slice(0, 100)}`);
      }
      if (thought.thought.includes('recommendation')) {
        insights.push(`Recommendation: ${thought.thought.slice(0, 100)}`);
      }
    }

    return insights;
  }

  /**
   * Determine next phase based on results.
   */
  private determineNextPhase(
    currentPhase: CognitivePhase,
    results: ThinkingResult[]
  ): CognitivePhase | undefined {
    const phases = this.config.enabledPhases;
    const currentIndex = phases.indexOf(currentPhase);

    if (currentIndex < phases.length - 1) {
      return phases[currentIndex + 1];
    }

    return undefined;
  }

  /**
   * Capture learning from the flow.
   */
  private async captureLearning(context: CognitiveContext, result: CognitiveResult): Promise<void> {
    const entry: LearningEntry = {
      id: `learning-${Date.now()}`,
      timestamp: new Date(),
      operation: context.operation,
      phase: context.phase,
      context,
      outcome: result.success ? 'success' : result.degraded ? 'partial' : 'failure',
      insights: result.insights,
      patterns: this.extractPatterns(result),
      effectiveness: this.calculateEffectiveness(result),
      serversUsed: Array.from(result.phases.values())
        .flatMap(p => p.thinkingResults.map(r => r.server)),
      toolsUsed: Array.from(result.phases.values())
        .flatMap(p => p.toolResults.map(r => `${r.server}__${r.tool}`)),
      duration: result.duration
    };

    this.learningBuffer.push(entry);

    // Store in debug-thinking graph if available
    this.emit('learning:capture', { data: entry });

    // Flush buffer periodically
    if (this.learningBuffer.length >= 10) {
      await this.flushLearningBuffer();
    }
  }

  /**
   * Extract patterns from result.
   */
  private extractPatterns(result: CognitiveResult): string[] {
    const patterns: string[] = [];

    // Pattern: Successful phase combinations
    const successfulPhases = Array.from(result.phases.entries())
      .filter(([_, p]) => p.success)
      .map(([phase]) => phase);

    if (successfulPhases.length > 1) {
      patterns.push(`Phase pattern: ${successfulPhases.join(' -> ')}`);
    }

    // Pattern: Tool usage patterns
    const tools = Array.from(result.phases.values())
      .flatMap(p => p.toolResults.filter(r => r.success).map(r => r.tool));

    if (tools.length > 0) {
      patterns.push(`Tool pattern: ${[...new Set(tools)].join(', ')}`);
    }

    return patterns;
  }

  /**
   * Calculate effectiveness score.
   */
  private calculateEffectiveness(result: CognitiveResult): number {
    let score = 0;

    // Success factor
    if (result.success) score += 50;
    else if (result.degraded) score += 25;

    // Phase completion factor
    const phaseCount = result.phases.size;
    const enabledCount = this.config.enabledPhases.length;
    score += (phaseCount / enabledCount) * 30;

    // Insights factor
    score += Math.min(result.insights.length * 5, 20);

    return Math.min(100, score);
  }

  /**
   * Flush learning buffer to storage.
   */
  private async flushLearningBuffer(): Promise<void> {
    if (this.learningBuffer.length === 0) return;

    // In production, would persist to debug-thinking graph
    // For now, clear buffer
    this.learningBuffer = [];
  }

  /**
   * Register an event handler.
   */
  on(eventType: CognitiveEventType, handler: CognitiveEventHandler): void {
    if (!this.eventHandlers.has(eventType)) {
      this.eventHandlers.set(eventType, []);
    }
    this.eventHandlers.get(eventType)!.push(handler);
  }

  /**
   * Emit an event.
   */
  private emit(type: CognitiveEventType, event: Partial<CognitiveEvent>): void {
    const handlers = this.eventHandlers.get(type) || [];

    const fullEvent: CognitiveEvent = {
      type,
      timestamp: new Date(),
      ...event
    };

    for (const handler of handlers) {
      try {
        handler(fullEvent);
      } catch (error) {
        // Ignore handler errors
      }
    }
  }

  /**
   * Get orchestrator status.
   */
  getStatus(): {
    serverPool: ReturnType<ServerPool['getStats']>;
    toolOptimizer: ReturnType<ToolOptimizer['getStats']>;
    activeFlows: number;
    learningBufferSize: number;
    config: CognitiveFlowConfig;
  } {
    return {
      serverPool: this.serverPool.getStats(),
      toolOptimizer: this.toolOptimizer.getStats(),
      activeFlows: this.activeFlows.size,
      learningBufferSize: this.learningBuffer.length,
      config: this.config
    };
  }

  /**
   * Update configuration.
   */
  updateConfig(config: Partial<CognitiveFlowConfig>): void {
    this.config = { ...this.config, ...config };

    // Update server pool config if provided
    if (config.serverPool) {
      this.serverPool = new ServerPool(this.config.serverPool);
    }
  }

  /**
   * Create a context builder.
   */
  static context(operation: string): CognitiveContextBuilder {
    return new CognitiveContextBuilder(operation);
  }

  /**
   * Quick execute with minimal setup.
   */
  async quickExecute(
    operation: string,
    input: any,
    options: {
      targetPath?: string;
      command?: string;
      timeout?: number;
    } = {}
  ): Promise<CognitiveResult> {
    const context = CognitiveOrchestrator.context(operation)
      .withInput(input)
      .withTargetPath(options.targetPath || '')
      .withCommand(options.command || '')
      .withTimeout(options.timeout || 10000)
      .build();

    return this.execute(context);
  }

  /**
   * Shutdown the orchestrator.
   */
  shutdown(): void {
    this.serverPool.stopHealthChecks();
    this.activeFlows.clear();
    this.learningBuffer = [];
    this.eventHandlers.clear();
  }
}

// Export singleton instance
let defaultOrchestrator: CognitiveOrchestrator | null = null;

/**
 * Get the default orchestrator instance.
 */
export function getOrchestrator(config?: Partial<CognitiveFlowConfig>): CognitiveOrchestrator {
  if (!defaultOrchestrator) {
    defaultOrchestrator = new CognitiveOrchestrator(config);
  }
  return defaultOrchestrator;
}

/**
 * Execute a cognitive flow using the default orchestrator.
 */
export async function executeCognitiveFlow(
  context: CognitiveContext
): Promise<CognitiveResult> {
  return getOrchestrator().execute(context);
}

export default CognitiveOrchestrator;

</document_content>
</document>
<document index="11">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\cognitive-flow\server-pool.ts</source>
<document_content>
/**
 * Thinking Server Pool Management
 *
 * Manages health checking, load balancing, and fallback chains for thinking servers.
 *
 * @module cognitive-flow/server-pool
 */

import {
  ThinkingServer,
  ServerHealth,
  ServerPoolConfig,
  ServerSelection,
  CognitiveContext,
  CognitivePhase
} from './types.js';

/**
 * Default server pool configuration.
 */
const DEFAULT_POOL_CONFIG: ServerPoolConfig = {
  healthCheckInterval: 30000,
  maxRetries: 3,
  retryDelay: 1000,
  timeout: 10000,
  fallbackChain: ['sequential', 'tractatus', 'debug']
};

/**
 * Server endpoint mapping.
 */
const SERVER_ENDPOINTS: Record<ThinkingServer, string> = {
  sequential: 'mcp__sequential-thinking__sequentialthinking',
  tractatus: 'mcp__tractatusthinking__tractatus_thinking',
  debug: 'mcp__debug-thinking__debug_thinking'
};

/**
 * Server capabilities mapping.
 */
const SERVER_CAPABILITIES: Record<ThinkingServer, string[]> = {
  sequential: [
    'step-planning',
    'execution-order',
    'task-decomposition',
    'process-sequencing',
    'dependency-ordering'
  ],
  tractatus: [
    'structural-analysis',
    'logical-dependencies',
    'concept-decomposition',
    'architecture-analysis',
    'relationship-mapping'
  ],
  debug: [
    'problem-detection',
    'hypothesis-generation',
    'root-cause-analysis',
    'solution-verification',
    'error-investigation'
  ]
};

/**
 * Phase-to-server affinity mapping.
 */
const PHASE_SERVER_AFFINITY: Record<CognitivePhase, ThinkingServer[]> = {
  [CognitivePhase.PREPARE]: ['tractatus', 'sequential'],
  [CognitivePhase.EXECUTE]: ['sequential', 'tractatus'],
  [CognitivePhase.REFLECT]: ['debug', 'tractatus'],
  [CognitivePhase.LEARN]: ['debug', 'sequential']
};

/**
 * Manages a pool of thinking servers with health checking and load balancing.
 */
export class ServerPool {
  private config: ServerPoolConfig;
  private healthStatus: Map<ThinkingServer, ServerHealth>;
  private healthCheckTimer?: ReturnType<typeof setInterval>;
  private callCount: Map<ThinkingServer, number>;
  private totalLatency: Map<ThinkingServer, number>;

  constructor(config: Partial<ServerPoolConfig> = {}) {
    this.config = { ...DEFAULT_POOL_CONFIG, ...config };
    this.healthStatus = new Map();
    this.callCount = new Map();
    this.totalLatency = new Map();

    // Initialize health status for all servers
    for (const server of ['sequential', 'tractatus', 'debug'] as ThinkingServer[]) {
      this.healthStatus.set(server, {
        server,
        available: true,
        latency: 0,
        lastCheck: new Date(),
        errorCount: 0
      });
      this.callCount.set(server, 0);
      this.totalLatency.set(server, 0);
    }
  }

  /**
   * Start health checking.
   */
  startHealthChecks(): void {
    if (this.healthCheckTimer) {
      return;
    }

    // Run initial health check
    this.checkAllHealth();

    // Schedule periodic health checks
    this.healthCheckTimer = setInterval(
      () => this.checkAllHealth(),
      this.config.healthCheckInterval
    );
  }

  /**
   * Stop health checking.
   */
  stopHealthChecks(): void {
    if (this.healthCheckTimer) {
      clearInterval(this.healthCheckTimer);
      this.healthCheckTimer = undefined;
    }
  }

  /**
   * Check health of all servers.
   */
  private async checkAllHealth(): Promise<void> {
    for (const server of ['sequential', 'tractatus', 'debug'] as ThinkingServer[]) {
      await this.checkServerHealth(server);
    }
  }

  /**
   * Check health of a specific server.
   */
  private async checkServerHealth(server: ThinkingServer): Promise<ServerHealth> {
    const startTime = Date.now();
    const health = this.healthStatus.get(server)!;

    try {
      // Simulate health check - in real implementation, would ping the MCP server
      // For now, assume server is available
      const latency = Date.now() - startTime;

      health.available = true;
      health.latency = latency;
      health.lastCheck = new Date();

      // Decay error count on successful check
      if (health.errorCount > 0) {
        health.errorCount = Math.max(0, health.errorCount - 1);
      }
    } catch (error) {
      health.available = false;
      health.latency = 0;
      health.lastCheck = new Date();
      health.errorCount++;
      health.lastError = error instanceof Error ? error.message : 'Unknown error';
    }

    this.healthStatus.set(server, health);
    return health;
  }

  /**
   * Get health status of a server.
   */
  getHealth(server: ThinkingServer): ServerHealth {
    return this.healthStatus.get(server)!;
  }

  /**
   * Get all server health statuses.
   */
  getAllHealth(): Map<ThinkingServer, ServerHealth> {
    return new Map(this.healthStatus);
  }

  /**
   * Select the best server for a given context.
   */
  selectServer(context: CognitiveContext): ServerSelection {
    const { phase, operation } = context;

    // Get phase-affinity servers
    const preferredServers = PHASE_SERVER_AFFINITY[phase] || this.config.fallbackChain;

    // Filter by availability and health
    const availableServers = preferredServers.filter(s => {
      const health = this.healthStatus.get(s);
      return health && health.available && health.errorCount < 3;
    });

    if (availableServers.length === 0) {
      // All servers degraded, use first in fallback chain
      return {
        server: this.config.fallbackChain[0],
        reason: 'All servers degraded, using primary fallback',
        alternatives: this.config.fallbackChain.slice(1),
        confidence: 0.3
      };
    }

    // Score each available server
    const scores = availableServers.map(server => ({
      server,
      score: this.scoreServer(server, context)
    }));

    // Sort by score (highest first)
    scores.sort((a, b) => b.score - a.score);

    const selected = scores[0];
    const alternatives = scores.slice(1).map(s => s.server);

    return {
      server: selected.server,
      reason: `Best match for ${phase} phase with score ${selected.score.toFixed(2)}`,
      alternatives,
      confidence: Math.min(0.5 + (selected.score / 100), 0.95)
    };
  }

  /**
   * Score a server for a given context.
   */
  private scoreServer(server: ThinkingServer, context: CognitiveContext): number {
    let score = 50; // Base score

    const health = this.healthStatus.get(server)!;

    // Health factor (0-20 points)
    if (health.available) {
      score += 20;
    }
    score -= health.errorCount * 5;

    // Latency factor (0-15 points)
    if (health.latency < 100) {
      score += 15;
    } else if (health.latency < 500) {
      score += 10;
    } else if (health.latency < 1000) {
      score += 5;
    }

    // Capability matching (0-15 points)
    const capabilities = SERVER_CAPABILITIES[server];
    const operationLower = context.operation.toLowerCase();

    for (const cap of capabilities) {
      if (operationLower.includes(cap.replace('-', ''))) {
        score += 3;
      }
    }

    // Phase affinity (0-10 points)
    const phaseServers = PHASE_SERVER_AFFINITY[context.phase];
    const phaseIndex = phaseServers.indexOf(server);
    if (phaseIndex === 0) {
      score += 10;
    } else if (phaseIndex === 1) {
      score += 5;
    }

    // Load balancing (-10 to 0 points)
    const callCount = this.callCount.get(server) || 0;
    const avgCount = this.getAverageCallCount();
    if (callCount > avgCount * 1.5) {
      score -= 10;
    } else if (callCount > avgCount) {
      score -= 5;
    }

    return Math.max(0, Math.min(100, score));
  }

  /**
   * Get average call count across all servers.
   */
  private getAverageCallCount(): number {
    const counts = Array.from(this.callCount.values());
    return counts.reduce((a, b) => a + b, 0) / counts.length;
  }

  /**
   * Record a server call.
   */
  recordCall(server: ThinkingServer, latency: number, success: boolean): void {
    // Update call count
    const count = this.callCount.get(server) || 0;
    this.callCount.set(server, count + 1);

    // Update total latency
    const total = this.totalLatency.get(server) || 0;
    this.totalLatency.set(server, total + latency);

    // Update health if failed
    if (!success) {
      const health = this.healthStatus.get(server)!;
      health.errorCount++;
      health.lastError = 'Call failed';
      this.healthStatus.set(server, health);
    }
  }

  /**
   * Get server endpoint.
   */
  getEndpoint(server: ThinkingServer): string {
    return SERVER_ENDPOINTS[server];
  }

  /**
   * Get server capabilities.
   */
  getCapabilities(server: ThinkingServer): string[] {
    return [...SERVER_CAPABILITIES[server]];
  }

  /**
   * Check if a server supports a capability.
   */
  supportsCapability(server: ThinkingServer, capability: string): boolean {
    return SERVER_CAPABILITIES[server].includes(capability);
  }

  /**
   * Get servers that support a capability.
   */
  getServersByCapability(capability: string): ThinkingServer[] {
    const servers: ThinkingServer[] = [];

    for (const [server, capabilities] of Object.entries(SERVER_CAPABILITIES)) {
      if (capabilities.includes(capability)) {
        servers.push(server as ThinkingServer);
      }
    }

    return servers;
  }

  /**
   * Get fallback chain for a server.
   */
  getFallbackChain(server: ThinkingServer): ThinkingServer[] {
    const chain = [server];

    for (const fallback of this.config.fallbackChain) {
      if (!chain.includes(fallback)) {
        chain.push(fallback);
      }
    }

    return chain;
  }

  /**
   * Get pool statistics.
   */
  getStats(): {
    totalCalls: number;
    avgLatency: number;
    serverStats: Map<ThinkingServer, {
      calls: number;
      avgLatency: number;
      errors: number;
      availability: number;
    }>;
  } {
    const serverStats = new Map<ThinkingServer, {
      calls: number;
      avgLatency: number;
      errors: number;
      availability: number;
    }>();

    let totalCalls = 0;
    let totalLatencySum = 0;

    for (const server of ['sequential', 'tractatus', 'debug'] as ThinkingServer[]) {
      const calls = this.callCount.get(server) || 0;
      const latency = this.totalLatency.get(server) || 0;
      const health = this.healthStatus.get(server)!;

      totalCalls += calls;
      totalLatencySum += latency;

      serverStats.set(server, {
        calls,
        avgLatency: calls > 0 ? latency / calls : 0,
        errors: health.errorCount,
        availability: health.available ? 100 : 0
      });
    }

    return {
      totalCalls,
      avgLatency: totalCalls > 0 ? totalLatencySum / totalCalls : 0,
      serverStats
    };
  }

  /**
   * Reset statistics.
   */
  resetStats(): void {
    for (const server of ['sequential', 'tractatus', 'debug'] as ThinkingServer[]) {
      this.callCount.set(server, 0);
      this.totalLatency.set(server, 0);
    }
  }

  /**
   * Mark a server as degraded.
   */
  markDegraded(server: ThinkingServer, reason: string): void {
    const health = this.healthStatus.get(server)!;
    health.available = false;
    health.lastError = reason;
    health.errorCount++;
    this.healthStatus.set(server, health);
  }

  /**
   * Mark a server as recovered.
   */
  markRecovered(server: ThinkingServer): void {
    const health = this.healthStatus.get(server)!;
    health.available = true;
    health.lastCheck = new Date();
    this.healthStatus.set(server, health);
  }
}

export default ServerPool;

</document_content>
</document>
<document index="12">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\cognitive-flow\tool-optimizer.ts</source>
<document_content>
/**
 * MCP Tool Optimizer
 *
 * Provides tool selection matrix, token cost estimation, batch optimization,
 * and parallel execution planning for MCP tools.
 *
 * @module cognitive-flow/tool-optimizer
 */

import {
  MCPToolCategory,
  MCPToolInfo,
  ToolSelectionEntry,
  BatchOptimization,
  MCPToolCall,
  MCPToolResult
} from './types.js';

/**
 * Tool selection matrix with preferred tools and token savings.
 */
const TOOL_SELECTION_MATRIX: ToolSelectionEntry[] = [
  // File Operations
  {
    operation: 'read-file',
    preferredTool: 'mcp__desktop-commander__read_file',
    alternatives: ['Read'],
    tokenSavings: 50,
    priority: 1
  },
  {
    operation: 'write-file',
    preferredTool: 'mcp__desktop-commander__write_file',
    alternatives: ['Write'],
    tokenSavings: 50,
    priority: 1
  },
  {
    operation: 'edit-file',
    preferredTool: 'mcp__desktop-commander__edit_block',
    alternatives: ['Edit'],
    tokenSavings: 60,
    priority: 1
  },
  {
    operation: 'list-directory',
    preferredTool: 'mcp__desktop-commander__list_directory',
    alternatives: ['Bash ls'],
    tokenSavings: 70,
    priority: 1
  },
  {
    operation: 'search-files',
    preferredTool: 'mcp__desktop-commander__start_search',
    alternatives: ['Grep', 'Glob'],
    tokenSavings: 80,
    priority: 1
  },
  {
    operation: 'create-directory',
    preferredTool: 'mcp__desktop-commander__create_directory',
    alternatives: ['Bash mkdir'],
    tokenSavings: 60,
    priority: 1
  },
  {
    operation: 'move-file',
    preferredTool: 'mcp__desktop-commander__move_file',
    alternatives: ['Bash mv'],
    tokenSavings: 60,
    priority: 1
  },
  {
    operation: 'read-multiple-files',
    preferredTool: 'mcp__desktop-commander__read_multiple_files',
    alternatives: ['Read (multiple calls)'],
    tokenSavings: 85,
    priority: 1
  },
  // Code Search
  {
    operation: 'search-code',
    preferredTool: 'mcp__code-index-mcp__search_code_advanced',
    alternatives: ['Grep'],
    tokenSavings: 75,
    priority: 1
  },
  {
    operation: 'find-files',
    preferredTool: 'mcp__code-index-mcp__find_files',
    alternatives: ['Glob'],
    tokenSavings: 70,
    priority: 1
  },
  {
    operation: 'get-symbol',
    preferredTool: 'mcp__code-index-mcp__get_symbol_body',
    alternatives: ['Read + Manual search'],
    tokenSavings: 90,
    priority: 1
  },
  {
    operation: 'file-summary',
    preferredTool: 'mcp__code-index-mcp__get_file_summary',
    alternatives: ['Read entire file'],
    tokenSavings: 85,
    priority: 1
  },
  // Process Management
  {
    operation: 'start-process',
    preferredTool: 'mcp__desktop-commander__start_process',
    alternatives: ['Bash'],
    tokenSavings: 60,
    priority: 1
  },
  {
    operation: 'interact-process',
    preferredTool: 'mcp__desktop-commander__interact_with_process',
    alternatives: ['Bash (limited)'],
    tokenSavings: 80,
    priority: 1
  },
  {
    operation: 'list-processes',
    preferredTool: 'mcp__desktop-commander__list_processes',
    alternatives: ['Bash ps'],
    tokenSavings: 50,
    priority: 1
  },
  // Documentation
  {
    operation: 'get-library-docs',
    preferredTool: 'mcp__context7__get-library-docs',
    alternatives: ['Web search'],
    tokenSavings: 70,
    priority: 1
  },
  {
    operation: 'resolve-library',
    preferredTool: 'mcp__context7__resolve-library-id',
    alternatives: ['Manual lookup'],
    tokenSavings: 80,
    priority: 1
  },
  {
    operation: 'wiki-contents',
    preferredTool: 'mcp__deepwiki__read_wiki_contents',
    alternatives: ['Manual browsing'],
    tokenSavings: 75,
    priority: 1
  },
  // Web Access
  {
    operation: 'fetch-url',
    preferredTool: 'mcp__web_reader__webReader',
    alternatives: ['Bash curl'],
    tokenSavings: 65,
    priority: 1
  },
  {
    operation: 'crawl-web',
    preferredTool: 'mcp__context-crawl__crawl',
    alternatives: ['Manual browsing'],
    tokenSavings: 80,
    priority: 1
  },
  {
    operation: 'search-web',
    preferredTool: 'mcp__rag-web-browser__search',
    alternatives: ['Manual search'],
    tokenSavings: 70,
    priority: 1
  }
];

/**
 * Token cost estimates for different tool categories.
 */
const CATEGORY_TOKEN_COSTS: Record<MCPToolCategory, { overhead: number; perCall: number }> = {
  'file-operations': { overhead: 500, perCall: 200 },
  'code-search': { overhead: 800, perCall: 300 },
  'process-management': { overhead: 600, perCall: 250 },
  'thinking': { overhead: 2000, perCall: 1000 },
  'documentation': { overhead: 1000, perCall: 400 },
  'web-access': { overhead: 1500, perCall: 500 }
};

/**
 * Tool information database.
 */
const TOOL_INFO: Map<string, MCPToolInfo> = new Map([
  // Desktop Commander
  ['mcp__desktop-commander__read_file', {
    name: 'read_file',
    category: 'file-operations',
    tokenCost: 700,
    avgLatency: 50,
    capabilities: ['read', 'file', 'text', 'binary', 'images'],
    dependencies: []
  }],
  ['mcp__desktop-commander__write_file', {
    name: 'write_file',
    category: 'file-operations',
    tokenCost: 800,
    avgLatency: 100,
    capabilities: ['write', 'file', 'create', 'append'],
    dependencies: []
  }],
  ['mcp__desktop-commander__edit_block', {
    name: 'edit_block',
    category: 'file-operations',
    tokenCost: 900,
    avgLatency: 75,
    capabilities: ['edit', 'replace', 'file', 'surgical'],
    dependencies: []
  }],
  ['mcp__desktop-commander__read_multiple_files', {
    name: 'read_multiple_files',
    category: 'file-operations',
    tokenCost: 1200,
    avgLatency: 100,
    capabilities: ['read', 'multiple', 'batch', 'files'],
    dependencies: []
  }],
  ['mcp__desktop-commander__list_directory', {
    name: 'list_directory',
    category: 'file-operations',
    tokenCost: 600,
    avgLatency: 30,
    capabilities: ['list', 'directory', 'files', 'recursive'],
    dependencies: []
  }],
  ['mcp__desktop-commander__start_search', {
    name: 'start_search',
    category: 'code-search',
    tokenCost: 800,
    avgLatency: 200,
    capabilities: ['search', 'files', 'content', 'streaming'],
    dependencies: []
  }],
  ['mcp__desktop-commander__start_process', {
    name: 'start_process',
    category: 'process-management',
    tokenCost: 850,
    avgLatency: 100,
    capabilities: ['process', 'execute', 'shell', 'interactive'],
    dependencies: []
  }],
  ['mcp__desktop-commander__interact_with_process', {
    name: 'interact_with_process',
    category: 'process-management',
    tokenCost: 700,
    avgLatency: 50,
    capabilities: ['interact', 'input', 'repl', 'process'],
    dependencies: ['start_process']
  }],

  // Code Index MCP
  ['mcp__code-index-mcp__search_code_advanced', {
    name: 'search_code_advanced',
    category: 'code-search',
    tokenCost: 1100,
    avgLatency: 150,
    capabilities: ['search', 'code', 'regex', 'fuzzy', 'indexed'],
    dependencies: ['build_deep_index']
  }],
  ['mcp__code-index-mcp__find_files', {
    name: 'find_files',
    category: 'code-search',
    tokenCost: 600,
    avgLatency: 30,
    capabilities: ['find', 'files', 'glob', 'indexed'],
    dependencies: ['build_deep_index']
  }],
  ['mcp__code-index-mcp__get_symbol_body', {
    name: 'get_symbol_body',
    category: 'code-search',
    tokenCost: 900,
    avgLatency: 50,
    capabilities: ['symbol', 'function', 'class', 'extract', 'indexed'],
    dependencies: ['build_deep_index']
  }],
  ['mcp__code-index-mcp__get_file_summary', {
    name: 'get_file_summary',
    category: 'code-search',
    tokenCost: 700,
    avgLatency: 40,
    capabilities: ['summary', 'file', 'stats', 'symbols'],
    dependencies: ['build_deep_index']
  }],
  ['mcp__code-index-mcp__build_deep_index', {
    name: 'build_deep_index',
    category: 'code-search',
    tokenCost: 3000,
    avgLatency: 5000,
    capabilities: ['index', 'build', 'symbols', 'cache'],
    dependencies: []
  }],

  // Context7
  ['mcp__context7__get-library-docs', {
    name: 'get-library-docs',
    category: 'documentation',
    tokenCost: 2000,
    avgLatency: 2000,
    capabilities: ['docs', 'library', 'api', 'examples'],
    dependencies: ['resolve-library-id']
  }],
  ['mcp__context7__resolve-library-id', {
    name: 'resolve-library-id',
    category: 'documentation',
    tokenCost: 800,
    avgLatency: 500,
    capabilities: ['resolve', 'library', 'id', 'search'],
    dependencies: []
  }],

  // DeepWiki
  ['mcp__deepwiki__read_wiki_contents', {
    name: 'read_wiki_contents',
    category: 'documentation',
    tokenCost: 1500,
    avgLatency: 1000,
    capabilities: ['wiki', 'docs', 'repository'],
    dependencies: []
  }],

  // Web Access
  ['mcp__web_reader__webReader', {
    name: 'webReader',
    category: 'web-access',
    tokenCost: 1800,
    avgLatency: 2000,
    capabilities: ['fetch', 'url', 'markdown', 'read'],
    dependencies: []
  }],
  ['mcp__context-crawl__crawl', {
    name: 'crawl',
    category: 'web-access',
    tokenCost: 2500,
    avgLatency: 5000,
    capabilities: ['crawl', 'website', 'extract', 'batch'],
    dependencies: []
  }],
  ['mcp__rag-web-browser__search', {
    name: 'search',
    category: 'web-access',
    tokenCost: 1200,
    avgLatency: 1500,
    capabilities: ['search', 'web', 'google', 'extract'],
    dependencies: []
  }]
]);

/**
 * MCP Tool Optimizer class.
 */
export class ToolOptimizer {
  private selectionMatrix: Map<string, ToolSelectionEntry>;
  private toolInfo: Map<string, MCPToolInfo>;
  private callHistory: MCPToolCall[];

  constructor() {
    this.selectionMatrix = new Map(
      TOOL_SELECTION_MATRIX.map(entry => [entry.operation, entry])
    );
    this.toolInfo = TOOL_INFO;
    this.callHistory = [];
  }

  /**
   * Select the best tool for an operation.
   */
  selectTool(operation: string): ToolSelectionEntry | null {
    const entry = this.selectionMatrix.get(operation);
    if (entry) {
      return entry;
    }

    // Try partial match
    for (const [key, value] of this.selectionMatrix) {
      if (operation.includes(key) || key.includes(operation)) {
        return value;
      }
    }

    return null;
  }

  /**
   * Get tool information.
   */
  getToolInfo(toolName: string): MCPToolInfo | null {
    return this.toolInfo.get(toolName) || null;
  }

  /**
   * Estimate token cost for a tool call.
   */
  estimateTokenCost(toolName: string, params?: Record<string, any>): number {
    const info = this.toolInfo.get(toolName);
    if (!info) {
      return 1000; // Default estimate
    }

    let cost = info.tokenCost;

    // Adjust based on params
    if (params) {
      // Add cost for large inputs
      if (params.path && Array.isArray(params.path)) {
        cost += params.path.length * 100;
      }
      if (params.content && typeof params.content === 'string') {
        cost += Math.ceil(params.content.length / 100) * 50;
      }
      if (params.pattern && typeof params.pattern === 'string') {
        cost += 50;
      }
    }

    return cost;
  }

  /**
   * Estimate token savings by using MCP tool over native.
   */
  estimateTokenSavings(operation: string): number {
    const entry = this.selectionMatrix.get(operation);
    return entry ? entry.tokenSavings : 0;
  }

  /**
   * Optimize a batch of tool calls.
   */
  optimizeBatch(calls: MCPToolCall[]): BatchOptimization {
    // Build dependency graph
    const dependencies = new Map<string, string[]>();
    const callMap = new Map<string, MCPToolCall>();

    for (const call of calls) {
      const id = this.generateCallId(call);
      callMap.set(id, call);

      const deps: string[] = [];
      if (call.dependencies) {
        deps.push(...call.dependencies);
      }

      // Check tool dependencies
      const info = this.toolInfo.get(`${call.server}__${call.tool}`);
      if (info && info.dependencies) {
        for (const dep of info.dependencies) {
          // Find calls that satisfy this dependency
          for (const [otherId, otherCall] of callMap) {
            if (otherCall.tool === dep) {
              deps.push(otherId);
            }
          }
        }
      }

      dependencies.set(id, deps);
    }

    // Topological sort for execution order
    const sorted = this.topologicalSort(callMap, dependencies);

    // Group into parallelizable batches
    const batches: MCPToolCall[][] = [];
    const completed = new Set<string>();

    while (completed.size < sorted.length) {
      const batch: MCPToolCall[] = [];

      for (const id of sorted) {
        if (completed.has(id)) continue;

        const deps = dependencies.get(id) || [];
        const allDepsMet = deps.every(dep => completed.has(dep));

        if (allDepsMet) {
          const call = callMap.get(id)!;
          batch.push(call);
          completed.add(id);

          // Limit batch size
          if (batch.length >= 5) break;
        }
      }

      if (batch.length > 0) {
        batches.push(batch);
      }
    }

    // Calculate token savings
    let estimatedTokenSavings = 0;
    for (const call of calls) {
      const operation = call.tool.replace(/_/g, '-');
      estimatedTokenSavings += this.estimateTokenSavings(operation);
    }

    return {
      batches,
      estimatedTokenSavings,
      parallelizable: batches.some(b => b.length > 1),
      dependencies
    };
  }

  /**
   * Topological sort for dependency resolution.
   */
  private topologicalSort(
    callMap: Map<string, MCPToolCall>,
    dependencies: Map<string, string[]>
  ): string[] {
    const result: string[] = [];
    const visited = new Set<string>();
    const visiting = new Set<string>();

    const visit = (id: string) => {
      if (visited.has(id)) return;
      if (visiting.has(id)) {
        // Circular dependency - just continue
        return;
      }

      visiting.add(id);

      const deps = dependencies.get(id) || [];
      for (const dep of deps) {
        visit(dep);
      }

      visiting.delete(id);
      visited.add(id);
      result.push(id);
    };

    for (const id of callMap.keys()) {
      visit(id);
    }

    return result;
  }

  /**
   * Generate a unique ID for a tool call.
   */
  private generateCallId(call: MCPToolCall): string {
    return `${call.server}__${call.tool}__${JSON.stringify(call.params).slice(0, 50)}`;
  }

  /**
   * Plan parallel execution for independent operations.
   */
  planParallelExecution(operations: string[]): {
    parallel: string[][];
    sequential: string[];
  } {
    const parallel: string[][] = [];
    const sequential: string[] = [];

    // Group operations by category
    const byCategory = new Map<MCPToolCategory, string[]>();

    for (const op of operations) {
      const entry = this.selectionMatrix.get(op);
      if (entry) {
        const info = this.toolInfo.get(entry.preferredTool);
        if (info) {
          const cat = info.category;
          if (!byCategory.has(cat)) {
            byCategory.set(cat, []);
          }
          byCategory.get(cat)!.push(op);
        }
      }
    }

    // Operations in different categories can run in parallel
    if (byCategory.size > 1) {
      const batch: string[] = [];
      for (const [cat, ops] of byCategory) {
        if (ops.length === 1) {
          batch.push(ops[0]);
        } else {
          // Multiple ops in same category - first can be parallel, rest sequential
          batch.push(ops[0]);
          sequential.push(...ops.slice(1));
        }
      }
      if (batch.length > 1) {
        parallel.push(batch);
      } else {
        sequential.push(...batch);
      }
    } else {
      // All operations in same category - mostly sequential
      sequential.push(...operations);
    }

    return { parallel, sequential };
  }

  /**
   * Optimize tool chain for minimum token usage.
   */
  optimizeToolChain(operations: string[]): {
    optimized: string[];
    savings: number;
  } {
    const optimized: string[] = [];
    let savings = 0;

    // Deduplicate operations
    const seen = new Set<string>();
    for (const op of operations) {
      if (!seen.has(op)) {
        seen.add(op);
        optimized.push(op);
        savings += this.estimateTokenSavings(op);
      }
    }

    // Reorder for efficiency (group by category)
    optimized.sort((a, b) => {
      const entryA = this.selectionMatrix.get(a);
      const entryB = this.selectionMatrix.get(b);

      if (!entryA || !entryB) return 0;

      const infoA = this.toolInfo.get(entryA.preferredTool);
      const infoB = this.toolInfo.get(entryB.preferredTool);

      if (!infoA || !infoB) return 0;

      // Sort by latency (faster first)
      return infoA.avgLatency - infoB.avgLatency;
    });

    return { optimized, savings };
  }

  /**
   * Record a tool call in history.
   */
  recordCall(call: MCPToolCall, result: MCPToolResult): void {
    this.callHistory.push(call);

    // Limit history size
    if (this.callHistory.length > 1000) {
      this.callHistory = this.callHistory.slice(-500);
    }
  }

  /**
   * Get tool call statistics.
   */
  getStats(): {
    totalCalls: number;
    byCategory: Map<MCPToolCategory, number>;
    byTool: Map<string, number>;
    avgLatency: number;
    totalTokensUsed: number;
    totalTokensSaved: number;
  } {
    const byCategory = new Map<MCPToolCategory, number>();
    const byTool = new Map<string, number>();
    let totalTokensUsed = 0;
    let totalTokensSaved = 0;

    for (const call of this.callHistory) {
      const toolKey = `${call.server}__${call.tool}`;
      byTool.set(toolKey, (byTool.get(toolKey) || 0) + 1);

      const info = this.toolInfo.get(toolKey);
      if (info) {
        byCategory.set(info.category, (byCategory.get(info.category) || 0) + 1);
        totalTokensUsed += info.tokenCost;
      }
    }

    // Estimate savings (compared to native tools)
    for (const entry of this.selectionMatrix.values()) {
      const toolKey = entry.preferredTool;
      const count = byTool.get(toolKey) || 0;
      totalTokensSaved += count * entry.tokenSavings;
    }

    return {
      totalCalls: this.callHistory.length,
      byCategory,
      byTool,
      avgLatency: 0, // Would need to track this
      totalTokensUsed,
      totalTokensSaved
    };
  }

  /**
   * Get all available tools.
   */
  getAvailableTools(): string[] {
    return Array.from(this.toolInfo.keys());
  }

  /**
   * Get tools by category.
   */
  getToolsByCategory(category: MCPToolCategory): MCPToolInfo[] {
    const tools: MCPToolInfo[] = [];

    for (const info of this.toolInfo.values()) {
      if (info.category === category) {
        tools.push(info);
      }
    }

    return tools;
  }

  /**
   * Check if a tool is an MCP tool.
   */
  isMCPTool(toolName: string): boolean {
    return toolName.startsWith('mcp__');
  }

  /**
   * Get native tool alternative.
   */
  getNativeAlternative(operation: string): string | null {
    const entry = this.selectionMatrix.get(operation);
    if (entry && entry.alternatives.length > 0) {
      return entry.alternatives[0];
    }
    return null;
  }
}

export default ToolOptimizer;

</document_content>
</document>
<document index="13">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\cognitive-flow\types.ts</source>
<document_content>
/**
 * Cognitive-Flow Orchestration Layer Types
 *
 * Unified types for coordinating thinking servers, MCP tools, and claudeception modules.
 *
 * @module cognitive-flow/types
 */

// ─── Cognitive Phases ─────────────────────────────────────────────────────────

/**
 * The four cognitive phases in the unified flow.
 *
 * PREPARE: Structure analysis using Tractatus thinking
 * EXECUTE: Step-by-step execution using Sequential thinking
 * REFLECT: Problem analysis using Debug thinking
 * LEARN: Knowledge capture and storage
 */
export enum CognitivePhase {
  PREPARE = 'PREPARE',
  EXECUTE = 'EXECUTE',
  REFLECT = 'REFLECT',
  LEARN = 'LEARN'
}

// ─── Thinking Server Types ─────────────────────────────────────────────────────

/**
 * Available thinking servers.
 */
export type ThinkingServer = 'sequential' | 'tractatus' | 'debug';

/**
 * Server health status.
 */
export interface ServerHealth {
  server: ThinkingServer;
  available: boolean;
  latency: number;
  lastCheck: Date;
  errorCount: number;
  lastError?: string;
}

/**
 * Server pool configuration.
 */
export interface ServerPoolConfig {
  healthCheckInterval: number;
  maxRetries: number;
  retryDelay: number;
  timeout: number;
  fallbackChain: ThinkingServer[];
}

/**
 * Server selection result.
 */
export interface ServerSelection {
  server: ThinkingServer;
  reason: string;
  alternatives: ThinkingServer[];
  confidence: number;
}

// ─── MCP Tool Types ───────────────────────────────────────────────────────────

/**
 * MCP tool categories.
 */
export type MCPToolCategory =
  | 'file-operations'
  | 'code-search'
  | 'process-management'
  | 'thinking'
  | 'documentation'
  | 'web-access';

/**
 * MCP tool metadata for optimization.
 */
export interface MCPToolInfo {
  name: string;
  category: MCPToolCategory;
  tokenCost: number;
  avgLatency: number;
  capabilities: string[];
  dependencies: string[];
}

/**
 * Tool selection matrix entry.
 */
export interface ToolSelectionEntry {
  operation: string;
  preferredTool: string;
  alternatives: string[];
  tokenSavings: number;
  priority: number;
}

/**
 * Batch optimization result.
 */
export interface BatchOptimization {
  batches: MCPToolCall[][];
  estimatedTokenSavings: number;
  parallelizable: boolean;
  dependencies: Map<string, string[]>;
}

/**
 * MCP tool call specification.
 */
export interface MCPToolCall {
  server: string;
  tool: string;
  params: Record<string, any>;
  dependencies?: string[];
}

// ─── Cognitive Context ────────────────────────────────────────────────────────

/**
 * Context for cognitive flow execution.
 */
export interface CognitiveContext {
  /** Operation being performed */
  operation: string;

  /** Phase being executed */
  phase: CognitivePhase;

  /** Input data for the operation */
  input: any;

  /** User-provided context */
  userContext?: Record<string, any>;

  /** Current file or path being worked on */
  targetPath?: string;

  /** Command being executed (if applicable) */
  command?: string;

  /** Agent type (if applicable) */
  agentType?: string;

  /** Timeout for the operation */
  timeout?: number;

  /** Whether to use BMAD enhancement */
  bmadEnabled?: boolean;

  /** Metadata for the operation */
  metadata?: Record<string, any>;
}

/**
 * Cognitive context builder for fluent API.
 */
export class CognitiveContextBuilder {
  private context: CognitiveContext;

  constructor(operation: string) {
    this.context = {
      operation,
      phase: CognitivePhase.PREPARE,
      input: null
    };
  }

  withPhase(phase: CognitivePhase): this {
    this.context.phase = phase;
    return this;
  }

  withInput(input: any): this {
    this.context.input = input;
    return this;
  }

  withUserContext(ctx: Record<string, any>): this {
    this.context.userContext = ctx;
    return this;
  }

  withTargetPath(path: string): this {
    this.context.targetPath = path;
    return this;
  }

  withCommand(command: string): this {
    this.context.command = command;
    return this;
  }

  withAgentType(agentType: string): this {
    this.context.agentType = agentType;
    return this;
  }

  withTimeout(timeout: number): this {
    this.context.timeout = timeout;
    return this;
  }

  withBMAD(enabled: boolean): this {
    this.context.bmadEnabled = enabled;
    return this;
  }

  withMetadata(metadata: Record<string, any>): this {
    this.context.metadata = metadata;
    return this;
  }

  build(): CognitiveContext {
    return { ...this.context };
  }
}

// ─── Cognitive Result ─────────────────────────────────────────────────────────

/**
 * Result from a thinking server.
 */
export interface ThinkingResult {
  server: ThinkingServer;
  phase: CognitivePhase;
  thoughts: ThinkingThought[];
  duration: number;
  success: boolean;
  error?: string;
  metadata?: Record<string, any>;
}

/**
 * Single thought from a thinking server.
 */
export interface ThinkingThought {
  thoughtNumber: number;
  totalThoughts: number;
  thought: string;
  nextThoughtNeeded: boolean;
  isRevision?: boolean;
  revisesThought?: number;
  branchFromThought?: number;
  branchId?: string;
  needsMoreThoughts?: boolean;
}

/**
 * Result from MCP tool execution.
 */
export interface MCPToolResult {
  tool: string;
  server: string;
  success: boolean;
  result?: any;
  error?: string;
  duration: number;
  tokensUsed: number;
}

/**
 * Phase execution result.
 */
export interface PhaseResult {
  phase: CognitivePhase;
  thinkingResults: ThinkingResult[];
  toolResults: MCPToolResult[];
  success: boolean;
  duration: number;
  insights: string[];
  learnings: string[];
  nextPhase?: CognitivePhase;
  error?: string;
}

/**
 * Complete cognitive flow result.
 */
export interface CognitiveResult {
  /** Whether the flow completed successfully */
  success: boolean;

  /** The operation that was performed */
  operation: string;

  /** Results from each phase */
  phases: Map<CognitivePhase, PhaseResult>;

  /** Overall duration in milliseconds */
  duration: number;

  /** Total tokens used */
  totalTokens: number;

  /** Aggregated insights from all phases */
  insights: string[];

  /** Learnings to store */
  learnings: string[];

  /** Recommended next steps */
  nextSteps: string[];

  /** Any errors that occurred */
  errors: string[];

  /** Whether any phase was degraded */
  degraded: boolean;

  /** Final output of the operation */
  output?: any;

  /** Timestamp of completion */
  timestamp: Date;
}

// ─── Learning Types ───────────────────────────────────────────────────────────

/**
 * Learning entry for storage.
 */
export interface LearningEntry {
  id: string;
  timestamp: Date;
  operation: string;
  phase: CognitivePhase;
  context: CognitiveContext;
  outcome: 'success' | 'failure' | 'partial';
  insights: string[];
  patterns: string[];
  effectiveness: number;
  serversUsed: ThinkingServer[];
  toolsUsed: string[];
  duration: number;
}

/**
 * Pattern for learning.
 */
export interface CognitivePattern {
  id: string;
  name: string;
  description: string;
  trigger: PatternTrigger;
  action: PatternAction;
  effectiveness: number;
  uses: number;
  lastUsed: Date;
}

/**
 * Pattern trigger conditions.
 */
export interface PatternTrigger {
  operationType?: string[];
  complexity?: { min: number; max: number };
  fileType?: string[];
  commandPattern?: string;
}

/**
 * Pattern action specification.
 */
export interface PatternAction {
  preferredServer?: ThinkingServer;
  preferredTools?: string[];
  suggestedPhase?: CognitivePhase;
  timeout?: number;
  bmadEnabled?: boolean;
}

// ─── Flow Configuration ───────────────────────────────────────────────────────

/**
 * Configuration for cognitive flow execution.
 */
export interface CognitiveFlowConfig {
  /** Enable/disable phases */
  enabledPhases: CognitivePhase[];

  /** Phase timeouts in milliseconds */
  phaseTimeouts: Map<CognitivePhase, number>;

  /** Server pool configuration */
  serverPool: ServerPoolConfig;

  /** Enable learning capture */
  learningEnabled: boolean;

  /** Enable parallel tool execution */
  parallelTools: boolean;

  /** Maximum parallel tools */
  maxParallelTools: number;

  /** Token budget for the flow */
  tokenBudget: number;

  /** Enable BMAD enhancement */
  bmadEnhancement: boolean;

  /** Verbose logging */
  verbose: boolean;
}

/**
 * Default flow configuration.
 */
export const DEFAULT_FLOW_CONFIG: CognitiveFlowConfig = {
  enabledPhases: [
    CognitivePhase.PREPARE,
    CognitivePhase.EXECUTE,
    CognitivePhase.REFLECT,
    CognitivePhase.LEARN
  ],
  phaseTimeouts: new Map([
    [CognitivePhase.PREPARE, 5000],
    [CognitivePhase.EXECUTE, 15000],
    [CognitivePhase.REFLECT, 5000],
    [CognitivePhase.LEARN, 3000]
  ]),
  serverPool: {
    healthCheckInterval: 30000,
    maxRetries: 3,
    retryDelay: 1000,
    timeout: 10000,
    fallbackChain: ['sequential', 'tractatus', 'debug']
  },
  learningEnabled: true,
  parallelTools: true,
  maxParallelTools: 5,
  tokenBudget: 50000,
  bmadEnhancement: true,
  verbose: false
};

// ─── Event Types ──────────────────────────────────────────────────────────────

/**
 * Events emitted during cognitive flow.
 */
export type CognitiveEventType =
  | 'flow:start'
  | 'flow:complete'
  | 'phase:start'
  | 'phase:complete'
  | 'phase:error'
  | 'server:select'
  | 'server:call'
  | 'server:result'
  | 'tool:select'
  | 'tool:call'
  | 'tool:result'
  | 'learning:capture'
  | 'error';

/**
 * Cognitive event payload.
 */
export interface CognitiveEvent {
  type: CognitiveEventType;
  timestamp: Date;
  phase?: CognitivePhase;
  server?: ThinkingServer;
  tool?: string;
  data?: any;
  error?: Error;
}

/**
 * Event handler type.
 */
export type CognitiveEventHandler = (event: CognitiveEvent) => void | Promise<void>;

</document_content>
</document>
<document index="14">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\workflow-modules\artifact-generator.ts</source>
<document_content>
/**
 * GSI Artifact Generator Module
 *
 * Generates multiple artifact types from extracted patterns:
 * - Skills: Claude Code skills for reuse
 * - Agents: GSI agent definitions
 * - Logic: TypeScript functions/logic modules
 * - Functions: Reusable function implementations
 * - Features: Feature specifications
 * - Improvements: Command enhancement suggestions
 * - Ideas: Visionary concepts and proposals
 *
 * Phase 38-01: Multi-Type Artifact Generation
 */

import { writeFileSync, mkdirSync, existsSync } from 'fs';
import { join, basename } from 'path';
import { KnowledgePattern, PatternCategory } from './knowledge-base.js';

// Artifact Type System
export type ArtifactType = 
  | 'SKILL' 
  | 'AGENT' 
  | 'LOGIC' 
  | 'FUNCTION' 
  | 'FEATURE' 
  | 'IMPROVEMENT' 
  | 'IDEA';

export interface GeneratedArtifact {
  type: ArtifactType;
  id: string;
  name: string;
  description: string;
  source_pattern: string;
  content: string;
  file_path: string;
  created_at: string;
  metadata: ArtifactMetadata;
}

export interface ArtifactMetadata {
  category: PatternCategory;
  effectiveness: number;
  tags: string[];
  dependencies: string[];
  version: string;
}

// Artifact Generator Interface
export interface ArtifactGenerator {
  type: ArtifactType;
  generate(pattern: KnowledgePattern, outputDir: string): Promise<GeneratedArtifact>;
  getTemplate(pattern: KnowledgePattern): string;
  getFileName(pattern: KnowledgePattern): string;
}

/**
 * Skill Artifact Generator
 * Generates Claude Code skill files from patterns
 */
export class SkillGenerator implements ArtifactGenerator {
  type: ArtifactType = 'SKILL';

  async generate(pattern: KnowledgePattern, outputDir: string): Promise<GeneratedArtifact> {
    const content = this.getTemplate(pattern);
    const fileName = this.getFileName(pattern);
    const filePath = join(outputDir, 'skills', fileName);
    
    mkdirSync(join(outputDir, 'skills'), { recursive: true });
    writeFileSync(filePath, content);
    
    return {
      type: this.type,
      id: `skill-${pattern.id}`,
      name: pattern.name,
      description: pattern.description,
      source_pattern: pattern.id,
      content,
      file_path: filePath,
      created_at: new Date().toISOString(),
      metadata: {
        category: pattern.category,
        effectiveness: pattern.effectiveness,
        tags: this.extractTags(pattern),
        dependencies: [],
        version: '1.0.0'
      }
    };
  }

  getTemplate(pattern: KnowledgePattern): string {
    return `# ${pattern.name}

## Purpose
${pattern.description}

## Context
Extracted from: ${pattern.source}

## When to Use
${pattern.whenToUse.map(u => `- ${u}`).join('\n')}

## How to Apply
${pattern.howToApply.map(a => a).join('\n')}

## Variations
${pattern.variations.length > 0 
  ? pattern.variations.map(v => `### ${v.name}\n${v.description}\nContext: ${v.context}`).join('\n\n')
  : 'No variations defined.'}

## Examples
${pattern.examples.map(e => `### ${e.name}\n\`\`\`\n${e.code}\n\`\`\`\n${e.explanation}`).join('\n\n')}

## Effectiveness
${(pattern.effectiveness * 100).toFixed(0)}% (based on ${pattern.uses} uses)

## History
- Extracted: ${new Date().toISOString()}
- Source: ${pattern.source}
- Uses: ${pattern.uses}
- Generated by: GSI Artifact Generator (Phase 38-01)
`;
  }

  getFileName(pattern: KnowledgePattern): string {
    const slug = pattern.name.toLowerCase()
      .replace(/[^a-z0-9]+/g, '-')
      .replace(/^-+|-+$/g, '');
    return `${slug}.md`;
  }

  private extractTags(pattern: KnowledgePattern): string[] {
    const tags = [pattern.category];
    pattern.whenToUse.forEach(u => {
      const words = u.toLowerCase().split(/\s+/);
      words.filter(w => w.length > 4).forEach(w => tags.push(w));
    });
    return [...new Set(tags)].slice(0, 10);
  }
}

/**
 * Agent Artifact Generator
 * Generates GSI agent definitions from patterns
 */
export class AgentGenerator implements ArtifactGenerator {
  type: ArtifactType = 'AGENT';

  async generate(pattern: KnowledgePattern, outputDir: string): Promise<GeneratedArtifact> {
    const content = this.getTemplate(pattern);
    const fileName = this.getFileName(pattern);
    const filePath = join(outputDir, 'agents', fileName);
    
    mkdirSync(join(outputDir, 'agents'), { recursive: true });
    writeFileSync(filePath, content);
    
    return {
      type: this.type,
      id: `agent-${pattern.id}`,
      name: this.generateAgentName(pattern),
      description: pattern.description,
      source_pattern: pattern.id,
      content,
      file_path: filePath,
      created_at: new Date().toISOString(),
      metadata: {
        category: pattern.category,
        effectiveness: pattern.effectiveness,
        tags: this.extractTags(pattern),
        dependencies: this.inferDependencies(pattern),
        version: '1.0.0'
      }
    };
  }

  getTemplate(pattern: KnowledgePattern): string {
    const agentName = this.generateAgentName(pattern);
    const thinkingConfig = this.inferThinkingConfig(pattern);
    
    return `---
name: ${agentName}
description: ${pattern.description}
allowed_tools:
${this.inferTools(pattern).map(t => `  - ${t}`).join('\n')}
thinking_phase:
  mode: ${thinkingConfig.mode}
  servers:
${thinkingConfig.servers.map(s => `    - ${s}`).join('\n')}
  bmad_enabled: ${thinkingConfig.bmad_enabled}
  timeout: ${thinkingConfig.timeout}
  rationale: "${thinkingConfig.rationale}"
---

# ${agentName}

## Objective
${pattern.description}

## Context
This agent was automatically generated from pattern: ${pattern.id}

Source: ${pattern.source}

## Capabilities
${pattern.whenToUse.map(u => `- ${u}`).join('\n')}

## Process

<process>
1. **Initialize**: Load context and verify requirements
${pattern.howToApply.map((a, i) => `${i + 2}. **${this.stepName(a)}**: ${a}`).join('\n')}
${pattern.examples.length > 0 ? `${pattern.howToApply.length + 3}. **Validate**: Verify output matches expected patterns` : ''}
${pattern.howToApply.length + 4}. **Complete**: Report results and update tracking
</process>

## Pattern Application

### When to Apply
${pattern.whenToUse.map(u => `- ${u}`).join('\n')}

### How to Apply
${pattern.howToApply.map(a => `- ${a}`).join('\n')}

## Examples
${pattern.examples.length > 0 
  ? pattern.examples.map(e => `### ${e.name}\n\`\`\`\n${e.code}\n\`\`\`\n${e.explanation}`).join('\n\n')
  : 'No examples available.'}

## Variations
${pattern.variations.length > 0
  ? pattern.variations.map(v => `### ${v.name}\n${v.description}\n- Context: ${v.context}`).join('\n\n')
  : 'No variations defined.'}

## Notes
- Effectiveness: ${(pattern.effectiveness * 100).toFixed(0)}%
- Uses: ${pattern.uses}
- Generated: ${new Date().toISOString()}

<!--
Generated by GSI Artifact Generator (Phase 38-01)
Pattern Source: ${pattern.source}
-->
`;
  }

  getFileName(pattern: KnowledgePattern): string {
    const slug = this.generateAgentName(pattern).toLowerCase()
      .replace(/[^a-z0-9]+/g, '-')
      .replace(/^-+|-+$/g, '');
    return `gsi-${slug}.md`;
  }

  private generateAgentName(pattern: KnowledgePattern): string {
    // Extract key concept from pattern name
    const words = pattern.name.replace(/Pattern/i, '').trim().split(/\s+/);
    const keyWords = words.filter(w => w.length > 3).slice(0, 3);
    return keyWords.join(' ');
  }

  private inferTools(pattern: KnowledgePattern): string[] {
    // Infer tools based on pattern category and content
    const baseTools = ['Read', 'Edit', 'Write'];
    const categoryTools: Record<PatternCategory, string[]> = {
      'command-patterns': ['Bash', 'Read', 'Edit'],
      'thinking-configs': ['Read', 'Edit'],
      'workflows': ['Read', 'Edit', 'Write', 'Bash'],
      'agents': ['Read', 'Edit', 'Write'],
      'error-handling': ['Read', 'Edit', 'Bash'],
      'optimization': ['Read', 'Edit', 'Bash']
    };
    return [...new Set([...baseTools, ...(categoryTools[pattern.category] || [])])];
  }

  private inferThinkingConfig(pattern: KnowledgePattern): {
    mode: string;
    servers: string[];
    bmad_enabled: boolean;
    timeout: number;
    rationale: string;
  } {
    // Determine thinking complexity based on pattern characteristics
    const complexity = this.assessComplexity(pattern);
    
    if (complexity === 'high') {
      return {
        mode: 'COMPREHENSIVE',
        servers: ['sequential', 'tractatus', 'debug'],
        bmad_enabled: true,
        timeout: 180000,
        rationale: 'High complexity pattern requires comprehensive analysis'
      };
    } else if (complexity === 'medium') {
      return {
        mode: 'STANDARD',
        servers: ['sequential', 'tractatus'],
        bmad_enabled: true,
        timeout: 120000,
        rationale: 'Medium complexity pattern benefits from structured thinking'
      };
    } else {
      return {
        mode: 'LIGHTWEIGHT',
        servers: ['sequential'],
        bmad_enabled: false,
        timeout: 60000,
        rationale: 'Low complexity pattern requires minimal cognitive enhancement'
      };
    }
  }

  private assessComplexity(pattern: KnowledgePattern): 'high' | 'medium' | 'low' {
    const factors = {
      steps: pattern.howToApply.length,
      variations: pattern.variations.length,
      examples: pattern.examples.length,
      uses: pattern.uses
    };
    
    const score = factors.steps * 2 + factors.variations + factors.examples + Math.min(factors.uses, 10);
    
    if (score > 15) return 'high';
    if (score > 8) return 'medium';
    return 'low';
  }

  private stepName(step: string): string {
    // Extract meaningful step name from instruction
    const match = step.match(/^\d+\.\s*(?:\*\*)?([^:*]+)(?:\*\*)?/);
    return match ? match[1].trim() : 'Process';
  }

  private extractTags(pattern: KnowledgePattern): string[] {
    return [pattern.category, 'auto-generated', 'gsi-agent'];
  }

  private inferDependencies(pattern: KnowledgePattern): string[] {
    // Infer dependencies based on pattern category
    const deps: Record<PatternCategory, string[]> = {
      'command-patterns': ['gsi-tools.js'],
      'thinking-configs': ['thinking-orchestrator'],
      'workflows': ['workflow-chainer', 'gsi-tools.js'],
      'agents': ['gsi-tools.js'],
      'error-handling': ['reflection-capture'],
      'optimization': ['pattern-learning']
    };
    return deps[pattern.category] || [];
  }
}

/**
 * Logic Artifact Generator
 * Generates TypeScript logic modules from patterns
 */
export class LogicGenerator implements ArtifactGenerator {
  type: ArtifactType = 'LOGIC';

  async generate(pattern: KnowledgePattern, outputDir: string): Promise<GeneratedArtifact> {
    const content = this.getTemplate(pattern);
    const fileName = this.getFileName(pattern);
    const filePath = join(outputDir, 'logic', fileName);
    
    mkdirSync(join(outputDir, 'logic'), { recursive: true });
    writeFileSync(filePath, content);
    
    return {
      type: this.type,
      id: `logic-${pattern.id}`,
      name: pattern.name,
      description: pattern.description,
      source_pattern: pattern.id,
      content,
      file_path: filePath,
      created_at: new Date().toISOString(),
      metadata: {
        category: pattern.category,
        effectiveness: pattern.effectiveness,
        tags: ['typescript', 'logic', pattern.category],
        dependencies: [],
        version: '1.0.0'
      }
    };
  }

  getTemplate(pattern: KnowledgePattern): string {
    const moduleName = this.generateModuleName(pattern);
    
    return `/**
 * ${pattern.name}
 * 
 * ${pattern.description}
 * 
 * @module ${moduleName}
 * @generated ${new Date().toISOString()}
 * @pattern ${pattern.id}
 */

/**
 * Pattern context interface
 */
export interface ${this.interfaceName(pattern)}Context {
  ${this.generateContextProperties(pattern)}
}

/**
 * Pattern result interface
 */
export interface ${this.interfaceName(pattern)}Result {
  success: boolean;
  data?: any;
  error?: string;
  metrics?: {
    duration: number;
    steps: number;
  };
}

/**
 * ${pattern.description}
 * 
 * @param context - Execution context
 * @returns Result of pattern application
 * 
 * @example
 * \`\`\`typescript
 * const result = await ${this.functionName(pattern)}({
 *   // context properties
 * });
 * if (result.success) {
 *   console.log('Pattern applied successfully');
 * }
 * \`\`\`
 */
export async function ${this.functionName(pattern)}(
  context: ${this.interfaceName(pattern)}Context
): Promise<${this.interfaceName(pattern)}Result> {
  const startTime = Date.now();
  let stepCount = 0;

  try {
    // Step 1: Initialize and validate
    ${this.generateValidationCode(pattern)}
    stepCount++;

    // Step 2: Apply pattern logic
    ${this.generateLogicCode(pattern)}
    stepCount++;

    // Step 3: Process results
    ${this.generateResultCode(pattern)}
    stepCount++;

    return {
      success: true,
      metrics: {
        duration: Date.now() - startTime,
        steps: stepCount
      }
    };
  } catch (error) {
    return {
      success: false,
      error: error instanceof Error ? error.message : String(error),
      metrics: {
        duration: Date.now() - startTime,
        steps: stepCount
      }
    };
  }
}

/**
 * Validate inputs before pattern application
 */
function validate${this.interfaceName(pattern)}Input(
  context: ${this.interfaceName(pattern)}Context
): void {
  ${this.generateValidationFunction(pattern)}
}

/**
 * Apply core pattern logic
 */
async function apply${this.interfaceName(pattern)}Logic(
  context: ${this.interfaceName(pattern)}Context
): Promise<any> {
  ${this.generateLogicFunction(pattern)}
}

/**
 * Pattern variations
 */
export const ${this.variationsName(pattern)} = {
  ${pattern.variations.map(v => `"${v.name.toLowerCase().replace(/\s+/g, '_')}": {
    description: "${v.description}",
    context: "${v.context}"
  }`).join(',\n  ')}
};

/**
 * Pattern metadata
 */
export const ${this.metadataName(pattern)} = {
  id: "${pattern.id}",
  name: "${pattern.name}",
  category: "${pattern.category}",
  source: "${pattern.source}",
  effectiveness: ${pattern.effectiveness},
  uses: ${pattern.uses},
  generatedAt: "${new Date().toISOString()}"
};

export default {
  ${this.functionName(pattern)},
  ${this.variationsName(pattern)},
  ${this.metadataName(pattern)}
};
`;
  }

  getFileName(pattern: KnowledgePattern): string {
    const slug = this.generateModuleName(pattern).toLowerCase()
      .replace(/[^a-z0-9]+/g, '-')
      .replace(/^-+|-+$/g, '');
    return `${slug}.ts`;
  }

  private generateModuleName(pattern: KnowledgePattern): string {
    return pattern.name.replace(/[^a-zA-Z0-9]/g, '');
  }

  private interfaceName(pattern: KnowledgePattern): string {
    return this.generateModuleName(pattern);
  }

  private functionName(pattern: KnowledgePattern): string {
    const name = pattern.name.replace(/Pattern/i, '').trim();
    return name.split(/\s+/).map(w => w.charAt(0).toUpperCase() + w.slice(1).toLowerCase()).join('');
  }

  private variationsName(pattern: KnowledgePattern): string {
    return `${this.generateModuleName(pattern).toLowerCase()}Variations`;
  }

  private metadataName(pattern: KnowledgePattern): string {
    return `${this.generateModuleName(pattern).toLowerCase()}Metadata`;
  }

  private generateContextProperties(pattern: KnowledgePattern): string {
    const props = ['input: any;', 'options?: Record<string, any>;'];
    pattern.howToApply.forEach((_, i) => {
      props.push(`step${i + 1}Input?: any;`);
    });
    return props.join('\n  ');
  }

  private generateValidationCode(pattern: KnowledgePattern): string {
    return `validate${this.interfaceName(pattern)}Input(context);`;
  }

  private generateLogicCode(pattern: KnowledgePattern): string {
    return `const result = await apply${this.interfaceName(pattern)}Logic(context);`;
  }

  private generateResultCode(pattern: KnowledgePattern): string {
    return `// Process and return result
    // TODO: Implement result processing based on pattern specifics`;
  }

  private generateValidationFunction(pattern: KnowledgePattern): string {
    return `// Validation logic derived from pattern
  if (!context.input) {
    throw new Error('Input is required');
  }
  // Add pattern-specific validations`;
  }

  private generateLogicFunction(pattern: KnowledgePattern): string {
    return `// Core logic derived from pattern: ${pattern.id}
  ${pattern.howToApply.map((step, i) => `// Step ${i + 1}: ${step}`).join('\n  ')}
  
  // TODO: Implement specific logic based on pattern
  return context.input;`;
  }
}

/**
 * Function Artifact Generator
 * Generates reusable TypeScript functions from patterns
 */
export class FunctionGenerator implements ArtifactGenerator {
  type: ArtifactType = 'FUNCTION';

  async generate(pattern: KnowledgePattern, outputDir: string): Promise<GeneratedArtifact> {
    const content = this.getTemplate(pattern);
    const fileName = this.getFileName(pattern);
    const filePath = join(outputDir, 'functions', fileName);
    
    mkdirSync(join(outputDir, 'functions'), { recursive: true });
    writeFileSync(filePath, content);
    
    return {
      type: this.type,
      id: `function-${pattern.id}`,
      name: pattern.name,
      description: pattern.description,
      source_pattern: pattern.id,
      content,
      file_path: filePath,
      created_at: new Date().toISOString(),
      metadata: {
        category: pattern.category,
        effectiveness: pattern.effectiveness,
        tags: ['typescript', 'function', 'reusable'],
        dependencies: [],
        version: '1.0.0'
      }
    };
  }

  getTemplate(pattern: KnowledgePattern): string {
    const functionName = this.generateFunctionName(pattern);
    
    return `/**
 * ${pattern.name}
 * 
 * ${pattern.description}
 * 
 * @param input - Input data
 * @param options - Optional configuration
 * @returns Processed result
 * 
 * @example
 * \`\`\`typescript
 * const result = ${functionName}(input, { verbose: true });
 * console.log(result);
 * \`\`\`
 * 
 * @pattern ${pattern.id}
 * @source ${pattern.source}
 * @generated ${new Date().toISOString()}
 */

export interface ${this.optionsInterface(pattern)} {
  verbose?: boolean;
  timeout?: number;
  ${pattern.variations.length > 0 ? 'variation?: string;' : ''}
}

export function ${functionName}(
  input: any,
  options?: ${this.optionsInterface(pattern)}
): any {
  const opts = {
    verbose: false,
    timeout: 30000,
    ...options
  };

  if (opts.verbose) {
    console.log('[${functionName}] Starting with input:', input);
  }

  try {
    ${pattern.howToApply.map((step, i) => `// Step ${i + 1}: ${step}`).join('\n    ')}
    
    // Implementation derived from pattern
    let result = input;
    
    ${pattern.examples.length > 0 ? `// Example reference: ${pattern.examples[0].name}` : ''}
    
    // TODO: Implement specific function logic based on pattern
    
    if (opts.verbose) {
      console.log('[${functionName}] Completed successfully');
    }
    
    return result;
  } catch (error) {
    if (opts.verbose) {
      console.error('[${functionName}] Error:', error);
    }
    throw error;
  }
}

${pattern.variations.length > 0 ? `/**
 * Available variations
 */
export const variations = {
  ${pattern.variations.map(v => `"${v.name.toLowerCase().replace(/\s+/g, '_')}": {
    description: "${v.description}",
    context: "${v.context}"
  }`).join(',\n  ')}
};

export function ${functionName}WithVariation(
  input: any,
  variation: string,
  options?: ${this.optionsInterface(pattern)}
): any {
  if (!variations[variation]) {
    throw new Error(\`Unknown variation: \${variation}\`);
  }
  
  // Apply variation-specific logic
  return ${functionName}(input, { ...options, variation });
}
` : ''}
export default ${functionName};
`;
  }

  getFileName(pattern: KnowledgePattern): string {
    const name = this.generateFunctionName(pattern);
    return `${name}.ts`;
  }

  private generateFunctionName(pattern: KnowledgePattern): string {
    const name = pattern.name.replace(/Pattern/i, '').trim();
    return name.split(/\s+/).map((w, i) => 
      i === 0 ? w.toLowerCase() : w.charAt(0).toUpperCase() + w.slice(1).toLowerCase()
    ).join('');
  }

  private optionsInterface(pattern: KnowledgePattern): string {
    return `${this.generateFunctionName(pattern).charAt(0).toUpperCase()}${this.generateFunctionName(pattern).slice(1)}Options`;
  }
}

/**
 * Feature Artifact Generator
 * Generates feature specifications from patterns
 */
export class FeatureGenerator implements ArtifactGenerator {
  type: ArtifactType = 'FEATURE';

  async generate(pattern: KnowledgePattern, outputDir: string): Promise<GeneratedArtifact> {
    const content = this.getTemplate(pattern);
    const fileName = this.getFileName(pattern);
    const filePath = join(outputDir, 'features', fileName);
    
    mkdirSync(join(outputDir, 'features'), { recursive: true });
    writeFileSync(filePath, content);
    
    return {
      type: this.type,
      id: `feature-${pattern.id}`,
      name: pattern.name,
      description: pattern.description,
      source_pattern: pattern.id,
      content,
      file_path: filePath,
      created_at: new Date().toISOString(),
      metadata: {
        category: pattern.category,
        effectiveness: pattern.effectiveness,
        tags: ['feature', 'specification', pattern.category],
        dependencies: [],
        version: '1.0.0'
      }
    };
  }

  getTemplate(pattern: KnowledgePattern): string {
    const featureName = pattern.name.replace(/Pattern/i, 'Feature').trim();
    
    return `# ${featureName}

## Overview

**Pattern ID**: ${pattern.id}
**Source**: ${pattern.source}
**Effectiveness**: ${(pattern.effectiveness * 100).toFixed(0)}%
**Generated**: ${new Date().toISOString()}

${pattern.description}

## Motivation

This feature was extracted from successful patterns in ${pattern.source}. 
It has been used ${pattern.uses} times with ${(pattern.effectiveness * 100).toFixed(0)}% effectiveness.

## Use Cases

${pattern.whenToUse.map((u, i) => `${i + 1}. ${u}`).join('\n')}

## Specification

### Functional Requirements

${pattern.howToApply.map((a, i) => `#### FR-${String(i + 1).padStart(2, '0')}: ${this.extractRequirement(a)}

${a}

**Acceptance Criteria**:
- [ ] Input validation complete
- [ ] Core logic implemented
- [ ] Output verification passes
`).join('\n')}

### Non-Functional Requirements

#### NFR-01: Performance
- Response time: < 5 seconds for typical inputs
- Memory usage: < 100MB

#### NFR-02: Reliability
- Error handling: Comprehensive
- Recovery: Automatic retry with backoff

#### NFR-03: Maintainability
- Code coverage: > 80%
- Documentation: Complete API docs

## Implementation Plan

### Phase 1: Core Implementation
${pattern.howToApply.slice(0, Math.ceil(pattern.howToApply.length / 2)).map((a, i) => `${i + 1}. ${a}`).join('\n')}

### Phase 2: Integration
${pattern.howToApply.slice(Math.ceil(pattern.howToApply.length / 2)).map((a, i) => `${i + 1}. ${a}`).join('\n')}

### Phase 3: Testing
1. Unit tests for core logic
2. Integration tests for workflows
3. Performance benchmarks

## Examples

${pattern.examples.length > 0 
  ? pattern.examples.map(e => `### ${e.name}

\`\`\`
${e.code}
\`\`\`

${e.explanation}
`).join('\n')
  : 'No examples available.'}

## Variations

${pattern.variations.length > 0
  ? pattern.variations.map(v => `### ${v.name}

${v.description}

**When to use**: ${v.context}
`).join('\n')
  : 'No variations defined.'}

## Dependencies

- Pattern category: ${pattern.category}
- Source file: ${pattern.source}

## Metrics

| Metric | Value |
|--------|-------|
| Effectiveness | ${(pattern.effectiveness * 100).toFixed(0)}% |
| Uses | ${pattern.uses} |
| Steps | ${pattern.howToApply.length} |
| Variations | ${pattern.variations.length} |
| Examples | ${pattern.examples.length} |

## References

- Source Pattern: ${pattern.id}
- Category: ${pattern.category}
- Generated by: GSI Artifact Generator (Phase 38-01)

---

*This feature specification was automatically generated from pattern ${pattern.id}*
`;
  }

  getFileName(pattern: KnowledgePattern): string {
    const name = pattern.name.replace(/Pattern/i, '').trim();
    const slug = name.toLowerCase().replace(/[^a-z0-9]+/g, '-').replace(/^-+|-+$/g, '');
    return `${slug}-feature.md`;
  }

  private extractRequirement(step: string): string {
    const match = step.match(/^\d+\.\s*(?:\*\*)?([^:*]+)(?:\*\*)?/);
    return match ? match[1].trim() : 'Requirement';
  }
}

/**
 * Improvement Artifact Generator
 * Generates improvement suggestions from patterns
 */
export class ImprovementGenerator implements ArtifactGenerator {
  type: ArtifactType = 'IMPROVEMENT';

  async generate(pattern: KnowledgePattern, outputDir: string): Promise<GeneratedArtifact> {
    const content = this.getTemplate(pattern);
    const fileName = this.getFileName(pattern);
    const filePath = join(outputDir, 'improvements', fileName);
    
    mkdirSync(join(outputDir, 'improvements'), { recursive: true });
    writeFileSync(filePath, content);
    
    return {
      type: this.type,
      id: `improvement-${pattern.id}`,
      name: pattern.name,
      description: pattern.description,
      source_pattern: pattern.id,
      content,
      file_path: filePath,
      created_at: new Date().toISOString(),
      metadata: {
        category: pattern.category,
        effectiveness: pattern.effectiveness,
        tags: ['improvement', 'enhancement', 'suggestion'],
        dependencies: [],
        version: '1.0.0'
      }
    };
  }

  getTemplate(pattern: KnowledgePattern): string {
    const improvements = this.generateImprovements(pattern);
    
    return `# Improvement Suggestion: ${pattern.name}

## Overview

**Pattern ID**: ${pattern.id}
**Source**: ${pattern.source}
**Generated**: ${new Date().toISOString()}

Based on analysis of pattern ${pattern.id}, the following improvements are suggested.

## Analysis

### Pattern Metrics
- **Effectiveness**: ${(pattern.effectiveness * 100).toFixed(0)}%
- **Uses**: ${pattern.uses}
- **Category**: ${pattern.category}

### Current State
${pattern.description}

## Suggested Improvements

${improvements.map((imp, i) => `### ${imp.priority} Priority: ${imp.title}

**Rationale**: ${imp.rationale}

**Implementation**:
\`\`\`
${imp.implementation}
\`\`\`

**Expected Impact**: ${imp.impact}

**Effort**: ${imp.effort}

---
`).join('\n')}

## Implementation Roadmap

### Short-term (1-2 weeks)
${improvements.filter(i => i.priority === 'High').map(i => `- [ ] ${i.title}`).join('\n') || '- No high priority items'}

### Medium-term (1 month)
${improvements.filter(i => i.priority === 'Medium').map(i => `- [ ] ${i.title}`).join('\n') || '- No medium priority items'}

### Long-term (2+ months)
${improvements.filter(i => i.priority === 'Low').map(i => `- [ ] ${i.title}`).join('\n') || '- No low priority items'}

## Risk Assessment

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Implementation complexity | Medium | Medium | Start with small changes |
| Breaking changes | Low | High | Comprehensive testing |
| Performance regression | Low | Medium | Benchmark before/after |

## Success Criteria

- [ ] All high-priority improvements implemented
- [ ] Test coverage maintained or improved
- [ ] No performance regression
- [ ] Documentation updated

## References

- Source Pattern: ${pattern.id}
- Category: ${pattern.category}
- Generated by: GSI Artifact Generator (Phase 38-01)

---

*This improvement suggestion was automatically generated from pattern ${pattern.id}*
`;
  }

  getFileName(pattern: KnowledgePattern): string {
    const name = pattern.name.replace(/Pattern/i, '').trim();
    const slug = name.toLowerCase().replace(/[^a-z0-9]+/g, '-').replace(/^-+|-+$/g, '');
    return `${slug}-improvement.md`;
  }

  private generateImprovements(pattern: KnowledgePattern): Array<{
    priority: 'High' | 'Medium' | 'Low';
    title: string;
    rationale: string;
    implementation: string;
    impact: string;
    effort: string;
  }> {
    const improvements: Array<{
      priority: 'High' | 'Medium' | 'Low';
      title: string;
      rationale: string;
      implementation: string;
      impact: string;
      effort: string;
    }> = [];

    // Effectiveness improvement
    if (pattern.effectiveness < 0.8) {
      improvements.push({
        priority: 'High',
        title: 'Improve Pattern Effectiveness',
        rationale: `Current effectiveness of ${(pattern.effectiveness * 100).toFixed(0)}% indicates room for improvement`,
        implementation: '1. Analyze failure cases\n2. Identify common issues\n3. Refine pattern logic\n4. Add validation steps',
        impact: 'Could improve success rate by 20-30%',
        effort: 'Medium (2-3 days)'
      });
    }

    // Documentation improvement
    if (pattern.examples.length < 2) {
      improvements.push({
        priority: 'Medium',
        title: 'Expand Example Coverage',
        rationale: 'Limited examples may hinder adoption',
        implementation: '1. Document common use cases\n2. Add edge case examples\n3. Include error handling examples',
        impact: 'Improved usability and adoption',
        effort: 'Low (1 day)'
      });
    }

    // Variation expansion
    if (pattern.variations.length < 2) {
      improvements.push({
        priority: 'Medium',
        title: 'Add Pattern Variations',
        rationale: 'More variations increase pattern applicability',
        implementation: '1. Identify common modifications\n2. Document each variation\n3. Create variation tests',
        impact: 'Increased flexibility for users',
        effort: 'Medium (2 days)'
      });
    }

    // Performance optimization
    if (pattern.howToApply.length > 5) {
      improvements.push({
        priority: 'Low',
        title: 'Optimize Step Count',
        rationale: 'Many steps may indicate over-engineering',
        implementation: '1. Review each step\n2. Combine related steps\n3. Remove redundant steps',
        impact: 'Reduced complexity, faster execution',
        effort: 'Low (1 day)'
      });
    }

    return improvements;
  }
}

/**
 * Idea Artifact Generator
 * Generates visionary ideas and concepts from patterns
 */
export class IdeaGenerator implements ArtifactGenerator {
  type: ArtifactType = 'IDEA';

  async generate(pattern: KnowledgePattern, outputDir: string): Promise<GeneratedArtifact> {
    const content = this.getTemplate(pattern);
    const fileName = this.getFileName(pattern);
    const filePath = join(outputDir, 'ideas', fileName);
    
    mkdirSync(join(outputDir, 'ideas'), { recursive: true });
    writeFileSync(filePath, content);
    
    return {
      type: this.type,
      id: `idea-${pattern.id}`,
      name: pattern.name,
      description: pattern.description,
      source_pattern: pattern.id,
      content,
      file_path: filePath,
      created_at: new Date().toISOString(),
      metadata: {
        category: pattern.category,
        effectiveness: pattern.effectiveness,
        tags: ['idea', 'vision', 'concept'],
        dependencies: [],
        version: '1.0.0'
      }
    };
  }

  getTemplate(pattern: KnowledgePattern): string {
    const ideas = this.generateIdeas(pattern);
    
    return `# Visionary Idea: ${pattern.name}

## Concept Overview

**Pattern ID**: ${pattern.id}
**Source**: ${pattern.source}
**Generated**: ${new Date().toISOString()}

This document explores visionary concepts and innovative ideas derived from pattern analysis.

## Origin Pattern

${pattern.description}

**Metrics**:
- Effectiveness: ${(pattern.effectiveness * 100).toFixed(0)}%
- Uses: ${pattern.uses}
- Category: ${pattern.category}

---

## Generated Ideas

${ideas.map((idea, i) => `### Idea ${i + 1}: ${idea.title}

**Vision**: ${idea.vision}

**Description**:
${idea.description}

**Potential Impact**:
${idea.impact}

**Feasibility**: ${idea.feasibility}

**Next Steps**:
${idea.nextSteps.map((s, j) => `${j + 1}. ${s}`).join('\n')}

**Related Patterns**: ${idea.relatedPatterns.join(', ') || 'None identified'}

---
`).join('\n')}

## Innovation Themes

${this.generateThemes(pattern).map(t => `- **${t.name}**: ${t.description}`).join('\n')}

## Research Questions

${this.generateResearchQuestions(pattern).map((q, i) => `${i + 1}. ${q}`).join('\n')}

## Exploration Roadmap

### Phase 1: Concept Validation (2 weeks)
- Research existing solutions
- Identify key challenges
- Validate assumptions

### Phase 2: Prototype (4 weeks)
- Build minimal viable concept
- Test core functionality
- Gather feedback

### Phase 3: Refinement (4 weeks)
- Iterate on feedback
- Improve implementation
- Document findings

## References

- Source Pattern: ${pattern.id}
- Category: ${pattern.category}
- Generated by: GSI Artifact Generator (Phase 38-01)

---

*This visionary idea document was automatically generated from pattern ${pattern.id}*  
*Human review and refinement recommended before implementation*
`;
  }

  getFileName(pattern: KnowledgePattern): string {
    const name = pattern.name.replace(/Pattern/i, '').trim();
    const slug = name.toLowerCase().replace(/[^a-z0-9]+/g, '-').replace(/^-+|-+$/g, '');
    return `${slug}-idea.md`;
  }

  private generateIdeas(pattern: KnowledgePattern): Array<{
    title: string;
    vision: string;
    description: string;
    impact: string;
    feasibility: string;
    nextSteps: string[];
    relatedPatterns: string[];
  }> {
    const ideas: Array<{
      title: string;
      vision: string;
      description: string;
      impact: string;
      feasibility: string;
      nextSteps: string[];
      relatedPatterns: string[];
    }> = [];

    // Generate idea based on pattern category
    switch (pattern.category) {
      case 'command-patterns':
        ideas.push({
          title: 'Self-Evolving Command System',
          vision: 'Commands that automatically improve based on usage patterns',
          description: 'Create a system where commands learn from successful executions and automatically suggest improvements to their own implementation.',
          impact: 'Could dramatically reduce maintenance burden and improve command effectiveness over time',
          feasibility: 'Medium - Requires ML integration and careful safety constraints',
          nextSteps: [
            'Design command telemetry system',
            'Create improvement suggestion engine',
            'Build safety validation layer',
            'Implement gradual rollout mechanism'
          ],
          relatedPatterns: ['optimization', 'error-handling']
        });
        break;

      case 'thinking-configs':
        ideas.push({
          title: 'Adaptive Cognitive Enhancement',
          vision: 'Thinking systems that adapt to user preferences and task types',
          description: 'Build a thinking orchestrator that learns optimal configurations for different users and task types, automatically adjusting complexity.',
          impact: 'Personalized cognitive enhancement that maximizes effectiveness while minimizing token usage',
          feasibility: 'High - Pattern data already exists for learning',
          nextSteps: [
            'Analyze thinking config effectiveness data',
            'Build preference learning model',
            'Create adaptive selection algorithm',
            'Test with diverse task types'
          ],
          relatedPatterns: ['optimization', 'workflows']
        });
        break;

      case 'workflows':
        ideas.push({
          title: 'Autonomous Workflow Composition',
          vision: 'Workflows that compose themselves based on goal descriptions',
          description: 'Enable users to describe high-level goals and have the system automatically compose optimal workflows from available patterns.',
          impact: 'Could reduce workflow creation time by 90% while improving quality',
          feasibility: 'Medium - Requires sophisticated pattern matching and composition',
          nextSteps: [
            'Build workflow pattern library',
            'Create goal-to-pattern matching system',
            'Develop composition algorithm',
            'Add validation and optimization'
          ],
          relatedPatterns: ['command-patterns', 'agents']
        });
        break;

      default:
        ideas.push({
          title: 'Cross-Pattern Synergy Detection',
          vision: 'Automatic detection of synergistic pattern combinations',
          description: 'System that identifies when combining multiple patterns would produce better results than using them individually.',
          impact: 'Could discover new best practices through automated analysis',
          feasibility: 'High - Pattern data available for analysis',
          nextSteps: [
            'Analyze pattern co-occurrence',
            'Identify successful combinations',
            'Build synergy scoring system',
            'Create recommendation engine'
          ],
          relatedPatterns: ['optimization', 'workflows']
        });
    }

    // Add generic innovation idea
    ideas.push({
      title: 'Pattern-Driven Documentation Generation',
      vision: 'Documentation that writes itself from pattern analysis',
      description: 'Automatically generate comprehensive documentation by analyzing how patterns are used across the codebase.',
      impact: 'Always up-to-date documentation with minimal manual effort',
      feasibility: 'High - Pattern extraction already exists',
      nextSteps: [
        'Enhance pattern extraction for doc elements',
        'Build documentation templates',
        'Create doc generation pipeline',
        'Add human review integration'
      ],
      relatedPatterns: [pattern.category]
    });

    return ideas;
  }

  private generateThemes(pattern: KnowledgePattern): Array<{name: string; description: string}> {
    return [
      { name: 'Automation', description: 'Reducing manual intervention through intelligent automation' },
      { name: 'Adaptation', description: 'Systems that learn and adapt from usage patterns' },
      { name: 'Composition', description: 'Building complex solutions from simpler components' },
      { name: 'Optimization', description: 'Continuous improvement through pattern analysis' }
    ];
  }

  private generateResearchQuestions(pattern: KnowledgePattern): string[] {
    return [
      `How can ${pattern.category} patterns be combined for maximum effectiveness?`,
      'What metrics best predict pattern success in different contexts?',
      'Can pattern effectiveness be improved through automated refinement?',
      'What prevents patterns from achieving 100% effectiveness?',
      'How do user preferences affect pattern applicability?'
    ];
  }
}

/**
 * Master Artifact Generator
 * Coordinates all artifact type generators
 */
export class ArtifactGeneratorManager {
  private generators: Map<ArtifactType, ArtifactGenerator>;
  private outputDir: string;

  constructor(outputDir: string) {
    this.outputDir = outputDir;
    this.generators = new Map([
      ['SKILL', new SkillGenerator()],
      ['AGENT', new AgentGenerator()],
      ['LOGIC', new LogicGenerator()],
      ['FUNCTION', new FunctionGenerator()],
      ['FEATURE', new FeatureGenerator()],
      ['IMPROVEMENT', new ImprovementGenerator()],
      ['IDEA', new IdeaGenerator()]
    ]);
  }

  /**
   * Generate a single artifact type from a pattern
   */
  async generate(pattern: KnowledgePattern, type: ArtifactType): Promise<GeneratedArtifact> {
    const generator = this.generators.get(type);
    if (!generator) {
      throw new Error(`Unknown artifact type: ${type}`);
    }
    return generator.generate(pattern, this.outputDir);
  }

  /**
   * Generate all artifact types from a pattern
   */
  async generateAll(pattern: KnowledgePattern): Promise<GeneratedArtifact[]> {
    const artifacts: GeneratedArtifact[] = [];
    const types: ArtifactType[] = ['SKILL', 'AGENT', 'LOGIC', 'FUNCTION', 'FEATURE', 'IMPROVEMENT', 'IDEA'];
    
    for (const type of types) {
      try {
        const artifact = await this.generate(pattern, type);
        artifacts.push(artifact);
      } catch (error) {
        console.error(`Failed to generate ${type} for pattern ${pattern.id}:`, error);
      }
    }
    
    return artifacts;
  }

  /**
   * Generate specific artifact types from a pattern
   */
  async generateTypes(pattern: KnowledgePattern, types: ArtifactType[]): Promise<GeneratedArtifact[]> {
    const artifacts: GeneratedArtifact[] = [];
    
    for (const type of types) {
      try {
        const artifact = await this.generate(pattern, type);
        artifacts.push(artifact);
      } catch (error) {
        console.error(`Failed to generate ${type} for pattern ${pattern.id}:`, error);
      }
    }
    
    return artifacts;
  }

  /**
   * Get list of available artifact types
   */
  getAvailableTypes(): ArtifactType[] {
    return Array.from(this.generators.keys());
  }

  /**
   * Get generator for a specific type
   */
  getGenerator(type: ArtifactType): ArtifactGenerator | undefined {
    return this.generators.get(type);
  }
}

export default ArtifactGeneratorManager;

</document_content>
</document>
<document index="15">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\workflow-modules\index.d.ts</source>
<document_content>
/**
 * GSI Workflow Modules Index (TypeScript definitions)
 */

export * from './patch-manager';
export * from './thinking-orchestrator';
export * from './workflow-chainer';
export * from './knowledge-base';

</document_content>
</document>
<document index="16">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\workflow-modules\index.js</source>
<document_content>
/**
 * GSI Workflow Modules Index
 * 
 * Exports all workflow modules for use by GSI commands and CLI.
 * These modules provide the foundation for claudeception-style self-improvement.
 */

// Patch Manager - Handles backup/restore of local modifications across GSI updates
export { PatchManager } from './patch-manager.js';
export type { 
  PatchMetadata, 
  PatchFile, 
  PatchSummary, 
  MergeResult, 
  Conflict 
} from './patch-manager.js';

// Thinking Orchestrator - Coordinates MCP thinking servers based on thinking_phase configs
export { ThinkingOrchestrator } from './thinking-orchestrator.js';
export type { 
  ThinkingMode, 
  ThinkingServer, 
  ThinkingPhaseConfig, 
  ThinkingContext,
  ThinkingResult,
  ThinkingThought
} from './thinking-orchestrator.js';

// Workflow Chainer - Chains multiple GSI commands with dependency resolution
export { WorkflowChainer } from './workflow-chainer.js';
export type { 
  WorkflowChain, 
  WorkflowStep, 
  WorkflowState,
  WorkflowResult,
  ParallelGroup,
  CheckpointData,
  CheckpointStrategy,
  FailureStrategy
} from './workflow-chainer.js';

// Knowledge Base - Extracts patterns and generates skills/agents/features
export { KnowledgeBase } from './knowledge-base.js';
export type { 
  KnowledgePattern, 
  PatternCategory,
  KnowledgeTemplate,
  BestPractice,
  AntiPattern,
  ExtractionResult,
  PatternVariation,
  PatternExample
} from './knowledge-base.js';

// Convenience function to initialize all modules
export function initializeWorkflowModules(options?: {
  knowledgeDir?: string;
  stateDir?: string;
  patchesDir?: string;
}) {
  return {
    patchManager: new PatchManager(options?.patchesDir),
    thinkingOrchestrator: new ThinkingOrchestrator(),
    workflowChainer: new WorkflowChainer(options?.stateDir),
    knowledgeBase: new KnowledgeBase(options?.knowledgeDir)
  };
}

</document_content>
</document>
<document index="17">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\workflow-modules\knowledge-base.ts</source>
<document_content>
/**
 * GSI Knowledge Base Module
 *
 * Extracts patterns, principles, and reusable knowledge from the GSI codebase
 * to create new skills, improve existing commands, and build searchable knowledge.
 *
 * Extracted from: Claudeception analysis of GSI patch reapplication session
 */

import { readFileSync, writeFileSync, existsSync, mkdirSync, readdirSync } from 'fs';
import { join, basename } from 'path';
import { ArtifactGeneratorManager, ArtifactType, GeneratedArtifact } from './artifact-generator.js';

export interface KnowledgePattern {
  id: string;
  name: string;
  category: PatternCategory;
  description: string;
  source: string;
  whenToUse: string[];
  howToApply: string[];
  variations: PatternVariation[];
  examples: PatternExample[];
  effectiveness: number;
  uses: number;
}

export type PatternCategory =
  | 'command-patterns'
  | 'thinking-configs'
  | 'workflows'
  | 'agents'
  | 'error-handling'
  | 'optimization';

export interface PatternVariation {
  name: string;
  description: string;
  context: string;
}

export interface PatternExample {
  name: string;
  code: string;
  explanation: string;
}

export interface KnowledgeTemplate {
  type: 'gsi-command' | 'thinking-config' | 'workflow';
  template: string;
  variables: string[];
  description: string;
}

export interface BestPractice {
  id: string;
  title: string;
  category: string;
  description: string;
  rationale: string;
  examples: string[];
  antiPatterns: string[];
}

export interface AntiPattern {
  id: string;
  name: string;
  description: string;
  whyBad: string;
  instead: string;
  examples: string[];
}

export interface ExtractionResult {
  patternsFound: number;
  patternsExtracted: KnowledgePattern[];
  templatesGenerated: KnowledgeTemplate[];
  bestPractices: BestPractice[];
}

export interface MultiTypeGenerationResult {
  pattern: KnowledgePattern;
  artifacts: GeneratedArtifact[];
  types: ArtifactType[];
  success: boolean;
  errors: string[];
}

/**
 * Manages knowledge extraction and storage for GSI
 */
export class KnowledgeBase {
  private knowledgeDir: string;
  private patternsDir: string;
  private templatesDir: string;
  private practicesDir: string;
  private indexFile: string;
  private artifactGenerator: ArtifactGeneratorManager;

  constructor(knowledgeDir: string = join(process.env.HOME || '', '.claude', 'gsi-knowledge')) {
    this.knowledgeDir = knowledgeDir;
    this.patternsDir = join(knowledgeDir, 'patterns');
    this.templatesDir = join(knowledgeDir, 'templates');
    this.practicesDir = join(knowledgeDir, 'best-practices');
    this.indexFile = join(knowledgeDir, 'index.json');
    this.artifactGenerator = new ArtifactGeneratorManager(knowledgeDir);

    this.ensureDirectories();
  }

  /**
   * Extract patterns from GSI files
   */
  async extract(sourcePath: string, category?: PatternCategory): Promise<ExtractionResult> {
    const patterns: KnowledgePattern[] = [];
    const templates: KnowledgeTemplate[] = [];
    const practices: BestPractice[] = [];

    // Read GSI files
    const files = await this.discoverFiles(sourcePath);

    for (const file of files) {
      const content = readFileSync(file, 'utf-8');

      // Extract patterns
      const filePatterns = this.extractPatternsFromFile(file, content, category);
      patterns.push(...filePatterns);

      // Extract templates
      const fileTemplates = this.extractTemplatesFromFile(file, content);
      templates.push(...fileTemplates);

      // Extract best practices
      const filePractices = this.extractBestPracticesFromFile(file, content);
      practices.push(...filePractices);
    }

    // Store extracted knowledge
    for (const pattern of patterns) {
      await this.storePattern(pattern);
    }

    for (const template of templates) {
      await this.storeTemplate(template);
    }

    for (const practice of practices) {
      await this.storeBestPractice(practice);
    }

    // Update index
    this.updateIndex(patterns, templates, practices);

    return {
      patternsFound: files.length,
      patternsExtracted: patterns,
      templatesGenerated: templates,
      bestPractices: practices
    };
  }

  /**
   * Extract patterns from a single file
   */
  private extractPatternsFromFile(
    filePath: string,
    content: string,
    category?: PatternCategory
  ): KnowledgePattern[] {
    const patterns: KnowledgePattern[] = [];
    const frontmatter = this.parseYAMLFrontmatter(content);

    // Detect command patterns
    if (frontmatter.allowed_tools && !category) {
      patterns.push(this.extractCommandPattern(filePath, frontmatter));
    }

    // Detect thinking patterns
    if (frontmatter.thinking_phase) {
      patterns.push(this.extractThinkingPattern(filePath, frontmatter));
    }

    // Detect workflow patterns from process sections
    const processMatch = content.match(/<process>([\s\S]*?)<\/process>/);
    if (processMatch) {
      patterns.push(this.extractWorkflowPattern(filePath, processMatch[1]));
    }

    return patterns;
  }

  /**
   * Extract command pattern
   */
  private extractCommandPattern(
    filePath: string,
    frontmatter: Record<string, any>
  ): KnowledgePattern {
    const commandName = frontmatter.name || basename(filePath, '.md');
    const toolCount = frontmatter.allowed_tools?.length || 0;

    return {
      id: `pattern-command-${commandName}`,
      name: `${commandName} Command Pattern`,
      category: 'command-patterns',
      description: `Pattern for ${commandName} command with ${toolCount} tools`,
      source: filePath,
      whenToUse: [
        `When implementing a command similar to ${commandName}`,
        `When ${toolCount} tools are needed`,
        `When the command has similar complexity`
      ],
      howToApply: [
        '1. Copy the command structure',
        '2. Modify description and objective',
        '3. Adjust allowed-tools list',
        '4. Update process section'
      ],
      variations: [
        {
          name: 'Simplified',
          description: 'Remove non-essential tools',
          context: 'When simpler version is needed'
        }
      ],
      examples: [
        {
          name: 'Basic usage',
          code: frontmatter.description || '',
          explanation: 'Command description'
        }
      ],
      effectiveness: 1.0,
      uses: 0
    };
  }

  /**
   * Extract thinking pattern
   */
  private extractThinkingPattern(
    filePath: string,
    frontmatter: Record<string, any>
  ): KnowledgePattern {
    const thinking = frontmatter.thinking_phase;

    return {
      id: `pattern-thinking-${basename(filePath, '.md')}`,
      name: `${thinking.mode} Thinking Pattern`,
      category: 'thinking-configs',
      description: `Thinking configuration with ${thinking.mode} mode`,
      source: filePath,
      whenToUse: [
        `When ${thinking.mode.toLowerCase()} cognitive enhancement is needed`,
        `When using ${thinking.servers?.join(', ') || 'no'} servers`,
        `Timeout around ${thinking.timeout}ms`
      ],
      howToApply: [
        '1. Copy thinking_phase section',
        '2. Adjust mode based on complexity',
        '3. Select appropriate servers',
        '4. Set timeout based on expected duration'
      ],
      variations: [
        {
          name: 'Lighter',
          description: 'Use LIGHTWEIGHT instead of STANDARD',
          context: 'When faster execution is needed'
        },
        {
          name: 'Heavier',
          description: 'Use COMPREHENSIVE instead of STANDARD',
          context: 'When deeper analysis is needed'
        }
      ],
      examples: [
        {
          name: 'Thinking config',
          code: JSON.stringify(thinking, null, 2),
          explanation: thinking.rationale || 'Thinking configuration'
        }
      ],
      effectiveness: 1.0,
      uses: 0
    };
  }

  /**
   * Extract workflow pattern
   */
  private extractWorkflowPattern(filePath: string, processContent: string): KnowledgePattern {
    const steps = processContent.split('\n').filter(line => line.trim().length > 0);

    return {
      id: `pattern-workflow-${basename(filePath, '.md')}`,
      name: `Workflow Pattern (${steps.length} steps)`,
      category: 'workflows',
      description: `Multi-step workflow with ${steps.length} process steps`,
      source: filePath,
      whenToUse: [
        'When implementing multi-step processes',
        'When sequential execution is required',
        'When checkpoint/resume is needed'
      ],
      howToApply: [
        '1. Define process steps clearly',
        '2. Add validation between steps',
        '3. Implement error handling',
        '4. Add checkpoint markers'
      ],
      variations: [],
      examples: [
        {
          name: 'Process steps',
          code: processContent.substring(0, 500),
          explanation: 'First 500 chars of process'
        }
      ],
      effectiveness: 1.0,
      uses: 0
    };
  }

  /**
   * Extract templates from file
   */
  private extractTemplatesFromFile(filePath: string, content: string): KnowledgeTemplate[] {
    const templates: KnowledgeTemplate[] = [];
    const frontmatter = this.parseYAMLFrontmatter(content);

    if (frontmatter.name && frontmatter.description) {
      templates.push({
        type: 'gsi-command',
        template: content,
        variables: ['${name}', '${description}', '${thinking_phase}', '${allowed-tools}'],
        description: `Template based on ${frontmatter.name} command`
      });
    }

    if (frontmatter.thinking_phase) {
      templates.push({
        type: 'thinking-config',
        template: JSON.stringify(frontmatter.thinking_phase, null, 2),
        variables: ['${mode}', '${servers}', '${bmad_enabled}', '${timeout}', '${rationale}'],
        description: `Thinking config template (${frontmatter.thinking_phase.mode})`
      });
    }

    return templates;
  }

  /**
   * Extract best practices from file
   */
  private extractBestPracticesFromFile(filePath: string, content: string): BestPractice[] {
    const practices: BestPractice[] = [];

    // Extract from comments or documentation sections
    const bestPracticeMatches = content.matchAll(/Best Practice[s]?:\s*(.*?)(?=\n\n|\n#|$)/gis);

    for (const match of bestPracticeMatches) {
      practices.push({
        id: `practice-${basename(filePath, '.md')}-${practices.length}`,
        title: `Best Practice from ${basename(filePath)}`,
        category: 'general',
        description: match[1].trim(),
        rationale: 'Extracted from GSI documentation',
        examples: [],
        antiPatterns: []
      });
    }

    return practices;
  }

  /**
   * Search knowledge base
   */
  search(query: string, category?: PatternCategory): KnowledgePattern[] {
    const results: KnowledgePattern[] = [];
    const queryLower = query.toLowerCase();

    if (!existsSync(this.patternsDir)) {
      return results;
    }

    const files = readdirSync(this.patternsDir, { recursive: true }) as string[];

    for (const file of files) {
      if (!file.endsWith('.json')) continue;

      const pattern: KnowledgePattern = JSON.parse(
        readFileSync(join(this.patternsDir, file), 'utf-8')
      );

      // Filter by category
      if (category && pattern.category !== category) {
        continue;
      }

      // Search in pattern fields
      if (
        pattern.name.toLowerCase().includes(queryLower) ||
        pattern.description.toLowerCase().includes(queryLower) ||
        pattern.whenToUse.some(u => u.toLowerCase().includes(queryLower))
      ) {
        results.push(pattern);
      }
    }

    // Sort by effectiveness
    results.sort((a, b) => b.effectiveness - a.effectiveness);

    return results;
  }

  /**
   * Generate skill from pattern
   */
  async generateSkill(patternId: string): Promise<string> {
    const pattern = await this.getPattern(patternId);
    if (!pattern) {
      throw new Error(`Pattern not found: ${patternId}`);
    }

    const skillContent = this.patternToSkill(pattern);

    // Save skill
    const skillPath = join(
      process.env.HOME || '',
      '.claude',
      'skills',
      `generated-${pattern.id}`,
      'skill.md'
    );

    mkdirSync(join(skillPath, '..'), { recursive: true });
    writeFileSync(skillPath, skillContent);

    return skillPath;
  }

  /**
   * Convert pattern to skill
   */
  private patternToSkill(pattern: KnowledgePattern): string {
    return `# ${pattern.name}

## Purpose
${pattern.description}

## Context
Extracted from: ${pattern.source}

## When to Use
${pattern.whenToUse.map(u => `- ${u}`).join('\n')}

## How to Apply
${pattern.howToApply.map(a => a).join('\n')}

## Variations
${pattern.variations.map(v => `### ${v.name}\n${v.description}\nContext: ${v.context}`).join('\n\n')}

## Examples
${pattern.examples.map(e => `### ${e.name}\n\`\`\`\n${e.code}\n\`\`\`\n${e.explanation}`).join('\n\n')}

## Effectiveness
${(pattern.effectiveness * 100).toFixed(0)}% (based on ${pattern.uses} uses)

## History
- Extracted: ${new Date().toISOString()}
- Source: ${pattern.source}
- Uses: ${pattern.uses}
`;
  }

  /**
   * Get pattern by ID
   */
  private async getPattern(patternId: string): Promise<KnowledgePattern | null> {
    const patternFile = join(this.patternsDir, `${patternId}.json`);

    if (!existsSync(patternFile)) {
      return null;
    }

    return JSON.parse(readFileSync(patternFile, 'utf-8'));
  }

  /**
   * Store pattern
   */
  private async storePattern(pattern: KnowledgePattern): Promise<void> {
    const categoryDir = join(this.patternsDir, pattern.category);
    mkdirSync(categoryDir, { recursive: true });

    const patternFile = join(categoryDir, `${pattern.id}.json`);
    writeFileSync(patternFile, JSON.stringify(pattern, null, 2));
  }

  /**
   * Store template
   */
  private async storeTemplate(template: KnowledgeTemplate): Promise<void> {
    const templateFile = join(this.templatesDir, `${template.type}-${Date.now()}.json`);
    writeFileSync(templateFile, JSON.stringify(template, null, 2));
  }

  /**
   * Store best practice
   */
  private async storeBestPractice(practice: BestPractice): Promise<void> {
    const practiceFile = join(this.practicesDir, `${practice.id}.md`);
    writeFileSync(practiceFile, `# ${practice.title}\n\n${practice.description}`);
  }

  /**
   * Update index
   */
  private updateIndex(
    patterns: KnowledgePattern[],
    templates: KnowledgeTemplate[],
    practices: BestPractice[]
  ): void {
    const index = {
      lastUpdated: new Date().toISOString(),
      patterns: patterns.length,
      templates: templates.length,
      practices: practices.length,
      categories: [...new Set(patterns.map(p => p.category))]
    };

    writeFileSync(this.indexFile, JSON.stringify(index, null, 2));
  }

  /**
   * Discover GSI files
   */
  private async discoverFiles(sourcePath: string): Promise<string[]> {
    const files: string[] = [];

    if (!existsSync(sourcePath)) {
      return files;
    }

    // In a real implementation, would recursively find all .md files
    // For now, return common locations
    const commonFiles = [
      'commands/GSI/add-phase.md',
      'commands/GSI/debug.md',
      'agents/gsi-planner.md'
    ];

    for (const file of commonFiles) {
      const fullPath = join(sourcePath, file);
      if (existsSync(fullPath)) {
        files.push(fullPath);
      }
    }

    return files;
  }

  /**
   * Parse YAML frontmatter
   */
  private parseYAMLFrontmatter(content: string): Record<string, any> {
    const match = content.match(/^---\n([\s\S]*?)\n---/);
    if (!match) return {};

    // Simple YAML parser - in production would use proper YAML library
    const result: Record<string, any> = {};
    const lines = match[1].split('\n');

    for (const line of lines) {
      const colonIndex = line.indexOf(':');
      if (colonIndex > 0) {
        const key = line.substring(0, colonIndex).trim();
        const value = line.substring(colonIndex + 1).trim();
        result[key] = value;
      }
    }

    return result;
  }

  /**
   * Ensure directories exist
   */
  private ensureDirectories(): void {
    if (!existsSync(this.knowledgeDir)) {
      mkdirSync(this.knowledgeDir, { recursive: true });
    }
    if (!existsSync(this.patternsDir)) {
      mkdirSync(this.patternsDir, { recursive: true });
    }
    if (!existsSync(this.templatesDir)) {
      mkdirSync(this.templatesDir, { recursive: true });
    }
    if (!existsSync(this.practicesDir)) {
      mkdirSync(this.practicesDir, { recursive: true });
    }
  }

  /**
   * Track pattern effectiveness
   */
  trackEffectiveness(patternId: string, success: boolean): void {
    const pattern = this.getPattern(patternId);
    if (!pattern) return;

    pattern.then(p => {
      p.uses++;
      if (success) {
        // Update effectiveness with moving average
        p.effectiveness = (p.effectiveness * (p.uses - 1) + 1) / p.uses;
      } else {
        p.effectiveness = (p.effectiveness * (p.uses - 1)) / p.uses;
      }

      this.storePattern(p);
    });
  }

  // ============================================================
  // Multi-Type Artifact Generation Methods (Phase 38-01)
  // ============================================================

  /**
   * Get the artifact generator manager
   */
  getArtifactGenerator(): ArtifactGeneratorManager {
    return this.artifactGenerator;
  }

  /**
   * Get available artifact types
   */
  getAvailableArtifactTypes(): ArtifactType[] {
    return this.artifactGenerator.getAvailableTypes();
  }

  /**
   * Generate all artifact types from a pattern
   */
  async generateAllArtifacts(patternId: string): Promise<MultiTypeGenerationResult> {
    const pattern = await this.getPattern(patternId);
    if (!pattern) {
      return {
        pattern: null as any,
        artifacts: [],
        types: [],
        success: false,
        errors: [`Pattern not found: ${patternId}`]
      };
    }

    const errors: string[] = [];
    const artifacts: GeneratedArtifact[] = [];

    try {
      const generatedArtifacts = await this.artifactGenerator.generateAll(pattern);
      artifacts.push(...generatedArtifacts);
    } catch (error) {
      errors.push(`Failed to generate artifacts: ${error}`);
    }

    return {
      pattern,
      artifacts,
      types: artifacts.map(a => a.type),
      success: errors.length === 0,
      errors
    };
  }

  /**
   * Generate specific artifact types from a pattern
   */
  async generateArtifactTypes(patternId: string, types: ArtifactType[]): Promise<MultiTypeGenerationResult> {
    const pattern = await this.getPattern(patternId);
    if (!pattern) {
      return {
        pattern: null as any,
        artifacts: [],
        types: [],
        success: false,
        errors: [`Pattern not found: ${patternId}`]
      };
    }

    const errors: string[] = [];
    const artifacts: GeneratedArtifact[] = [];

    try {
      const generatedArtifacts = await this.artifactGenerator.generateTypes(pattern, types);
      artifacts.push(...generatedArtifacts);
    } catch (error) {
      errors.push(`Failed to generate artifacts: ${error}`);
    }

    return {
      pattern,
      artifacts,
      types: artifacts.map(a => a.type),
      success: errors.length === 0,
      errors
    };
  }

  /**
   * Generate a single artifact type from a pattern
   */
  async generateArtifact(patternId: string, type: ArtifactType): Promise<GeneratedArtifact | null> {
    const pattern = await this.getPattern(patternId);
    if (!pattern) {
      throw new Error(`Pattern not found: ${patternId}`);
    }

    return this.artifactGenerator.generate(pattern, type);
  }

  /**
   * Generate an agent from a pattern
   */
  async generateAgent(patternId: string): Promise<GeneratedArtifact> {
    return this.generateArtifact(patternId, 'AGENT');
  }

  /**
   * Generate a feature specification from a pattern
   */
  async generateFeature(patternId: string): Promise<GeneratedArtifact> {
    return this.generateArtifact(patternId, 'FEATURE');
  }

  /**
   * Generate an idea document from a pattern
   */
  async generateIdea(patternId: string): Promise<GeneratedArtifact> {
    return this.generateArtifact(patternId, 'IDEA');
  }

  /**
   * Generate a logic module from a pattern
   */
  async generateLogic(patternId: string): Promise<GeneratedArtifact> {
    return this.generateArtifact(patternId, 'LOGIC');
  }

  /**
   * Generate a function from a pattern
   */
  async generateFunction(patternId: string): Promise<GeneratedArtifact> {
    return this.generateArtifact(patternId, 'FUNCTION');
  }

  /**
   * Generate an improvement suggestion from a pattern
   */
  async generateImprovement(patternId: string): Promise<GeneratedArtifact> {
    return this.generateArtifact(patternId, 'IMPROVEMENT');
  }

  /**
   * Extract patterns and generate all artifact types in one operation
   */
  async extractAndGenerate(
    sourcePath: string,
    category?: PatternCategory,
    artifactTypes?: ArtifactType[]
  ): Promise<{ extraction: ExtractionResult; generations: MultiTypeGenerationResult[] }> {
    // Extract patterns
    const extraction = await this.extract(sourcePath, category);

    // Generate artifacts for each pattern
    const generations: MultiTypeGenerationResult[] = [];

    for (const pattern of extraction.patternsExtracted) {
      // Store pattern first
      await this.storePattern(pattern);

      // Generate artifacts
      if (artifactTypes && artifactTypes.length > 0) {
        const result = await this.generateArtifactTypes(pattern.id, artifactTypes);
        generations.push(result);
      } else {
        const result = await this.generateAllArtifacts(pattern.id);
        generations.push(result);
      }
    }

    return { extraction, generations };
  }

  /**
   * Batch generate artifacts for multiple patterns
   */
  async batchGenerate(
    patternIds: string[],
    types: ArtifactType[]
  ): Promise<Map<string, MultiTypeGenerationResult>> {
    const results = new Map<string, MultiTypeGenerationResult>();

    for (const patternId of patternIds) {
      try {
        const result = await this.generateArtifactTypes(patternId, types);
        results.set(patternId, result);
      } catch (error) {
        results.set(patternId, {
          pattern: null as any,
          artifacts: [],
          types: [],
          success: false,
          errors: [String(error)]
        });
      }
    }

    return results;
  }
}

export default KnowledgeBase;

</document_content>
</document>
<document index="18">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\workflow-modules\patch-manager.ts</source>
<document_content>
/**
 * GSI Patch Manager Module
 *
 * Handles backup and restoration of local modifications across GSI package updates.
 * Extracted from v1.18.0 → v1.23.0 migration session (28 files patched).
 */

import { createHash } from 'crypto';
import { readFileSync, writeFileSync, existsSync, mkdirSync } from 'fs';
import { join, basename } from 'path';

interface PatchMetadata {
  version: string;
  timestamp: string;
  files: PatchFile[];
  patches: PatchSummary[];
}

interface PatchFile {
  path: string;
  hash: string;
  modified: boolean;
}

interface PatchSummary {
  file: string;
  type: 'thinking_phase' | 'allowed_tools' | 'content' | 'mixed';
  description: string;
}

interface MergeResult {
  success: boolean;
  conflicts: Conflict[];
  mergedContent: string;
}

interface Conflict {
  section: string;
  userVersion: string;
  upstreamVersion: string;
  resolution?: 'user' | 'upstream' | 'merged';
}

export class PatchManager {
  private patchesDir: string;
  private gsiInstallDir: string;
  private metadataFile: string;

  constructor(patchesDir: string = join(process.env.HOME || '', '.claude', 'GSI-local-patches')) {
    this.patchesDir = patchesDir;
    this.metadataFile = join(patchesDir, 'backup-meta.json');
    this.gsiInstallDir = this.detectGSIInstallDir();
  }

  /**
   * Backup all local modifications before update
   */
  async backup(): Promise<PatchMetadata> {
    const modifiedFiles = await this.detectModifications();
    const metadata: PatchMetadata = {
      version: await this.getCurrentVersion(),
      timestamp: new Date().toISOString(),
      files: [],
      patches: []
    };

    if (!existsSync(this.patchesDir)) {
      mkdirSync(this.patchesDir, { recursive: true });
    }

    for (const file of modifiedFiles) {
      const sourcePath = join(this.gsiInstallDir, file);
      const backupPath = join(this.patchesDir, file);

      // Copy file to backup
      const content = readFileSync(sourcePath, 'utf-8');
      mkdirSync(join(backupPath, '..'), { recursive: true });
      writeFileSync(backupPath, content);

      // Analyze what changed
      const summary = this.analyzeModification(content);
      metadata.patches.push(summary);
      metadata.files.push({
        path: file,
        hash: this.hashFile(content),
        modified: true
      });
    }

    // Save metadata
    writeFileSync(this.metadataFile, JSON.stringify(metadata, null, 2));

    return metadata;
  }

  /**
   * Restore backed-up modifications to new version
   */
  async restore(): Promise<Map<string, MergeResult>> {
    const results = new Map<string, MergeResult>();

    if (!existsSync(this.metadataFile)) {
      throw new Error('No backup metadata found. Run backup() first.');
    }

    const metadata: PatchMetadata = JSON.parse(
      readFileSync(this.metadataFile, 'utf-8')
    );

    for (const file of metadata.files) {
      const backupPath = join(this.patchesDir, file.path);
      const currentPath = join(this.gsiInstallDir, file.path);

      if (!existsSync(backupPath) || !existsSync(currentPath)) {
        continue;
      }

      const backupContent = readFileSync(backupPath, 'utf-8');
      const currentContent = readFileSync(currentPath, 'utf-8');

      // Merge modifications
      const mergeResult = this.mergeFile(backupContent, currentContent, metadata.patches);

      if (mergeResult.success) {
        writeFileSync(currentPath, mergeResult.mergedContent);
      }

      results.set(file.path, mergeResult);
    }

    return results;
  }

  /**
   * Detect which files have local modifications
   */
  private async detectModifications(): Promise<string[]> {
    // In a real implementation, this would:
    // 1. Get list of all GSI files
    // 2. Compare hashes against known-good version
    // 3. Return files with different hashes

    // For now, return common modification locations
    return [
      'commands/GSI/add-phase.md',
      'commands/GSI/debug.md',
      // ... other files
    ];
  }

  /**
   * Analyze what was modified in a file
   */
  private analyzeModification(content: string): PatchSummary {
    // Detect thinking_phase additions
    if (content.includes('thinking_phase:')) {
      return {
        file: 'unknown',
        type: 'thinking_phase',
        description: 'Added thinking_phase configuration'
      };
    }

    // Detect allowed_tools modifications
    if (content.includes('allowed-tools:')) {
      return {
        file: 'unknown',
        type: 'allowed_tools',
        description: 'Modified allowed-tools list'
      };
    }

    return {
      file: 'unknown',
      type: 'content',
      description: 'Content modifications'
    };
  }

  /**
   * Intelligently merge backup with current version
   */
  private mergeFile(
    backupContent: string,
    currentContent: string,
    patches: PatchSummary[]
  ): MergeResult {
    const conflicts: Conflict[] = [];

    // Parse YAML frontmatter
    const backupFrontmatter = this.parseYAMLFrontmatter(backupContent);
    const currentFrontmatter = this.parseYAMLFrontmatter(currentContent);

    // Merge thinking_phase if present in backup but not in current
    if (backupFrontmatter.thinking_phase && !currentFrontmatter.thinking_phase) {
      currentFrontmatter.thinking_phase = backupFrontmatter.thinking_phase;
    }

    // Check for conflicts
    if (backupFrontmatter.thinking_phase && currentFrontmatter.thinking_phase) {
      // Both have thinking_phase - check if different
      if (JSON.stringify(backupFrontmatter.thinking_phase) !==
          JSON.stringify(currentFrontmatter.thinking_phase)) {
        conflicts.push({
          section: 'thinking_phase',
          userVersion: JSON.stringify(backupFrontmatter.thinking_phase),
          upstreamVersion: JSON.stringify(currentFrontmatter.thinking_phase)
        });
      }
    }

    // Reconstruct file with merged frontmatter
    const mergedContent = this.reconstructFile(currentContent, currentFrontmatter);

    return {
      success: conflicts.length === 0,
      conflicts,
      mergedContent
    };
  }

  /**
   * Parse YAML frontmatter from markdown
   */
  private parseYAMLFrontmatter(content: string): Record<string, any> {
    const match = content.match(/^---\n([\s\S]*?)\n---/);
    if (!match) return {};

    const yaml = match[1];
    const result: Record<string, any> = {};

    // Simple YAML parser for GSI format
    const lines = yaml.split('\n');
    let currentKey = '';
    let currentValue: any = '';
    let inArray = false;
    let arrayValues: string[] = [];

    for (const line of lines) {
      const keyMatch = line.match(/^(\w+):\s*(.*)$/);
      if (keyMatch) {
        if (currentKey && inArray) {
          result[currentKey] = arrayValues;
          arrayValues = [];
          inArray = false;
        }

        currentKey = keyMatch[1];
        currentValue = keyMatch[2];

        if (currentValue === '') {
          inArray = true;
        } else {
          result[currentKey] = currentValue;
        }
      } else if (inArray && line.trim().startsWith('- ')) {
        arrayValues.push(line.trim().substring(2));
      } else if (line.startsWith('  ') && currentKey) {
        // Nested value (e.g., thinking_phase fields)
        const nestedMatch = line.match(/^\s+(\w+):\s*(.*)$/);
        if (nestedMatch) {
          if (typeof result[currentKey] === 'string') {
            result[currentKey] = {};
          }
          result[currentKey][nestedMatch[1]] = nestedMatch[2];
        }
      }
    }

    if (currentKey && inArray) {
      result[currentKey] = arrayValues;
    }

    return result;
  }

  /**
   * Reconstruct file with merged frontmatter
   */
  private reconstructFile(originalContent: string, frontmatter: Record<string, any>): string {
    const contentWithoutFrontmatter = originalContent.replace(/^---\n[\s\S]*?\n---\n?/, '');

    let yamlStr = '---\n';
    for (const [key, value] of Object.entries(frontmatter)) {
      if (typeof value === 'object' && !Array.isArray(value)) {
        // Nested object (e.g., thinking_phase)
        yamlStr += `${key}:\n`;
        for (const [nestedKey, nestedValue] of Object.entries(value)) {
          yamlStr += `  ${nestedKey}: ${nestedValue}\n`;
        }
      } else if (Array.isArray(value)) {
        yamlStr += `${key}:\n`;
        for (const item of value) {
          yamlStr += `  - ${item}\n`;
        }
      } else {
        yamlStr += `${key}: ${value}\n`;
      }
    }
    yamlStr += '---\n';

    return yamlStr + contentWithoutFrontmatter;
  }

  /**
   * Calculate file hash
   */
  private hashFile(content: string): string {
    return createHash('sha256').update(content).digest('hex');
  }

  /**
   * Detect GSI installation directory
   */
  private detectGSIInstallDir(): string {
    // Check for global installation
    const globalPath = join(
      process.env.APPDATA || '',
      'npm',
      'node_modules',
      'get-shit-indexed-cc'
    );
    if (existsSync(globalPath)) {
      return globalPath;
    }

    // Check for local installation
    const localPath = join(process.cwd(), 'node_modules', 'get-shit-indexed-cc');
    if (existsSync(localPath)) {
      return localPath;
    }

    throw new Error('GSI installation not found');
  }

  /**
   * Get current GSI version
   */
  private async getCurrentVersion(): Promise<string> {
    const packageJsonPath = join(this.gsiInstallDir, 'package.json');
    if (existsSync(packageJsonPath)) {
      const packageJson = JSON.parse(readFileSync(packageJsonPath, 'utf-8'));
      return packageJson.version || 'unknown';
    }
    return 'unknown';
  }
}

export default PatchManager;

</document_content>
</document>
<document index="19">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\workflow-modules\pattern-miner.ts</source>
<document_content>
/**
 * GSI Pattern Miner Module
 *
 * Discovers and creates workflow patterns from observed command sequences.
 * Tracks usage, mines patterns, generates templates, and suggests optimizations.
 *
 * Phase 38-03: Enhance workflow-chainer with Pattern Discovery
 */

import { writeFileSync, readFileSync, existsSync, mkdirSync, readdirSync } from 'fs';
import { join, dirname } from 'path';
import type { WorkflowChain, WorkflowStep } from './workflow-chainer.js';

// ─── Types ─────────────────────────────────────────────────────────────────────

export interface CommandExecution {
  command: string;
  args?: string;
  timestamp: string;
  success: boolean;
  duration: number;
  context?: Record<string, any>;
}

export interface CommandSequence {
  id: string;
  commands: CommandExecution[];
  startTime: string;
  endTime: string;
  totalDuration: number;
  successRate: number;
  source: 'manual' | 'workflow' | 'discovered';
  workflowName?: string;
}

export interface DiscoveredPattern {
  id: string;
  name: string;
  description: string;
  sequence: string[];
  frequency: number;
  successRate: number;
  avgDuration: number;
  timeSavings: number;
  qualityScore: number;
  variables: PatternVariable[];
  conditions?: PatternCondition[];
  optimizations?: PatternOptimization[];
  firstSeen: string;
  lastSeen: string;
  sources: string[];
}

export interface PatternVariable {
  name: string;
  type: 'phase' | 'string' | 'number' | 'boolean';
  extraction: string; // Regex or extraction rule
  required: boolean;
  defaultValue?: string;
}

export interface PatternCondition {
  type: 'if_success' | 'if_failure' | 'if_exists' | 'if_equals';
  target: string;
  value?: string;
  then_step?: string;
  else_step?: string;
}

export interface PatternOptimization {
  type: 'parallel' | 'skip' | 'reorder' | 'merge';
  steps: string[];
  reason: string;
  estimatedSavings: number;
}

export interface WorkflowHistory {
  sequences: CommandSequence[];
  executions: CommandExecution[];
  patterns: DiscoveredPattern[];
  stats: HistoryStats;
}

export interface HistoryStats {
  totalExecutions: number;
  totalSequences: number;
  successfulExecutions: number;
  failedExecutions: number;
  avgExecutionTime: number;
  mostUsedCommands: { command: string; count: number }[];
  patternsDiscovered: number;
  templatesGenerated: number;
}

export interface PatternRecommendation {
  pattern: DiscoveredPattern;
  relevanceScore: number;
  reason: string;
  suggestedVariables: Record<string, string>;
}

export interface OptimizationSuggestion {
  type: 'parallel' | 'skip' | 'reorder' | 'merge' | 'checkpoint';
  steps: string[];
  description: string;
  estimatedTimeSavings: number;
  riskLevel: 'low' | 'medium' | 'high';
}

// ─── Pattern Miner Class ───────────────────────────────────────────────────────

export class PatternMiner {
  private historyFile: string;
  private templatesDir: string;
  private history: WorkflowHistory;

  constructor(stateDir: string = '.planning') {
    this.historyFile = join(stateDir, 'workflow-history.json');
    this.templatesDir = join(stateDir, 'workflow-templates', 'discovered');
    this.history = this.loadHistory();
  }

  // ─── Usage Tracking ───────────────────────────────────────────────────────────

  /**
   * Track a command execution
   */
  trackExecution(execution: CommandExecution): void {
    this.history.executions.push(execution);
    this.updateStats();
    this.saveHistory();
  }

  /**
   * Track a command sequence (complete workflow run)
   */
  trackSequence(sequence: CommandSequence): void {
    this.history.sequences.push(sequence);
    this.updateStats();
    this.saveHistory();
  }

  /**
   * Start tracking a new sequence
   */
  startSequence(source: 'manual' | 'workflow' | 'discovered' = 'manual', workflowName?: string): string {
    const id = this.generateId('seq');
    const sequence: CommandSequence = {
      id,
      commands: [],
      startTime: new Date().toISOString(),
      endTime: '',
      totalDuration: 0,
      successRate: 0,
      source,
      workflowName
    };

    // Store temporarily (will be completed later)
    this.history.sequences.push(sequence);
    this.saveHistory();

    return id;
  }

  /**
   * Add command to active sequence
   */
  addToSequence(sequenceId: string, execution: CommandExecution): void {
    const sequence = this.history.sequences.find(s => s.id === sequenceId);
    if (sequence) {
      sequence.commands.push(execution);
      this.saveHistory();
    }
  }

  /**
   * Complete a sequence
   */
  completeSequence(sequenceId: string): CommandSequence | null {
    const sequence = this.history.sequences.find(s => s.id === sequenceId);
    if (!sequence) return null;

    sequence.endTime = new Date().toISOString();
    sequence.totalDuration = sequence.commands.reduce((sum, c) => sum + c.duration, 0);
    sequence.successRate = sequence.commands.filter(c => c.success).length / sequence.commands.length;

    this.updateStats();
    this.saveHistory();

    return sequence;
  }

  // ─── Pattern Mining ───────────────────────────────────────────────────────────

  /**
   * Mine patterns from command history
   */
  minePatterns(options: {
    minFrequency?: number;
    minSuccessRate?: number;
    minLength?: number;
    maxLength?: number;
  } = {}): DiscoveredPattern[] {
    const {
      minFrequency = 2,
      minSuccessRate = 0.5,
      minLength = 2,
      maxLength = 10
    } = options;

    // Extract all command sequences
    const allSequences = this.history.sequences.map(s => s.commands.map(c => c.command));
    const allExecutions = this.extractExecutionPatterns();

    // Combine sequences
    const patterns = this.findFrequentPatterns(
      [...allSequences, ...allExecutions],
      minFrequency,
      minLength,
      maxLength
    );

    // Score and filter patterns
    const scoredPatterns = patterns
      .map(p => this.scorePattern(p))
      .filter(p => p.successRate >= minSuccessRate && p.frequency >= minFrequency);

    // Merge with existing patterns
    for (const pattern of scoredPatterns) {
      const existing = this.history.patterns.find(p => p.id === pattern.id);
      if (existing) {
        existing.frequency += pattern.frequency;
        existing.lastSeen = new Date().toISOString();
      } else {
        this.history.patterns.push(pattern);
      }
    }

    this.updateStats();
    this.saveHistory();

    return scoredPatterns;
  }

  /**
   * Extract execution patterns from individual commands
   */
  private extractExecutionPatterns(): string[][] {
    const patterns: string[][] = [];
    const windowSize = 5;

    // Sliding window over executions to find patterns
    for (let i = 0; i <= this.history.executions.length - windowSize; i++) {
      const window = this.history.executions.slice(i, i + windowSize);
      patterns.push(window.map(e => e.command));
    }

    return patterns;
  }

  /**
   * Find frequent patterns using pattern matching
   */
  private findFrequentPatterns(
    sequences: string[][],
    minFrequency: number,
    minLength: number,
    maxLength: number
  ): DiscoveredPattern[] {
    const patternCounts = new Map<string, { count: number; sequences: number[][]; durations: number[]; successes: number[] }>();

    // Find all subsequences
    for (let seqIdx = 0; seqIdx < sequences.length; seqIdx++) {
      const seq = sequences[seqIdx];

      for (let start = 0; start < seq.length; start++) {
        for (let len = minLength; len <= Math.min(maxLength, seq.length - start); len++) {
          const subseq = seq.slice(start, start + len);
          const key = subseq.join(' -> ');

          if (!patternCounts.has(key)) {
            patternCounts.set(key, { count: 0, sequences: [], durations: [], successes: [] });
          }

          const entry = patternCounts.get(key)!;
          entry.count++;
          entry.sequences.push([seqIdx, start, start + len]);

          // Get timing data if available
          const sequence = this.history.sequences[seqIdx];
          if (sequence && sequence.commands.length >= start + len) {
            const duration = sequence.commands
              .slice(start, start + len)
              .reduce((sum, c) => sum + c.duration, 0);
            entry.durations.push(duration);

            const successCount = sequence.commands
              .slice(start, start + len)
              .filter(c => c.success).length;
            entry.successes.push(successCount / len);
          }
        }
      }
    }

    // Convert to DiscoveredPattern objects
    const patterns: DiscoveredPattern[] = [];

    for (const [key, data] of patternCounts) {
      if (data.count >= minFrequency) {
        const commands = key.split(' -> ');

        patterns.push({
          id: this.generatePatternId(commands),
          name: this.generatePatternName(commands),
          description: `Discovered pattern: ${commands.slice(0, 3).join(' -> ')}${commands.length > 3 ? '...' : ''}`,
          sequence: commands,
          frequency: data.count,
          successRate: data.successes.length > 0
            ? data.successes.reduce((a, b) => a + b, 0) / data.successes.length
            : 1,
          avgDuration: data.durations.length > 0
            ? data.durations.reduce((a, b) => a + b, 0) / data.durations.length
            : 0,
          timeSavings: 0, // Calculated during scoring
          qualityScore: 0, // Calculated during scoring
          variables: this.extractVariables(commands),
          firstSeen: new Date().toISOString(),
          lastSeen: new Date().toISOString(),
          sources: ['history']
        });
      }
    }

    return patterns;
  }

  /**
   * Extract variables from command sequence
   */
  private extractVariables(commands: string[]): PatternVariable[] {
    const variables: PatternVariable[] = [];
    const seenVars = new Set<string>();

    for (const cmd of commands) {
      // Extract phase numbers
      const phaseMatches = cmd.matchAll(/(\d+(?:\.\d+)?)/g);
      for (const match of phaseMatches) {
        if (!seenVars.has('phase')) {
          variables.push({
            name: 'phase',
            type: 'phase',
            extraction: '(\\d+(?:\\.\\d+)?)',
            required: true
          });
          seenVars.add('phase');
        }
      }

      // Extract quoted strings as potential name variables
      const nameMatches = cmd.matchAll(/"([^"]+)"/g);
      for (const match of nameMatches) {
        if (!seenVars.has('name')) {
          variables.push({
            name: 'name',
            type: 'string',
            extraction: '"([^"]+)"',
            required: false,
            defaultValue: 'unnamed'
          });
          seenVars.add('name');
        }
      }
    }

    return variables;
  }

  /**
   * Score a pattern based on multiple factors
   */
  private scorePattern(pattern: DiscoveredPattern): DiscoveredPattern {
    // Calculate time savings (compare to average individual execution)
    const individualAvg = this.getCommandAvgDuration(pattern.sequence[0]) || pattern.avgDuration / pattern.sequence.length;
    const sequentialTime = individualAvg * pattern.sequence.length;
    const timeSavings = Math.max(0, sequentialTime - pattern.avgDuration);

    // Calculate quality score
    const frequencyScore = Math.min(pattern.frequency / 10, 1) * 25; // 0-25 points
    const successScore = pattern.successRate * 35; // 0-35 points
    const savingsScore = Math.min(timeSavings / 60000, 1) * 25; // 0-25 points (1min max)
    const lengthScore = Math.min(pattern.sequence.length / 5, 1) * 15; // 0-15 points (5 steps max)

    pattern.timeSavings = timeSavings;
    pattern.qualityScore = frequencyScore + successScore + savingsScore + lengthScore;

    return pattern;
  }

  /**
   * Get average duration for a command
   */
  private getCommandAvgDuration(command: string): number | null {
    const executions = this.history.executions.filter(e => e.command === command);
    if (executions.length === 0) return null;
    return executions.reduce((sum, e) => sum + e.duration, 0) / executions.length;
  }

  // ─── Template Generation ──────────────────────────────────────────────────────

  /**
   * Generate a workflow template from a pattern
   */
  generateTemplate(patternId: string): WorkflowChain | null {
    const pattern = this.history.patterns.find(p => p.id === patternId);
    if (!pattern) return null;

    // Convert pattern sequence to workflow steps
    const chain: WorkflowStep[] = pattern.sequence.map((cmd, idx) => {
      const step: WorkflowStep = {
        command: cmd,
        checkpoint: idx === 0 || idx === pattern.sequence.length - 1
      };

      // Add args with variable substitution
      const vars = this.extractVariablesFromCommand(cmd, pattern.variables);
      if (Object.keys(vars).length > 0) {
        step.args = this.createVariableArgs(cmd, pattern.variables);
      }

      return step;
    });

    // Determine checkpoint strategy based on pattern
    const checkpoint: 'after-each' | 'after-phase' | 'before-execute' | 'manual' =
      pattern.sequence.some(cmd => cmd.includes('execute')) ? 'before-execute' :
      pattern.sequence.some(cmd => cmd.includes('phase')) ? 'after-phase' : 'after-each';

    // Determine if rollback should be enabled
    const rollback = pattern.successRate > 0.8;

    const template: WorkflowChain = {
      name: pattern.name,
      description: pattern.description,
      chain,
      checkpoint,
      rollback,
      metadata: {
        pattern_id: pattern.id,
        frequency: pattern.frequency,
        success_rate: pattern.successRate,
        quality_score: pattern.qualityScore,
        discovered_at: pattern.firstSeen,
        auto_generated: true
      }
    };

    // Add optimizations if available
    if (pattern.optimizations && pattern.optimizations.length > 0) {
      template.parallel = this.convertOptimizationsToParallel(pattern.optimizations);
    }

    return template;
  }

  /**
   * Extract variables from a command string
   */
  private extractVariablesFromCommand(cmd: string, variables: PatternVariable[]): Record<string, string> {
    const result: Record<string, string> = {};

    for (const v of variables) {
      const regex = new RegExp(v.extraction);
      const match = cmd.match(regex);
      if (match) {
        result[v.name] = match[1];
      }
    }

    return result;
  }

  /**
   * Create args string with variable placeholders
   */
  private createVariableArgs(cmd: string, variables: PatternVariable[]): string {
    let result = cmd;

    for (const v of variables) {
      const regex = new RegExp(v.extraction, 'g');
      result = result.replace(regex, `\${${v.name}}`);
    }

    // Remove the command prefix, keep only args
    const parts = result.split(' ');
    if (parts.length > 1) {
      return parts.slice(1).join(' ');
    }

    return '';
  }

  /**
   * Convert optimizations to parallel groups
   */
  private convertOptimizationsToParallel(optimizations: PatternOptimization[]): any[] {
    return optimizations
      .filter(o => o.type === 'parallel')
      .map(o => ({
        name: `parallel-${o.steps.join('-')}`,
        steps: o.steps.map(s => ({ command: s }))
      }));
  }

  /**
   * Save template to discovered templates directory
   */
  saveTemplate(template: WorkflowChain): string {
    if (!existsSync(this.templatesDir)) {
      mkdirSync(this.templatesDir, { recursive: true });
    }

    const filePath = join(this.templatesDir, `${template.name}.json`);
    writeFileSync(filePath, JSON.stringify(template, null, 2));

    return filePath;
  }

  /**
   * Generate and save all high-quality patterns as templates
   */
  generateAllTemplates(minQualityScore: number = 50): string[] {
    const templates: string[] = [];

    for (const pattern of this.history.patterns) {
      if (pattern.qualityScore >= minQualityScore) {
        const template = this.generateTemplate(pattern.id);
        if (template) {
          const path = this.saveTemplate(template);
          templates.push(path);
        }
      }
    }

    return templates;
  }

  // ─── Pattern Scoring & Recommendations ────────────────────────────────────────

  /**
   * Get pattern recommendations based on current context
   */
  getRecommendations(context: {
    currentPhase?: string;
    recentCommands?: string[];
    workflowGoal?: string;
  }): PatternRecommendation[] {
    const recommendations: PatternRecommendation[] = [];

    for (const pattern of this.history.patterns) {
      const relevanceScore = this.calculateRelevance(pattern, context);

      if (relevanceScore > 0.3) {
        recommendations.push({
          pattern,
          relevanceScore,
          reason: this.getRecommendationReason(pattern, context),
          suggestedVariables: this.suggestVariables(pattern, context)
        });
      }
    }

    // Sort by relevance
    recommendations.sort((a, b) => b.relevanceScore - a.relevanceScore);

    return recommendations.slice(0, 5);
  }

  /**
   * Calculate relevance score for a pattern
   */
  private calculateRelevance(pattern: DiscoveredPattern, context: {
    currentPhase?: string;
    recentCommands?: string[];
    workflowGoal?: string;
  }): number {
    let score = 0;

    // Check if recent commands match pattern start
    if (context.recentCommands && context.recentCommands.length > 0) {
      const lastCmd = context.recentCommands[context.recentCommands.length - 1];
      const patternIdx = pattern.sequence.indexOf(lastCmd);
      if (patternIdx >= 0 && patternIdx < pattern.sequence.length - 1) {
        score += 0.4;
      }
    }

    // Check phase relevance
    if (context.currentPhase) {
      const hasPhase = pattern.sequence.some(cmd =>
        cmd.includes('phase') || cmd.includes(context.currentPhase!)
      );
      if (hasPhase) {
        score += 0.3;
      }
    }

    // Factor in quality score
    score += (pattern.qualityScore / 100) * 0.3;

    return Math.min(score, 1);
  }

  /**
   * Get human-readable recommendation reason
   */
  private getRecommendationReason(pattern: DiscoveredPattern, context: {
    currentPhase?: string;
    recentCommands?: string[];
    workflowGoal?: string;
  }): string {
    if (context.recentCommands && context.recentCommands.length > 0) {
      const lastCmd = context.recentCommands[context.recentCommands.length - 1];
      const patternIdx = pattern.sequence.indexOf(lastCmd);
      if (patternIdx >= 0 && patternIdx < pattern.sequence.length - 1) {
        return `Continues from ${lastCmd} with ${pattern.sequence.slice(patternIdx + 1).join(' -> ')}`;
      }
    }

    if (context.currentPhase && pattern.sequence.some(cmd => cmd.includes('phase'))) {
      return `Frequently used pattern for phase operations (${pattern.frequency} times)`;
    }

    return `High-quality pattern with ${(pattern.successRate * 100).toFixed(0)}% success rate`;
  }

  /**
   * Suggest variable values for a pattern
   */
  private suggestVariables(pattern: DiscoveredPattern, context: {
    currentPhase?: string;
    recentCommands?: string[];
    workflowGoal?: string;
  }): Record<string, string> {
    const vars: Record<string, string> = {};

    for (const v of pattern.variables) {
      if (v.type === 'phase' && context.currentPhase) {
        vars[v.name] = context.currentPhase;
      } else if (v.defaultValue) {
        vars[v.name] = v.defaultValue;
      }
    }

    return vars;
  }

  // ─── Optimization Engine ──────────────────────────────────────────────────────

  /**
   * Analyze a workflow for optimization opportunities
   */
  analyzeOptimizations(workflowName: string): OptimizationSuggestion[] {
    const suggestions: OptimizationSuggestion[] = [];

    // Find workflow in sequences
    const sequences = this.history.sequences.filter(s => s.workflowName === workflowName);
    if (sequences.length === 0) return [];

    // Analyze each sequence
    for (const seq of sequences) {
      // Find parallel opportunities
      const parallelOpts = this.findParallelOpportunities(seq);
      suggestions.push(...parallelOpts);

      // Find redundant steps
      const skipOpts = this.findSkipOpportunities(seq);
      suggestions.push(...skipOpts);

      // Find reorder opportunities
      const reorderOpts = this.findReorderOpportunities(seq);
      suggestions.push(...reorderOpts);

      // Find merge opportunities
      const mergeOpts = this.findMergeOpportunities(seq);
      suggestions.push(...mergeOpts);
    }

    // Deduplicate and sort by estimated savings
    const unique = this.deduplicateSuggestions(suggestions);
    unique.sort((a, b) => b.estimatedTimeSavings - a.estimatedTimeSavings);

    return unique;
  }

  /**
   * Find opportunities for parallel execution
   */
  private findParallelOpportunities(seq: CommandSequence): OptimizationSuggestion[] {
    const suggestions: OptimizationSuggestion[] = [];

    for (let i = 0; i < seq.commands.length - 1; i++) {
      for (let j = i + 2; j < seq.commands.length; j++) {
        const cmd1 = seq.commands[i];
        const cmd2 = seq.commands[j];

        // Check if commands are independent (no data dependency)
        if (this.areIndependent(cmd1, cmd2)) {
          const timeSavings = Math.min(cmd1.duration, cmd2.duration);

          if (timeSavings > 1000) { // Only suggest if saves > 1 second
            suggestions.push({
              type: 'parallel',
              steps: [cmd1.command, cmd2.command],
              description: `${cmd1.command} and ${cmd2.command} can run in parallel`,
              estimatedTimeSavings: timeSavings,
              riskLevel: 'low'
            });
          }
        }
      }
    }

    return suggestions;
  }

  /**
   * Find steps that can be skipped
   */
  private findSkipOpportunities(seq: CommandSequence): OptimizationSuggestion[] {
    const suggestions: OptimizationSuggestion[] = [];

    // Find duplicate commands
    const seen = new Map<string, number>();

    for (let i = 0; i < seq.commands.length; i++) {
      const cmd = seq.commands[i];

      if (seen.has(cmd.command)) {
        const prevIdx = seen.get(cmd.command)!;
        suggestions.push({
          type: 'skip',
          steps: [cmd.command],
          description: `${cmd.command} is redundant (already executed at step ${prevIdx + 1})`,
          estimatedTimeSavings: cmd.duration,
          riskLevel: 'medium'
        });
      } else {
        seen.set(cmd.command, i);
      }
    }

    return suggestions;
  }

  /**
   * Find opportunities to reorder steps for efficiency
   */
  private findReorderOpportunities(seq: CommandSequence): OptimizationSuggestion[] {
    const suggestions: OptimizationSuggestion[] = [];

    // Look for quick commands that are delayed behind slow ones
    for (let i = 0; i < seq.commands.length - 1; i++) {
      const current = seq.commands[i];
      const next = seq.commands[i + 1];

      // If current is slow and next is fast, and they're independent
      if (current.duration > next.duration * 2 && this.areIndependent(current, next)) {
        suggestions.push({
          type: 'reorder',
          steps: [current.command, next.command],
          description: `Move fast step ${next.command} before slow step ${current.command}`,
          estimatedTimeSavings: (current.duration - next.duration) * 0.1, // Estimated overlap
          riskLevel: 'medium'
        });
      }
    }

    return suggestions;
  }

  /**
   * Find opportunities to merge similar commands
   */
  private findMergeOpportunities(seq: CommandSequence): OptimizationSuggestion[] {
    const suggestions: OptimizationSuggestion[] = [];

    // Find consecutive similar commands
    for (let i = 0; i < seq.commands.length - 1; i++) {
      const current = seq.commands[i];
      const next = seq.commands[i + 1];

      if (this.areMergeable(current, next)) {
        suggestions.push({
          type: 'merge',
          steps: [current.command, next.command],
          description: `${current.command} and ${next.command} could be merged into a single operation`,
          estimatedTimeSavings: (current.duration + next.duration) * 0.2, // 20% savings from merge
          riskLevel: 'high'
        });
      }
    }

    return suggestions;
  }

  /**
   * Check if two commands are independent (can run in parallel)
   */
  private areIndependent(cmd1: CommandExecution, cmd2: CommandExecution): boolean {
    // Commands that read vs write to different resources
    const readOnlyCommands = ['check', 'list', 'status', 'verify', 'progress', 'get'];
    const writeCommands = ['create', 'update', 'delete', 'execute', 'commit', 'complete'];

    const cmd1IsRead = readOnlyCommands.some(c => cmd1.command.includes(c));
    const cmd2IsRead = readOnlyCommands.some(c => cmd2.command.includes(c));

    // Both read-only commands are independent
    if (cmd1IsRead && cmd2IsRead) return true;

    // Commands on different phases are independent
    const phase1 = cmd1.args?.match(/(\d+(?:\.\d+)?)/)?.[1];
    const phase2 = cmd2.args?.match(/(\d+(?:\.\d+)?)/)?.[1];

    if (phase1 && phase2 && phase1 !== phase2) return true;

    return false;
  }

  /**
   * Check if two commands can be merged
   */
  private areMergeable(cmd1: CommandExecution, cmd2: CommandExecution): boolean {
    // Same command base with different args
    const base1 = cmd1.command.split(' ').slice(0, 2).join(' ');
    const base2 = cmd2.command.split(' ').slice(0, 2).join(' ');

    return base1 === base2 && cmd1.command !== cmd2.command;
  }

  /**
   * Deduplicate optimization suggestions
   */
  private deduplicateSuggestions(suggestions: OptimizationSuggestion[]): OptimizationSuggestion[] {
    const seen = new Set<string>();
    return suggestions.filter(s => {
      const key = `${s.type}:${s.steps.join(',')}`;
      if (seen.has(key)) return false;
      seen.add(key);
      return true;
    });
  }

  // ─── Analysis & Reporting ─────────────────────────────────────────────────────

  /**
   * Analyze all workflows and patterns
   */
  analyzeWorkflows(): {
    patterns: DiscoveredPattern[];
    topPatterns: DiscoveredPattern[];
    optimizationOpportunities: number;
    recommendations: PatternRecommendation[];
  } {
    // Get top patterns by quality score
    const topPatterns = [...this.history.patterns]
      .sort((a, b) => b.qualityScore - a.qualityScore)
      .slice(0, 10);

    // Count optimization opportunities
    const workflowNames = new Set(
      this.history.sequences
        .filter(s => s.workflowName)
        .map(s => s.workflowName!)
    );

    let optimizationOpportunities = 0;
    for (const name of workflowNames) {
      optimizationOpportunities += this.analyzeOptimizations(name).length;
    }

    // Get general recommendations
    const recommendations = this.getRecommendations({});

    return {
      patterns: this.history.patterns,
      topPatterns,
      optimizationOpportunities,
      recommendations
    };
  }

  /**
   * Get usage statistics
   */
  getStats(): HistoryStats {
    return this.history.stats;
  }

  /**
   * Get all patterns
   */
  getPatterns(): DiscoveredPattern[] {
    return this.history.patterns;
  }

  /**
   * Get pattern by ID
   */
  getPattern(patternId: string): DiscoveredPattern | null {
    return this.history.patterns.find(p => p.id === patternId) || null;
  }

  // ─── Persistence ──────────────────────────────────────────────────────────────

  /**
   * Update statistics
   */
  private updateStats(): void {
    const stats = this.history.stats;

    stats.totalExecutions = this.history.executions.length;
    stats.totalSequences = this.history.sequences.length;
    stats.successfulExecutions = this.history.executions.filter(e => e.success).length;
    stats.failedExecutions = this.history.executions.filter(e => !e.success).length;
    stats.patternsDiscovered = this.history.patterns.length;

    // Calculate average execution time
    if (this.history.executions.length > 0) {
      stats.avgExecutionTime = this.history.executions.reduce((sum, e) => sum + e.duration, 0) / this.history.executions.length;
    }

    // Find most used commands
    const commandCounts = new Map<string, number>();
    for (const e of this.history.executions) {
      commandCounts.set(e.command, (commandCounts.get(e.command) || 0) + 1);
    }

    stats.mostUsedCommands = Array.from(commandCounts.entries())
      .map(([command, count]) => ({ command, count }))
      .sort((a, b) => b.count - a.count)
      .slice(0, 10);
  }

  /**
   * Load history from file
   */
  private loadHistory(): WorkflowHistory {
    if (!existsSync(this.historyFile)) {
      return {
        sequences: [],
        executions: [],
        patterns: [],
        stats: {
          totalExecutions: 0,
          totalSequences: 0,
          successfulExecutions: 0,
          failedExecutions: 0,
          avgExecutionTime: 0,
          mostUsedCommands: [],
          patternsDiscovered: 0,
          templatesGenerated: 0
        }
      };
    }

    try {
      return JSON.parse(readFileSync(this.historyFile, 'utf-8'));
    } catch {
      return {
        sequences: [],
        executions: [],
        patterns: [],
        stats: {
          totalExecutions: 0,
          totalSequences: 0,
          successfulExecutions: 0,
          failedExecutions: 0,
          avgExecutionTime: 0,
          mostUsedCommands: [],
          patternsDiscovered: 0,
          templatesGenerated: 0
        }
      };
    }
  }

  /**
   * Save history to file
   */
  private saveHistory(): void {
    const dir = dirname(this.historyFile);
    if (!existsSync(dir)) {
      mkdirSync(dir, { recursive: true });
    }
    writeFileSync(this.historyFile, JSON.stringify(this.history, null, 2));
  }

  // ─── Utility Methods ──────────────────────────────────────────────────────────

  /**
   * Generate unique ID
   */
  private generateId(prefix: string): string {
    return `${prefix}-${Date.now()}-${Math.random().toString(36).substring(2, 9)}`;
  }

  /**
   * Generate pattern ID from command sequence
   */
  private generatePatternId(commands: string[]): string {
    const hash = commands.reduce((acc, cmd) => {
      for (let i = 0; i < cmd.length; i++) {
        acc = ((acc << 5) - acc + cmd.charCodeAt(i)) | 0;
      }
      return acc;
    }, 0);

    return `pattern-${Math.abs(hash).toString(16)}`;
  }

  /**
   * Generate pattern name from commands
   */
  private generatePatternName(commands: string[]): string {
    const verbs = commands.map(cmd => {
      const parts = cmd.split(/[ :]/);
      return parts[parts.length - 1] || parts[0];
    });

    if (verbs.length <= 3) {
      return verbs.join('-');
    }

    return `${verbs[0]}-${verbs.length}-step`;
  }

  /**
   * Export pattern as template JSON
   */
  exportPattern(patternId: string): string | null {
    const pattern = this.getPattern(patternId);
    if (!pattern) return null;

    const template = this.generateTemplate(patternId);
    if (!template) return null;

    return JSON.stringify(template, null, 2);
  }
}

export default PatternMiner;

</document_content>
</document>
<document index="20">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\workflow-modules\thinking-orchestrator.ts</source>
<document_content>
/**
 * Thinking Orchestrator Module
 *
 * Coordinates MCP thinking servers (Sequential, Tractatus, Debug) based on
 * thinking_phase configurations in GSI commands.
 *
 * Extracted from: v1.18.0 → v1.23.0 patch analysis (28 commands with thinking configs)
 *
 * Enhanced: v1.24.0 - Added expanded complexity algorithm (25 factors)
 * - Tool combination analysis
 * - Workflow step analysis
 * - Error handling complexity
 * - MCP server dependency analysis
 */

export type ThinkingMode = 'NONE' | 'LIGHTWEIGHT' | 'STANDARD' | 'COMPREHENSIVE';
export type ThinkingServer = 'sequential' | 'tractatus' | 'debug';

export interface ThinkingPhaseConfig {
  mode: ThinkingMode;
  servers: ThinkingServer[];
  bmad_enabled: boolean;
  timeout: number;
  rationale: string;
}

export interface ThinkingContext {
  command: string;
  description: string;
  objective?: string;
  process?: string;
  additionalContext?: Record<string, any>;
}

export interface ComplexityFactor {
  name: string;
  score: number;
  description?: string;
}

export interface ComplexityAnalysis {
  totalScore: number;
  mode: ThinkingMode;
  factors: ComplexityFactor[];
  breakdown: Record<string, number>;
}

export interface ThinkingResult {
  server: ThinkingServer;
  thoughts: ThinkingThought[];
  duration: number;
  success: boolean;
  error?: string;
}

export interface ThinkingThought {
  thoughtNumber: number;
  totalThoughts: number;
  thought: string;
  nextThoughtNeeded: boolean;
  isRevision?: boolean;
  revisesThought?: number;
  branchFromThought?: number;
  branchId?: string;
  needsMoreThoughts?: boolean;
}

/**
 * Orchestrates thinking servers for GSI commands
 */
export class ThinkingOrchestrator {
  private serverEndpoints: Record<ThinkingServer, string>;

  constructor() {
    this.serverEndpoints = {
      sequential: 'mcp__sequential-thinking__sequentialthinking',
      tractatus: 'mcp__tractatusthinking__tractatus_thinking',
      debug: 'mcp__debug-thinking__debug_thinking'
    };
  }

  /**
   * Execute thinking phase for a command
   */
  async think(
    config: ThinkingPhaseConfig,
    context: ThinkingContext
  ): Promise<Map<ThinkingServer, ThinkingResult>> {
    const results = new Map<ThinkingServer, ThinkingResult>();

    // Skip if mode is NONE
    if (config.mode === 'NONE') {
      return results;
    }

    // Execute each configured server
    for (const server of config.servers) {
      const startTime = Date.now();

      try {
        const thoughts = await this.executeServer(server, config, context);
        const duration = Date.now() - startTime;

        results.set(server, {
          server,
          thoughts,
          duration,
          success: true
        });
      } catch (error) {
        const duration = Date.now() - startTime;
        results.set(server, {
          server,
          thoughts: [],
          duration,
          success: false,
          error: error instanceof Error ? error.message : 'Unknown error'
        });
      }
    }

    return results;
  }

  /**
   * Execute a specific thinking server
   */
  private async executeServer(
    server: ThinkingServer,
    config: ThinkingPhaseConfig,
    context: ThinkingContext
  ): Promise<ThinkingThought[]> {
    const prompt = this.buildPrompt(server, config, context);

    // In a real implementation, this would call the MCP server
    // For now, we simulate the thinking process

    const thoughts: ThinkingThought[] = [];
    const maxThoughts = this.getMaxThoughts(config.mode);

    for (let i = 1; i <= maxThoughts; i++) {
      const thought = await this.generateThought(server, i, maxThoughts, prompt, thoughts);
      thoughts.push(thought);

      if (!thought.nextThoughtNeeded) {
        break;
      }
    }

    return thoughts;
  }

  /**
   * Build prompt for thinking server
   */
  private buildPrompt(
    server: ThinkingServer,
    config: ThinkingPhaseConfig,
    context: ThinkingContext
  ): string {
    let prompt = `Command: ${context.command}\n`;
    prompt += `Description: ${context.description}\n`;

    if (context.objective) {
      prompt += `Objective: ${context.objective}\n`;
    }

    if (context.process) {
      prompt += `Process: ${context.process}\n`;
    }

    prompt += `\nThinking Mode: ${config.mode}\n`;
    prompt += `BMAD Enabled: ${config.bmad_enabled}\n`;
    prompt += `Rationale: ${config.rationale}\n`;

    // Add server-specific context
    switch (server) {
      case 'sequential':
        prompt += `\nFocus on: Sequential step planning and execution order\n`;
        break;
      case 'tractatus':
        prompt += `\nFocus on: Structural analysis, relationships, and logical dependencies\n`;
        break;
      case 'debug':
        prompt += `\nFocus on: Problem detection, hypothesis generation, and solution verification\n`;
        break;
    }

    return prompt;
  }

  /**
   * Generate a single thought
   */
  private async generateThought(
    server: ThinkingServer,
    thoughtNumber: number,
    totalThoughts: number,
    prompt: string,
    previousThoughts: ThinkingThought[]
  ): Promise<ThinkingThought> {
    // In a real implementation, this would call the MCP server
    // For simulation, we generate placeholder thoughts

    const nextThoughtNeeded = thoughtNumber < totalThoughts;

    return {
      thoughtNumber,
      totalThoughts,
      thought: `[${server}] Thought ${thoughtNumber}/${totalThoughts} for: ${prompt.substring(0, 50)}...`,
      nextThoughtNeeded
    };
  }

  /**
   * Get max thoughts based on mode
   */
  private getMaxThoughts(mode: ThinkingMode): number {
    switch (mode) {
      case 'LIGHTWEIGHT':
        return 3;
      case 'STANDARD':
        return 5;
      case 'COMPREHENSIVE':
        return 10;
      default:
        return 0;
    }
  }

  /**
   * Analyze command and recommend thinking config
   */
  analyzeCommand(command: {
    description: string;
    allowedTools?: string[];
    process?: string;
    objective?: string;
  }): ThinkingPhaseConfig {
    const analysis = this.analyzeComplexity(command);
    const mode = analysis.mode;
    const servers = this.selectServers(command, analysis.totalScore);
    const timeout = this.calculateTimeout(mode, command.allowedTools?.length || 0);
    const rationale = this.generateRationale(command, mode, servers);

    return {
      mode,
      servers,
      bmad_enabled: mode === 'STANDARD' || mode === 'COMPREHENSIVE',
      timeout,
      rationale
    };
  }

  /**
   * Generate thinking_phase frontmatter for a command file
   */
  generateFrontmatter(config: ThinkingPhaseConfig): string {
    const lines = [
      'thinking_phase:',
      `  mode: ${config.mode}`,
      `  servers:`,
      ...config.servers.map(s => `    - ${s}`),
      `  bmad_enabled: ${config.bmad_enabled}`,
      `  timeout: ${config.timeout}`,
      `  rationale: "${config.rationale}"`
    ];
    return lines.join('\n');
  }

  /**
   * Validate a thinking_phase configuration
   */
  validateConfig(config: ThinkingPhaseConfig): { valid: boolean; errors: string[]; warnings: string[] } {
    const errors: string[] = [];
    const warnings: string[] = [];

    // Validate mode
    const validModes: ThinkingMode[] = ['NONE', 'LIGHTWEIGHT', 'STANDARD', 'COMPREHENSIVE'];
    if (!validModes.includes(config.mode)) {
      errors.push(`Invalid mode: ${config.mode}. Must be one of: ${validModes.join(', ')}`);
    }

    // Validate servers
    const validServers: ThinkingServer[] = ['sequential', 'tractatus', 'debug'];
    for (const server of config.servers) {
      if (!validServers.includes(server)) {
        errors.push(`Invalid server: ${server}. Must be one of: ${validServers.join(', ')}`);
      }
    }

    // Validate server/mode consistency
    if (config.mode === 'NONE' && config.servers.length > 0) {
      warnings.push('Mode is NONE but servers are specified. Servers will be ignored.');
    }
    if (config.mode !== 'NONE' && !config.servers.includes('sequential')) {
      warnings.push('Sequential server is recommended for all non-NONE modes.');
    }

    // Validate timeout
    if (config.timeout < 0) {
      errors.push(`Timeout cannot be negative: ${config.timeout}`);
    }
    if (config.timeout > 15000) {
      warnings.push(`Timeout exceeds 15 seconds: ${config.timeout}ms. This may cause delays.`);
    }

    // Validate timeout/mode consistency
    const expectedTimeouts = { NONE: 0, LIGHTWEIGHT: 2000, STANDARD: 5000, COMPREHENSIVE: 9000 };
    const baseExpected = expectedTimeouts[config.mode];
    if (config.timeout > 0 && config.timeout < baseExpected * 0.5) {
      warnings.push(`Timeout seems low for ${config.mode} mode: ${config.timeout}ms (expected ~${baseExpected}ms)`);
    }

    // Validate bmad_enabled/mode consistency
    if (config.mode === 'NONE' && config.bmad_enabled) {
      warnings.push('BMAD is enabled but mode is NONE. BMAD will have no effect.');
    }
    if (config.mode === 'LIGHTWEIGHT' && config.bmad_enabled) {
      warnings.push('BMAD is typically not used with LIGHTWEIGHT mode.');
    }

    return {
      valid: errors.length === 0,
      errors,
      warnings
    };
  }

  /**
   * Get complexity factor descriptions for documentation
   */
  getComplexityFactorDescriptions(): Record<string, { category: string; description: string; range: string }> {
    return {
      // Tool-based factors
      tool_count: { category: 'Tool-Based', description: 'Number of allowed tools', range: '0-15+' },
      execution_tools: { category: 'Tool-Based', description: 'Tools for executing commands', range: '0-6' },
      delegation: { category: 'Tool-Based', description: 'Task/subagent delegation tools', range: '0-3' },
      web_integration: { category: 'Tool-Based', description: 'Web/API integration tools', range: '0-6' },
      file_modification: { category: 'Tool-Based', description: 'File modification tools', range: '0-5' },
      code_analysis: { category: 'Tool-Based', description: 'Code analysis/indexing tools', range: '0-3' },
      tool_combination: { category: 'Tool-Based', description: 'Multiple tool categories combined', range: '0-5' },
      mcp_dependency: { category: 'Tool-Based', description: 'MCP server dependencies beyond 3', range: '0-3' },
      dc_comprehensive: { category: 'Tool-Based', description: 'Comprehensive Desktop Commander usage', range: '0-2' },
      parallel_potential: { category: 'Tool-Based', description: 'High parallel execution potential', range: '0-2' },
      
      // Keyword-based factors
      debug_keywords: { category: 'Keyword-Based', description: 'Debug/troubleshoot operation', range: '0-4' },
      analysis_keywords: { category: 'Keyword-Based', description: 'Analysis/research operation', range: '0-3' },
      planning_keywords: { category: 'Keyword-Based', description: 'Planning/design operation', range: '0-3' },
      integration_keywords: { category: 'Keyword-Based', description: 'Integration/migration operation', range: '0-3' },
      verification_keywords: { category: 'Keyword-Based', description: 'Verification/testing operation', range: '0-2' },
      simplicity_keywords: { category: 'Keyword-Based', description: 'Simple/quick operation (negative)', range: '-3-0' },
      critical_keywords: { category: 'Keyword-Based', description: 'Critical/urgent operation', range: '0-3' },
      multi_component: { category: 'Keyword-Based', description: 'Multi-component operation', range: '0-2' },
      
      // Workflow factors
      workflow_steps: { category: 'Workflow', description: 'Number of workflow steps', range: '0-5' },
      workflow_branching: { category: 'Workflow', description: 'Branching/conditional points', range: '0-3' },
      workflow_checkpoints: { category: 'Workflow', description: 'Checkpoint/pause points', range: '0-2' },
      workflow_parallel: { category: 'Workflow', description: 'Parallel execution in workflow', range: '0-2' },
      
      // Error handling factors
      error_recovery: { category: 'Error Handling', description: 'Error handling points', range: '0-3' },
      validation_gates: { category: 'Error Handling', description: 'Validation gates', range: '0-2' },
      rollback_capability: { category: 'Error Handling', description: 'Rollback capability', range: '0-2' }
    };
  }

  /**
   * Get mode thresholds for documentation
   */
  getModeThresholds(): Record<ThinkingMode, { min: number; max: number; description: string }> {
    return {
      NONE: { min: 0, max: 2, description: 'Simple display commands, status checks' },
      LIGHTWEIGHT: { min: 3, max: 6, description: 'Quick operations, single-step modifications' },
      STANDARD: { min: 7, max: 12, description: 'Planning operations, multi-step workflows' },
      COMPREHENSIVE: { min: 13, max: 100, description: 'Complex debugging, architecture design' }
    };
  }

  /**
   * Calculate complexity score for a command (Enhanced with 25 factors)
   * 
   * Factor Categories:
   * 1. Tool-based factors (10): Count, combinations, execution, delegation
   * 2. Keyword-based factors (8): Debug, analysis, planning, simplicity
   * 3. Workflow factors (4): Steps, branching, checkpoints, parallelism
   * 4. Error handling factors (3): Recovery, validation, rollback
   */
  private calculateComplexity(command: {
    description: string;
    allowedTools?: string[];
    process?: string;
    objective?: string;
  }): number {
    const analysis = this.analyzeComplexity(command);
    return analysis.totalScore;
  }

  /**
   * Full complexity analysis with factor breakdown
   */
  analyzeComplexity(command: {
    description: string;
    allowedTools?: string[];
    process?: string;
    objective?: string;
  }): ComplexityAnalysis {
    const factors: ComplexityFactor[] = [];
    const breakdown: Record<string, number> = {};
    const desc = command.description.toLowerCase();
    const objective = (command.objective || '').toLowerCase();
    const combined = `${desc} ${objective}`;

    // ═══════════════════════════════════════════════════════════════
    // CATEGORY 1: TOOL-BASED FACTORS (10 factors)
    // ═══════════════════════════════════════════════════════════════

    // Factor 1: Tool count (base)
    const toolCount = command.allowedTools?.length || 0;
    if (toolCount > 0) {
      factors.push({ name: 'tool_count', score: toolCount, description: `${toolCount} tools` });
      breakdown.tools = toolCount;
    }

    // Factor 2: Execution tools (Bash, start_process)
    const execTools = command.allowedTools?.filter(t => 
      t.includes('process') || t.includes('execute') || t.includes('Bash') || t.includes('start_process')
    ) || [];
    if (execTools.length > 0) {
      const score = execTools.length * 2;
      factors.push({ name: 'execution_tools', score, description: `${execTools.length} execution tools` });
      breakdown.execution = score;
    }

    // Factor 3: Task/delegation tools
    const hasTaskTool = command.allowedTools?.some(t => t === 'Task' || t.includes('subagent')) || false;
    if (hasTaskTool) {
      factors.push({ name: 'delegation', score: 3, description: 'Has Task/subagent tool' });
      breakdown.delegation = 3;
    }

    // Factor 4: Web/API integration tools
    const webTools = command.allowedTools?.filter(t => 
      t.includes('web') || t.includes('api') || t.includes('fetch') || t.includes('http')
    ) || [];
    if (webTools.length > 0) {
      const score = webTools.length * 2;
      factors.push({ name: 'web_integration', score, description: `${webTools.length} web/API tools` });
      breakdown.web = score;
    }

    // Factor 5: File modification tools (Write, Edit)
    const fileModTools = command.allowedTools?.filter(t => 
      t.includes('write') || t.includes('edit') || t.includes('Write') || t.includes('Edit')
    ) || [];
    if (fileModTools.length > 0) {
      const score = fileModTools.length;
      factors.push({ name: 'file_modification', score, description: `${fileModTools.length} file modification tools` });
      breakdown.fileMod = score;
    }

    // Factor 6: Code analysis tools (code-index-mcp)
    const codeAnalysisTools = command.allowedTools?.filter(t => 
      t.includes('code-index') || t.includes('search_code') || t.includes('get_symbol')
    ) || [];
    if (codeAnalysisTools.length > 0) {
      const score = Math.min(codeAnalysisTools.length, 3);
      factors.push({ name: 'code_analysis', score, description: `${codeAnalysisTools.length} code analysis tools` });
      breakdown.codeAnalysis = score;
    }

    // Factor 7: Tool combination complexity (multiple categories)
    const toolCategories = new Set([
      execTools.length > 0 ? 'exec' : null,
      hasTaskTool ? 'delegation' : null,
      webTools.length > 0 ? 'web' : null,
      fileModTools.length > 0 ? 'fileMod' : null,
      codeAnalysisTools.length > 0 ? 'analysis' : null,
    ].filter(Boolean));
    if (toolCategories.size >= 3) {
      const score = toolCategories.size;
      factors.push({ name: 'tool_combination', score, description: `${toolCategories.size} tool categories combined` });
      breakdown.toolCombination = score;
    }

    // Factor 8: MCP server dependency count
    const mcpTools = command.allowedTools?.filter(t => t.startsWith('mcp__')) || [];
    if (mcpTools.length > 3) {
      const score = Math.min(mcpTools.length - 3, 3);
      factors.push({ name: 'mcp_dependency', score, description: `${mcpTools.length} MCP tool dependencies` });
      breakdown.mcpDependency = score;
    }

    // Factor 9: Desktop Commander comprehensive usage
    const dcTools = command.allowedTools?.filter(t => t.includes('desktop-commander')) || [];
    if (dcTools.length >= 4) {
      factors.push({ name: 'dc_comprehensive', score: 2, description: 'Comprehensive Desktop Commander usage' });
      breakdown.dcComprehensive = 2;
    }

    // Factor 10: Parallel execution potential (multiple independent tools)
    if (toolCount >= 6 && toolCategories.size >= 2) {
      factors.push({ name: 'parallel_potential', score: 2, description: 'High parallel execution potential' });
      breakdown.parallelPotential = 2;
    }

    // ═══════════════════════════════════════════════════════════════
    // CATEGORY 2: KEYWORD-BASED FACTORS (8 factors)
    // ═══════════════════════════════════════════════════════════════

    // Factor 11: Debug/troubleshoot keywords
    if (combined.includes('debug') || combined.includes('troubleshoot') || combined.includes('fix') || combined.includes('resolve')) {
      factors.push({ name: 'debug_keywords', score: 4, description: 'Debug/troubleshoot operation' });
      breakdown.debug = 4;
    }

    // Factor 12: Analysis/research keywords
    if (combined.includes('analyze') || combined.includes('research') || combined.includes('investigate') || combined.includes('explore')) {
      factors.push({ name: 'analysis_keywords', score: 3, description: 'Analysis/research operation' });
      breakdown.analysis = 3;
    }

    // Factor 13: Planning/design keywords
    if (combined.includes('plan') || combined.includes('design') || combined.includes('architect') || combined.includes('structure')) {
      factors.push({ name: 'planning_keywords', score: 3, description: 'Planning/design operation' });
      breakdown.planning = 3;
    }

    // Factor 14: Integration/migration keywords
    if (combined.includes('integrate') || combined.includes('migrate') || combined.includes('refactor') || combined.includes('transform')) {
      factors.push({ name: 'integration_keywords', score: 3, description: 'Integration/migration operation' });
      breakdown.integration = 3;
    }

    // Factor 15: Verification/test keywords
    if (combined.includes('verify') || combined.includes('test') || combined.includes('validate') || combined.includes('check')) {
      factors.push({ name: 'verification_keywords', score: 2, description: 'Verification/testing operation' });
      breakdown.verification = 2;
    }

    // Factor 16: Simplicity/reduction keywords (negative factor)
    if (combined.includes('quick') || combined.includes('simple') || combined.includes('display') || combined.includes('show') || combined.includes('list')) {
      factors.push({ name: 'simplicity_keywords', score: -3, description: 'Simple/quick operation' });
      breakdown.simplicity = -3;
    }

    // Factor 17: Critical/urgent keywords
    if (combined.includes('critical') || combined.includes('urgent') || combined.includes('production') || combined.includes('breaking')) {
      factors.push({ name: 'critical_keywords', score: 3, description: 'Critical/urgent operation' });
      breakdown.critical = 3;
    }

    // Factor 18: Multi-component keywords
    if (combined.includes('multi') || combined.includes('across') || combined.includes('several') || combined.includes('all ')) {
      factors.push({ name: 'multi_component', score: 2, description: 'Multi-component operation' });
      breakdown.multiComponent = 2;
    }

    // ═══════════════════════════════════════════════════════════════
    // CATEGORY 3: WORKFLOW FACTORS (4 factors)
    // ═══════════════════════════════════════════════════════════════

    if (command.process) {
      const lines = command.process.split('\n').filter(line => line.trim().length > 0);

      // Factor 19: Process step count
      if (lines.length > 0) {
        const score = Math.min(lines.length, 5);
        factors.push({ name: 'workflow_steps', score, description: `${lines.length} workflow steps` });
        breakdown.workflowSteps = score;
      }

      // Factor 20: Branching/conditional logic
      const branchingPatterns = /if|when|case|otherwise|else|depending|branch/gi;
      const branchingMatches = command.process.match(branchingPatterns) || [];
      if (branchingMatches.length > 0) {
        const score = Math.min(branchingMatches.length, 3);
        factors.push({ name: 'workflow_branching', score, description: `${branchingMatches.length} branching points` });
        breakdown.branching = score;
      }

      // Factor 21: Checkpoint/pause points
      const checkpointPatterns = /checkpoint|pause|wait|confirm|ask|review/gi;
      const checkpointMatches = command.process.match(checkpointPatterns) || [];
      if (checkpointMatches.length > 0) {
        const score = Math.min(checkpointMatches.length, 2);
        factors.push({ name: 'workflow_checkpoints', score, description: `${checkpointMatches.length} checkpoint points` });
        breakdown.checkpoints = score;
      }

      // Factor 22: Parallel execution in workflow
      const parallelPatterns = /parallel|concurrent|simultaneous|in parallel|at the same time/gi;
      if (parallelPatterns.test(command.process)) {
        factors.push({ name: 'workflow_parallel', score: 2, description: 'Parallel execution in workflow' });
        breakdown.parallelWorkflow = 2;
      }
    }

    // ═══════════════════════════════════════════════════════════════
    // CATEGORY 4: ERROR HANDLING FACTORS (3 factors)
    // ═══════════════════════════════════════════════════════════════

    if (command.process) {
      // Factor 23: Error recovery patterns
      const errorPatterns = /catch|error|fail|retry|fallback|handle|recover/gi;
      const errorMatches = command.process.match(errorPatterns) || [];
      if (errorMatches.length > 0) {
        const score = Math.min(errorMatches.length, 3);
        factors.push({ name: 'error_recovery', score, description: `${errorMatches.length} error handling points` });
        breakdown.errorRecovery = score;
      }

      // Factor 24: Validation gates
      const validationPatterns = /validate|verify|check|ensure|confirm|assert/gi;
      const validationMatches = command.process.match(validationPatterns) || [];
      if (validationMatches.length > 1) {
        const score = Math.min(validationMatches.length - 1, 2);
        factors.push({ name: 'validation_gates', score, description: `${validationMatches.length} validation gates` });
        breakdown.validation = score;
      }

      // Factor 25: Rollback capability
      const rollbackPatterns = /rollback|undo|revert|restore|backup/gi;
      if (rollbackPatterns.test(command.process)) {
        factors.push({ name: 'rollback_capability', score: 2, description: 'Has rollback capability' });
        breakdown.rollback = 2;
      }
    }

    // Calculate total
    const totalScore = Math.max(0, factors.reduce((sum, f) => sum + f.score, 0));
    const mode = this.determineMode(totalScore);

    return {
      totalScore,
      mode,
      factors,
      breakdown
    };
  }

  /**
   * Determine thinking mode from complexity score
   */
  private determineMode(complexity: number): ThinkingMode {
    if (complexity <= 2) return 'NONE';
    if (complexity <= 6) return 'LIGHTWEIGHT';
    if (complexity <= 12) return 'STANDARD';
    return 'COMPREHENSIVE';
  }

  /**
   * Select appropriate thinking servers
   */
  private selectServers(
    command: { description: string; allowedTools?: string[]; objective?: string },
    complexity: number
  ): ThinkingServer[] {
    const servers: ThinkingServer[] = ['sequential']; // Always include sequential

    const desc = command.description.toLowerCase();
    const objective = (command.objective || '').toLowerCase();
    const combined = `${desc} ${objective}`;

    // Add tractatus for structural analysis
    if (
      combined.includes('analyze') ||
      combined.includes('structure') ||
      combined.includes('architecture') ||
      combined.includes('design') ||
      combined.includes('plan') ||
      combined.includes('research') ||
      (command.allowedTools?.some(t => t.includes('code-index-mcp')) ?? false)
    ) {
      servers.push('tractatus');
    }

    // Add debug for problem-solving
    if (
      combined.includes('debug') ||
      combined.includes('troubleshoot') ||
      combined.includes('fix') ||
      combined.includes('verify') ||
      combined.includes('test') ||
      combined.includes('resolve') ||
      combined.includes('investigate')
    ) {
      servers.push('debug');
    }

    return servers;
  }

  /**
   * Calculate timeout based on mode and tool count
   */
  private calculateTimeout(mode: ThinkingMode, toolCount: number): number {
    const baseTimeout = {
      'NONE': 0,
      'LIGHTWEIGHT': 2000,
      'STANDARD': 5000,
      'COMPREHENSIVE': 9000
    };

    const toolFactor = 500; // ms per tool
    const calculated = baseTimeout[mode] + (toolCount * toolFactor);

    return Math.min(calculated, 15000); // Max 15 seconds
  }

  /**
   * Generate rationale for thinking config
   */
  private generateRationale(
    command: { description: string },
    mode: ThinkingMode,
    servers: ThinkingServer[]
  ): string {
    const taskType = this.identifyTaskType(command.description);
    const serverDescriptions = servers.map(s => {
      switch (s) {
        case 'sequential': return 'step sequencing (Sequential)';
        case 'tractatus': return 'structural analysis (Tractatus)';
        case 'debug': return 'problem-solving (Debug)';
      }
    }).join(' and ');

    return `${taskType} requiring ${serverDescriptions}`;
  }

  /**
   * Identify task type from description
   */
  private identifyTaskType(description: string): string {
    const desc = description.toLowerCase();

    if (desc.includes('debug') || desc.includes('troubleshoot')) {
      return 'Debugging workflow';
    }
    if (desc.includes('research') || desc.includes('investigate')) {
      return 'Research task';
    }
    if (desc.includes('plan') || desc.includes('design')) {
      return 'Planning task';
    }
    if (desc.includes('execute') || desc.includes('implement')) {
      return 'Execution task';
    }
    if (desc.includes('verify') || desc.includes('test')) {
      return 'Verification task';
    }

    return 'Task execution';
  }

  /**
   * Check if thinking should be invoked based on context
   */
  shouldInvokeThinking(config: ThinkingPhaseConfig): boolean {
    return config.mode !== 'NONE' && config.servers.length > 0;
  }

  /**
   * Format thinking results for display
   */
  formatResults(results: Map<ThinkingServer, ThinkingResult>): string {
    let output = '## Thinking Phase Results\n\n';

    for (const [server, result] of results) {
      output += `### ${server.toUpperCase()} Server\n`;
      output += `- Duration: ${result.duration}ms\n`;
      output += `- Status: ${result.success ? '✓ Success' : '✗ Failed'}\n`;

      if (result.error) {
        output += `- Error: ${result.error}\n`;
      }

      output += `- Thoughts: ${result.thoughts.length}\n`;

      if (result.thoughts.length > 0) {
        output += '\n```\n';
        for (const thought of result.thoughts) {
          output += `[${thought.thoughtNumber}/${thought.totalThoughts}] ${thought.thought}\n`;
        }
        output += '```\n';
      }

      output += '\n';
    }

    return output;
  }
}

export default ThinkingOrchestrator;

</document_content>
</document>
<document index="21">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\lib\workflow-modules\workflow-chainer.ts</source>
<document_content>
/**
 * GSI Workflow Chainer Module
 *
 * Chains multiple GSI commands into unified workflows with automatic
 * dependency resolution and parallel execution.
 *
 * Extracted from: Common GSI command patterns analysis
 */

import { writeFileSync, readFileSync, existsSync } from 'fs';
import { join } from 'path';

export type CheckpointStrategy = 'after-each' | 'after-phase' | 'before-execute' | 'manual';
export type FailureStrategy = 'stop-on-error' | 'continue-on-error' | 'rollback-on-error';

export interface WorkflowChain {
  name: string;
  description: string;
  chain: WorkflowStep[];
  parallel?: ParallelGroup[];
  checkpoint: CheckpointStrategy;
  rollback: boolean;
  dependencies?: Record<string, string[]>;
}

export interface WorkflowStep {
  command: string;
  args?: string;
  condition?: string;
  checkpoint?: boolean;
}

export interface ParallelGroup {
  name: string;
  steps: WorkflowStep[];
}

export interface WorkflowState {
  chain: string;
  variables: Record<string, string>;
  completed: string[];
  current?: string;
  pending: string[];
  checkpoint?: CheckpointData;
  startTime: string;
  status: 'running' | 'paused' | 'completed' | 'failed';
}

export interface CheckpointData {
  timestamp: string;
  gitCommit?: string;
  filesChanged: string[];
  stateSnapshot: Record<string, any>;
}

export interface WorkflowResult {
  chain: string;
  success: boolean;
  completedSteps: string[];
  failedStep?: string;
  error?: string;
  duration: number;
  checkpoints: CheckpointData[];
}

/**
 * Manages workflow chains for GSI commands
 */
export class WorkflowChainer {
  private stateFile: string;
  private templates: Map<string, WorkflowChain>;
  private activeWorkflows: Map<string, WorkflowState>;

  constructor(stateDir: string = '.planning') {
    this.stateFile = join(stateDir, 'workflow-state.json');
    this.templates = new Map();
    this.activeWorkflows = new Map();

    this.loadTemplates();
    this.loadState();
  }

  /**
   * Load workflow templates
   */
  private loadTemplates(): void {
    // Full development cycle
    this.templates.set('full-cycle', {
      name: 'full-cycle',
      description: 'Research → Plan → Execute → Verify',
      chain: [
        { command: 'gsi:research-phase', args: '${phase}' },
        { command: 'gsi:plan-phase', args: '${phase}' },
        { command: 'gsi:execute-phase', args: '${phase}' },
        { command: 'gsi:verify-work', args: '${phase}' }
      ],
      checkpoint: 'after-each',
      rollback: true
    });

    // Quick fix (skip research)
    this.templates.set('quick-fix', {
      name: 'quick-fix',
      description: 'Plan → Execute → Verify (skip research)',
      chain: [
        { command: 'gsi:plan-phase', args: '${phase} --skip-research' },
        { command: 'gsi:execute-phase', args: '${phase}' },
        { command: 'gsi:verify-work', args: '${phase}' }
      ],
      checkpoint: 'before-execute',
      rollback: true
    });

    // Project setup
    this.templates.set('project-setup', {
      name: 'project-setup',
      description: 'Initialize new project with all phases',
      chain: [
        { command: 'gsi:new-project' },
        { command: 'gsi:map-codebase' },
        { command: 'gsi:add-phase', args: '"Foundation"' },
        { command: 'gsi:plan-phase', args: '01' }
      ],
      parallel: [
        {
          name: 'status-check',
          steps: [
            { command: 'gsi:check-todos' },
            { command: 'gsi:progress' }
          ]
        }
      ],
      checkpoint: 'after-phase',
      rollback: false
    });

    // Milestone complete
    this.templates.set('milestone-complete', {
      name: 'milestone-complete',
      description: 'Complete milestone and prepare next',
      chain: [
        { command: 'gsi:audit-milestone' },
        { command: 'gsi:verify-work', args: '--all' },
        { command: 'gsi:complete-milestone' },
        { command: 'gsi:new-milestone' }
      ],
      checkpoint: 'manual',
      rollback: true
    });
  }

  /**
   * Run a workflow chain
   */
  async run(
    chainName: string,
    variables: Record<string, string> = {},
    options: {
      failureStrategy?: FailureStrategy;
      yoloMode?: boolean;
    } = {}
  ): Promise<WorkflowResult> {
    const template = this.templates.get(chainName);
    if (!template) {
      throw new Error(`Unknown workflow chain: ${chainName}`);
    }

    const startTime = Date.now();
    const checkpoints: CheckpointData[] = [];
    const completedSteps: string[] = [];
    const failureStrategy = options.failureStrategy || 'stop-on-error';
    const yoloMode = options.yoloMode || false;

    // Initialize workflow state
    const state: WorkflowState = {
      chain: chainName,
      variables,
      completed: [],
      pending: template.chain.map(s => s.command),
      startTime: new Date().toISOString(),
      status: 'running'
    };
    this.activeWorkflows.set(chainName, state);
    this.saveState();

    let failedStep: string | undefined;
    let error: string | undefined;

    try {
      // Execute sequential chain
      for (const step of template.chain) {
        const resolvedCommand = this.resolveVariables(step.command, variables);
        const resolvedArgs = step.args ? this.resolveVariables(step.args, variables) : '';

        state.current = resolvedCommand;
        this.saveState();

        try {
          await this.executeStep(resolvedCommand, resolvedArgs, yoloMode);
          completedSteps.push(resolvedCommand);
          state.completed.push(resolvedCommand);
          state.pending = state.pending.filter(p => p !== resolvedCommand);

          // Create checkpoint if needed
          if (this.shouldCheckpoint(template.checkpoint, step, completedSteps.length)) {
            const checkpoint = await this.createCheckpoint(state);
            checkpoints.push(checkpoint);
            state.checkpoint = checkpoint;
            this.saveState();
          }
        } catch (stepError) {
          failedStep = resolvedCommand;
          error = stepError instanceof Error ? stepError.message : 'Unknown error';

          if (failureStrategy === 'stop-on-error') {
            state.status = 'failed';
            this.saveState();
            throw stepError;
          } else if (failureStrategy === 'rollback-on-error' && template.rollback) {
            await this.rollbackToCheckpoint(state, checkpoints);
            state.status = 'failed';
            this.saveState();
            throw stepError;
          }
          // continue-on-error: just log and continue
        }
      }

      // Execute parallel groups
      if (template.parallel) {
        for (const group of template.parallel) {
          await this.executeParallelGroup(group, variables, yoloMode);
        }
      }

      state.status = 'completed';
      state.current = undefined;
      this.saveState();

    } catch (e) {
      error = e instanceof Error ? e.message : 'Unknown error';
      state.status = 'failed';
      this.saveState();
    }

    const duration = Date.now() - startTime;

    return {
      chain: chainName,
      success: state.status === 'completed',
      completedSteps,
      failedStep,
      error,
      duration,
      checkpoints
    };
  }

  /**
   * Pause a running workflow
   */
  async pause(chainName: string): Promise<void> {
    const state = this.activeWorkflows.get(chainName);
    if (!state) {
      throw new Error(`No active workflow: ${chainName}`);
    }

    if (state.status !== 'running') {
      throw new Error(`Workflow is not running: ${chainName}`);
    }

    state.status = 'paused';
    this.saveState();
  }

  /**
   * Resume a paused workflow
   */
  async resume(chainName: string): Promise<WorkflowResult> {
    const state = this.activeWorkflows.get(chainName);
    if (!state) {
      throw new Error(`No paused workflow: ${chainName}`);
    }

    if (state.status !== 'paused') {
      throw new Error(`Workflow is not paused: ${chainName}`);
    }

    // Re-run from where we left off
    return this.run(chainName, state.variables);
  }

  /**
   * Rollback to last checkpoint
   */
  async rollback(chainName: string): Promise<void> {
    const state = this.activeWorkflows.get(chainName);
    if (!state || !state.checkpoint) {
      throw new Error(`No checkpoint available for: ${chainName}`);
    }

    await this.rollbackToCheckpoint(state, [state.checkpoint]);
  }

  /**
   * Get workflow status
   */
  getStatus(chainName?: string): WorkflowState | WorkflowState[] {
    if (chainName) {
      const state = this.activeWorkflows.get(chainName);
      if (!state) {
        throw new Error(`Unknown workflow: ${chainName}`);
      }
      return state;
    }

    return Array.from(this.activeWorkflows.values());
  }

  /**
   * Execute a single step
   */
  private async executeStep(
    command: string,
    args: string,
    yoloMode: boolean
  ): Promise<void> {
    // In a real implementation, this would invoke the GSI command
    // For now, we simulate execution

    console.log(`Executing: ${command} ${args}`);

    // Simulate async execution
    await new Promise(resolve => setTimeout(resolve, 100));
  }

  /**
   * Execute a parallel group
   */
  private async executeParallelGroup(
    group: ParallelGroup,
    variables: Record<string, string>,
    yoloMode: boolean
  ): Promise<void> {
    // Execute all steps in parallel
    const promises = group.steps.map(step => {
      const resolvedCommand = this.resolveVariables(step.command, variables);
      const resolvedArgs = step.args ? this.resolveVariables(step.args, variables) : '';
      return this.executeStep(resolvedCommand, resolvedArgs, yoloMode);
    });

    await Promise.all(promises);
  }

  /**
   * Determine if checkpoint should be created
   */
  private shouldCheckpoint(
    strategy: CheckpointStrategy,
    step: WorkflowStep,
    completedCount: number
  ): boolean {
    switch (strategy) {
      case 'after-each':
        return true;
      case 'after-phase':
        return step.command.includes('phase');
      case 'before-execute':
        return step.command.includes('execute');
      case 'manual':
        return step.checkpoint || false;
      default:
        return false;
    }
  }

  /**
   * Create a checkpoint
   */
  private async createCheckpoint(state: WorkflowState): Promise<CheckpointData> {
    return {
      timestamp: new Date().toISOString(),
      filesChanged: [],
      stateSnapshot: {
        completed: [...state.completed],
        pending: [...state.pending]
      }
    };
  }

  /**
   * Rollback to a checkpoint
   */
  private async rollbackToCheckpoint(
    state: WorkflowState,
    checkpoints: CheckpointData[]
  ): Promise<void> {
    if (checkpoints.length === 0) {
      return;
    }

    const lastCheckpoint = checkpoints[checkpoints.length - 1];

    // Restore state
    state.completed = lastCheckpoint.stateSnapshot.completed || [];
    state.pending = lastCheckpoint.stateSnapshot.pending || [];
    state.checkpoint = lastCheckpoint;

    // In a real implementation, would also:
    // - git reset to commit
    // - restore modified files
    // - rollback database changes
  }

  /**
   * Resolve variables in command/args
   */
  private resolveVariables(template: string, variables: Record<string, string>): string {
    let resolved = template;

    for (const [key, value] of Object.entries(variables)) {
      const regex = new RegExp(`\\$\\{${key}\\}`, 'g');
      resolved = resolved.replace(regex, value);
    }

    return resolved;
  }

  /**
   * Save state to file
   */
  private saveState(): void {
    const stateObj: Record<string, WorkflowState> = {};

    for (const [name, state] of this.activeWorkflows) {
      stateObj[name] = state;
    }

    writeFileSync(this.stateFile, JSON.stringify(stateObj, null, 2));
  }

  /**
   * Load state from file
   */
  private loadState(): void {
    if (!existsSync(this.stateFile)) {
      return;
    }

    try {
      const stateObj = JSON.parse(readFileSync(this.stateFile, 'utf-8'));

      for (const [name, state] of Object.entries(stateObj)) {
        this.activeWorkflows.set(name, state as WorkflowState);
      }
    } catch (error) {
      // Ignore errors loading state
    }
  }

  /**
   * Clear completed workflows
   */
  clearCompleted(): void {
    for (const [name, state] of this.activeWorkflows) {
      if (state.status === 'completed' || state.status === 'failed') {
        this.activeWorkflows.delete(name);
      }
    }
    this.saveState();
  }

  /**
   * Create custom workflow chain
   */
  createChain(definition: WorkflowChain): void {
    this.templates.set(definition.name, definition);
  }

  /**
   * List available templates
   */
  listTemplates(): WorkflowChain[] {
    return Array.from(this.templates.values());
  }
}

export default WorkflowChainer;

</document_content>
</document>
<document index="22">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\profiles\comprehensive.json</source>
<document_content>
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "name": "comprehensive",
  "displayName": "Comprehensive Thinking Profile",
  "description": "Full thinking configuration for complex operations requiring deep analysis",
  "mode": "COMPREHENSIVE",
  "servers": ["sequential", "tractatus", "debug"],
  "bmad_enabled": true,
  "baseTimeout": 9000,
  "maxThoughts": 10,
  "complexityThreshold": {
    "min": 13,
    "max": 100
  },
  "useCases": [
    "Complex debugging",
    "Architecture design",
    "Multi-phase integration",
    "Critical path operations",
    "Cross-cutting concerns"
  ],
  "serverConfig": {
    "sequential": {
      "enabled": true,
      "priority": 1,
      "maxThoughts": 10,
      "focusAreas": ["complex-planning", "multi-step-sequencing", "dependency-graphs"]
    },
    "tractatus": {
      "enabled": true,
      "priority": 2,
      "maxThoughts": 10,
      "focusAreas": ["deep-structural-analysis", "logical-foundations", "system-architecture"]
    },
    "debug": {
      "enabled": true,
      "priority": 3,
      "maxThoughts": 10,
      "focusAreas": ["problem-isolation", "hypothesis-testing", "root-cause-analysis"]
    }
  },
  "parallelExecution": {
    "enabled": true,
    "strategy": "parallel",
    "mergeStrategy": "consensus"
  },
  "examples": [
    {
      "command": "gsi debug --complex",
      "description": "Debug complex multi-component issue"
    },
    {
      "command": "gsi new-project --comprehensive",
      "description": "Start comprehensive project setup"
    },
    {
      "command": "gsi verify-work 20 --deep",
      "description": "Deep verification of phase work"
    }
  ]
}

</document_content>
</document>
<document index="23">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\profiles\quick.json</source>
<document_content>
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "name": "quick",
  "displayName": "Quick Thinking Profile",
  "description": "Lightweight thinking configuration for simple, fast operations",
  "mode": "LIGHTWEIGHT",
  "servers": ["sequential"],
  "bmad_enabled": false,
  "baseTimeout": 2000,
  "maxThoughts": 3,
  "complexityThreshold": {
    "min": 3,
    "max": 6
  },
  "useCases": [
    "Simple display operations",
    "Status checks",
    "Quick lookups",
    "Single-step operations",
    "Non-critical path operations"
  ],
  "serverConfig": {
    "sequential": {
      "enabled": true,
      "priority": 1,
      "maxThoughts": 3,
      "focusAreas": ["step-ordering", "basic-planning"]
    },
    "tractatus": {
      "enabled": false,
      "priority": 2
    },
    "debug": {
      "enabled": false,
      "priority": 3
    }
  },
  "examples": [
    {
      "command": "gsi state get",
      "description": "Display state information"
    },
    {
      "command": "gsi progress",
      "description": "Show progress bar"
    },
    {
      "command": "gsi list-todos",
      "description": "List pending todos"
    }
  ]
}

</document_content>
</document>
<document index="24">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\profiles\standard.json</source>
<document_content>
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "name": "standard",
  "displayName": "Standard Thinking Profile",
  "description": "Standard thinking configuration for typical planning and execution operations",
  "mode": "STANDARD",
  "servers": ["sequential", "tractatus"],
  "bmad_enabled": true,
  "baseTimeout": 5000,
  "maxThoughts": 5,
  "complexityThreshold": {
    "min": 7,
    "max": 12
  },
  "useCases": [
    "Planning operations",
    "Phase execution",
    "Code analysis",
    "Multi-step workflows",
    "Research tasks"
  ],
  "serverConfig": {
    "sequential": {
      "enabled": true,
      "priority": 1,
      "maxThoughts": 5,
      "focusAreas": ["step-planning", "execution-order", "dependency-resolution"]
    },
    "tractatus": {
      "enabled": true,
      "priority": 2,
      "maxThoughts": 5,
      "focusAreas": ["structural-analysis", "logical-dependencies", "architecture"]
    },
    "debug": {
      "enabled": false,
      "priority": 3
    }
  },
  "examples": [
    {
      "command": "gsi plan-phase 20",
      "description": "Plan a phase with dependencies"
    },
    {
      "command": "gsi execute-phase 20-01",
      "description": "Execute a phase plan"
    },
    {
      "command": "gsi research-phase 21",
      "description": "Research phase requirements"
    }
  ]
}

</document_content>
</document>
<document index="25">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\agent-tracking.md</source>
<document_content>
﻿# Agent Tracking Reference

Documentation for agent tracking protocol used across GSI workflows for monitoring parallel agent execution and resume capability.

---

## JSON Schema

### agent-history.json

```json
{
  "version": "1.0",
  "max_entries": 50,
  "entries": [
    {
      "agent_id": "mapper-tech-20250213-110500",
      "task_description": "Map codebase technology stack",
      "phase": "08-advanced-workflow-features",
      "plan": "01",
      "segment": null,
      "timestamp": "2025-02-13T11:05:00Z",
      "status": "spawned",
      "completion_timestamp": null,
      "focus": "tech"
    }
  ]
}
```

### Schema Fields

| Field | Type | Description |
|-------|-------|-------------|
| `version` | string | Schema version for format changes |
| `max_entries` | number | Maximum number of entries to keep (oldest "completed" pruned first) |
| `entries` | array | Array of agent records |
| `agent_id` | string | Unique identifier in format `{focus}-{datestamp}` |
| `task_description` | string | Human-readable description of agent's task |
| `phase` | string | Phase identifier (e.g., "08-advanced-workflow-features") |
| `plan` | string | Plan identifier within phase (e.g., "01") |
| `segment` | number\|null | Segment number for segmented plans, null for full-plan agents |
| `timestamp` | string | ISO 8601 datetime when agent was spawned |
| `status` | string | Current status: "spawned", "running", "completed", "failed" |
| `completion_timestamp` | string\|null | ISO 8601 datetime when agent completed (null if not complete) |
| `focus` | string | Agent's focus area (tech, arch, quality, concerns, etc.) |

---

## Tracking Protocol

### On Spawn

```bash
# Generate unique agent ID
AGENT_ID="agent-${FOCUS}-$(date +%Y%m%d-%H%M%S)"

# Add to agent-history.json
node ~/.claude/get-shit-indexed/bin/GSI-tools.js track-agent "$AGENT_ID" "$DESCRIPTION" "$PHASE" "$PLAN" --status "spawned"

# Write current agent ID for resumption
echo "$AGENT_ID" > .planning/current-agent-id.txt
```

### On Completion

```bash
# Update agent status in history
node ~/.claude/get-shit-indexed/bin/GSI-tools.js track-agent "$AGENT_ID" "$DESCRIPTION" "$PHASE" "$PLAN" --status "completed" --completion-timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)"

# Clean up current agent ID
rm -f .planning/current-agent-id.txt
```

### On Failure

```bash
# Mark as failed
node ~/.claude/get-shit-indexed/bin/GSI-tools.js track-agent "$AGENT_ID" "$DESCRIPTION" "$PHASE" "$PLAN" --status "failed" --error "Error description"
```

---

## Interrupt Detection

On workflow startup, check for interrupted agents:

```bash
# Check if current-agent-id.txt exists from previous interrupted session
if [ -f .planning/current-agent-id ]; then
  INTERRUPTED_ID=$(cat .planning/current-agent-id.txt)
  echo "Found interrupted agent: $INTERRUPTED_ID"
  # Prompt: "Resume agent $INTERRUPTED_ID or start fresh?"
fi
```

---

## Pruning

When `entries.length` exceeds `max_entries`:

1. Sort entries by timestamp (oldest first)
2. Remove entries with `status: "completed"` (never remove "spawned" or "running")
3. Keep at most `max_entries` total entries
4. Preserve newest entries

---

## Usage Patterns

### Wave-based Spawning

Track multiple agents spawned in waves:

```json
{
  "agent_id": "mapper-tech-20250213-110500",
  "wave": 1,
  "status": "spawned"
}
```

### Segmented Plans

Track segment number for agents executing partial plans:

```json
{
  "agent_id": "executor-08-02-03",
  "segment": 2,
  "status": "spawned"
}
```

---

## File Locations

- **History**: `.planning/agent-history.json`
- **Current agent**: `.planning/current-agent-id.txt`

---

## Examples

### Example 1: Spawn tech mapper agent

```bash
# Spawn agent for technology stack analysis
AGENT_ID="mapper-tech-$(date +%Y%m%d-%H%M%S)"

# Add to history
node ~/.claude/get-shit-indexed/bin/GSI-tools.js track-agent "$AGENT_ID" "Map codebase tech stack" "08-advanced-workflow-features" "01" --status "spawned"

# Track current agent
echo "$AGENT_ID" > .planning/current-agent-id.txt
```

### Example 2: Agent completes

```bash
# Update status to completed
node ~/.claude/get-shit-indexed/bin/GSI-tools.js track-agent "$AGENT_ID" "Map codebase tech stack" "08-advanced-workflow-features" "01" --status "completed" --completion-timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)"

# Clean up
rm -f .planning/current-agent-id.txt
```

### Example 3: Resume interrupted agent

```bash
# Check for interrupted agent
if [ -f .planning/current-agent-id.txt ]; then
  INTERRUPTED_ID=$(cat .planning/current-agent-id.txt)
  
  # Resume with same agent ID
  # (use Task tool's resume parameter if available)
fi
```

---

*Generated for GSI Phase 8 - Advanced Workflow Features*
</document_content>
</document>
<document index="26">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\checkpoints.md</source>
<document_content>
<overview>
Plans execute autonomously. Checkpoints formalize interaction points where human verification or decisions are needed.

**Core principle:** Claude automates everything with CLI/API. Checkpoints are for verification and decisions, not manual work.

**Golden rules:**
1. **If Claude can run it, Claude runs it** - Never ask user to execute CLI commands, start servers, or run builds
2. **Claude sets up the verification environment** - Start dev servers, seed databases, configure env vars
3. **User only does what requires human judgment** - Visual checks, UX evaluation, "does this feel right?"
4. **Secrets come from user, automation comes from Claude** - Ask for API keys, then Claude uses them via CLI
</overview>

<checkpoint_types>

<type name="human-verify">
## checkpoint:human-verify (Most Common - 90%)

**When:** Claude completed automated work, human confirms it works correctly.

**Use for:**
- Visual UI checks (layout, styling, responsiveness)
- Interactive flows (click through wizard, test user flows)
- Functional verification (feature works as expected)
- Audio/video playback quality
- Animation smoothness
- Accessibility testing

**Structure:**
```xml
<task type="checkpoint:human-verify" gate="blocking">
  <what-built>[What Claude automated and deployed/built]</what-built>
  <how-to-verify>
    [Exact steps to test - URLs, commands, expected behavior]
  </how-to-verify>
  <resume-signal>[How to continue - "approved", "yes", or describe issues]</resume-signal>
</task>
```

**Example: UI Component (shows key pattern: Claude starts server BEFORE checkpoint)**
```xml
<task type="auto">
  <name>Build responsive dashboard layout</name>
  <files>src/components/Dashboard.tsx, src/app/dashboard/page.tsx</files>
  <action>Create dashboard with sidebar, header, and content area. Use Tailwind responsive classes for mobile.</action>
  <verify>npm run build succeeds, no TypeScript errors</verify>
  <done>Dashboard component builds without errors</done>
</task>

<task type="auto">
  <name>Start dev server for verification</name>
  <action>Run `npm run dev` in background, wait for "ready" message, capture port</action>
  <verify>curl http://localhost:3000 returns 200</verify>
  <done>Dev server running at http://localhost:3000</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Responsive dashboard layout - dev server running at http://localhost:3000</what-built>
  <how-to-verify>
    Visit http://localhost:3000/dashboard and verify:
    1. Desktop (>1024px): Sidebar left, content right, header top
    2. Tablet (768px): Sidebar collapses to hamburger menu
    3. Mobile (375px): Single column layout, bottom nav appears
    4. No layout shift or horizontal scroll at any size
  </how-to-verify>
  <resume-signal>Type "approved" or describe layout issues</resume-signal>
</task>
```

**Example: Xcode Build**
```xml
<task type="auto">
  <name>Build macOS app with Xcode</name>
  <files>App.xcodeproj, Sources/</files>
  <action>Run `xcodebuild -project App.xcodeproj -scheme App build`. Check for compilation errors in output.</action>
  <verify>Build output contains "BUILD SUCCEEDED", no errors</verify>
  <done>App builds successfully</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Built macOS app at DerivedData/Build/Products/Debug/App.app</what-built>
  <how-to-verify>
    Open App.app and test:
    - App launches without crashes
    - Menu bar icon appears
    - Preferences window opens correctly
    - No visual glitches or layout issues
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>
```
</type>

<type name="decision">
## checkpoint:decision (9%)

**When:** Human must make choice that affects implementation direction.

**Use for:**
- Technology selection (which auth provider, which database)
- Architecture decisions (monorepo vs separate repos)
- Design choices (color scheme, layout approach)
- Feature prioritization (which variant to build)
- Data model decisions (schema structure)

**Structure:**
```xml
<task type="checkpoint:decision" gate="blocking">
  <decision>[What's being decided]</decision>
  <context>[Why this decision matters]</context>
  <options>
    <option id="option-a">
      <name>[Option name]</name>
      <pros>[Benefits]</pros>
      <cons>[Tradeoffs]</cons>
    </option>
    <option id="option-b">
      <name>[Option name]</name>
      <pros>[Benefits]</pros>
      <cons>[Tradeoffs]</cons>
    </option>
  </options>
  <resume-signal>[How to indicate choice]</resume-signal>
</task>
```

**Example: Auth Provider Selection**
```xml
<task type="checkpoint:decision" gate="blocking">
  <decision>Select authentication provider</decision>
  <context>
    Need user authentication for the app. Three solid options with different tradeoffs.
  </context>
  <options>
    <option id="supabase">
      <name>Supabase Auth</name>
      <pros>Built-in with Supabase DB we're using, generous free tier, row-level security integration</pros>
      <cons>Less customizable UI, tied to Supabase ecosystem</cons>
    </option>
    <option id="clerk">
      <name>Clerk</name>
      <pros>Beautiful pre-built UI, best developer experience, excellent docs</pros>
      <cons>Paid after 10k MAU, vendor lock-in</cons>
    </option>
    <option id="nextauth">
      <name>NextAuth.js</name>
      <pros>Free, self-hosted, maximum control, widely adopted</pros>
      <cons>More setup work, you manage security updates, UI is DIY</cons>
    </option>
  </options>
  <resume-signal>Select: supabase, clerk, or nextauth</resume-signal>
</task>
```

**Example: Database Selection**
```xml
<task type="checkpoint:decision" gate="blocking">
  <decision>Select database for user data</decision>
  <context>
    App needs persistent storage for users, sessions, and user-generated content.
    Expected scale: 10k users, 1M records first year.
  </context>
  <options>
    <option id="supabase">
      <name>Supabase (Postgres)</name>
      <pros>Full SQL, generous free tier, built-in auth, real-time subscriptions</pros>
      <cons>Vendor lock-in for real-time features, less flexible than raw Postgres</cons>
    </option>
    <option id="planetscale">
      <name>PlanetScale (MySQL)</name>
      <pros>Serverless scaling, branching workflow, excellent DX</pros>
      <cons>MySQL not Postgres, no foreign keys in free tier</cons>
    </option>
    <option id="convex">
      <name>Convex</name>
      <pros>Real-time by default, TypeScript-native, automatic caching</pros>
      <cons>Newer platform, different mental model, less SQL flexibility</cons>
    </option>
  </options>
  <resume-signal>Select: supabase, planetscale, or convex</resume-signal>
</task>
```
</type>

<type name="human-action">
## checkpoint:human-action (1% - Rare)

**When:** Action has NO CLI/API and requires human-only interaction, OR Claude hit an authentication gate during automation.

**Use ONLY for:**
- **Authentication gates** - Claude tried CLI/API but needs credentials (this is NOT a failure)
- Email verification links (clicking email)
- SMS 2FA codes (phone verification)
- Manual account approvals (platform requires human review)
- Credit card 3D Secure flows (web-based payment authorization)
- OAuth app approvals (web-based approval)

**Do NOT use for pre-planned manual work:**
- Deploying (use CLI - auth gate if needed)
- Creating webhooks/databases (use API/CLI - auth gate if needed)
- Running builds/tests (use Bash tool)
- Creating files (use Write tool)

**Structure:**
```xml
<task type="checkpoint:human-action" gate="blocking">
  <action>[What human must do - Claude already did everything automatable]</action>
  <instructions>
    [What Claude already automated]
    [The ONE thing requiring human action]
  </instructions>
  <verification>[What Claude can check afterward]</verification>
  <resume-signal>[How to continue]</resume-signal>
</task>
```

**Example: Email Verification**
```xml
<task type="auto">
  <name>Create SendGrid account via API</name>
  <action>Use SendGrid API to create subuser account with provided email. Request verification email.</action>
  <verify>API returns 201, account created</verify>
  <done>Account created, verification email sent</done>
</task>

<task type="checkpoint:human-action" gate="blocking">
  <action>Complete email verification for SendGrid account</action>
  <instructions>
    I created the account and requested verification email.
    Check your inbox for SendGrid verification link and click it.
  </instructions>
  <verification>SendGrid API key works: curl test succeeds</verification>
  <resume-signal>Type "done" when email verified</resume-signal>
</task>
```

**Example: Authentication Gate (Dynamic Checkpoint)**
```xml
<task type="auto">
  <name>Deploy to Vercel</name>
  <files>.vercel/, vercel.json</files>
  <action>Run `vercel --yes` to deploy</action>
  <verify>vercel ls shows deployment, curl returns 200</verify>
</task>

<!-- If vercel returns "Error: Not authenticated", Claude creates checkpoint on the fly -->

<task type="checkpoint:human-action" gate="blocking">
  <action>Authenticate Vercel CLI so I can continue deployment</action>
  <instructions>
    I tried to deploy but got authentication error.
    Run: vercel login
    This will open your browser - complete the authentication flow.
  </instructions>
  <verification>vercel whoami returns your account email</verification>
  <resume-signal>Type "done" when authenticated</resume-signal>
</task>

<!-- After authentication, Claude retries the deployment -->

<task type="auto">
  <name>Retry Vercel deployment</name>
  <action>Run `vercel --yes` (now authenticated)</action>
  <verify>vercel ls shows deployment, curl returns 200</verify>
</task>
```

**Key distinction:** Auth gates are created dynamically when Claude encounters auth errors. NOT pre-planned — Claude automates first, asks for credentials only when blocked.
</type>
</checkpoint_types>

<execution_protocol>

When Claude encounters `type="checkpoint:*"`:

1. **Stop immediately** - do not proceed to next task
2. **Display checkpoint clearly** using the format below
3. **Wait for user response** - do not hallucinate completion
4. **Verify if possible** - check files, run tests, whatever is specified
5. **Resume execution** - continue to next task only after confirmation

**For checkpoint:human-verify:**
```
╔═══════════════════════════════════════════════════════╗
║  CHECKPOINT: Verification Required                    ║
╚═══════════════════════════════════════════════════════╝

Progress: 5/8 tasks complete
Task: Responsive dashboard layout

Built: Responsive dashboard at /dashboard

How to verify:
  1. Visit: http://localhost:3000/dashboard
  2. Desktop (>1024px): Sidebar visible, content fills remaining space
  3. Tablet (768px): Sidebar collapses to icons
  4. Mobile (375px): Sidebar hidden, hamburger menu appears

────────────────────────────────────────────────────────
→ YOUR ACTION: Type "approved" or describe issues
────────────────────────────────────────────────────────
```

**For checkpoint:decision:**
```
╔═══════════════════════════════════════════════════════╗
║  CHECKPOINT: Decision Required                        ║
╚═══════════════════════════════════════════════════════╝

Progress: 2/6 tasks complete
Task: Select authentication provider

Decision: Which auth provider should we use?

Context: Need user authentication. Three options with different tradeoffs.

Options:
  1. supabase - Built-in with our DB, free tier
     Pros: Row-level security integration, generous free tier
     Cons: Less customizable UI, ecosystem lock-in

  2. clerk - Best DX, paid after 10k users
     Pros: Beautiful pre-built UI, excellent documentation
     Cons: Vendor lock-in, pricing at scale

  3. nextauth - Self-hosted, maximum control
     Pros: Free, no vendor lock-in, widely adopted
     Cons: More setup work, DIY security updates

────────────────────────────────────────────────────────
→ YOUR ACTION: Select supabase, clerk, or nextauth
────────────────────────────────────────────────────────
```

**For checkpoint:human-action:**
```
╔═══════════════════════════════════════════════════════╗
║  CHECKPOINT: Action Required                          ║
╚═══════════════════════════════════════════════════════╝

Progress: 3/8 tasks complete
Task: Deploy to Vercel

Attempted: vercel --yes
Error: Not authenticated. Please run 'vercel login'

What you need to do:
  1. Run: vercel login
  2. Complete browser authentication when it opens
  3. Return here when done

I'll verify: vercel whoami returns your account

────────────────────────────────────────────────────────
→ YOUR ACTION: Type "done" when authenticated
────────────────────────────────────────────────────────
```
</execution_protocol>

<authentication_gates>

**Auth gate = Claude tried CLI/API, got auth error.** Not a failure — a gate requiring human input to unblock.

**Pattern:** Claude tries automation → auth error → creates checkpoint:human-action → user authenticates → Claude retries → continues

**Gate protocol:**
1. Recognize it's not a failure - missing auth is expected
2. Stop current task - don't retry repeatedly
3. Create checkpoint:human-action dynamically
4. Provide exact authentication steps
5. Verify authentication works
6. Retry the original task
7. Continue normally

**Key distinction:**
- Pre-planned checkpoint: "I need you to do X" (wrong - Claude should automate)
- Auth gate: "I tried to automate X but need credentials" (correct - unblocks automation)

</authentication_gates>

<automation_reference>

**The rule:** If it has CLI/API, Claude does it. Never ask human to perform automatable work.

## Service CLI Reference

| Service | CLI/API | Key Commands | Auth Gate |
|---------|---------|--------------|-----------|
| Vercel | `vercel` | `--yes`, `env add`, `--prod`, `ls` | `vercel login` |
| Railway | `railway` | `init`, `up`, `variables set` | `railway login` |
| Fly | `fly` | `launch`, `deploy`, `secrets set` | `fly auth login` |
| Stripe | `stripe` + API | `listen`, `trigger`, API calls | API key in .env |
| Supabase | `supabase` | `init`, `link`, `db push`, `gen types` | `supabase login` |
| Upstash | `upstash` | `redis create`, `redis get` | `upstash auth login` |
| PlanetScale | `pscale` | `database create`, `branch create` | `pscale auth login` |
| GitHub | `gh` | `repo create`, `pr create`, `secret set` | `gh auth login` |
| Node | `npm`/`pnpm` | `install`, `run build`, `test`, `run dev` | N/A |
| Xcode | `xcodebuild` | `-project`, `-scheme`, `build`, `test` | N/A |
| Convex | `npx convex` | `dev`, `deploy`, `env set`, `env get` | `npx convex login` |

## Environment Variable Automation

**Env files:** Use Write/Edit tools. Never ask human to create .env manually.

**Dashboard env vars via CLI:**

| Platform | CLI Command | Example |
|----------|-------------|---------|
| Convex | `npx convex env set` | `npx convex env set OPENAI_API_KEY sk-...` |
| Vercel | `vercel env add` | `vercel env add STRIPE_KEY production` |
| Railway | `railway variables set` | `railway variables set API_KEY=value` |
| Fly | `fly secrets set` | `fly secrets set DATABASE_URL=...` |
| Supabase | `supabase secrets set` | `supabase secrets set MY_SECRET=value` |

**Secret collection pattern:**
```xml
<!-- WRONG: Asking user to add env vars in dashboard -->
<task type="checkpoint:human-action">
  <action>Add OPENAI_API_KEY to Convex dashboard</action>
  <instructions>Go to dashboard.convex.dev → Settings → Environment Variables → Add</instructions>
</task>

<!-- RIGHT: Claude asks for value, then adds via CLI -->
<task type="checkpoint:human-action">
  <action>Provide your OpenAI API key</action>
  <instructions>
    I need your OpenAI API key for Convex backend.
    Get it from: https://platform.openai.com/api-keys
    Paste the key (starts with sk-)
  </instructions>
  <verification>I'll add it via `npx convex env set` and verify</verification>
  <resume-signal>Paste your API key</resume-signal>
</task>

<task type="auto">
  <name>Configure OpenAI key in Convex</name>
  <action>Run `npx convex env set OPENAI_API_KEY {user-provided-key}`</action>
  <verify>`npx convex env get OPENAI_API_KEY` returns the key (masked)</verify>
</task>
```

## Dev Server Automation

| Framework | Start Command | Ready Signal | Default URL |
|-----------|---------------|--------------|-------------|
| Next.js | `npm run dev` | "Ready in" or "started server" | http://localhost:3000 |
| Vite | `npm run dev` | "ready in" | http://localhost:5173 |
| Convex | `npx convex dev` | "Convex functions ready" | N/A (backend only) |
| Express | `npm start` | "listening on port" | http://localhost:3000 |
| Django | `python manage.py runserver` | "Starting development server" | http://localhost:8000 |

**Server lifecycle:**
```bash
# Run in background, capture PID
npm run dev &
DEV_SERVER_PID=$!

# Wait for ready (max 30s)
timeout 30 bash -c 'until curl -s localhost:3000 > /dev/null 2>&1; do sleep 1; done'
```

**Port conflicts:** Kill stale process (`lsof -ti:3000 | xargs kill`) or use alternate port (`--port 3001`).

**Server stays running** through checkpoints. Only kill when plan complete, switching to production, or port needed for different service.

## CLI Installation Handling

| CLI | Auto-install? | Command |
|-----|---------------|---------|
| npm/pnpm/yarn | No - ask user | User chooses package manager |
| vercel | Yes | `npm i -g vercel` |
| gh (GitHub) | Yes | `brew install gh` (macOS) or `apt install gh` (Linux) |
| stripe | Yes | `npm i -g stripe` |
| supabase | Yes | `npm i -g supabase` |
| convex | No - use npx | `npx convex` (no install needed) |
| fly | Yes | `brew install flyctl` or curl installer |
| railway | Yes | `npm i -g @railway/cli` |

**Protocol:** Try command → "command not found" → auto-installable? → yes: install silently, retry → no: checkpoint asking user to install.

## Pre-Checkpoint Automation Failures

| Failure | Response |
|---------|----------|
| Server won't start | Check error, fix issue, retry (don't proceed to checkpoint) |
| Port in use | Kill stale process or use alternate port |
| Missing dependency | Run `npm install`, retry |
| Build error | Fix the error first (bug, not checkpoint issue) |
| Auth error | Create auth gate checkpoint |
| Network timeout | Retry with backoff, then checkpoint if persistent |

**Never present a checkpoint with broken verification environment.** If `curl localhost:3000` fails, don't ask user to "visit localhost:3000".

```xml
<!-- WRONG: Checkpoint with broken environment -->
<task type="checkpoint:human-verify">
  <what-built>Dashboard (server failed to start)</what-built>
  <how-to-verify>Visit http://localhost:3000...</how-to-verify>
</task>

<!-- RIGHT: Fix first, then checkpoint -->
<task type="auto">
  <name>Fix server startup issue</name>
  <action>Investigate error, fix root cause, restart server</action>
  <verify>curl http://localhost:3000 returns 200</verify>
</task>

<task type="checkpoint:human-verify">
  <what-built>Dashboard - server running at http://localhost:3000</what-built>
  <how-to-verify>Visit http://localhost:3000/dashboard...</how-to-verify>
</task>
```

## Automatable Quick Reference

| Action | Automatable? | Claude does it? |
|--------|--------------|-----------------|
| Deploy to Vercel | Yes (`vercel`) | YES |
| Create Stripe webhook | Yes (API) | YES |
| Write .env file | Yes (Write tool) | YES |
| Create Upstash DB | Yes (`upstash`) | YES |
| Run tests | Yes (`npm test`) | YES |
| Start dev server | Yes (`npm run dev`) | YES |
| Add env vars to Convex | Yes (`npx convex env set`) | YES |
| Add env vars to Vercel | Yes (`vercel env add`) | YES |
| Seed database | Yes (CLI/API) | YES |
| Click email verification link | No | NO |
| Enter credit card with 3DS | No | NO |
| Complete OAuth in browser | No | NO |
| Visually verify UI looks correct | No | NO |
| Test interactive user flows | No | NO |

</automation_reference>

<writing_guidelines>

**DO:**
- Automate everything with CLI/API before checkpoint
- Be specific: "Visit https://myapp.vercel.app" not "check deployment"
- Number verification steps
- State expected outcomes: "You should see X"
- Provide context: why this checkpoint exists

**DON'T:**
- Ask human to do work Claude can automate ❌
- Assume knowledge: "Configure the usual settings" ❌
- Skip steps: "Set up database" (too vague) ❌
- Mix multiple verifications in one checkpoint ❌

**Placement:**
- **After automation completes** - not before Claude does the work
- **After UI buildout** - before declaring phase complete
- **Before dependent work** - decisions before implementation
- **At integration points** - after configuring external services

**Bad placement:** Before automation ❌ | Too frequent ❌ | Too late (dependent tasks already needed the result) ❌
</writing_guidelines>

<examples>

### Example 1: Database Setup (No Checkpoint Needed)

```xml
<task type="auto">
  <name>Create Upstash Redis database</name>
  <files>.env</files>
  <action>
    1. Run `upstash redis create myapp-cache --region us-east-1`
    2. Capture connection URL from output
    3. Write to .env: UPSTASH_REDIS_URL={url}
    4. Verify connection with test command
  </action>
  <verify>
    - upstash redis list shows database
    - .env contains UPSTASH_REDIS_URL
    - Test connection succeeds
  </verify>
  <done>Redis database created and configured</done>
</task>

<!-- NO CHECKPOINT NEEDED - Claude automated everything and verified programmatically -->
```

### Example 2: Full Auth Flow (Single checkpoint at end)

```xml
<task type="auto">
  <name>Create user schema</name>
  <files>src/db/schema.ts</files>
  <action>Define User, Session, Account tables with Drizzle ORM</action>
  <verify>npm run db:generate succeeds</verify>
</task>

<task type="auto">
  <name>Create auth API routes</name>
  <files>src/app/api/auth/[...nextauth]/route.ts</files>
  <action>Set up NextAuth with GitHub provider, JWT strategy</action>
  <verify>TypeScript compiles, no errors</verify>
</task>

<task type="auto">
  <name>Create login UI</name>
  <files>src/app/login/page.tsx, src/components/LoginButton.tsx</files>
  <action>Create login page with GitHub OAuth button</action>
  <verify>npm run build succeeds</verify>
</task>

<task type="auto">
  <name>Start dev server for auth testing</name>
  <action>Run `npm run dev` in background, wait for ready signal</action>
  <verify>curl http://localhost:3000 returns 200</verify>
  <done>Dev server running at http://localhost:3000</done>
</task>

<!-- ONE checkpoint at end verifies the complete flow -->
<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete authentication flow - dev server running at http://localhost:3000</what-built>
  <how-to-verify>
    1. Visit: http://localhost:3000/login
    2. Click "Sign in with GitHub"
    3. Complete GitHub OAuth flow
    4. Verify: Redirected to /dashboard, user name displayed
    5. Refresh page: Session persists
    6. Click logout: Session cleared
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>
```
</examples>

<anti_patterns>

### ❌ BAD: Asking user to start dev server

```xml
<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Dashboard component</what-built>
  <how-to-verify>
    1. Run: npm run dev
    2. Visit: http://localhost:3000/dashboard
    3. Check layout is correct
  </how-to-verify>
</task>
```

**Why bad:** Claude can run `npm run dev`. User should only visit URLs, not execute commands.

### ✅ GOOD: Claude starts server, user visits

```xml
<task type="auto">
  <name>Start dev server</name>
  <action>Run `npm run dev` in background</action>
  <verify>curl localhost:3000 returns 200</verify>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Dashboard at http://localhost:3000/dashboard (server running)</what-built>
  <how-to-verify>
    Visit http://localhost:3000/dashboard and verify:
    1. Layout matches design
    2. No console errors
  </how-to-verify>
</task>
```

### ❌ BAD: Asking human to deploy / ✅ GOOD: Claude automates

```xml
<!-- BAD: Asking user to deploy via dashboard -->
<task type="checkpoint:human-action" gate="blocking">
  <action>Deploy to Vercel</action>
  <instructions>Visit vercel.com/new → Import repo → Click Deploy → Copy URL</instructions>
</task>

<!-- GOOD: Claude deploys, user verifies -->
<task type="auto">
  <name>Deploy to Vercel</name>
  <action>Run `vercel --yes`. Capture URL.</action>
  <verify>vercel ls shows deployment, curl returns 200</verify>
</task>

<task type="checkpoint:human-verify">
  <what-built>Deployed to {url}</what-built>
  <how-to-verify>Visit {url}, check homepage loads</how-to-verify>
  <resume-signal>Type "approved"</resume-signal>
</task>
```

### ❌ BAD: Too many checkpoints / ✅ GOOD: Single checkpoint

```xml
<!-- BAD: Checkpoint after every task -->
<task type="auto">Create schema</task>
<task type="checkpoint:human-verify">Check schema</task>
<task type="auto">Create API route</task>
<task type="checkpoint:human-verify">Check API</task>
<task type="auto">Create UI form</task>
<task type="checkpoint:human-verify">Check form</task>

<!-- GOOD: One checkpoint at end -->
<task type="auto">Create schema</task>
<task type="auto">Create API route</task>
<task type="auto">Create UI form</task>

<task type="checkpoint:human-verify">
  <what-built>Complete auth flow (schema + API + UI)</what-built>
  <how-to-verify>Test full flow: register, login, access protected page</how-to-verify>
  <resume-signal>Type "approved"</resume-signal>
</task>
```

### ❌ BAD: Vague verification / ✅ GOOD: Specific steps

```xml
<!-- BAD -->
<task type="checkpoint:human-verify">
  <what-built>Dashboard</what-built>
  <how-to-verify>Check it works</how-to-verify>
</task>

<!-- GOOD -->
<task type="checkpoint:human-verify">
  <what-built>Responsive dashboard - server running at http://localhost:3000</what-built>
  <how-to-verify>
    Visit http://localhost:3000/dashboard and verify:
    1. Desktop (>1024px): Sidebar visible, content area fills remaining space
    2. Tablet (768px): Sidebar collapses to icons
    3. Mobile (375px): Sidebar hidden, hamburger menu in header
    4. No horizontal scroll at any size
  </how-to-verify>
  <resume-signal>Type "approved" or describe layout issues</resume-signal>
</task>
```

### ❌ BAD: Asking user to run CLI commands

```xml
<task type="checkpoint:human-action">
  <action>Run database migrations</action>
  <instructions>Run: npx prisma migrate deploy && npx prisma db seed</instructions>
</task>
```

**Why bad:** Claude can run these commands. User should never execute CLI commands.

### ❌ BAD: Asking user to copy values between services

```xml
<task type="checkpoint:human-action">
  <action>Configure webhook URL in Stripe</action>
  <instructions>Copy deployment URL → Stripe Dashboard → Webhooks → Add endpoint → Copy secret → Add to .env</instructions>
</task>
```

**Why bad:** Stripe has an API. Claude should create the webhook via API and write to .env directly.

</anti_patterns>

<summary>

Checkpoints formalize human-in-the-loop points for verification and decisions, not manual work.

**The golden rule:** If Claude CAN automate it, Claude MUST automate it.

**Checkpoint priority:**
1. **checkpoint:human-verify** (90%) - Claude automated everything, human confirms visual/functional correctness
2. **checkpoint:decision** (9%) - Human makes architectural/technology choices
3. **checkpoint:human-action** (1%) - Truly unavoidable manual steps with no API/CLI

**When NOT to use checkpoints:**
- Things Claude can verify programmatically (tests, builds)
- File operations (Claude can read files)
- Code correctness (tests and static analysis)
- Anything automatable via CLI/API
</summary>

</document_content>
</document>
<document index="27">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\continuation-format.md</source>
<document_content>
﻿# Continuation Format

Standard format for presenting next steps after completing a command or workflow.

## Core Structure

```
---

## ▶ Next Up

**{identifier}: {name}** — {one-line description}

`{command to copy-paste}`

<sub>`/clear` first → fresh context window</sub>

---

**Also available:**
- `{alternative option 1}` — description
- `{alternative option 2}` — description

---
```

## Format Rules

1. **Always show what it is** — name + description, never just a command path
2. **Pull context from source** — ROADMAP.md for phases, PLAN.md `<objective>` for plans
3. **Command in inline code** — backticks, easy to copy-paste, renders as clickable link
4. **`/clear` explanation** — always include, keeps it concise but explains why
5. **"Also available" not "Other options"** — sounds more app-like
6. **Visual separators** — `---` above and below to make it stand out

## Variants

### Execute Next Plan

```
---

## ▶ Next Up

**02-03: Refresh Token Rotation** — Add /api/auth/refresh with sliding expiry

`/GSI:execute-phase 2`

<sub>`/clear` first → fresh context window</sub>

---

**Also available:**
- Review plan before executing
- `/GSI:list-phase-assumptions 2` — check assumptions

---
```

### Execute Final Plan in Phase

Add note that this is the last plan and what comes after:

```
---

## ▶ Next Up

**02-03: Refresh Token Rotation** — Add /api/auth/refresh with sliding expiry
<sub>Final plan in Phase 2</sub>

`/GSI:execute-phase 2`

<sub>`/clear` first → fresh context window</sub>

---

**After this completes:**
- Phase 2 → Phase 3 transition
- Next: **Phase 3: Core Features** — User dashboard and settings

---
```

### Plan a Phase

```
---

## ▶ Next Up

**Phase 2: Authentication** — JWT login flow with refresh tokens

`/GSI:plan-phase 2`

<sub>`/clear` first → fresh context window</sub>

---

**Also available:**
- `/GSI:discuss-phase 2` — gather context first
- `/GSI:research-phase 2` — investigate unknowns
- Review roadmap

---
```

### Phase Complete, Ready for Next

Show completion status before next action:

```
---

## ✓ Phase 2 Complete

3/3 plans executed

## ▶ Next Up

**Phase 3: Core Features** — User dashboard, settings, and data export

`/GSI:plan-phase 3`

<sub>`/clear` first → fresh context window</sub>

---

**Also available:**
- `/GSI:discuss-phase 3` — gather context first
- `/GSI:research-phase 3` — investigate unknowns
- Review what Phase 2 built

---
```

### Multiple Equal Options

When there's no clear primary action:

```
---

## ▶ Next Up

**Phase 3: Core Features** — User dashboard, settings, and data export

**To plan directly:** `/GSI:plan-phase 3`

**To discuss context first:** `/GSI:discuss-phase 3`

**To research unknowns:** `/GSI:research-phase 3`

<sub>`/clear` first → fresh context window</sub>

---
```

### Milestone Complete

```
---

## 🎉 Milestone v1.0 Complete

All 4 phases shipped

## ▶ Next Up

**Start v1.1** — questioning → research → requirements → roadmap

`/GSI:new-milestone`

<sub>`/clear` first → fresh context window</sub>

---
```

## Pulling Context

### For phases (from ROADMAP.md):

```markdown
### Phase 2: Authentication
**Goal**: JWT login flow with refresh tokens
```

Extract: `**Phase 2: Authentication** — JWT login flow with refresh tokens`

### For plans (from ROADMAP.md):

```markdown
Plans:
- [ ] 02-03: Add refresh token rotation
```

Or from PLAN.md `<objective>`:

```xml
<objective>
Add refresh token rotation with sliding expiry window.

Purpose: Extend session lifetime without compromising security.
</objective>
```

Extract: `**02-03: Refresh Token Rotation** — Add /api/auth/refresh with sliding expiry`

## Anti-Patterns

### Don't: Command-only (no context)

```
## To Continue

Run `/clear`, then paste:
/GSI:execute-phase 2
```

User has no idea what 02-03 is about.

### Don't: Missing /clear explanation

```
`/GSI:plan-phase 3`

Run /clear first.
```

Doesn't explain why. User might skip it.

### Don't: "Other options" language

```
Other options:
- Review roadmap
```

Sounds like an afterthought. Use "Also available:" instead.

### Don't: Fenced code blocks for commands

```
```
/GSI:plan-phase 3
```
```

Fenced blocks inside templates create nesting ambiguity. Use inline backticks instead.

</document_content>
</document>
<document index="28">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\decimal-phase-calculation.md</source>
<document_content>
﻿# Decimal Phase Calculation

Calculate the next decimal phase number for urgent insertions.

## Using GSI-tools

```bash
# Get next decimal phase after phase 6
node ~/.claude/get-shit-indexed/bin/GSI-tools.js phase next-decimal 6
```

Output:
```json
{
  "found": true,
  "base_phase": "06",
  "next": "06.1",
  "existing": []
}
```

With existing decimals:
```json
{
  "found": true,
  "base_phase": "06",
  "next": "06.3",
  "existing": ["06.1", "06.2"]
}
```

## Extract Values

```bash
DECIMAL_INFO=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js phase next-decimal "${AFTER_PHASE}")
DECIMAL_PHASE=$(echo "$DECIMAL_INFO" | jq -r '.next')
BASE_PHASE=$(echo "$DECIMAL_INFO" | jq -r '.base_phase')
```

Or with --raw flag:
```bash
DECIMAL_PHASE=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js phase next-decimal "${AFTER_PHASE}" --raw)
# Returns just: 06.1
```

## Examples

| Existing Phases | Next Phase |
|-----------------|------------|
| 06 only | 06.1 |
| 06, 06.1 | 06.2 |
| 06, 06.1, 06.2 | 06.3 |
| 06, 06.1, 06.3 (gap) | 06.4 |

## Directory Naming

Decimal phase directories use the full decimal number:

```bash
SLUG=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js generate-slug "$DESCRIPTION" --raw)
PHASE_DIR=".planning/phases/${DECIMAL_PHASE}-${SLUG}"
mkdir -p "$PHASE_DIR"
```

Example: `.planning/phases/06.1-fix-critical-auth-bug/`

</document_content>
</document>
<document index="29">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\git-integration.md</source>
<document_content>
﻿<overview>
Git integration for GSI framework.
</overview>

<core_principle>

**Commit outcomes, not process.**

The git log should read like a changelog of what shipped, not a diary of planning activity.
</core_principle>

<commit_points>

| Event                   | Commit? | Why                                              |
| ----------------------- | ------- | ------------------------------------------------ |
| BRIEF + ROADMAP created | YES     | Project initialization                           |
| PLAN.md created         | NO      | Intermediate - commit with plan completion       |
| RESEARCH.md created     | NO      | Intermediate                                     |
| DISCOVERY.md created    | NO      | Intermediate                                     |
| **Task completed**      | YES     | Atomic unit of work (1 commit per task)         |
| **Plan completed**      | YES     | Metadata commit (SUMMARY + STATE + ROADMAP)     |
| Handoff created         | YES     | WIP state preserved                              |

</commit_points>

<git_check>

```bash
[ -d .git ] && echo "GIT_EXISTS" || echo "NO_GIT"
```

If NO_GIT: Run `git init` silently. GSI projects always get their own repo.
</git_check>

<commit_formats>

<format name="initialization">
## Project Initialization (brief + roadmap together)

```
docs: initialize [project-name] ([N] phases)

[One-liner from PROJECT.md]

Phases:
1. [phase-name]: [goal]
2. [phase-name]: [goal]
3. [phase-name]: [goal]
```

What to commit:

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs: initialize [project-name] ([N] phases)" --files .planning/
```

</format>

<format name="task-completion">
## Task Completion (During Plan Execution)

Each task gets its own commit immediately after completion.

```
{type}({phase}-{plan}): {task-name}

- [Key change 1]
- [Key change 2]
- [Key change 3]
```

**Commit types:**
- `feat` - New feature/functionality
- `fix` - Bug fix
- `test` - Test-only (TDD RED phase)
- `refactor` - Code cleanup (TDD REFACTOR phase)
- `perf` - Performance improvement
- `chore` - Dependencies, config, tooling

**Examples:**

```bash
# Standard task
git add src/api/auth.ts src/types/user.ts
git commit -m "feat(08-02): create user registration endpoint

- POST /auth/register validates email and password
- Checks for duplicate users
- Returns JWT token on success
"

# TDD task - RED phase
git add src/__tests__/jwt.test.ts
git commit -m "test(07-02): add failing test for JWT generation

- Tests token contains user ID claim
- Tests token expires in 1 hour
- Tests signature verification
"

# TDD task - GREEN phase
git add src/utils/jwt.ts
git commit -m "feat(07-02): implement JWT generation

- Uses jose library for signing
- Includes user ID and expiry claims
- Signs with HS256 algorithm
"
```

</format>

<format name="plan-completion">
## Plan Completion (After All Tasks Done)

After all tasks committed, one final metadata commit captures plan completion.

```
docs({phase}-{plan}): complete [plan-name] plan

Tasks completed: [N]/[N]
- [Task 1 name]
- [Task 2 name]
- [Task 3 name]

SUMMARY: .planning/phases/XX-name/{phase}-{plan}-SUMMARY.md
```

What to commit:

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs({phase}-{plan}): complete [plan-name] plan" --files .planning/phases/XX-name/{phase}-{plan}-PLAN.md .planning/phases/XX-name/{phase}-{plan}-SUMMARY.md .planning/STATE.md .planning/ROADMAP.md
```

**Note:** Code files NOT included - already committed per-task.

</format>

<format name="handoff">
## Handoff (WIP)

```
wip: [phase-name] paused at task [X]/[Y]

Current: [task name]
[If blocked:] Blocked: [reason]
```

What to commit:

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "wip: [phase-name] paused at task [X]/[Y]" --files .planning/
```

</format>
</commit_formats>

<example_log>

**Old approach (per-plan commits):**
```
a7f2d1 feat(checkout): Stripe payments with webhook verification
3e9c4b feat(products): catalog with search, filters, and pagination
8a1b2c feat(auth): JWT with refresh rotation using jose
5c3d7e feat(foundation): Next.js 15 + Prisma + Tailwind scaffold
2f4a8d docs: initialize ecommerce-app (5 phases)
```

**New approach (per-task commits):**
```
# Phase 04 - Checkout
1a2b3c docs(04-01): complete checkout flow plan
4d5e6f feat(04-01): add webhook signature verification
7g8h9i feat(04-01): implement payment session creation
0j1k2l feat(04-01): create checkout page component

# Phase 03 - Products
3m4n5o docs(03-02): complete product listing plan
6p7q8r feat(03-02): add pagination controls
9s0t1u feat(03-02): implement search and filters
2v3w4x feat(03-01): create product catalog schema

# Phase 02 - Auth
5y6z7a docs(02-02): complete token refresh plan
8b9c0d feat(02-02): implement refresh token rotation
1e2f3g test(02-02): add failing test for token refresh
4h5i6j docs(02-01): complete JWT setup plan
7k8l9m feat(02-01): add JWT generation and validation
0n1o2p chore(02-01): install jose library

# Phase 01 - Foundation
3q4r5s docs(01-01): complete scaffold plan
6t7u8v feat(01-01): configure Tailwind and globals
9w0x1y feat(01-01): set up Prisma with database
2z3a4b feat(01-01): create Next.js 15 project

# Initialization
5c6d7e docs: initialize ecommerce-app (5 phases)
```

Each plan produces 2-4 commits (tasks + metadata). Clear, granular, bisectable.

</example_log>

<anti_patterns>

**Still don't commit (intermediate artifacts):**
- PLAN.md creation (commit with plan completion)
- RESEARCH.md (intermediate)
- DISCOVERY.md (intermediate)
- Minor planning tweaks
- "Fixed typo in roadmap"

**Do commit (outcomes):**
- Each task completion (feat/fix/test/refactor)
- Plan completion metadata (docs)
- Project initialization (docs)

**Key principle:** Commit working code and shipped outcomes, not planning process.

</anti_patterns>

<commit_strategy_rationale>

## Why Per-Task Commits?

**Context engineering for AI:**
- Git history becomes primary context source for future Claude sessions
- `git log --grep="{phase}-{plan}"` shows all work for a plan
- `git diff <hash>^..<hash>` shows exact changes per task
- Less reliance on parsing SUMMARY.md = more context for actual work

**Failure recovery:**
- Task 1 committed ✅, Task 2 failed ❌
- Claude in next session: sees task 1 complete, can retry task 2
- Can `git reset --hard` to last successful task

**Debugging:**
- `git bisect` finds exact failing task, not just failing plan
- `git blame` traces line to specific task context
- Each commit is independently revertable

**Observability:**
- Solo developer + Claude workflow benefits from granular attribution
- Atomic commits are git best practice
- "Commit noise" irrelevant when consumer is Claude, not humans

</commit_strategy_rationale>

</document_content>
</document>
<document index="30">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\git-planning-commit.md</source>
<document_content>
﻿# Git Planning Commit

Commit planning artifacts using the GSI-tools CLI, which automatically checks `commit_docs` config and gitignore status.

## Commit via CLI

Always use `GSI-tools.js commit` for `.planning/` files — it handles `commit_docs` and gitignore checks automatically:

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs({scope}): {description}" --files .planning/STATE.md .planning/ROADMAP.md
```

The CLI will return `skipped` (with reason) if `commit_docs` is `false` or `.planning/` is gitignored. No manual conditional checks needed.

## Amend previous commit

To fold `.planning/` file changes into the previous commit:

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "" --files .planning/codebase/*.md --amend
```

## Commit Message Patterns

| Command | Scope | Example |
|---------|-------|---------|
| plan-phase | phase | `docs(phase-03): create authentication plans` |
| execute-phase | phase | `docs(phase-03): complete authentication phase` |
| new-milestone | milestone | `docs: start milestone v1.1` |
| remove-phase | chore | `chore: remove phase 17 (dashboard)` |
| insert-phase | phase | `docs: insert phase 16.1 (critical fix)` |
| add-phase | phase | `docs: add phase 07 (settings page)` |

## When to Skip

- `commit_docs: false` in config
- `.planning/` is gitignored
- No changes to commit (check with `git status --porcelain .planning/`)

</document_content>
</document>
<document index="31">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\model-profile-resolution.md</source>
<document_content>
﻿# Model Profile Resolution

Resolve model profile once at the start of orchestration, then use it for all Task spawns.

## Resolution Pattern

```bash
MODEL_PROFILE=$(cat .planning/config.json 2>/dev/null | grep -o '"model_profile"[[:space:]]*:[[:space:]]*"[^"]*"' | grep -o '"[^"]*"$' | tr -d '"' || echo "balanced")
```

Default: `balanced` if not set or config missing.

## Lookup Table

@~/.claude/get-shit-indexed/references/model-profiles.md

Look up the agent in the table for the resolved profile. Pass the model parameter to Task calls:

```
Task(
  prompt="...",
  subagent_type="GSI-planner",
  model="{resolved_model}"  # e.g., "opus" for quality profile
)
```

## Usage

1. Resolve once at orchestration start
2. Store the profile value
3. Look up each agent's model from the table when spawning
4. Pass model parameter to each Task call

</document_content>
</document>
<document index="32">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\model-profiles.md</source>
<document_content>
﻿# Model Profiles

Model profiles control which Claude model each GSI agent uses. This allows balancing quality vs token spend.

## Profile Definitions

| Agent | `quality` | `balanced` | `budget` |
|-------|-----------|------------|----------|
| GSI-planner | opus | opus | sonnet |
| GSI-roadmapper | opus | sonnet | sonnet |
| GSI-executor | opus | sonnet | sonnet |
| GSI-phase-researcher | opus | sonnet | haiku |
| GSI-project-researcher | opus | sonnet | haiku |
| GSI-research-synthesizer | sonnet | sonnet | haiku |
| GSI-debugger | opus | sonnet | sonnet |
| GSI-codebase-mapper | sonnet | haiku | haiku |
| GSI-verifier | sonnet | sonnet | haiku |
| GSI-plan-checker | sonnet | sonnet | haiku |
| GSI-integration-checker | sonnet | sonnet | haiku |

## Profile Philosophy

**quality** - Maximum reasoning power
- Opus for all decision-making agents
- Sonnet for read-only verification
- Use when: quota available, critical architecture work

**balanced** (default) - Smart allocation
- Opus only for planning (where architecture decisions happen)
- Sonnet for execution and research (follows explicit instructions)
- Sonnet for verification (needs reasoning, not just pattern matching)
- Use when: normal development, good balance of quality and cost

**budget** - Minimal Opus usage
- Sonnet for anything that writes code
- Haiku for research and verification
- Use when: conserving quota, high-volume work, less critical phases

## Resolution Logic

Orchestrators resolve model before spawning:

```
1. Read .planning/config.json
2. Get model_profile (default: "balanced")
3. Look up agent in table above
4. Pass model parameter to Task call
```

## Switching Profiles

Runtime: `/GSI:set-profile <profile>`

Per-project default: Set in `.planning/config.json`:
```json
{
  "model_profile": "balanced"
}
```

## Design Rationale

**Why Opus for GSI-planner?**
Planning involves architecture decisions, goal decomposition, and task design. This is where model quality has the highest impact.

**Why Sonnet for GSI-executor?**
Executors follow explicit PLAN.md instructions. The plan already contains the reasoning; execution is implementation.

**Why Sonnet (not Haiku) for verifiers in balanced?**
Verification requires goal-backward reasoning - checking if code *delivers* what the phase promised, not just pattern matching. Sonnet handles this well; Haiku may miss subtle gaps.

**Why Haiku for GSI-codebase-mapper?**
Read-only exploration and pattern extraction. No reasoning required, just structured output from file contents.

</document_content>
</document>
<document index="33">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\phase-argument-parsing.md</source>
<document_content>
﻿# Phase Argument Parsing

Parse and normalize phase arguments for commands that operate on phases.

## Extraction

From `$ARGUMENTS`:
- Extract phase number (first numeric argument)
- Extract flags (prefixed with `--`)
- Remaining text is description (for insert/add commands)

## Using GSI-tools

The `find-phase` command handles normalization and validation in one step:

```bash
PHASE_INFO=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js find-phase "${PHASE}")
```

Returns JSON with:
- `found`: true/false
- `directory`: Full path to phase directory
- `phase_number`: Normalized number (e.g., "06", "06.1")
- `phase_name`: Name portion (e.g., "foundation")
- `plans`: Array of PLAN.md files
- `summaries`: Array of SUMMARY.md files

## Manual Normalization (Legacy)

Zero-pad integer phases to 2 digits. Preserve decimal suffixes.

```bash
# Normalize phase number
if [[ "$PHASE" =~ ^[0-9]+$ ]]; then
  # Integer: 8 → 08
  PHASE=$(printf "%02d" "$PHASE")
elif [[ "$PHASE" =~ ^([0-9]+)\.([0-9]+)$ ]]; then
  # Decimal: 2.1 → 02.1
  PHASE=$(printf "%02d.%s" "${BASH_REMATCH[1]}" "${BASH_REMATCH[2]}")
fi
```

## Validation

Use `roadmap get-phase` to validate phase exists:

```bash
PHASE_CHECK=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js roadmap get-phase "${PHASE}")
if [ "$(echo "$PHASE_CHECK" | jq -r '.found')" = "false" ]; then
  echo "ERROR: Phase ${PHASE} not found in roadmap"
  exit 1
fi
```

## Directory Lookup

Use `find-phase` for directory lookup:

```bash
PHASE_DIR=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js find-phase "${PHASE}" --raw)
```

</document_content>
</document>
<document index="34">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\planning-config.md</source>
<document_content>
﻿<planning_config>

Configuration options for `.planning/` directory behavior.

<config_schema>
```json
"planning": {
  "commit_docs": true,
  "search_gitignored": false
},
"git": {
  "branching_strategy": "none",
  "phase_branch_template": "GSI/phase-{phase}-{slug}",
  "milestone_branch_template": "GSI/{milestone}-{slug}"
}
```

| Option | Default | Description |
|--------|---------|-------------|
| `commit_docs` | `true` | Whether to commit planning artifacts to git |
| `search_gitignored` | `false` | Add `--no-ignore` to broad rg searches |
| `git.branching_strategy` | `"none"` | Git branching approach: `"none"`, `"phase"`, or `"milestone"` |
| `git.phase_branch_template` | `"GSI/phase-{phase}-{slug}"` | Branch template for phase strategy |
| `git.milestone_branch_template` | `"GSI/{milestone}-{slug}"` | Branch template for milestone strategy |
</config_schema>

<commit_docs_behavior>

**When `commit_docs: true` (default):**
- Planning files committed normally
- SUMMARY.md, STATE.md, ROADMAP.md tracked in git
- Full history of planning decisions preserved

**When `commit_docs: false`:**
- Skip all `git add`/`git commit` for `.planning/` files
- User must add `.planning/` to `.gitignore`
- Useful for: OSS contributions, client projects, keeping planning private

**Using GSI-tools.js (preferred):**

```bash
# Commit with automatic commit_docs + gitignore checks:
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs: update state" --files .planning/STATE.md

# Load config via state load (returns JSON):
INIT=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js state load)
# commit_docs is available in the JSON output

# Or use init commands which include commit_docs:
INIT=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js init execute-phase "1")
# commit_docs is included in all init command outputs
```

**Auto-detection:** If `.planning/` is gitignored, `commit_docs` is automatically `false` regardless of config.json. This prevents git errors when users have `.planning/` in `.gitignore`.

**Commit via CLI (handles checks automatically):**

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs: update state" --files .planning/STATE.md
```

The CLI checks `commit_docs` config and gitignore status internally — no manual conditionals needed.

</commit_docs_behavior>

<search_behavior>

**When `search_gitignored: false` (default):**
- Standard rg behavior (respects .gitignore)
- Direct path searches work: `rg "pattern" .planning/` finds files
- Broad searches skip gitignored: `rg "pattern"` skips `.planning/`

**When `search_gitignored: true`:**
- Add `--no-ignore` to broad rg searches that should include `.planning/`
- Only needed when searching entire repo and expecting `.planning/` matches

**Note:** Most GSI operations use direct file reads or explicit paths, which work regardless of gitignore status.

</search_behavior>

<setup_uncommitted_mode>

To use uncommitted mode:

1. **Set config:**
   ```json
   "planning": {
     "commit_docs": false,
     "search_gitignored": true
   }
   ```

2. **Add to .gitignore:**
   ```
   .planning/
   ```

3. **Existing tracked files:** If `.planning/` was previously tracked:
   ```bash
   git rm -r --cached .planning/
   git commit -m "chore: stop tracking planning docs"
   ```

</setup_uncommitted_mode>

<branching_strategy_behavior>

**Branching Strategies:**

| Strategy | When branch created | Branch scope | Merge point |
|----------|---------------------|--------------|-------------|
| `none` | Never | N/A | N/A |
| `phase` | At `execute-phase` start | Single phase | User merges after phase |
| `milestone` | At first `execute-phase` of milestone | Entire milestone | At `complete-milestone` |

**When `git.branching_strategy: "none"` (default):**
- All work commits to current branch
- Standard GSI behavior

**When `git.branching_strategy: "phase"`:**
- `execute-phase` creates/switches to a branch before execution
- Branch name from `phase_branch_template` (e.g., `GSI/phase-03-authentication`)
- All plan commits go to that branch
- User merges branches manually after phase completion
- `complete-milestone` offers to merge all phase branches

**When `git.branching_strategy: "milestone"`:**
- First `execute-phase` of milestone creates the milestone branch
- Branch name from `milestone_branch_template` (e.g., `GSI/v1.0-mvp`)
- All phases in milestone commit to same branch
- `complete-milestone` offers to merge milestone branch to main

**Template variables:**

| Variable | Available in | Description |
|----------|--------------|-------------|
| `{phase}` | phase_branch_template | Zero-padded phase number (e.g., "03") |
| `{slug}` | Both | Lowercase, hyphenated name |
| `{milestone}` | milestone_branch_template | Milestone version (e.g., "v1.0") |

**Checking the config:**

Use `init execute-phase` which returns all config as JSON:
```bash
INIT=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js init execute-phase "1")
# JSON output includes: branching_strategy, phase_branch_template, milestone_branch_template
```

Or use `state load` for the config values:
```bash
INIT=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js state load)
# Parse branching_strategy, phase_branch_template, milestone_branch_template from JSON
```

**Branch creation:**

```bash
# For phase strategy
if [ "$BRANCHING_STRATEGY" = "phase" ]; then
  PHASE_SLUG=$(echo "$PHASE_NAME" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9]/-/g' | sed 's/--*/-/g' | sed 's/^-//;s/-$//')
  BRANCH_NAME=$(echo "$PHASE_BRANCH_TEMPLATE" | sed "s/{phase}/$PADDED_PHASE/g" | sed "s/{slug}/$PHASE_SLUG/g")
  git checkout -b "$BRANCH_NAME" 2>/dev/null || git checkout "$BRANCH_NAME"
fi

# For milestone strategy
if [ "$BRANCHING_STRATEGY" = "milestone" ]; then
  MILESTONE_SLUG=$(echo "$MILESTONE_NAME" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9]/-/g' | sed 's/--*/-/g' | sed 's/^-//;s/-$//')
  BRANCH_NAME=$(echo "$MILESTONE_BRANCH_TEMPLATE" | sed "s/{milestone}/$MILESTONE_VERSION/g" | sed "s/{slug}/$MILESTONE_SLUG/g")
  git checkout -b "$BRANCH_NAME" 2>/dev/null || git checkout "$BRANCH_NAME"
fi
```

**Merge options at complete-milestone:**

| Option | Git command | Result |
|--------|-------------|--------|
| Squash merge (recommended) | `git merge --squash` | Single clean commit per branch |
| Merge with history | `git merge --no-ff` | Preserves all individual commits |
| Delete without merging | `git branch -D` | Discard branch work |
| Keep branches | (none) | Manual handling later |

Squash merge is recommended — keeps main branch history clean while preserving the full development history in the branch (until deleted).

**Use cases:**

| Strategy | Best for |
|----------|----------|
| `none` | Solo development, simple projects |
| `phase` | Code review per phase, granular rollback, team collaboration |
| `milestone` | Release branches, staging environments, PR per version |

</branching_strategy_behavior>

</planning_config>

</document_content>
</document>
<document index="35">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\questioning.md</source>
<document_content>
<questioning_guide>

Project initialization is dream extraction, not requirements gathering. You're helping the user discover and articulate what they want to build. This isn't a contract negotiation — it's collaborative thinking.

<philosophy>

**You are a thinking partner, not an interviewer.**

The user often has a fuzzy idea. Your job is to help them sharpen it. Ask questions that make them think "oh, I hadn't considered that" or "yes, that's exactly what I mean."

Don't interrogate. Collaborate. Don't follow a script. Follow the thread.

</philosophy>

<the_goal>

By the end of questioning, you need enough clarity to write a PROJECT.md that downstream phases can act on:

- **Research** needs: what domain to research, what the user already knows, what unknowns exist
- **Requirements** needs: clear enough vision to scope v1 features
- **Roadmap** needs: clear enough vision to decompose into phases, what "done" looks like
- **plan-phase** needs: specific requirements to break into tasks, context for implementation choices
- **execute-phase** needs: success criteria to verify against, the "why" behind requirements

A vague PROJECT.md forces every downstream phase to guess. The cost compounds.

</the_goal>

<how_to_question>

**Start open.** Let them dump their mental model. Don't interrupt with structure.

**Follow energy.** Whatever they emphasized, dig into that. What excited them? What problem sparked this?

**Challenge vagueness.** Never accept fuzzy answers. "Good" means what? "Users" means who? "Simple" means how?

**Make the abstract concrete.** "Walk me through using this." "What does that actually look like?"

**Clarify ambiguity.** "When you say Z, do you mean A or B?" "You mentioned X — tell me more."

**Know when to stop.** When you understand what they want, why they want it, who it's for, and what done looks like — offer to proceed.

</how_to_question>

<question_types>

Use these as inspiration, not a checklist. Pick what's relevant to the thread.

**Motivation — why this exists:**
- "What prompted this?"
- "What are you doing today that this replaces?"
- "What would you do if this existed?"

**Concreteness — what it actually is:**
- "Walk me through using this"
- "You said X — what does that actually look like?"
- "Give me an example"

**Clarification — what they mean:**
- "When you say Z, do you mean A or B?"
- "You mentioned X — tell me more about that"

**Success — how you'll know it's working:**
- "How will you know this is working?"
- "What does done look like?"

</question_types>

<using_askuserquestion>

Use AskUserQuestion to help users think by presenting concrete options to react to.

**Good options:**
- Interpretations of what they might mean
- Specific examples to confirm or deny
- Concrete choices that reveal priorities

**Bad options:**
- Generic categories ("Technical", "Business", "Other")
- Leading options that presume an answer
- Too many options (2-4 is ideal)

**Example — vague answer:**
User says "it should be fast"

- header: "Fast"
- question: "Fast how?"
- options: ["Sub-second response", "Handles large datasets", "Quick to build", "Let me explain"]

**Example — following a thread:**
User mentions "frustrated with current tools"

- header: "Frustration"
- question: "What specifically frustrates you?"
- options: ["Too many clicks", "Missing features", "Unreliable", "Let me explain"]

</using_askuserquestion>

<context_checklist>

Use this as a **background checklist**, not a conversation structure. Check these mentally as you go. If gaps remain, weave questions naturally.

- [ ] What they're building (concrete enough to explain to a stranger)
- [ ] Why it needs to exist (the problem or desire driving it)
- [ ] Who it's for (even if just themselves)
- [ ] What "done" looks like (observable outcomes)

Four things. If they volunteer more, capture it.

</context_checklist>

<decision_gate>

When you could write a clear PROJECT.md, offer to proceed:

- header: "Ready?"
- question: "I think I understand what you're after. Ready to create PROJECT.md?"
- options:
  - "Create PROJECT.md" — Let's move forward
  - "Keep exploring" — I want to share more / ask me more

If "Keep exploring" — ask what they want to add or identify gaps and probe naturally.

Loop until "Create PROJECT.md" selected.

</decision_gate>

<anti_patterns>

- **Checklist walking** — Going through domains regardless of what they said
- **Canned questions** — "What's your core value?" "What's out of scope?" regardless of context
- **Corporate speak** — "What are your success criteria?" "Who are your stakeholders?"
- **Interrogation** — Firing questions without building on answers
- **Rushing** — Minimizing questions to get to "the work"
- **Shallow acceptance** — Taking vague answers without probing
- **Premature constraints** — Asking about tech stack before understanding the idea
- **User skills** — NEVER ask about user's technical experience. Claude builds.

</anti_patterns>

</questioning_guide>

</document_content>
</document>
<document index="36">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\tdd.md</source>
<document_content>
<overview>
TDD is about design quality, not coverage metrics. The red-green-refactor cycle forces you to think about behavior before implementation, producing cleaner interfaces and more testable code.

**Principle:** If you can describe the behavior as `expect(fn(input)).toBe(output)` before writing `fn`, TDD improves the result.

**Key insight:** TDD work is fundamentally heavier than standard tasks—it requires 2-3 execution cycles (RED → GREEN → REFACTOR), each with file reads, test runs, and potential debugging. TDD features get dedicated plans to ensure full context is available throughout the cycle.
</overview>

<when_to_use_tdd>
## When TDD Improves Quality

**TDD candidates (create a TDD plan):**
- Business logic with defined inputs/outputs
- API endpoints with request/response contracts
- Data transformations, parsing, formatting
- Validation rules and constraints
- Algorithms with testable behavior
- State machines and workflows
- Utility functions with clear specifications

**Skip TDD (use standard plan with `type="auto"` tasks):**
- UI layout, styling, visual components
- Configuration changes
- Glue code connecting existing components
- One-off scripts and migrations
- Simple CRUD with no business logic
- Exploratory prototyping

**Heuristic:** Can you write `expect(fn(input)).toBe(output)` before writing `fn`?
→ Yes: Create a TDD plan
→ No: Use standard plan, add tests after if needed
</when_to_use_tdd>

<tdd_plan_structure>
## TDD Plan Structure

Each TDD plan implements **one feature** through the full RED-GREEN-REFACTOR cycle.

```markdown
---
phase: XX-name
plan: NN
type: tdd
---

<objective>
[What feature and why]
Purpose: [Design benefit of TDD for this feature]
Output: [Working, tested feature]
</objective>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@relevant/source/files.ts
</context>

<feature>
  <name>[Feature name]</name>
  <files>[source file, test file]</files>
  <behavior>
    [Expected behavior in testable terms]
    Cases: input → expected output
  </behavior>
  <implementation>[How to implement once tests pass]</implementation>
</feature>

<verification>
[Test command that proves feature works]
</verification>

<success_criteria>
- Failing test written and committed
- Implementation passes test
- Refactor complete (if needed)
- All 2-3 commits present
</success_criteria>

<output>
After completion, create SUMMARY.md with:
- RED: What test was written, why it failed
- GREEN: What implementation made it pass
- REFACTOR: What cleanup was done (if any)
- Commits: List of commits produced
</output>
```

**One feature per TDD plan.** If features are trivial enough to batch, they're trivial enough to skip TDD—use a standard plan and add tests after.
</tdd_plan_structure>

<execution_flow>
## Red-Green-Refactor Cycle

**RED - Write failing test:**
1. Create test file following project conventions
2. Write test describing expected behavior (from `<behavior>` element)
3. Run test - it MUST fail
4. If test passes: feature exists or test is wrong. Investigate.
5. Commit: `test({phase}-{plan}): add failing test for [feature]`

**GREEN - Implement to pass:**
1. Write minimal code to make test pass
2. No cleverness, no optimization - just make it work
3. Run test - it MUST pass
4. Commit: `feat({phase}-{plan}): implement [feature]`

**REFACTOR (if needed):**
1. Clean up implementation if obvious improvements exist
2. Run tests - MUST still pass
3. Only commit if changes made: `refactor({phase}-{plan}): clean up [feature]`

**Result:** Each TDD plan produces 2-3 atomic commits.
</execution_flow>

<test_quality>
## Good Tests vs Bad Tests

**Test behavior, not implementation:**
- Good: "returns formatted date string"
- Bad: "calls formatDate helper with correct params"
- Tests should survive refactors

**One concept per test:**
- Good: Separate tests for valid input, empty input, malformed input
- Bad: Single test checking all edge cases with multiple assertions

**Descriptive names:**
- Good: "should reject empty email", "returns null for invalid ID"
- Bad: "test1", "handles error", "works correctly"

**No implementation details:**
- Good: Test public API, observable behavior
- Bad: Mock internals, test private methods, assert on internal state
</test_quality>

<framework_setup>
## Test Framework Setup (If None Exists)

When executing a TDD plan but no test framework is configured, set it up as part of the RED phase:

**1. Detect project type:**
```bash
# JavaScript/TypeScript
if [ -f package.json ]; then echo "node"; fi

# Python
if [ -f requirements.txt ] || [ -f pyproject.toml ]; then echo "python"; fi

# Go
if [ -f go.mod ]; then echo "go"; fi

# Rust
if [ -f Cargo.toml ]; then echo "rust"; fi
```

**2. Install minimal framework:**
| Project | Framework | Install |
|---------|-----------|---------|
| Node.js | Jest | `npm install -D jest @types/jest ts-jest` |
| Node.js (Vite) | Vitest | `npm install -D vitest` |
| Python | pytest | `pip install pytest` |
| Go | testing | Built-in |
| Rust | cargo test | Built-in |

**3. Create config if needed:**
- Jest: `jest.config.js` with ts-jest preset
- Vitest: `vitest.config.ts` with test globals
- pytest: `pytest.ini` or `pyproject.toml` section

**4. Verify setup:**
```bash
# Run empty test suite - should pass with 0 tests
npm test  # Node
pytest    # Python
go test ./...  # Go
cargo test    # Rust
```

**5. Create first test file:**
Follow project conventions for test location:
- `*.test.ts` / `*.spec.ts` next to source
- `__tests__/` directory
- `tests/` directory at root

Framework setup is a one-time cost included in the first TDD plan's RED phase.
</framework_setup>

<error_handling>
## Error Handling

**Test doesn't fail in RED phase:**
- Feature may already exist - investigate
- Test may be wrong (not testing what you think)
- Fix before proceeding

**Test doesn't pass in GREEN phase:**
- Debug implementation
- Don't skip to refactor
- Keep iterating until green

**Tests fail in REFACTOR phase:**
- Undo refactor
- Commit was premature
- Refactor in smaller steps

**Unrelated tests break:**
- Stop and investigate
- May indicate coupling issue
- Fix before proceeding
</error_handling>

<commit_pattern>
## Commit Pattern for TDD Plans

TDD plans produce 2-3 atomic commits (one per phase):

```
test(08-02): add failing test for email validation

- Tests valid email formats accepted
- Tests invalid formats rejected
- Tests empty input handling

feat(08-02): implement email validation

- Regex pattern matches RFC 5322
- Returns boolean for validity
- Handles edge cases (empty, null)

refactor(08-02): extract regex to constant (optional)

- Moved pattern to EMAIL_REGEX constant
- No behavior changes
- Tests still pass
```

**Comparison with standard plans:**
- Standard plans: 1 commit per task, 2-4 commits per plan
- TDD plans: 2-3 commits for single feature

Both follow same format: `{type}({phase}-{plan}): {description}`

**Benefits:**
- Each commit independently revertable
- Git bisect works at commit level
- Clear history showing TDD discipline
- Consistent with overall commit strategy
</commit_pattern>

<context_budget>
## Context Budget

TDD plans target **~40% context usage** (lower than standard plans' ~50%).

Why lower:
- RED phase: write test, run test, potentially debug why it didn't fail
- GREEN phase: implement, run test, potentially iterate on failures
- REFACTOR phase: modify code, run tests, verify no regressions

Each phase involves reading files, running commands, analyzing output. The back-and-forth is inherently heavier than linear task execution.

Single feature focus ensures full quality throughout the cycle.
</context_budget>

</document_content>
</document>
<document index="37">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\ui-brand.md</source>
<document_content>
﻿<ui_patterns>

Visual patterns for user-facing GSI output. Orchestrators @-reference this file.

## Stage Banners

Use for major workflow transitions.

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► {STAGE NAME}
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**Stage names (uppercase):**
- `QUESTIONING`
- `RESEARCHING`
- `DEFINING REQUIREMENTS`
- `CREATING ROADMAP`
- `PLANNING PHASE {N}`
- `EXECUTING WAVE {N}`
- `VERIFYING`
- `PHASE {N} COMPLETE ✓`
- `MILESTONE COMPLETE 🎉`

---

## Checkpoint Boxes

User action required. 62-character width.

```
╔══════════════════════════════════════════════════════════════╗
║  CHECKPOINT: {Type}                                          ║
╚══════════════════════════════════════════════════════════════╝

{Content}

──────────────────────────────────────────────────────────────
→ {ACTION PROMPT}
──────────────────────────────────────────────────────────────
```

**Types:**
- `CHECKPOINT: Verification Required` → `→ Type "approved" or describe issues`
- `CHECKPOINT: Decision Required` → `→ Select: option-a / option-b`
- `CHECKPOINT: Action Required` → `→ Type "done" when complete`

---

## Status Symbols

```
✓  Complete / Passed / Verified
✗  Failed / Missing / Blocked
◆  In Progress
○  Pending
⚡ Auto-approved
⚠  Warning
🎉 Milestone complete (only in banner)
```

---

## Progress Display

**Phase/milestone level:**
```
Progress: ████████░░ 80%
```

**Task level:**
```
Tasks: 2/4 complete
```

**Plan level:**
```
Plans: 3/5 complete
```

---

## Spawning Indicators

```
◆ Spawning researcher...

◆ Spawning 4 researchers in parallel...
  → Stack research
  → Features research
  → Architecture research
  → Pitfalls research

✓ Researcher complete: STACK.md written
```

---

## Next Up Block

Always at end of major completions.

```
───────────────────────────────────────────────────────────────

## ▶ Next Up

**{Identifier}: {Name}** — {one-line description}

`{copy-paste command}`

<sub>`/clear` first → fresh context window</sub>

───────────────────────────────────────────────────────────────

**Also available:**
- `/GSI:alternative-1` — description
- `/GSI:alternative-2` — description

───────────────────────────────────────────────────────────────
```

---

## Error Box

```
╔══════════════════════════════════════════════════════════════╗
║  ERROR                                                       ║
╚══════════════════════════════════════════════════════════════╝

{Error description}

**To fix:** {Resolution steps}
```

---

## Tables

```
| Phase | Status | Plans | Progress |
|-------|--------|-------|----------|
| 1     | ✓      | 3/3   | 100%     |
| 2     | ◆      | 1/4   | 25%      |
| 3     | ○      | 0/2   | 0%       |
```

---

## Anti-Patterns

- Varying box/banner widths
- Mixing banner styles (`===`, `---`, `***`)
- Skipping `GSI ►` prefix in banners
- Random emoji (`🚀`, `✨`, `💫`)
- Missing Next Up block after completions

</ui_patterns>

</document_content>
</document>
<document index="38">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\verification-patterns.md</source>
<document_content>
﻿# Verification Patterns

How to verify different types of artifacts are real implementations, not stubs or placeholders.

<core_principle>
**Existence ≠ Implementation**

A file existing does not mean the feature works. Verification must check:
1. **Exists** - File is present at expected path
2. **Substantive** - Content is real implementation, not placeholder
3. **Wired** - Connected to the rest of the system
4. **Functional** - Actually works when invoked

Levels 1-3 can be checked programmatically. Level 4 often requires human verification.
</core_principle>

<stub_detection>

## Universal Stub Patterns

These patterns indicate placeholder code regardless of file type:

**Comment-based stubs:**
```bash
# Grep patterns for stub comments
grep -E "(TODO|FIXME|XXX|HACK|PLACEHOLDER)" "$file"
grep -E "implement|add later|coming soon|will be" "$file" -i
grep -E "// \.\.\.|/\* \.\.\. \*/|# \.\.\." "$file"
```

**Placeholder text in output:**
```bash
# UI placeholder patterns
grep -E "placeholder|lorem ipsum|coming soon|under construction" "$file" -i
grep -E "sample|example|test data|dummy" "$file" -i
grep -E "\[.*\]|<.*>|\{.*\}" "$file"  # Template brackets left in
```

**Empty or trivial implementations:**
```bash
# Functions that do nothing
grep -E "return null|return undefined|return \{\}|return \[\]" "$file"
grep -E "pass$|\.\.\.|\bnothing\b" "$file"
grep -E "console\.(log|warn|error).*only" "$file"  # Log-only functions
```

**Hardcoded values where dynamic expected:**
```bash
# Hardcoded IDs, counts, or content
grep -E "id.*=.*['\"].*['\"]" "$file"  # Hardcoded string IDs
grep -E "count.*=.*\d+|length.*=.*\d+" "$file"  # Hardcoded counts
grep -E "\\\$\d+\.\d{2}|\d+ items" "$file"  # Hardcoded display values
```

</stub_detection>

<react_components>

## React/Next.js Components

**Existence check:**
```bash
# File exists and exports component
[ -f "$component_path" ] && grep -E "export (default |)function|export const.*=.*\(" "$component_path"
```

**Substantive check:**
```bash
# Returns actual JSX, not placeholder
grep -E "return.*<" "$component_path" | grep -v "return.*null" | grep -v "placeholder" -i

# Has meaningful content (not just wrapper div)
grep -E "<[A-Z][a-zA-Z]+|className=|onClick=|onChange=" "$component_path"

# Uses props or state (not static)
grep -E "props\.|useState|useEffect|useContext|\{.*\}" "$component_path"
```

**Stub patterns specific to React:**
```javascript
// RED FLAGS - These are stubs:
return <div>Component</div>
return <div>Placeholder</div>
return <div>{/* TODO */}</div>
return <p>Coming soon</p>
return null
return <></>

// Also stubs - empty handlers:
onClick={() => {}}
onChange={() => console.log('clicked')}
onSubmit={(e) => e.preventDefault()}  // Only prevents default, does nothing
```

**Wiring check:**
```bash
# Component imports what it needs
grep -E "^import.*from" "$component_path"

# Props are actually used (not just received)
# Look for destructuring or props.X usage
grep -E "\{ .* \}.*props|\bprops\.[a-zA-Z]+" "$component_path"

# API calls exist (for data-fetching components)
grep -E "fetch\(|axios\.|useSWR|useQuery|getServerSideProps|getStaticProps" "$component_path"
```

**Functional verification (human required):**
- Does the component render visible content?
- Do interactive elements respond to clicks?
- Does data load and display?
- Do error states show appropriately?

</react_components>

<api_routes>

## API Routes (Next.js App Router / Express / etc.)

**Existence check:**
```bash
# Route file exists
[ -f "$route_path" ]

# Exports HTTP method handlers (Next.js App Router)
grep -E "export (async )?(function|const) (GET|POST|PUT|PATCH|DELETE)" "$route_path"

# Or Express-style handlers
grep -E "\.(get|post|put|patch|delete)\(" "$route_path"
```

**Substantive check:**
```bash
# Has actual logic, not just return statement
wc -l "$route_path"  # More than 10-15 lines suggests real implementation

# Interacts with data source
grep -E "prisma\.|db\.|mongoose\.|sql|query|find|create|update|delete" "$route_path" -i

# Has error handling
grep -E "try|catch|throw|error|Error" "$route_path"

# Returns meaningful response
grep -E "Response\.json|res\.json|res\.send|return.*\{" "$route_path" | grep -v "message.*not implemented" -i
```

**Stub patterns specific to API routes:**
```typescript
// RED FLAGS - These are stubs:
export async function POST() {
  return Response.json({ message: "Not implemented" })
}

export async function GET() {
  return Response.json([])  // Empty array with no DB query
}

export async function PUT() {
  return new Response()  // Empty response
}

// Console log only:
export async function POST(req) {
  console.log(await req.json())
  return Response.json({ ok: true })
}
```

**Wiring check:**
```bash
# Imports database/service clients
grep -E "^import.*prisma|^import.*db|^import.*client" "$route_path"

# Actually uses request body (for POST/PUT)
grep -E "req\.json\(\)|req\.body|request\.json\(\)" "$route_path"

# Validates input (not just trusting request)
grep -E "schema\.parse|validate|zod|yup|joi" "$route_path"
```

**Functional verification (human or automated):**
- Does GET return real data from database?
- Does POST actually create a record?
- Does error response have correct status code?
- Are auth checks actually enforced?

</api_routes>

<database_schema>

## Database Schema (Prisma / Drizzle / SQL)

**Existence check:**
```bash
# Schema file exists
[ -f "prisma/schema.prisma" ] || [ -f "drizzle/schema.ts" ] || [ -f "src/db/schema.sql" ]

# Model/table is defined
grep -E "^model $model_name|CREATE TABLE $table_name|export const $table_name" "$schema_path"
```

**Substantive check:**
```bash
# Has expected fields (not just id)
grep -A 20 "model $model_name" "$schema_path" | grep -E "^\s+\w+\s+\w+"

# Has relationships if expected
grep -E "@relation|REFERENCES|FOREIGN KEY" "$schema_path"

# Has appropriate field types (not all String)
grep -A 20 "model $model_name" "$schema_path" | grep -E "Int|DateTime|Boolean|Float|Decimal|Json"
```

**Stub patterns specific to schemas:**
```prisma
// RED FLAGS - These are stubs:
model User {
  id String @id
  // TODO: add fields
}

model Message {
  id        String @id
  content   String  // Only one real field
}

// Missing critical fields:
model Order {
  id     String @id
  // No: userId, items, total, status, createdAt
}
```

**Wiring check:**
```bash
# Migrations exist and are applied
ls prisma/migrations/ 2>/dev/null | wc -l  # Should be > 0
npx prisma migrate status 2>/dev/null | grep -v "pending"

# Client is generated
[ -d "node_modules/.prisma/client" ]
```

**Functional verification:**
```bash
# Can query the table (automated)
npx prisma db execute --stdin <<< "SELECT COUNT(*) FROM $table_name"
```

</database_schema>

<hooks_utilities>

## Custom Hooks and Utilities

**Existence check:**
```bash
# File exists and exports function
[ -f "$hook_path" ] && grep -E "export (default )?(function|const)" "$hook_path"
```

**Substantive check:**
```bash
# Hook uses React hooks (for custom hooks)
grep -E "useState|useEffect|useCallback|useMemo|useRef|useContext" "$hook_path"

# Has meaningful return value
grep -E "return \{|return \[" "$hook_path"

# More than trivial length
[ $(wc -l < "$hook_path") -gt 10 ]
```

**Stub patterns specific to hooks:**
```typescript
// RED FLAGS - These are stubs:
export function useAuth() {
  return { user: null, login: () => {}, logout: () => {} }
}

export function useCart() {
  const [items, setItems] = useState([])
  return { items, addItem: () => console.log('add'), removeItem: () => {} }
}

// Hardcoded return:
export function useUser() {
  return { name: "Test User", email: "test@example.com" }
}
```

**Wiring check:**
```bash
# Hook is actually imported somewhere
grep -r "import.*$hook_name" src/ --include="*.tsx" --include="*.ts" | grep -v "$hook_path"

# Hook is actually called
grep -r "$hook_name()" src/ --include="*.tsx" --include="*.ts" | grep -v "$hook_path"
```

</hooks_utilities>

<environment_config>

## Environment Variables and Configuration

**Existence check:**
```bash
# .env file exists
[ -f ".env" ] || [ -f ".env.local" ]

# Required variable is defined
grep -E "^$VAR_NAME=" .env .env.local 2>/dev/null
```

**Substantive check:**
```bash
# Variable has actual value (not placeholder)
grep -E "^$VAR_NAME=.+" .env .env.local 2>/dev/null | grep -v "your-.*-here|xxx|placeholder|TODO" -i

# Value looks valid for type:
# - URLs should start with http
# - Keys should be long enough
# - Booleans should be true/false
```

**Stub patterns specific to env:**
```bash
# RED FLAGS - These are stubs:
DATABASE_URL=your-database-url-here
STRIPE_SECRET_KEY=sk_test_xxx
API_KEY=placeholder
NEXT_PUBLIC_API_URL=http://localhost:3000  # Still pointing to localhost in prod
```

**Wiring check:**
```bash
# Variable is actually used in code
grep -r "process\.env\.$VAR_NAME|env\.$VAR_NAME" src/ --include="*.ts" --include="*.tsx"

# Variable is in validation schema (if using zod/etc for env)
grep -E "$VAR_NAME" src/env.ts src/env.mjs 2>/dev/null
```

</environment_config>

<wiring_verification>

## Wiring Verification Patterns

Wiring verification checks that components actually communicate. This is where most stubs hide.

### Pattern: Component → API

**Check:** Does the component actually call the API?

```bash
# Find the fetch/axios call
grep -E "fetch\(['\"].*$api_path|axios\.(get|post).*$api_path" "$component_path"

# Verify it's not commented out
grep -E "fetch\(|axios\." "$component_path" | grep -v "^.*//.*fetch"

# Check the response is used
grep -E "await.*fetch|\.then\(|setData|setState" "$component_path"
```

**Red flags:**
```typescript
// Fetch exists but response ignored:
fetch('/api/messages')  // No await, no .then, no assignment

// Fetch in comment:
// fetch('/api/messages').then(r => r.json()).then(setMessages)

// Fetch to wrong endpoint:
fetch('/api/message')  // Typo - should be /api/messages
```

### Pattern: API → Database

**Check:** Does the API route actually query the database?

```bash
# Find the database call
grep -E "prisma\.$model|db\.query|Model\.find" "$route_path"

# Verify it's awaited
grep -E "await.*prisma|await.*db\." "$route_path"

# Check result is returned
grep -E "return.*json.*data|res\.json.*result" "$route_path"
```

**Red flags:**
```typescript
// Query exists but result not returned:
await prisma.message.findMany()
return Response.json({ ok: true })  // Returns static, not query result

// Query not awaited:
const messages = prisma.message.findMany()  // Missing await
return Response.json(messages)  // Returns Promise, not data
```

### Pattern: Form → Handler

**Check:** Does the form submission actually do something?

```bash
# Find onSubmit handler
grep -E "onSubmit=\{|handleSubmit" "$component_path"

# Check handler has content
grep -A 10 "onSubmit.*=" "$component_path" | grep -E "fetch|axios|mutate|dispatch"

# Verify not just preventDefault
grep -A 5 "onSubmit" "$component_path" | grep -v "only.*preventDefault" -i
```

**Red flags:**
```typescript
// Handler only prevents default:
onSubmit={(e) => e.preventDefault()}

// Handler only logs:
const handleSubmit = (data) => {
  console.log(data)
}

// Handler is empty:
onSubmit={() => {}}
```

### Pattern: State → Render

**Check:** Does the component render state, not hardcoded content?

```bash
# Find state usage in JSX
grep -E "\{.*messages.*\}|\{.*data.*\}|\{.*items.*\}" "$component_path"

# Check map/render of state
grep -E "\.map\(|\.filter\(|\.reduce\(" "$component_path"

# Verify dynamic content
grep -E "\{[a-zA-Z_]+\." "$component_path"  # Variable interpolation
```

**Red flags:**
```tsx
// Hardcoded instead of state:
return <div>
  <p>Message 1</p>
  <p>Message 2</p>
</div>

// State exists but not rendered:
const [messages, setMessages] = useState([])
return <div>No messages</div>  // Always shows "no messages"

// Wrong state rendered:
const [messages, setMessages] = useState([])
return <div>{otherData.map(...)}</div>  // Uses different data
```

</wiring_verification>

<verification_checklist>

## Quick Verification Checklist

For each artifact type, run through this checklist:

### Component Checklist
- [ ] File exists at expected path
- [ ] Exports a function/const component
- [ ] Returns JSX (not null/empty)
- [ ] No placeholder text in render
- [ ] Uses props or state (not static)
- [ ] Event handlers have real implementations
- [ ] Imports resolve correctly
- [ ] Used somewhere in the app

### API Route Checklist
- [ ] File exists at expected path
- [ ] Exports HTTP method handlers
- [ ] Handlers have more than 5 lines
- [ ] Queries database or service
- [ ] Returns meaningful response (not empty/placeholder)
- [ ] Has error handling
- [ ] Validates input
- [ ] Called from frontend

### Schema Checklist
- [ ] Model/table defined
- [ ] Has all expected fields
- [ ] Fields have appropriate types
- [ ] Relationships defined if needed
- [ ] Migrations exist and applied
- [ ] Client generated

### Hook/Utility Checklist
- [ ] File exists at expected path
- [ ] Exports function
- [ ] Has meaningful implementation (not empty returns)
- [ ] Used somewhere in the app
- [ ] Return values consumed

### Wiring Checklist
- [ ] Component → API: fetch/axios call exists and uses response
- [ ] API → Database: query exists and result returned
- [ ] Form → Handler: onSubmit calls API/mutation
- [ ] State → Render: state variables appear in JSX

</verification_checklist>

<automated_verification_script>

## Automated Verification Approach

For the verification subagent, use this pattern:

```bash
# 1. Check existence
check_exists() {
  [ -f "$1" ] && echo "EXISTS: $1" || echo "MISSING: $1"
}

# 2. Check for stub patterns
check_stubs() {
  local file="$1"
  local stubs=$(grep -c -E "TODO|FIXME|placeholder|not implemented" "$file" 2>/dev/null || echo 0)
  [ "$stubs" -gt 0 ] && echo "STUB_PATTERNS: $stubs in $file"
}

# 3. Check wiring (component calls API)
check_wiring() {
  local component="$1"
  local api_path="$2"
  grep -q "$api_path" "$component" && echo "WIRED: $component → $api_path" || echo "NOT_WIRED: $component → $api_path"
}

# 4. Check substantive (more than N lines, has expected patterns)
check_substantive() {
  local file="$1"
  local min_lines="$2"
  local pattern="$3"
  local lines=$(wc -l < "$file" 2>/dev/null || echo 0)
  local has_pattern=$(grep -c -E "$pattern" "$file" 2>/dev/null || echo 0)
  [ "$lines" -ge "$min_lines" ] && [ "$has_pattern" -gt 0 ] && echo "SUBSTANTIVE: $file" || echo "THIN: $file ($lines lines, $has_pattern matches)"
}
```

Run these checks against each must-have artifact. Aggregate results into VERIFICATION.md.

</automated_verification_script>

<human_verification_triggers>

## When to Require Human Verification

Some things can't be verified programmatically. Flag these for human testing:

**Always human:**
- Visual appearance (does it look right?)
- User flow completion (can you actually do the thing?)
- Real-time behavior (WebSocket, SSE)
- External service integration (Stripe, email sending)
- Error message clarity (is the message helpful?)
- Performance feel (does it feel fast?)

**Human if uncertain:**
- Complex wiring that grep can't trace
- Dynamic behavior depending on state
- Edge cases and error states
- Mobile responsiveness
- Accessibility

**Format for human verification request:**
```markdown
## Human Verification Required

### 1. Chat message sending
**Test:** Type a message and click Send
**Expected:** Message appears in list, input clears
**Check:** Does message persist after refresh?

### 2. Error handling
**Test:** Disconnect network, try to send
**Expected:** Error message appears, message not lost
**Check:** Can retry after reconnect?
```

</human_verification_triggers>

<checkpoint_automation_reference>

## Pre-Checkpoint Automation

For automation-first checkpoint patterns, server lifecycle management, CLI installation handling, and error recovery protocols, see:

**@~/.claude/get-shit-indexed/references/checkpoints.md** → `<automation_reference>` section

Key principles:
- Claude sets up verification environment BEFORE presenting checkpoints
- Users never run CLI commands (visit URLs only)
- Server lifecycle: start before checkpoint, handle port conflicts, keep running for duration
- CLI installation: auto-install where safe, checkpoint for user choice otherwise
- Error handling: fix broken environment before checkpoint, never present checkpoint with failed setup

</checkpoint_automation_reference>

</document_content>
</document>
<document index="39">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\wave-tuning.md</source>
<document_content>
﻿# Wave Configuration Tuning Guide

Guide for optimizing wave-based spawning parameters for different environments and use cases.

---

## Overview

Wave-based spawning prevents API rate limits by controlling:
- How many agents run concurrently (max_concurrent_agents)
- How quickly agents spawn (stagger_delay_ms)
- Delay between waves (inter_wave_delay_ms)
- How long to wait before giving up (wave_timeout_seconds)

---

## Tuning Scenarios

### Scenario 1: High-Performance Environment

**Use case:** Development machine with fast network, robust MCP servers

**Goal:** Maximize throughput without hitting rate limits

**Recommended configuration:**

```yaml
rate_limiting:
  enabled: true
  max_concurrent_agents: 5
  stagger_delay_ms: 200
  inter_wave_delay_ms: 1000
  wave_timeout_seconds: 300
  adaptive_rate_limiting: false
```

**Rationale:**
- 5 concurrent agents process work quickly
- 200ms stagger = 1 second total spread time (minimal delay)
- 1s between waves allows for rapid progression
- No adaptation needed - environment is stable

**Trade-offs:**
- Pro: Maximum speed
- Con: Higher API load (may hit limits on unstable connections)

---

### Scenario 2: Standard Development

**Use case:** Typical development on shared infrastructure

**Goal:** Balance speed with stability

**Recommended configuration:**

```yaml
rate_limiting:
  enabled: true
  max_concurrent_agents: 3
  stagger_delay_ms: 500
  inter_wave_delay_ms: 2000
  wave_timeout_seconds: 300
  adaptive_rate_limiting: true
```

**Rationale:**
- 3 concurrent agents - safe for most APIs
- 500ms stagger = spreads API calls moderately
- 2s between waves allows API recovery
- Adaptive behavior handles unexpected rate limits

**Trade-offs:**
- Pro: Balanced performance
- Con: Moderate latency (waiting between waves)

---

### Scenario 3: Rate-Limited API

**Use case:** External API with strict rate limits (e.g., 10 requests/minute)

**Goal:** Avoid hitting rate limits while maintaining progress

**Recommended configuration:**

```yaml
rate_limiting:
  enabled: true
  max_concurrent_agents: 2
  stagger_delay_ms: 1000
  inter_wave_delay_ms: 3000
  wave_timeout_seconds: 600
  adaptive_rate_limiting: true
```

**Rationale:**
- 2 concurrent agents - under typical rate limits
- 1s stagger - generous spacing between agent spawns
- 3s between waves - ensures API quota recovery
- 10min timeout - allows for slow operations
- Adaptation - auto-backs off on 429 errors

**Trade-offs:**
- Pro: Stays within rate limits
- Con: Slower overall execution

---

### Scenario 4: Unstable Network

**Use case:** Remote development, intermittent connectivity issues

**Goal:** Maximize reliability despite network issues

**Recommended configuration:**

```yaml
rate_limiting:
  enabled: true
  max_concurrent_agents: 1
  stagger_delay_ms: 2000
  inter_wave_delay_ms: 5000
  wave_timeout_seconds: 900
  adaptive_rate_limiting: true
```

**Rationale:**
- Single agent - no concurrent network stress
- 2s stagger - significant buffer between spawns
- 5s between waves - extended recovery time
- 15min timeout - accommodates slow networks
- Adaptation - backs off aggressively on errors

**Trade-offs:**
- Pro: Maximum reliability
- Con: Significantly slower execution

---

## Parameter Reference

### max_concurrent_agents

Controls how many agents run simultaneously within a wave.

| Value | Use Case | Description |
|--------|----------|-------------|
| 1 | Unstable network, strict rate limits | Single agent avoids all concurrency issues |
| 2 | Rate-limited APIs | Conservative parallelism |
| 3 | Standard development | Default safe setting |
| 4-5 | High-performance environments | Faster processing on robust infrastructure |

### stagger_delay_ms

Delay between agent spawns within a wave (in milliseconds).

| Value | Spread Time | Use Case |
|--------|-------------|-----------|
| 200 | High-performance | 1 second total for 5 agents |
| 500 | Standard | 2.5 seconds for 5 agents |
| 1000 | Rate-limited | 5 seconds for 5 agents |
| 2000 | Unstable | 10 seconds for 5 agents |

### inter_wave_delay_ms

Delay between waves (in milliseconds).

| Value | Use Case |
|--------|-----------|
| 1000 | High-performance | Quick wave progression |
| 2000 | Standard | Normal wave progression |
| 3000-5000 | Rate-limited | Extended API recovery |
| 5000+ | Unstable | Maximum recovery time |

### wave_timeout_seconds

Maximum wait time for a wave before marking as failed.

| Value | Use Case |
|--------|-----------|
| 300 | Standard | 5 minutes per wave |
| 600 | Long-running tasks | 10 minutes per wave |
| 900 | Unstable network | 15 minutes per wave |

### adaptive_rate_limiting

When enabled, automatically adjusts parameters on 429 errors.

| Value | Behavior |
|--------|----------|
| true | Auto-back off on rate limits, increase delays |
| false | Use fixed parameters, fail on repeated errors |

---

## Tuning Workflow

### 1. Start with Defaults

Begin with standard configuration:

```yaml
max_concurrent_agents: 3
stagger_delay_ms: 500
inter_wave_delay_ms: 2000
wave_timeout_seconds: 300
adaptive_rate_limiting: true
```

### 2. Monitor Execution

Run wave execution and monitor:

- Wave completion times
- 429 error frequency
- Agent success rate

```bash
node ~/.claude/get-shit-indexed/bin/wave-health.js
```

### 3. Adjust Based on Results

| Observation | Adjustment |
|-----------|------------|
| Frequent 429 errors | Decrease max_concurrent_agents, increase stagger_delay_ms |
| All waves complete quickly | Increase max_concurrent_agents, decrease stagger_delay_ms |
| Network timeouts | Increase wave_timeout_seconds, enable adaptive_rate_limiting |
| Consistent failures | Check MCP server status, reduce max_concurrent_agents to 1 |

### 4. Test New Configuration

Validate tuning with test wave:

```bash
node ~/.claude/get-shit-indexed/bin/test-wave-spawning.js
```

---

## Environment-Specific Presets

### Local Development (robust)

```yaml
max_concurrent_agents: 4
stagger_delay_ms: 300
inter_wave_delay_ms: 1000
wave_timeout_seconds: 300
adaptive_rate_limiting: false
```

### CI/CD Environment

```yaml
max_concurrent_agents: 2
stagger_delay_ms: 1000
inter_wave_delay_ms: 3000
wave_timeout_seconds: 600
adaptive_rate_limiting: true
```

### Remote Development (unstable)

```yaml
max_concurrent_agents: 1
stagger_delay_ms: 2000
inter_wave_delay_ms: 5000
wave_timeout_seconds: 900
adaptive_rate_limiting: true
```

---

## Verification

After tuning, verify:

1. Run test wave spawning
2. Check wave-health.js output
3. Monitor for 429 errors in wave-history.json
4. Adjust parameters iteratively

---

## Common Issues

### Issue: Waves Not Completing

**Symptoms:** Waves timeout or agents hang indefinitely

**Diagnosis:**
```bash
# Check wave history
cat .planning/wave-history.json | grep "status.*failed"
```

**Solutions:**
1. Increase wave_timeout_seconds
2. Reduce task complexity per agent
3. Check MCP server connectivity
4. Review agent prompts for complexity

### Issue: Slow Execution

**Symptoms:** Waves complete but overall time is excessive

**Diagnosis:**
```bash
# Calculate average wave duration
node ~/.claude/get-shit-indexed/bin/wave-health.js --show-stats
```

**Solutions:**
1. Increase max_concurrent_agents
2. Decrease inter_wave_delay_ms
3. Reduce task complexity per agent
4. Use faster model profiles

---

## Decision Tree

```
Start
  |
  v
Are you experiencing issues?
  |
  v
Check wave-health.js output
  |
  +--< 429 errors? ----> Yes ----> Reduce concurrency, increase stagger
  |                                      |
  |                                      No
  |                                       |
  |                                 +--< Waves timing out? ----> Yes ----> Increase timeout
  |                                      |
  |                                      No
  |                                       |
  |                                    +--< All waves complete? ----> Yes ----> Increase concurrency
  |                                      |
  |                                      No
  |                                       |
  +---------------------------------------+
  |
  v
Optimal configuration found
```

---

## Configuration Template

Copy this template to `.planning/config.json`:

```json
{
  "rate_limiting": {
    "enabled": true,
    "max_concurrent_agents": 3,
    "stagger_delay_ms": 500,
    "inter_wave_delay_ms": 2000,
    "wave_timeout_seconds": 300,
    "adaptive_rate_limiting": true
  }
}
```

---

## See Also

- `@get-shit-indexed/references/wave-verification.md` - Wave verification documentation
- `@.planning/config.json` - Configuration storage
- `bin/wave-health.js` - Health monitoring script
- `bin/test-wave-spawning.js` - Wave testing script

---

*Generated for GSI Phase 8 - Advanced Workflow Features*
</document_content>
</document>
<document index="40">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\wave-verification.md</source>
<document_content>
﻿# Wave Verification and Testing

Documentation for wave-based spawning system that prevents API rate limits through testing and validation.

---

## Wave Architecture

### Wave Structure

Agents are organized into waves to prevent overwhelming MCP servers and API rate limits:

**Wave 1: Independent parallel agents**
- No dependencies between agents
- Can run simultaneously within rate limits
- Example: Tech, Architecture, Quality, Concerns mappers

**Wave 2: Dependent refinement agents**
- Only run if Wave 1 produces incomplete results
- Depends on Wave 1 documents for context
- Typically 0-2 agents

**Wave 3: Synthesis agents**
- Combines results from previous waves
- Cross-cutting analysis and verification
- Depends on all Wave 1 and Wave 2 completions

### Rate Limiting Parameters

```yaml
rate_limiting:
  enabled: true
  max_concurrent_agents: 3      # Maximum agents running simultaneously
  inter_wave_delay_ms: 2000        # Delay between waves
  stagger_delay_ms: 500            # Delay between agent spawns within a wave
  wave_timeout_seconds: 300         # Maximum wait time per wave
```

### Configuration Source

Parameters are read from `.planning/config.json` under `rate_limiting` section.

Fallback defaults:
- max_concurrent_agents: 3
- stagger_delay_ms: 500
- inter_wave_delay_ms: 2000
- wave_timeout_seconds: 300

---

## Adaptive Rate Limiting

### Error Detection

When to adapt:

- **429 Too Many Requests** - API rate limit exceeded
- **429 Rate limit exceeded** - Rate limit message in error
- **Connection timeout** - API overwhelmed

### Adaptive Behavior

On rate limit errors:

1. **Increase stagger_delay_ms** by 2x (max: 5000ms)
2. **Back off max_concurrent_agents** by 1 (min: 1)
3. **Retry failed wave** after delay
4. **Log adaptation** to wave-history.json

### Adaptation Limits

- Maximum stagger: 5000ms
- Minimum concurrent: 1
- Max retries: 5 attempts

---

## Wave History Logging

### File Location

`.planning/wave-history.json`

### Schema

```json
{
  "version": "1.0",
  "waves": [
    {
      "wave_number": 1,
      "agents": ["agent-id-1", "agent-id-2", "agent-id-3"],
      "start_time": "2025-02-13T11:00:00Z",
      "end_time": "2025-02-13T11:02:30Z",
      "status": "complete",
      "errors": []
    }
  ]
}
```

### Fields

| Field | Type | Description |
|-------|-------|-------------|
| `wave_number` | number | Wave sequence (1, 2, 3, ...) |
| `agents` | array | List of agent IDs spawned in this wave |
| `start_time` | string | ISO 8601 datetime when wave started |
| `end_time` | string | ISO 8601 datetime when wave completed |
| `status` | string | "running", "complete", "failed" |
| `errors` | array | Error messages if any (empty if successful) |

---

## Verification Checklist

### Before Wave Execution

- [ ] Rate limiting configured in config.json
- [ ] Max concurrent agents set appropriately
- [ ] Stagger delay configured for API limits
- [ ] Wave timeout allows for full completion
- [ ] Agent-history.json initialized

### After Wave Execution

- [ ] All agents in wave completed successfully
- [ ] No 429 errors encountered
- [ ] Stagger delays were applied correctly
- [ ] Wave-history.json updated with results

---

## Testing Procedures

### Test Staggered Spawning

```bash
# Run wave with monitoring
node ~/.claude/get-shit-indexed/bin/GSI-tools.js test-wave-spawning \
  --max-concurrent 3 \
  --stagger-delay 500 \
  --wave-timeout 30
```

Expected results:
- Agents spawn with 500ms intervals
- No more than 3 agents running concurrently
- All agents complete within timeout

### Test Rate Limit Adaptation

```bash
# Simulate rate limit errors
node ~/.claude/get-shit-indexed/bin/GSI-tools.js test-wave-spawning \
  --simulate-rate-limit \
  --max-concurrent 3
```

Expected results:
- First wave hits rate limit
- Second wave backs off (reduced concurrency)
- Third wave succeeds with conservative settings

---

## Health Monitoring

### Wave Health Script

```bash
# Check wave execution health
node ~/.claude/get-shit-indexed/bin/wave-health.js
```

Health indicators:
- **Success rate** - Percentage of waves completing successfully
- **Average duration** - Time per wave completion
- **Error rate** - Frequency of 429/rate limit errors
- **Adaptation count** - Number of times rate limiting adapted

### Health Status Codes

| Status | Success Rate | Meaning |
|---------|--------------|---------|
| Healthy | >95% | Optimal configuration |
| Warning | 80-95% | Consider adjustments |
| Error | <80% | Needs attention |

---

## Configuration Tuning

### High-Speed Environments

For environments with robust API limits:

```yaml
rate_limiting:
  max_concurrent_agents: 5      # Increase parallelism
  stagger_delay_ms: 200            # Reduce stagger for speed
  inter_wave_delay_ms: 1000        # Faster wave progression
```

### Rate-Limited Environments

For APIs with strict rate limits:

```yaml
rate_limiting:
  max_concurrent_agents: 2      # Conservative parallelism
  stagger_delay_ms: 1000           # Longer stagger between spawns
  inter_wave_delay_ms: 3000        # Longer recovery between waves
  wave_timeout_seconds: 600         # Generous timeout
```

### Unstable Networks

```yaml
rate_limiting:
  max_concurrent_agents: 1      # Single agent at a time
  stagger_delay_ms: 2000           # Significant stagger
  inter_wave_delay_ms: 5000        # Extended recovery
  wave_timeout_seconds: 900         # Extended timeout
  adaptive_rate_limiting: true   # Enable auto-adaptation
```

---

## Decision Matrix

| Environment | max_concurrent | stagger_ms | inter_wave_ms | timeout | adaptive |
|-------------|----------------|--------------|---------------|----------|
| High-speed | 5 | 200 | 1000 | 300 | false |
| Standard | 3 | 500 | 2000 | 300 | false |
| Rate-limited | 2 | 1000 | 3000 | 600 | true |
| Unstable | 1 | 2000 | 5000 | 900 | true |

---

## Troubleshooting

### All Agents Failing

**Symptom:** Every agent in wave fails

**Possible causes:**
- MCP servers not running
- Network connectivity issues
- Invalid agent model
- Systemic configuration error

**Resolution:**
1. Check MCP server status
2. Verify model availability
3. Check agent-history.json for error patterns
4. Test with single agent first

### Wave Timeout

**Symptom:** Wave doesn't complete within timeout_seconds

**Possible causes:**
- Agents stuck on long-running tasks
- Insufficient timeout for task complexity
- Deadlock in agent dependencies

**Resolution:**
1. Increase wave_timeout_seconds in config
2. Break tasks into smaller units
3. Use segmented execution instead of full-plan

### Repeated 429 Errors

**Symptom:** Multiple waves hit rate limits

**Resolution:**
1. Reduce max_concurrent_agents
2. Increase stagger_delay_ms
3. Enable adaptive_rate_limiting
4. Check for API quota issues

---

## Integration Points

- `.planning/config.json` - Rate limiting configuration
- `.planning/wave-history.json` - Wave execution logs
- `.planning/agent-history.json` - Agent tracking
- `bin/wave-health.js` - Health monitoring script
- `bin/test-wave-spawning.js` - Wave testing script

---

*Generated for GSI Phase 8 - Advanced Workflow Features*
</document_content>
</document>
<document index="41">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\references\yolo-mode.md</source>
<document_content>
﻿# YOLO Mode Reference

Documentation for YOLO (You Only Live Once) mode - frictionless execution without checkpoint confirmations.

---

## What is YOLO Mode?

YOLO mode enables **frictionless execution** by auto-approving all checkpoints and confirmation prompts that normally require user interaction.

**"YOLO" = "You Only Live Once"** - Execute without stopping for approval.

---

## Behavior

### Auto-Approval

When YOLO mode is enabled, the following checkpoints are **automatically approved**:

| Checkpoint Type | Normal Behavior | YOLO Behavior |
|----------------|----------------|----------------|
| `checkpoint:human-verify` | Wait for "approved" | Auto-approve with log entry |
| `checkpoint:decision` | Wait for option selection | Auto-select first/default option |
| `checkpoint:human-action` | Wait for manual step completion | Skip with warning |

### What YOLO Does NOT Bypass

YOLO mode does NOT bypass:

- **Authentication gates** - Real authentication errors still require manual action
- **Actual errors** - Code failures, crashes, validation errors still stop execution
- **Critical failures** - Systemic issues still require intervention

YOLO only skips **optional user confirmations** for verification/decision checkpoints.

---

## Activation Methods

### 1. Global Configuration

Set in `.planning/config.json`:

```json
{
  "mode": "yolo"
}
```

### 2. Per-Command Flag

```bash
/GSI:execute-phase 08 --yolo
/GSI:execute-plan 08 --yolo
```

### 3. Environment Variable

```bash
export YOLO=true
/GSI:execute-phase 08
```

**Priority:** Per-command flag > global config > environment variable

---

## Logging

When YOLO mode auto-approves a checkpoint, it logs:

```
⚡ YOLO: Auto-approving checkpoint:human-verify
Task: Verify database schema
Built: User and Session tables with relations
```

After all auto-approvals, summary includes:

```markdown
## Execution Mode

**Mode:** YOLO
**Auto-approvals:** 5 checkpoints auto-approved

### Checkpoints Auto-Approved

1. Task 3: human-verify (auto-approved)
2. Task 7: decision (auto-selected option 1)
3. Task 12: human-action (skipped with warning)
```

---

## Safety Warnings

### When to Use YOLO Mode

**Use YOLO for:**

✅ Well-tested workflows you've run many times before

✅ Non-destructive operations (reads, analysis, documentation)

✅ When you can afford to rollback (git reset if needed)

✅ Experimental features or rapid prototyping

**DO NOT use YOLO for:**

❌ First-time workflows - unknown behavior, unexpected errors

❌ Destructive operations (database migrations, deletions, production deployments)

❌ Critical systems (production databases, user-facing services)

### Risks

- **Commits without review** - All changes auto-approved and committed
- **No human verification** - Visual/functional checks are skipped
- **Fast error propagation** - Issues cascade through multiple tasks
- **Auth gates still apply** - You'll still need to manually authenticate

### Mitigation

- Use git branches for YOLO executions
- Review git log before merging
- Keep recent backups
- Test in staging first

---

## When NOT to Use YOLO Mode

### Never Use YOLO for:

1. **Production deployments** - Always verify deployments manually
2. **Database schema changes** - Migrations can destroy data
3. **Security-critical changes** - Auth, payments, permissions
4. **First-time workflows** - Unknown behavior patterns
5. **Irreversible operations** - Data deletion, permanent changes

### Proceed with Manual Approval Instead

For these operations, run with standard mode (checkpoints enabled):

```bash
# Standard execution with checkpoints
/GSI:execute-phase 05
```

---

## Example Execution Traces

### Standard Mode (with checkpoints)

```
Task 1 complete...
Task 2 complete...
╔══════════════════════════════════════════════════╗
║ CHECKPOINT: Verification Required                    ║
╚═════════════════════════════════════════════════════╝

Waiting for approval...
```

### YOLO Mode (auto-approval)

```
Task 1 complete...
Task 2 complete...
⚡ YOLO: Auto-approving checkpoint:human-verify
Task 3 complete...
Task 4 complete...
⚡ YOLO: Auto-selecting option 1 for checkpoint:decision
Task 5 complete...
```

---

## Verification After YOLO Execution

After YOLO execution, verify:

1. **Check git log** - Review auto-approved commits
2. **Run tests** - Ensure nothing is broken
3. **Manual verification** - Spot-check critical functionality
4. **Staging deploy** - Test before production

---

## Configuration Reference

See `.planning/config.json` for YOLO configuration.

See also:
- `@get-shit-indexed/workflows/execute-phase.md` - Main execution workflow
- `@get-shit-indexed/workflows/execute-plan.md` - Orchestrator workflow
- `@get-shit-indexed/templates/summary.md` - Summary template with YOLO section

---

*Generated for GSI Phase 8 - Advanced Workflow Features*
</document_content>
</document>
<document index="42">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\DEBUG.md</source>
<document_content>
﻿# Debug Template

Template for `.planning/debug/[slug].md` — active debug session tracking.

---

## Debug Thinking Protocol

Use `mcp__debug-thinking__debug_thinking` for systematic debugging:

1. **Create problem node**: Document the error/issue
2. **Query for similar problems**: Find past solutions
3. **Create hypothesis nodes**: Based on similar cases or analysis
4. **Create experiment nodes**: For each hypothesis to test
5. **Track observations**: Record results of experiments
6. **Create solution and learning nodes**: When resolved

**Data persists in**: `~/.debug-thinking-mcp/` for future reference

**Integration with 7-BMAD**:
- Method Circle: Verify solution correctness
- Mad Circle: Check all integrations work
- Model Circle: Store pattern for reuse

## Debug Graph Structure Template

```
### Debug Session: [issue-title]

**Problem**: [description]

**Graph Structure**:
- Problem: [error description]
- Hypotheses: [list of hypotheses]
- Experiments: [list of experiments]
- Observations: [results found]
- Solution: [final fix]
- Learnings: [insights for future]
```

---

## File Template

```markdown
---
status: gathering | investigating | fixing | verifying | resolved
trigger: "[verbatim user input]"
created: [ISO timestamp]
updated: [ISO timestamp]
---

## Current Focus
<!-- OVERWRITE on each update - always reflects NOW -->

hypothesis: [current theory being tested]
test: [how testing it]
expecting: [what result means if true/false]
next_action: [immediate next step]

## Symptoms
<!-- Written during gathering, then immutable -->

expected: [what should happen]
actual: [what actually happens]
errors: [error messages if any]
reproduction: [how to trigger]
started: [when it broke / always broken]

## Eliminated
<!-- APPEND only - prevents re-investigating after /clear -->

- hypothesis: [theory that was wrong]
  evidence: [what disproved it]
  timestamp: [when eliminated]

## Evidence
<!-- APPEND only - facts discovered during investigation -->

- timestamp: [when found]
  checked: [what was examined]
  found: [what was observed]
  implication: [what this means]

## Resolution
<!-- OVERWRITE as understanding evolves -->

root_cause: [empty until found]
fix: [empty until applied]
verification: [empty until verified]
files_changed: []
```

---

<section_rules>

**Frontmatter (status, trigger, timestamps):**
- `status`: OVERWRITE - reflects current phase
- `trigger`: IMMUTABLE - verbatim user input, never changes
- `created`: IMMUTABLE - set once
- `updated`: OVERWRITE - update on every change

**Current Focus:**
- OVERWRITE entirely on each update
- Always reflects what Claude is doing RIGHT NOW
- If Claude reads this after /clear, it knows exactly where to resume
- Fields: hypothesis, test, expecting, next_action

**Symptoms:**
- Written during initial gathering phase
- IMMUTABLE after gathering complete
- Reference point for what we're trying to fix
- Fields: expected, actual, errors, reproduction, started

**Eliminated:**
- APPEND only - never remove entries
- Prevents re-investigating dead ends after context reset
- Each entry: hypothesis, evidence that disproved it, timestamp
- Critical for efficiency across /clear boundaries

**Evidence:**
- APPEND only - never remove entries
- Facts discovered during investigation
- Each entry: timestamp, what checked, what found, implication
- Builds the case for root cause

**Resolution:**
- OVERWRITE as understanding evolves
- May update multiple times as fixes are tried
- Final state shows confirmed root cause and verified fix
- Fields: root_cause, fix, verification, files_changed

</section_rules>

<lifecycle>

**Creation:** Immediately when /GSI:debug is called
- Create file with trigger from user input
- Set status to "gathering"
- Current Focus: next_action = "gather symptoms"
- Symptoms: empty, to be filled

**During symptom gathering:**
- Update Symptoms section as user answers questions
- Update Current Focus with each question
- When complete: status → "investigating"

**During investigation:**
- OVERWRITE Current Focus with each hypothesis
- APPEND to Evidence with each finding
- APPEND to Eliminated when hypothesis disproved
- Update timestamp in frontmatter

**During fixing:**
- status → "fixing"
- Update Resolution.root_cause when confirmed
- Update Resolution.fix when applied
- Update Resolution.files_changed

**During verification:**
- status → "verifying"
- Update Resolution.verification with results
- If verification fails: status → "investigating", try again

**On resolution:**
- status → "resolved"
- Move file to .planning/debug/resolved/

</lifecycle>

<resume_behavior>

When Claude reads this file after /clear:

1. Parse frontmatter → know status
2. Read Current Focus → know exactly what was happening
3. Read Eliminated → know what NOT to retry
4. Read Evidence → know what's been learned
5. Continue from next_action

The file IS the debugging brain. Claude should be able to resume perfectly from any interruption point.

</resume_behavior>

<size_constraint>

Keep debug files focused:
- Evidence entries: 1-2 lines each, just the facts
- Eliminated: brief - hypothesis + why it failed
- No narrative prose - structured data only

If evidence grows very large (10+ entries), consider whether you're going in circles. Check Eliminated to ensure you're not re-treading.

</size_constraint>

</document_content>
</document>
<document index="43">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\UAT.md</source>
<document_content>
﻿# UAT Template

Template for `.planning/phases/XX-name/{phase}-UAT.md` — persistent UAT session tracking.

---

## File Template

```markdown
---
status: testing | complete | diagnosed
phase: XX-name
source: [list of SUMMARY.md files tested]
started: [ISO timestamp]
updated: [ISO timestamp]
---

## Current Test
<!-- OVERWRITE each test - shows where we are -->

number: [N]
name: [test name]
expected: |
  [what user should observe]
awaiting: user response

## Tests

### 1. [Test Name]
expected: [observable behavior - what user should see]
result: [pending]

### 2. [Test Name]
expected: [observable behavior]
result: pass

### 3. [Test Name]
expected: [observable behavior]
result: issue
reported: "[verbatim user response]"
severity: major

### 4. [Test Name]
expected: [observable behavior]
result: skipped
reason: [why skipped]

...

## Summary

total: [N]
passed: [N]
issues: [N]
pending: [N]
skipped: [N]

## Gaps

<!-- YAML format for plan-phase --gaps consumption -->
- truth: "[expected behavior from test]"
  status: failed
  reason: "User reported: [verbatim response]"
  severity: blocker | major | minor | cosmetic
  test: [N]
  root_cause: ""     # Filled by diagnosis
  artifacts: []      # Filled by diagnosis
  missing: []        # Filled by diagnosis
  debug_session: ""  # Filled by diagnosis
```

---

<section_rules>

**Frontmatter:**
- `status`: OVERWRITE - "testing" or "complete"
- `phase`: IMMUTABLE - set on creation
- `source`: IMMUTABLE - SUMMARY files being tested
- `started`: IMMUTABLE - set on creation
- `updated`: OVERWRITE - update on every change

**Current Test:**
- OVERWRITE entirely on each test transition
- Shows which test is active and what's awaited
- On completion: "[testing complete]"

**Tests:**
- Each test: OVERWRITE result field when user responds
- `result` values: [pending], pass, issue, skipped
- If issue: add `reported` (verbatim) and `severity` (inferred)
- If skipped: add `reason` if provided

**Summary:**
- OVERWRITE counts after each response
- Tracks: total, passed, issues, pending, skipped

**Gaps:**
- APPEND only when issue found (YAML format)
- After diagnosis: fill `root_cause`, `artifacts`, `missing`, `debug_session`
- This section feeds directly into /GSI:plan-phase --gaps

</section_rules>

<diagnosis_lifecycle>

**After testing complete (status: complete), if gaps exist:**

1. User runs diagnosis (from verify-work offer or manually)
2. diagnose-issues workflow spawns parallel debug agents
3. Each agent investigates one gap, returns root cause
4. UAT.md Gaps section updated with diagnosis:
   - Each gap gets `root_cause`, `artifacts`, `missing`, `debug_session` filled
5. status → "diagnosed"
6. Ready for /GSI:plan-phase --gaps with root causes

**After diagnosis:**
```yaml
## Gaps

- truth: "Comment appears immediately after submission"
  status: failed
  reason: "User reported: works but doesn't show until I refresh the page"
  severity: major
  test: 2
  root_cause: "useEffect in CommentList.tsx missing commentCount dependency"
  artifacts:
    - path: "src/components/CommentList.tsx"
      issue: "useEffect missing dependency"
  missing:
    - "Add commentCount to useEffect dependency array"
  debug_session: ".planning/debug/comment-not-refreshing.md"
```

</diagnosis_lifecycle>

<lifecycle>

**Creation:** When /GSI:verify-work starts new session
- Extract tests from SUMMARY.md files
- Set status to "testing"
- Current Test points to test 1
- All tests have result: [pending]

**During testing:**
- Present test from Current Test section
- User responds with pass confirmation or issue description
- Update test result (pass/issue/skipped)
- Update Summary counts
- If issue: append to Gaps section (YAML format), infer severity
- Move Current Test to next pending test

**On completion:**
- status → "complete"
- Current Test → "[testing complete]"
- Commit file
- Present summary with next steps

**Resume after /clear:**
1. Read frontmatter → know phase and status
2. Read Current Test → know where we are
3. Find first [pending] result → continue from there
4. Summary shows progress so far

</lifecycle>

<severity_guide>

Severity is INFERRED from user's natural language, never asked.

| User describes | Infer |
|----------------|-------|
| Crash, error, exception, fails completely, unusable | blocker |
| Doesn't work, nothing happens, wrong behavior, missing | major |
| Works but..., slow, weird, minor, small issue | minor |
| Color, font, spacing, alignment, visual, looks off | cosmetic |

Default: **major** (safe default, user can clarify if wrong)

</severity_guide>

<good_example>
```markdown
---
status: diagnosed
phase: 04-comments
source: 04-01-SUMMARY.md, 04-02-SUMMARY.md
started: 2025-01-15T10:30:00Z
updated: 2025-01-15T10:45:00Z
---

## Current Test

[testing complete]

## Tests

### 1. View Comments on Post
expected: Comments section expands, shows count and comment list
result: pass

### 2. Create Top-Level Comment
expected: Submit comment via rich text editor, appears in list with author info
result: issue
reported: "works but doesn't show until I refresh the page"
severity: major

### 3. Reply to a Comment
expected: Click Reply, inline composer appears, submit shows nested reply
result: pass

### 4. Visual Nesting
expected: 3+ level thread shows indentation, left borders, caps at reasonable depth
result: pass

### 5. Delete Own Comment
expected: Click delete on own comment, removed or shows [deleted] if has replies
result: pass

### 6. Comment Count
expected: Post shows accurate count, increments when adding comment
result: pass

## Summary

total: 6
passed: 5
issues: 1
pending: 0
skipped: 0

## Gaps

- truth: "Comment appears immediately after submission in list"
  status: failed
  reason: "User reported: works but doesn't show until I refresh the page"
  severity: major
  test: 2
  root_cause: "useEffect in CommentList.tsx missing commentCount dependency"
  artifacts:
    - path: "src/components/CommentList.tsx"
      issue: "useEffect missing dependency"
  missing:
    - "Add commentCount to useEffect dependency array"
  debug_session: ".planning/debug/comment-not-refreshing.md"
```
</good_example>

</document_content>
</document>
<document index="44">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\config.json</source>
<document_content>
{
  "mode": "interactive",
  "depth": "standard",
  "workflow": {
    "research": true,
    "plan_check": true,
    "verifier": true
  },
  "planning": {
    "commit_docs": true,
    "search_gitignored": false
  },
  "parallelization": {
    "enabled": true,
    "plan_level": true,
    "task_level": false,
    "skip_checkpoints": true,
    "max_concurrent_agents": 3,
    "min_plans_for_parallel": 2
  },
  "gates": {
    "confirm_project": true,
    "confirm_phases": true,
    "confirm_roadmap": true,
    "confirm_breakdown": true,
    "confirm_plan": true,
    "execute_next_plan": true,
    "issues_review": true,
    "confirm_transition": true
  },
  "safety": {
    "always_confirm_destructive": true,
    "always_confirm_external_services": true
  }
}

</document_content>
</document>
<document index="45">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\context.md</source>
<document_content>
﻿# Phase Context Template

Template for `.planning/phases/XX-name/{phase}-CONTEXT.md` - captures implementation decisions for a phase.

**Purpose:** Document decisions that downstream agents need. Researcher uses this to know WHAT to investigate. Planner uses this to know WHAT choices are locked vs flexible.

**Key principle:** Categories are NOT predefined. They emerge from what was actually discussed for THIS phase. A CLI phase has CLI-relevant sections, a UI phase has UI-relevant sections.

**Downstream consumers:**
- `GSI-phase-researcher` — Reads decisions to focus research (e.g., "card layout" → research card component patterns)
- `GSI-planner` — Reads decisions to create specific tasks (e.g., "infinite scroll" → task includes virtualization)

---

## File Template

```markdown
# Phase [X]: [Name] - Context

**Gathered:** [date]
**Status:** Ready for planning

<domain>
## Phase Boundary

[Clear statement of what this phase delivers — the scope anchor. This comes from ROADMAP.md and is fixed. Discussion clarifies implementation within this boundary.]

</domain>

<decisions>
## Implementation Decisions

### [Area 1 that was discussed]
- [Specific decision made]
- [Another decision if applicable]

### [Area 2 that was discussed]
- [Specific decision made]

### [Area 3 that was discussed]
- [Specific decision made]

### Claude's Discretion
[Areas where user explicitly said "you decide" — Claude has flexibility here during planning/implementation]

</decisions>

<specifics>
## Specific Ideas

[Any particular references, examples, or "I want it like X" moments from discussion. Product references, specific behaviors, interaction patterns.]

[If none: "No specific requirements — open to standard approaches"]

</specifics>

<deferred>
## Deferred Ideas

[Ideas that came up during discussion but belong in other phases. Captured here so they're not lost, but explicitly out of scope for this phase.]

[If none: "None — discussion stayed within phase scope"]

</deferred>

---

*Phase: XX-name*
*Context gathered: [date]*
```

<good_examples>

**Example 1: Visual feature (Post Feed)**

```markdown
# Phase 3: Post Feed - Context

**Gathered:** 2025-01-20
**Status:** Ready for planning

<domain>
## Phase Boundary

Display posts from followed users in a scrollable feed. Users can view posts and see engagement counts. Creating posts and interactions are separate phases.

</domain>

<decisions>
## Implementation Decisions

### Layout style
- Card-based layout, not timeline or list
- Each card shows: author avatar, name, timestamp, full post content, reaction counts
- Cards have subtle shadows, rounded corners — modern feel

### Loading behavior
- Infinite scroll, not pagination
- Pull-to-refresh on mobile
- New posts indicator at top ("3 new posts") rather than auto-inserting

### Empty state
- Friendly illustration + "Follow people to see posts here"
- Suggest 3-5 accounts to follow based on interests

### Claude's Discretion
- Loading skeleton design
- Exact spacing and typography
- Error state handling

</decisions>

<specifics>
## Specific Ideas

- "I like how Twitter shows the new posts indicator without disrupting your scroll position"
- Cards should feel like Linear's issue cards — clean, not cluttered

</specifics>

<deferred>
## Deferred Ideas

- Commenting on posts — Phase 5
- Bookmarking posts — add to backlog

</deferred>

---

*Phase: 03-post-feed*
*Context gathered: 2025-01-20*
```

**Example 2: CLI tool (Database backup)**

```markdown
# Phase 2: Backup Command - Context

**Gathered:** 2025-01-20
**Status:** Ready for planning

<domain>
## Phase Boundary

CLI command to backup database to local file or S3. Supports full and incremental backups. Restore command is a separate phase.

</domain>

<decisions>
## Implementation Decisions

### Output format
- JSON for programmatic use, table format for humans
- Default to table, --json flag for JSON
- Verbose mode (-v) shows progress, silent by default

### Flag design
- Short flags for common options: -o (output), -v (verbose), -f (force)
- Long flags for clarity: --incremental, --compress, --encrypt
- Required: database connection string (positional or --db)

### Error recovery
- Retry 3 times on network failure, then fail with clear message
- --no-retry flag to fail fast
- Partial backups are deleted on failure (no corrupt files)

### Claude's Discretion
- Exact progress bar implementation
- Compression algorithm choice
- Temp file handling

</decisions>

<specifics>
## Specific Ideas

- "I want it to feel like pg_dump — familiar to database people"
- Should work in CI pipelines (exit codes, no interactive prompts)

</specifics>

<deferred>
## Deferred Ideas

- Scheduled backups — separate phase
- Backup rotation/retention — add to backlog

</deferred>

---

*Phase: 02-backup-command*
*Context gathered: 2025-01-20*
```

**Example 3: Organization task (Photo library)**

```markdown
# Phase 1: Photo Organization - Context

**Gathered:** 2025-01-20
**Status:** Ready for planning

<domain>
## Phase Boundary

Organize existing photo library into structured folders. Handle duplicates and apply consistent naming. Tagging and search are separate phases.

</domain>

<decisions>
## Implementation Decisions

### Grouping criteria
- Primary grouping by year, then by month
- Events detected by time clustering (photos within 2 hours = same event)
- Event folders named by date + location if available

### Duplicate handling
- Keep highest resolution version
- Move duplicates to _duplicates folder (don't delete)
- Log all duplicate decisions for review

### Naming convention
- Format: YYYY-MM-DD_HH-MM-SS_originalname.ext
- Preserve original filename as suffix for searchability
- Handle name collisions with incrementing suffix

### Claude's Discretion
- Exact clustering algorithm
- How to handle photos with no EXIF data
- Folder emoji usage

</decisions>

<specifics>
## Specific Ideas

- "I want to be able to find photos by roughly when they were taken"
- Don't delete anything — worst case, move to a review folder

</specifics>

<deferred>
## Deferred Ideas

- Face detection grouping — future phase
- Cloud sync — out of scope for now

</deferred>

---

*Phase: 01-photo-organization*
*Context gathered: 2025-01-20*
```

</good_examples>

<guidelines>
**This template captures DECISIONS for downstream agents.**

The output should answer: "What does the researcher need to investigate? What choices are locked for the planner?"

**Good content (concrete decisions):**
- "Card-based layout, not timeline"
- "Retry 3 times on network failure, then fail"
- "Group by year, then by month"
- "JSON for programmatic use, table for humans"

**Bad content (too vague):**
- "Should feel modern and clean"
- "Good user experience"
- "Fast and responsive"
- "Easy to use"

**After creation:**
- File lives in phase directory: `.planning/phases/XX-name/{phase}-CONTEXT.md`
- `GSI-phase-researcher` uses decisions to focus investigation
- `GSI-planner` uses decisions + research to create executable tasks
- Downstream agents should NOT need to ask the user again about captured decisions
</guidelines>

</document_content>
</document>
<document index="46">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\continue-here.md</source>
<document_content>
# Continue-Here Template

Copy and fill this structure for `.planning/phases/XX-name/.continue-here.md`:

```yaml
---
phase: XX-name
task: 3
total_tasks: 7
status: in_progress
last_updated: 2025-01-15T14:30:00Z
---
```

```markdown
<current_state>
[Where exactly are we? What's the immediate context?]
</current_state>

<completed_work>
[What got done this session - be specific]

- Task 1: [name] - Done
- Task 2: [name] - Done
- Task 3: [name] - In progress, [what's done on it]
</completed_work>

<remaining_work>
[What's left in this phase]

- Task 3: [name] - [what's left to do]
- Task 4: [name] - Not started
- Task 5: [name] - Not started
</remaining_work>

<decisions_made>
[Key decisions and why - so next session doesn't re-debate]

- Decided to use [X] because [reason]
- Chose [approach] over [alternative] because [reason]
</decisions_made>

<blockers>
[Anything stuck or waiting on external factors]

- [Blocker 1]: [status/workaround]
</blockers>

<context>
[Mental state, "vibe", anything that helps resume smoothly]

[What were you thinking about? What was the plan?
This is the "pick up exactly where you left off" context.]
</context>

<next_action>
[The very first thing to do when resuming]

Start with: [specific action]
</next_action>
```

<yaml_fields>
Required YAML frontmatter:

- `phase`: Directory name (e.g., `02-authentication`)
- `task`: Current task number
- `total_tasks`: How many tasks in phase
- `status`: `in_progress`, `blocked`, `almost_done`
- `last_updated`: ISO timestamp
</yaml_fields>

<guidelines>
- Be specific enough that a fresh Claude instance understands immediately
- Include WHY decisions were made, not just what
- The `<next_action>` should be actionable without reading anything else
- This file gets DELETED after resume - it's not permanent storage
</guidelines>

</document_content>
</document>
<document index="47">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\debug-subagent-prompt.md</source>
<document_content>
﻿# Debug Subagent Prompt Template

Template for spawning GSI-debugger agent. The agent contains all debugging expertise - this template provides problem context only.

---

## Template

```markdown
<objective>
Investigate issue: {issue_id}

**Summary:** {issue_summary}

**MCP Tools for Debugging:**
- Use Code-Index MCP to trace bug propagation through codebase
- Use Code-Index MCP for finding related code and symbol extraction
- Use Desktop Commander's read_multiple_files for batch analysis
</objective>

<symptoms>
expected: {expected}
actual: {actual}
errors: {errors}
reproduction: {reproduction}
timeline: {timeline}
</symptoms>

<mode>
symptoms_prefilled: {true_or_false}
goal: {find_root_cause_only | find_and_fix}

**MCP Analysis Steps:**
1. Use Code-Index MCP to find callers/callees of affected code
2. Use Code-Index MCP to search for similar error patterns
3. Use batch reading to examine multiple files simultaneously
</mode>

<debug_file>
Create: .planning/debug/{slug}.md
</debug_file>
```

---

## Placeholders

| Placeholder | Source | Example |
|-------------|--------|---------|
| `{issue_id}` | Orchestrator-assigned | `auth-screen-dark` |
| `{issue_summary}` | User description | `Auth screen is too dark` |
| `{expected}` | From symptoms | `See logo clearly` |
| `{actual}` | From symptoms | `Screen is dark` |
| `{errors}` | From symptoms | `None in console` |
| `{reproduction}` | From symptoms | `Open /auth page` |
| `{timeline}` | From symptoms | `After recent deploy` |
| `{goal}` | Orchestrator sets | `find_and_fix` |
| `{slug}` | Generated | `auth-screen-dark` |

---

## Usage

**From /GSI:debug:**
```python
Task(
  prompt=filled_template,
  subagent_type="GSI-debugger",
  description="Debug {slug}"
)
```

**From diagnose-issues (UAT):**
```python
Task(prompt=template, subagent_type="GSI-debugger", description="Debug UAT-001")
```

---

## Continuation

For checkpoints, spawn fresh agent with:

```markdown
<objective>
Continue debugging {slug}. Evidence is in the debug file.
</objective>

<prior_state>
Debug file: @.planning/debug/{slug}.md
</prior_state>

<checkpoint_response>
**Type:** {checkpoint_type}
**Response:** {user_response}
</checkpoint_response>

<mode>
goal: {goal}
</mode>
```

</document_content>
</document>
<document index="48">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\discovery.md</source>
<document_content>
﻿# Discovery Template

Template for `.planning/phases/XX-name/DISCOVERY.md` - shallow research for library/option decisions.

**Purpose:** Answer "which library/option should we use" questions during mandatory discovery in plan-phase.

For deep ecosystem research ("how do experts build this"), use `/GSI:research-phase` which produces RESEARCH.md.

---

## File Template

```markdown
---
phase: XX-name
type: discovery
topic: [discovery-topic]
---

<session_initialization>
Before beginning discovery, verify today's date:
!`date +%Y-%m-%d`

Use this date when searching for "current" or "latest" information.
Example: If today is 2025-11-22, search for "2025" not "2024".
</session_initialization>

<discovery_objective>
Discover [topic] to inform [phase name] implementation.

Purpose: [What decision/implementation this enables]
Scope: [Boundaries]
Output: DISCOVERY.md with recommendation
</discovery_objective>

<discovery_scope>
<include>
- [Question to answer]
- [Area to investigate]
- [Specific comparison if needed]
</include>

<exclude>
- [Out of scope for this discovery]
- [Defer to implementation phase]
</exclude>
</discovery_scope>

<discovery_protocol>

**Source Priority:**
1. **Context7 MCP** - For library/framework documentation (current, authoritative)
2. **Code-Index MCP** - For ecosystem analysis, code search, and symbol extraction
3. **Official Docs** - For platform-specific or non-indexed libraries
4. **WebSearch** - For comparisons, trends, community patterns (verify all findings)

**Method Circle (Implementation) Thinking:**
Since discovery is an implementation task, use Sequential thinking for structured research:
1. **Step 1**: Define discovery scope and objectives
2. **Step 2**: Identify relevant sources and MCP tools
3. **Step 3**: Execute information gathering systematically
4. **Step 4**: Analyze findings against criteria
5. **Step 5**: Document results with clear recommendations

**Sequential Thought Pattern:**
```
Step 1: Understand requirements
- What decision needs to be made?
- What criteria matter most?
- What's the decision context?

Step 2: Design approach
- Which MCP tools to use?
- What sources to prioritize?
- How to structure the search?

Step 3: Execute research
- Gather information systematically
- Cross-reference findings
- Document sources

Step 4: Analyze results
- Compare alternatives
- Evaluate against criteria
- Identify gaps

Step 5: Document conclusions
- Summarize findings
- Make recommendation
- Document uncertainties
```

**Quality Checklist:**
Before completing discovery, verify:
- [ ] All claims have authoritative sources (Context7 or official docs)
- [ ] Negative claims ("X is not possible") verified with official documentation
- [ ] API syntax/configuration from Context7 or official docs (never WebSearch alone)
- [ ] WebSearch findings cross-checked with authoritative sources
- [ ] Recent updates/changelogs checked for breaking changes
- [ ] Alternative approaches considered (not just first solution found)
- [ ] MCP tools used for batch operations when reading multiple files
- [ ] Code-Index MCP used for code search and symbol extraction

**Confidence Levels:**
- HIGH: Context7 or official docs confirm
- MEDIUM: WebSearch + Context7/official docs confirm
- LOW: WebSearch only or training knowledge only (mark for validation)

</discovery_protocol>


<output_structure>
Create `.planning/phases/XX-name/DISCOVERY.md`:

```markdown
# [Topic] Discovery

## Summary
[2-3 paragraph executive summary - what was researched, what was found, what's recommended]

## Primary Recommendation
[What to do and why - be specific and actionable]

## Alternatives Considered
[What else was evaluated and why not chosen]

## Key Findings

### [Category 1]
- [Finding with source URL and relevance to our case]

### [Category 2]
- [Finding with source URL and relevance]

## Code Examples
[Relevant implementation patterns, if applicable]

## Metadata

<metadata>
<confidence level="high|medium|low">
[Why this confidence level - based on source quality and verification]
</confidence>

<sources>
- [Primary authoritative sources used]
</sources>

<open_questions>
[What couldn't be determined or needs validation during implementation]
</open_questions>

<validation_checkpoints>
[If confidence is LOW or MEDIUM, list specific things to verify during implementation]
</validation_checkpoints>
</metadata>
```
</output_structure>

<success_criteria>
- All scope questions answered with authoritative sources
- Quality checklist items completed
- Clear primary recommendation
- Low-confidence findings marked with validation checkpoints
- Ready to inform PLAN.md creation
- MCP tool patterns documented for future use
</success_criteria>

<guidelines>
**When to use discovery:**
- Technology choice unclear (library A vs B)
- Best practices needed for unfamiliar integration
- API/library investigation required
- Single decision pending

**When NOT to use:**
- Established patterns (CRUD, auth with known library)
- Implementation details (defer to execution)
- Questions answerable from existing project context

**When to use RESEARCH.md instead:**
- Niche/complex domains (3D, games, audio, shaders)
- Need ecosystem knowledge, not just library choice
- "How do experts build this" questions
- Use `/GSI:research-phase` for these
</guidelines>

</document_content>
</document>
<document index="49">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\milestone-archive.md</source>
<document_content>
# Milestone Archive Template

This template is used by the complete-milestone workflow to create archive files in `.planning/milestones/`.

---

## File Template

# Milestone v{{VERSION}}: {{MILESTONE_NAME}}

**Status:** ✅ SHIPPED {{DATE}}
**Phases:** {{PHASE_START}}-{{PHASE_END}}
**Total Plans:** {{TOTAL_PLANS}}

## Overview

{{MILESTONE_DESCRIPTION}}

## Phases

{{PHASES_SECTION}}

[For each phase in this milestone, include:]

### Phase {{PHASE_NUM}}: {{PHASE_NAME}}

**Goal**: {{PHASE_GOAL}}
**Depends on**: {{DEPENDS_ON}}
**Plans**: {{PLAN_COUNT}} plans

Plans:

- [x] {{PHASE}}-01: {{PLAN_DESCRIPTION}}
- [x] {{PHASE}}-02: {{PLAN_DESCRIPTION}}
      [... all plans ...]

**Details:**
{{PHASE_DETAILS_FROM_ROADMAP}}

**For decimal phases, include (INSERTED) marker:**

### Phase 2.1: Critical Security Patch (INSERTED)

**Goal**: Fix authentication bypass vulnerability
**Depends on**: Phase 2
**Plans**: 1 plan

Plans:

- [x] 02.1-01: Patch auth vulnerability

**Details:**
{{PHASE_DETAILS_FROM_ROADMAP}}

---

## Milestone Summary

**Decimal Phases:**

- Phase 2.1: Critical Security Patch (inserted after Phase 2 for urgent fix)
- Phase 5.1: Performance Hotfix (inserted after Phase 5 for production issue)

**Key Decisions:**
{{DECISIONS_FROM_PROJECT_STATE}}
[Example:]

- Decision: Use ROADMAP.md split (Rationale: Constant context cost)
- Decision: Decimal phase numbering (Rationale: Clear insertion semantics)

**Issues Resolved:**
{{ISSUES_RESOLVED_DURING_MILESTONE}}
[Example:]

- Fixed context overflow at 100+ phases
- Resolved phase insertion confusion

**Issues Deferred:**
{{ISSUES_DEFERRED_TO_LATER}}
[Example:]

- PROJECT-STATE.md tiering (deferred until decisions > 300)

**Technical Debt Incurred:**
{{SHORTCUTS_NEEDING_FUTURE_WORK}}
[Example:]

- Some workflows still have hardcoded paths (fix in Phase 5)

---

_For current project status, see .planning/ROADMAP.md_

---

## Usage Guidelines

<guidelines>
**When to create milestone archives:**
- After completing all phases in a milestone (v1.0, v1.1, v2.0, etc.)
- Triggered by complete-milestone workflow
- Before planning next milestone work

**How to fill template:**

- Replace {{PLACEHOLDERS}} with actual values
- Extract phase details from ROADMAP.md
- Document decimal phases with (INSERTED) marker
- Include key decisions from PROJECT-STATE.md or SUMMARY files
- List issues resolved vs deferred
- Capture technical debt for future reference

**Archive location:**

- Save to `.planning/milestones/v{VERSION}-{NAME}.md`
- Example: `.planning/milestones/v1.0-mvp.md`

**After archiving:**

- Update ROADMAP.md to collapse completed milestone in `<details>` tag
- Update PROJECT.md to brownfield format with Current State section
- Continue phase numbering in next milestone (never restart at 01)
  </guidelines>

</document_content>
</document>
<document index="50">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\milestone.md</source>
<document_content>
# Milestone Entry Template

Add this entry to `.planning/MILESTONES.md` when completing a milestone:

```markdown
## v[X.Y] [Name] (Shipped: YYYY-MM-DD)

**Delivered:** [One sentence describing what shipped]

**Phases completed:** [X-Y] ([Z] plans total)

**Key accomplishments:**
- [Major achievement 1]
- [Major achievement 2]
- [Major achievement 3]
- [Major achievement 4]

**Stats:**
- [X] files created/modified
- [Y] lines of code (primary language)
- [Z] phases, [N] plans, [M] tasks
- [D] days from start to ship (or milestone to milestone)

**Git range:** `feat(XX-XX)` → `feat(YY-YY)`

**What's next:** [Brief description of next milestone goals, or "Project complete"]

---
```

<structure>
If MILESTONES.md doesn't exist, create it with header:

```markdown
# Project Milestones: [Project Name]

[Entries in reverse chronological order - newest first]
```
</structure>

<guidelines>
**When to create milestones:**
- Initial v1.0 MVP shipped
- Major version releases (v2.0, v3.0)
- Significant feature milestones (v1.1, v1.2)
- Before archiving planning (capture what was shipped)

**Don't create milestones for:**
- Individual phase completions (normal workflow)
- Work in progress (wait until shipped)
- Minor bug fixes that don't constitute a release

**Stats to include:**
- Count modified files: `git diff --stat feat(XX-XX)..feat(YY-YY) | tail -1`
- Count LOC: `find . -name "*.swift" -o -name "*.ts" | xargs wc -l` (or relevant extension)
- Phase/plan/task counts from ROADMAP
- Timeline from first phase commit to last phase commit

**Git range format:**
- First commit of milestone → last commit of milestone
- Example: `feat(01-01)` → `feat(04-01)` for phases 1-4
</guidelines>

<example>
```markdown
# Project Milestones: WeatherBar

## v1.1 Security & Polish (Shipped: 2025-12-10)

**Delivered:** Security hardening with Keychain integration and comprehensive error handling

**Phases completed:** 5-6 (3 plans total)

**Key accomplishments:**
- Migrated API key storage from plaintext to macOS Keychain
- Implemented comprehensive error handling for network failures
- Added Sentry crash reporting integration
- Fixed memory leak in auto-refresh timer

**Stats:**
- 23 files modified
- 650 lines of Swift added
- 2 phases, 3 plans, 12 tasks
- 8 days from v1.0 to v1.1

**Git range:** `feat(05-01)` → `feat(06-02)`

**What's next:** v2.0 SwiftUI redesign with widget support

---

## v1.0 MVP (Shipped: 2025-11-25)

**Delivered:** Menu bar weather app with current conditions and 3-day forecast

**Phases completed:** 1-4 (7 plans total)

**Key accomplishments:**
- Menu bar app with popover UI (AppKit)
- OpenWeather API integration with auto-refresh
- Current weather display with conditions icon
- 3-day forecast list with high/low temperatures
- Code signed and notarized for distribution

**Stats:**
- 47 files created
- 2,450 lines of Swift
- 4 phases, 7 plans, 28 tasks
- 12 days from start to ship

**Git range:** `feat(01-01)` → `feat(04-01)`

**What's next:** Security audit and hardening for v1.1
```
</example>

</document_content>
</document>
<document index="51">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\phase-prompt.md</source>
<document_content>
﻿# Phase Prompt Template

> **Note:** Planning methodology is in `agents/GSI-planner.md`.
> This template defines the PLAN.md output format that the agent produces.

Template for `.planning/phases/XX-name/{phase}-{plan}-PLAN.md` - executable phase plans optimized for parallel execution.

**Naming:** Use `{phase}-{plan}-PLAN.md` format (e.g., `01-02-PLAN.md` for Phase 1, Plan 2)

---

## File Template

```markdown
---
phase: XX-name
plan: NN
type: execute
wave: N                     # Execution wave (1, 2, 3...). Pre-computed at plan time.
depends_on: []              # Plan IDs this plan requires (e.g., ["01-01"]).
files_modified: []          # Files this plan modifies.
autonomous: true            # false if plan has checkpoints requiring user interaction
user_setup: []              # Human-required setup Claude cannot automate (see below)

# Goal-backward verification (derived during planning, verified after execution)
must_haves:
  truths: []                # Observable behaviors that must be true for goal achievement
  artifacts: []             # Files that must exist with real implementation
  key_links: []             # Critical connections between artifacts
---

<objective>
[What this plan accomplishes]

Purpose: [Why this matters for the project]
Output: [What artifacts will be created]
</objective>

<execution_context>
@~/.claude/get-shit-indexed/workflows/execute-plan.md
@~/.claude/get-shit-indexed/templates/summary.md
[If plan contains checkpoint tasks (type="checkpoint:*"), add:]
@~/.claude/get-shit-indexed/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Only reference prior plan SUMMARYs if genuinely needed:
# - This plan uses types/exports from prior plan
# - Prior plan made decision that affects this plan
# Do NOT reflexively chain: Plan 02 refs 01, Plan 03 refs 02...

[Relevant source files:]
@src/path/to/relevant.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: [Action-oriented name]</name>
  <files>path/to/file.ext, another/file.ext</files>
  <action>[Specific implementation - what to do, how to do it, what to avoid and WHY]</action>
  <verify>[Command or check to prove it worked]</verify>
  <done>[Measurable acceptance criteria]</done>
</task>

<task type="auto">
  <name>Task 2: [Action-oriented name]</name>
  <files>path/to/file.ext</files>
  <action>[Specific implementation]</action>
  <verify>[Command or check]</verify>
  <done>[Acceptance criteria]</done>
</task>

<!-- For checkpoint task examples and patterns, see @~/.claude/get-shit-indexed/references/checkpoints.md -->
<!-- Key rule: Claude starts dev server BEFORE human-verify checkpoints. User only visits URLs. -->

<task type="checkpoint:decision" gate="blocking">
  <decision>[What needs deciding]</decision>
  <context>[Why this decision matters]</context>
  <options>
    <option id="option-a"><name>[Name]</name><pros>[Benefits]</pros><cons>[Tradeoffs]</cons></option>
    <option id="option-b"><name>[Name]</name><pros>[Benefits]</pros><cons>[Tradeoffs]</cons></option>
  </options>
  <resume-signal>Select: option-a or option-b</resume-signal>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>[What Claude built] - server running at [URL]</what-built>
  <how-to-verify>Visit [URL] and verify: [visual checks only, NO CLI commands]</how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] [Specific test command]
- [ ] [Build/type check passes]
- [ ] [Behavior verification]
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No errors or warnings introduced
- [Plan-specific criteria]
  </success_criteria>

<output>
After completion, create `.planning/phases/XX-name/{phase}-{plan}-SUMMARY.md`
</output>
```

---

## Frontmatter Fields

| Field | Required | Purpose |
|-------|----------|---------|
| `phase` | Yes | Phase identifier (e.g., `01-foundation`) |
| `plan` | Yes | Plan number within phase (e.g., `01`, `02`) |
| `type` | Yes | Always `execute` for standard plans, `tdd` for TDD plans |
| `wave` | Yes | Execution wave number (1, 2, 3...). Pre-computed at plan time. |
| `depends_on` | Yes | Array of plan IDs this plan requires. |
| `files_modified` | Yes | Files this plan touches. |
| `autonomous` | Yes | `true` if no checkpoints, `false` if has checkpoints |
| `user_setup` | No | Array of human-required setup items (external services) |
| `must_haves` | Yes | Goal-backward verification criteria (see below) |

**Wave is pre-computed:** Wave numbers are assigned during `/GSI:plan-phase`. Execute-phase reads `wave` directly from frontmatter and groups plans by wave number. No runtime dependency analysis needed.

**Must-haves enable verification:** The `must_haves` field carries goal-backward requirements from planning to execution. After all plans complete, execute-phase spawns a verification subagent that checks these criteria against the actual codebase.

---

## Parallel vs Sequential

<parallel_examples>

**Wave 1 candidates (parallel):**

```yaml
# Plan 01 - User feature
wave: 1
depends_on: []
files_modified: [src/models/user.ts, src/api/users.ts]
autonomous: true

# Plan 02 - Product feature (no overlap with Plan 01)
wave: 1
depends_on: []
files_modified: [src/models/product.ts, src/api/products.ts]
autonomous: true

# Plan 03 - Order feature (no overlap)
wave: 1
depends_on: []
files_modified: [src/models/order.ts, src/api/orders.ts]
autonomous: true
```

All three run in parallel (Wave 1) - no dependencies, no file conflicts.

**Sequential (genuine dependency):**

```yaml
# Plan 01 - Auth foundation
wave: 1
depends_on: []
files_modified: [src/lib/auth.ts, src/middleware/auth.ts]
autonomous: true

# Plan 02 - Protected features (needs auth)
wave: 2
depends_on: ["01"]
files_modified: [src/features/dashboard.ts]
autonomous: true
```

Plan 02 in Wave 2 waits for Plan 01 in Wave 1 - genuine dependency on auth types/middleware.

**Checkpoint plan:**

```yaml
# Plan 03 - UI with verification
wave: 3
depends_on: ["01", "02"]
files_modified: [src/components/Dashboard.tsx]
autonomous: false  # Has checkpoint:human-verify
```

Wave 3 runs after Waves 1 and 2. Pauses at checkpoint, orchestrator presents to user, resumes on approval.

</parallel_examples>

---

## Context Section

**Parallel-aware context:**

```markdown
<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Only include SUMMARY refs if genuinely needed:
# - This plan imports types from prior plan
# - Prior plan made decision affecting this plan
# - Prior plan's output is input to this plan
#
# Independent plans need NO prior SUMMARY references.
# Do NOT reflexively chain: 02 refs 01, 03 refs 02...

@src/relevant/source.ts
</context>
```

**Bad pattern (creates false dependencies):**
```markdown
<context>
@.planning/phases/03-features/03-01-SUMMARY.md  # Just because it's earlier
@.planning/phases/03-features/03-02-SUMMARY.md  # Reflexive chaining
</context>
```

---

## Scope Guidance

**Plan sizing:**

- 2-3 tasks per plan
- ~50% context usage maximum
- Complex phases: Multiple focused plans, not one large plan

**When to split:**

- Different subsystems (auth vs API vs UI)
- >3 tasks
- Risk of context overflow
- TDD candidates - separate plans

**Vertical slices preferred:**

```
PREFER: Plan 01 = User (model + API + UI)
        Plan 02 = Product (model + API + UI)

AVOID:  Plan 01 = All models
        Plan 02 = All APIs
        Plan 03 = All UIs
```

---

## TDD Plans

TDD features get dedicated plans with `type: tdd`.

**Heuristic:** Can you write `expect(fn(input)).toBe(output)` before writing `fn`?
→ Yes: Create a TDD plan
→ No: Standard task in standard plan

See `~/.claude/get-shit-indexed/references/tdd.md` for TDD plan structure.

---

## Task Types

| Type | Use For | Autonomy |
|------|---------|----------|
| `auto` | Everything Claude can do independently | Fully autonomous |
| `checkpoint:human-verify` | Visual/functional verification | Pauses, returns to orchestrator |
| `checkpoint:decision` | Implementation choices | Pauses, returns to orchestrator |
| `checkpoint:human-action` | Truly unavoidable manual steps (rare) | Pauses, returns to orchestrator |

**Checkpoint behavior in parallel execution:**
- Plan runs until checkpoint
- Agent returns with checkpoint details + agent_id
- Orchestrator presents to user
- User responds
- Orchestrator resumes agent with `resume: agent_id`

---

## Examples

**Autonomous parallel plan:**

```markdown
---
phase: 03-features
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [src/features/user/model.ts, src/features/user/api.ts, src/features/user/UserList.tsx]
autonomous: true
---

<objective>
Implement complete User feature as vertical slice.

Purpose: Self-contained user management that can run parallel to other features.
Output: User model, API endpoints, and UI components.
</objective>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
</context>

<tasks>
<task type="auto">
  <name>Task 1: Create User model</name>
  <files>src/features/user/model.ts</files>
  <action>Define User type with id, email, name, createdAt. Export TypeScript interface.</action>
  <verify>tsc --noEmit passes</verify>
  <done>User type exported and usable</done>
</task>

<task type="auto">
  <name>Task 2: Create User API endpoints</name>
  <files>src/features/user/api.ts</files>
  <action>GET /users (list), GET /users/:id (single), POST /users (create). Use User type from model.</action>
  <verify>curl tests pass for all endpoints</verify>
  <done>All CRUD operations work</done>
</task>
</tasks>

<verification>
- [ ] npm run build succeeds
- [ ] API endpoints respond correctly
</verification>

<success_criteria>
- All tasks completed
- User feature works end-to-end
</success_criteria>

<output>
After completion, create `.planning/phases/03-features/03-01-SUMMARY.md`
</output>
```

**Plan with checkpoint (non-autonomous):**

```markdown
---
phase: 03-features
plan: 03
type: execute
wave: 2
depends_on: ["03-01", "03-02"]
files_modified: [src/components/Dashboard.tsx]
autonomous: false
---

<objective>
Build dashboard with visual verification.

Purpose: Integrate user and product features into unified view.
Output: Working dashboard component.
</objective>

<execution_context>
@~/.claude/get-shit-indexed/workflows/execute-plan.md
@~/.claude/get-shit-indexed/templates/summary.md
@~/.claude/get-shit-indexed/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-features/03-01-SUMMARY.md
@.planning/phases/03-features/03-02-SUMMARY.md
</context>

<tasks>
<task type="auto">
  <name>Task 1: Build Dashboard layout</name>
  <files>src/components/Dashboard.tsx</files>
  <action>Create responsive grid with UserList and ProductList components. Use Tailwind for styling.</action>
  <verify>npm run build succeeds</verify>
  <done>Dashboard renders without errors</done>
</task>

<!-- Checkpoint pattern: Claude starts server, user visits URL. See checkpoints.md for full patterns. -->
<task type="auto">
  <name>Start dev server</name>
  <action>Run `npm run dev` in background, wait for ready</action>
  <verify>curl localhost:3000 returns 200</verify>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Dashboard - server at http://localhost:3000</what-built>
  <how-to-verify>Visit localhost:3000/dashboard. Check: desktop grid, mobile stack, no scroll issues.</how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>
</tasks>

<verification>
- [ ] npm run build succeeds
- [ ] Visual verification passed
</verification>

<success_criteria>
- All tasks completed
- User approved visual layout
</success_criteria>

<output>
After completion, create `.planning/phases/03-features/03-03-SUMMARY.md`
</output>
```

---

## Anti-Patterns

**Bad: Reflexive dependency chaining**
```yaml
depends_on: ["03-01"]  # Just because 01 comes before 02
```

**Bad: Horizontal layer grouping**
```
Plan 01: All models
Plan 02: All APIs (depends on 01)
Plan 03: All UIs (depends on 02)
```

**Bad: Missing autonomy flag**
```yaml
# Has checkpoint but no autonomous: false
depends_on: []
files_modified: [...]
# autonomous: ???  <- Missing!
```

**Bad: Vague tasks**
```xml
<task type="auto">
  <name>Set up authentication</name>
  <action>Add auth to the app</action>
</task>
```

---

## Guidelines

- Always use XML structure for Claude parsing
- Include `wave`, `depends_on`, `files_modified`, `autonomous` in every plan
- Prefer vertical slices over horizontal layers
- Only reference prior SUMMARYs when genuinely needed
- Group checkpoints with related auto tasks in same plan
- 2-3 tasks per plan, ~50% context max

---

## User Setup (External Services)

When a plan introduces external services requiring human configuration, declare in frontmatter:

```yaml
user_setup:
  - service: stripe
    why: "Payment processing requires API keys"
    env_vars:
      - name: STRIPE_SECRET_KEY
        source: "Stripe Dashboard → Developers → API keys → Secret key"
      - name: STRIPE_WEBHOOK_SECRET
        source: "Stripe Dashboard → Developers → Webhooks → Signing secret"
    dashboard_config:
      - task: "Create webhook endpoint"
        location: "Stripe Dashboard → Developers → Webhooks → Add endpoint"
        details: "URL: https://[your-domain]/api/webhooks/stripe"
    local_dev:
      - "stripe listen --forward-to localhost:3000/api/webhooks/stripe"
```

**The automation-first rule:** `user_setup` contains ONLY what Claude literally cannot do:
- Account creation (requires human signup)
- Secret retrieval (requires dashboard access)
- Dashboard configuration (requires human in browser)

**NOT included:** Package installs, code changes, file creation, CLI commands Claude can run.

**Result:** Execute-plan generates `{phase}-USER-SETUP.md` with checklist for the user.

See `~/.claude/get-shit-indexed/templates/user-setup.md` for full schema and examples

---

## Must-Haves (Goal-Backward Verification)

The `must_haves` field defines what must be TRUE for the phase goal to be achieved. Derived during planning, verified after execution.

**Structure:**

```yaml
must_haves:
  truths:
    - "User can see existing messages"
    - "User can send a message"
    - "Messages persist across refresh"
  artifacts:
    - path: "src/components/Chat.tsx"
      provides: "Message list rendering"
      min_lines: 30
    - path: "src/app/api/chat/route.ts"
      provides: "Message CRUD operations"
      exports: ["GET", "POST"]
    - path: "prisma/schema.prisma"
      provides: "Message model"
      contains: "model Message"
  key_links:
    - from: "src/components/Chat.tsx"
      to: "/api/chat"
      via: "fetch in useEffect"
      pattern: "fetch.*api/chat"
    - from: "src/app/api/chat/route.ts"
      to: "prisma.message"
      via: "database query"
      pattern: "prisma\\.message\\.(find|create)"
```

**Field descriptions:**

| Field | Purpose |
|-------|---------|
| `truths` | Observable behaviors from user perspective. Each must be testable. |
| `artifacts` | Files that must exist with real implementation. |
| `artifacts[].path` | File path relative to project root. |
| `artifacts[].provides` | What this artifact delivers. |
| `artifacts[].min_lines` | Optional. Minimum lines to be considered substantive. |
| `artifacts[].exports` | Optional. Expected exports to verify. |
| `artifacts[].contains` | Optional. Pattern that must exist in file. |
| `key_links` | Critical connections between artifacts. |
| `key_links[].from` | Source artifact. |
| `key_links[].to` | Target artifact or endpoint. |
| `key_links[].via` | How they connect (description). |
| `key_links[].pattern` | Optional. Regex to verify connection exists. |

**Why this matters:**

Task completion ≠ Goal achievement. A task "create chat component" can complete by creating a placeholder. The `must_haves` field captures what must actually work, enabling verification to catch gaps before they compound.

**Verification flow:**

1. Plan-phase derives must_haves from phase goal (goal-backward)
2. Must_haves written to PLAN.md frontmatter
3. Execute-phase runs all plans
4. Verification subagent checks must_haves against codebase
5. Gaps found → fix plans created → execute → re-verify
6. All must_haves pass → phase complete

See `~/.claude/get-shit-indexed/workflows/verify-phase.md` for verification logic.

</document_content>
</document>
<document index="52">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\planner-subagent-prompt.md</source>
<document_content>
﻿# Planner Subagent Prompt Template

Template for spawning GSI-planner agent. The agent contains all planning expertise - this template provides planning context only.

---

## Template

```markdown
<planning_context>

**Phase:** {phase_number}
**Mode:** {standard | gap_closure}

**Project State:**
@.planning/STATE.md

**Roadmap:**
@.planning/ROADMAP.md

**Requirements (if exists):**
@.planning/REQUIREMENTS.md

**Phase Context (if exists):**
@.planning/phases/{phase_dir}/{phase}-CONTEXT.md

**Research (if exists):**
@.planning/phases/{phase_dir}/{phase}-RESEARCH.md

**Gap Closure (if --gaps mode):**
@.planning/phases/{phase_dir}/{phase}-VERIFICATION.md
@.planning/phases/{phase_dir}/{phase}-UAT.md

**MCP Tool Priority:**
- Use Code-Index MCP (CI) for code search, symbol extraction, and file analysis
- Use Desktop Commander's `read_multiple_files` for batch file reading
- Follow tool hierarchy: Skills > MCP > Native

</planning_context>

<downstream_consumer>
Output consumed by /GSI:execute-phase
Plans must be executable prompts with:
- Frontmatter (wave, depends_on, files_modified, autonomous)
- Tasks in XML format
- Verification criteria
- must_haves for goal-backward verification
</downstream_consumer>

<quality_gate>
Before returning PLANNING COMPLETE:
- [ ] PLAN.md files created in phase directory
- [ ] Each plan has valid frontmatter
- [ ] Tasks are specific and actionable
- [ ] Dependencies correctly identified
- [ ] Waves assigned for parallel execution
- [ ] must_haves derived from phase goal
- [ ] MCP tool patterns included in task descriptions
- [ ] Relationship analysis documented for complex changes
</quality_gate>
```

---

## Placeholders

| Placeholder | Source | Example |
|-------------|--------|---------|
| `{phase_number}` | From roadmap/arguments | `5` or `2.1` |
| `{phase_dir}` | Phase directory name | `05-user-profiles` |
| `{phase}` | Phase prefix | `05` |
| `{standard \| gap_closure}` | Mode flag | `standard` |

---

## Usage

**From /GSI:plan-phase (standard mode):**
```python
Task(
  prompt=filled_template,
  subagent_type="GSI-planner",
  description="Plan Phase {phase}"
)
```

**From /GSI:plan-phase --gaps (gap closure mode):**
```python
Task(
  prompt=filled_template,  # with mode: gap_closure
  subagent_type="GSI-planner",
  description="Plan gaps for Phase {phase}"
)
```

---

## Continuation

For checkpoints, spawn fresh agent with:

```markdown
<objective>
Continue planning for Phase {phase_number}: {phase_name}
</objective>

<prior_state>
Phase directory: @.planning/phases/{phase_dir}/
Existing plans: @.planning/phases/{phase_dir}/*-PLAN.md
</prior_state>

<checkpoint_response>
**Type:** {checkpoint_type}
**Response:** {user_response}
</checkpoint_response>

<mode>
Continue: {standard | gap_closure}
</mode>
```

---

**Note:** Planning methodology, task breakdown, dependency analysis, wave assignment, TDD detection, and goal-backward derivation are baked into the GSI-planner agent. This template only passes context.

</document_content>
</document>
<document index="53">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\project.md</source>
<document_content>
﻿# PROJECT.md Template

Template for `.planning/PROJECT.md` — the living project context document.

<template>

```markdown
# [Project Name]

## What This Is

[Current accurate description — 2-3 sentences. What does this product do and who is it for?
Use the user's language and framing. Update whenever reality drifts from this description.]

## Core Value

[The ONE thing that matters most. If everything else fails, this must work.
One sentence that drives prioritization when tradeoffs arise.]

## Requirements

### Validated

<!-- Shipped and confirmed valuable. -->

(None yet — ship to validate)

### Active

<!-- Current scope. Building toward these. -->

- [ ] [Requirement 1]
- [ ] [Requirement 2]
- [ ] [Requirement 3]

### Out of Scope

<!-- Explicit boundaries. Includes reasoning to prevent re-adding. -->

- [Exclusion 1] — [why]
- [Exclusion 2] — [why]

## Context

[Background information that informs implementation:
- Technical environment or ecosystem
- Relevant prior work or experience
- User research or feedback themes
- Known issues to address]

## Constraints

- **[Type]**: [What] — [Why]
- **[Type]**: [What] — [Why]

Common types: Tech stack, Timeline, Budget, Dependencies, Compatibility, Performance, Security

## Key Decisions

<!-- Decisions that constrain future work. Add throughout project lifecycle. -->

| Decision | Rationale | Outcome |
|----------|-----------|---------|
| [Choice] | [Why] | [✓ Good / ⚠️ Revisit / — Pending] |

---
*Last updated: [date] after [trigger]*

## 7-BMAD Thinking Integration

This project uses the 7-BMAD methodology integrated with thinking servers for quality assurance:

### Mode Circle (Pattern Consistency) → Sequential Thinking
**Purpose:** Ensure consistent patterns across the project
**Sequential Pattern:**
1. Identify existing patterns
2. Document pattern rules
3. Apply consistently
4. Validate adherence
5. Refactor deviations

### Mod Circle (Maintainability) → Tractatus Thinking
**Purpose:** Analyze and improve code structure
**Tractatus Operations:**
- `start`: Begin structural analysis
- `add`: Refactor for maintainability
- `analyze`: Verify improvements

### Modd Circle (Extensibility) → Tractatus Thinking
**Purpose:** Design future-proof architecture
**Tractatus Focus:**
- Identify extension points
- Design pluggable components
- Ensure backward compatibility

### Methodd Circle (Documentation) → Sequential Thinking
**Purpose:** Structure documentation creation
**Sequential Process:**
1. Understand audience needs
2. Structure content logically
3. Create drafts
4. Review and refine
5. Publish and maintain
```

</template>

<guidelines>

**What This Is:**
- Current accurate description of the product
- 2-3 sentences capturing what it does and who it's for
- Use the user's words and framing
- Update when the product evolves beyond this description

**Core Value:**
- The single most important thing
- Everything else can fail; this cannot
- Drives prioritization when tradeoffs arise
- Rarely changes; if it does, it's a significant pivot

**Requirements — Validated:**
- Requirements that shipped and proved valuable
- Format: `- ✓ [Requirement] — [version/phase]`
- These are locked — changing them requires explicit discussion

**Requirements — Active:**
- Current scope being built toward
- These are hypotheses until shipped and validated
- Move to Validated when shipped, Out of Scope if invalidated

**Requirements — Out of Scope:**
- Explicit boundaries on what we're not building
- Always include reasoning (prevents re-adding later)
- Includes: considered and rejected, deferred to future, explicitly excluded

**Context:**
- Background that informs implementation decisions
- Technical environment, prior work, user feedback
- Known issues or technical debt to address
- Update as new context emerges

**Constraints:**
- Hard limits on implementation choices
- Tech stack, timeline, budget, compatibility, dependencies
- Include the "why" — constraints without rationale get questioned

**Key Decisions:**
- Significant choices that affect future work
- Add decisions as they're made throughout the project
- Track outcome when known:
  - ✓ Good — decision proved correct
  - ⚠️ Revisit — decision may need reconsideration
  - — Pending — too early to evaluate

**Last Updated:**
- Always note when and why the document was updated
- Format: `after Phase 2` or `after v1.0 milestone`
- Triggers review of whether content is still accurate

</guidelines>

<evolution>

PROJECT.md evolves throughout the project lifecycle.

**After each phase transition:**
1. Requirements invalidated? → Move to Out of Scope with reason
2. Requirements validated? → Move to Validated with phase reference
3. New requirements emerged? → Add to Active
4. Decisions to log? → Add to Key Decisions
5. "What This Is" still accurate? → Update if drifted

**After each milestone:**
1. Full review of all sections
2. Core Value check — still the right priority?
3. Audit Out of Scope — reasons still valid?
4. Update Context with current state (users, feedback, metrics)

</evolution>

<brownfield>

For existing codebases:

1. **Map codebase first** via `/GSI:map-codebase`

2. **Infer Validated requirements** from existing code:
   - What does the codebase actually do?
   - What patterns are established?
   - What's clearly working and relied upon?

3. **Gather Active requirements** from user:
   - Present inferred current state
   - Ask what they want to build next

4. **Initialize:**
   - Validated = inferred from existing code
   - Active = user's goals for this work
   - Out of Scope = boundaries user specifies
   - Context = includes current codebase state

</brownfield>

<state_reference>

STATE.md references PROJECT.md:

```markdown
## Project Reference

See: .planning/PROJECT.md (updated [date])

**Core value:** [One-liner from Core Value section]
**Current focus:** [Current phase name]
```

This ensures Claude reads current PROJECT.md context.

</state_reference>

</document_content>
</document>
<document index="54">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\requirements.md</source>
<document_content>
# Requirements Template

Template for `.planning/REQUIREMENTS.md` — checkable requirements that define "done."

<template>

```markdown
# Requirements: [Project Name]

**Defined:** [date]
**Core Value:** [from PROJECT.md]

## v1 Requirements

Requirements for initial release. Each maps to roadmap phases.

### Authentication

- [ ] **AUTH-01**: User can sign up with email and password
- [ ] **AUTH-02**: User receives email verification after signup
- [ ] **AUTH-03**: User can reset password via email link
- [ ] **AUTH-04**: User session persists across browser refresh

### [Category 2]

- [ ] **[CAT]-01**: [Requirement description]
- [ ] **[CAT]-02**: [Requirement description]
- [ ] **[CAT]-03**: [Requirement description]

### [Category 3]

- [ ] **[CAT]-01**: [Requirement description]
- [ ] **[CAT]-02**: [Requirement description]

## v2 Requirements

Deferred to future release. Tracked but not in current roadmap.

### [Category]

- **[CAT]-01**: [Requirement description]
- **[CAT]-02**: [Requirement description]

## Out of Scope

Explicitly excluded. Documented to prevent scope creep.

| Feature | Reason |
|---------|--------|
| [Feature] | [Why excluded] |
| [Feature] | [Why excluded] |

## Traceability

Which phases cover which requirements. Updated during roadmap creation.

| Requirement | Phase | Status |
|-------------|-------|--------|
| AUTH-01 | Phase 1 | Pending |
| AUTH-02 | Phase 1 | Pending |
| AUTH-03 | Phase 1 | Pending |
| AUTH-04 | Phase 1 | Pending |
| [REQ-ID] | Phase [N] | Pending |

**Coverage:**
- v1 requirements: [X] total
- Mapped to phases: [Y]
- Unmapped: [Z] ⚠️

---
*Requirements defined: [date]*
*Last updated: [date] after [trigger]*
```

</template>

<guidelines>

**Requirement Format:**
- ID: `[CATEGORY]-[NUMBER]` (AUTH-01, CONTENT-02, SOCIAL-03)
- Description: User-centric, testable, atomic
- Checkbox: Only for v1 requirements (v2 are not yet actionable)

**Categories:**
- Derive from research FEATURES.md categories
- Keep consistent with domain conventions
- Typical: Authentication, Content, Social, Notifications, Moderation, Payments, Admin

**v1 vs v2:**
- v1: Committed scope, will be in roadmap phases
- v2: Acknowledged but deferred, not in current roadmap
- Moving v2 → v1 requires roadmap update

**Out of Scope:**
- Explicit exclusions with reasoning
- Prevents "why didn't you include X?" later
- Anti-features from research belong here with warnings

**Traceability:**
- Empty initially, populated during roadmap creation
- Each requirement maps to exactly one phase
- Unmapped requirements = roadmap gap

**Status Values:**
- Pending: Not started
- In Progress: Phase is active
- Complete: Requirement verified
- Blocked: Waiting on external factor

</guidelines>

<evolution>

**After each phase completes:**
1. Mark covered requirements as Complete
2. Update traceability status
3. Note any requirements that changed scope

**After roadmap updates:**
1. Verify all v1 requirements still mapped
2. Add new requirements if scope expanded
3. Move requirements to v2/out of scope if descoped

**Requirement completion criteria:**
- Requirement is "Complete" when:
  - Feature is implemented
  - Feature is verified (tests pass, manual check done)
  - Feature is committed

</evolution>

<example>

```markdown
# Requirements: CommunityApp

**Defined:** 2025-01-14
**Core Value:** Users can share and discuss content with people who share their interests

## v1 Requirements

### Authentication

- [ ] **AUTH-01**: User can sign up with email and password
- [ ] **AUTH-02**: User receives email verification after signup
- [ ] **AUTH-03**: User can reset password via email link
- [ ] **AUTH-04**: User session persists across browser refresh

### Profiles

- [ ] **PROF-01**: User can create profile with display name
- [ ] **PROF-02**: User can upload avatar image
- [ ] **PROF-03**: User can write bio (max 500 chars)
- [ ] **PROF-04**: User can view other users' profiles

### Content

- [ ] **CONT-01**: User can create text post
- [ ] **CONT-02**: User can upload image with post
- [ ] **CONT-03**: User can edit own posts
- [ ] **CONT-04**: User can delete own posts
- [ ] **CONT-05**: User can view feed of posts

### Social

- [ ] **SOCL-01**: User can follow other users
- [ ] **SOCL-02**: User can unfollow users
- [ ] **SOCL-03**: User can like posts
- [ ] **SOCL-04**: User can comment on posts
- [ ] **SOCL-05**: User can view activity feed (followed users' posts)

## v2 Requirements

### Notifications

- **NOTF-01**: User receives in-app notifications
- **NOTF-02**: User receives email for new followers
- **NOTF-03**: User receives email for comments on own posts
- **NOTF-04**: User can configure notification preferences

### Moderation

- **MODR-01**: User can report content
- **MODR-02**: User can block other users
- **MODR-03**: Admin can view reported content
- **MODR-04**: Admin can remove content
- **MODR-05**: Admin can ban users

## Out of Scope

| Feature | Reason |
|---------|--------|
| Real-time chat | High complexity, not core to community value |
| Video posts | Storage/bandwidth costs, defer to v2+ |
| OAuth login | Email/password sufficient for v1 |
| Mobile app | Web-first, mobile later |

## Traceability

| Requirement | Phase | Status |
|-------------|-------|--------|
| AUTH-01 | Phase 1 | Pending |
| AUTH-02 | Phase 1 | Pending |
| AUTH-03 | Phase 1 | Pending |
| AUTH-04 | Phase 1 | Pending |
| PROF-01 | Phase 2 | Pending |
| PROF-02 | Phase 2 | Pending |
| PROF-03 | Phase 2 | Pending |
| PROF-04 | Phase 2 | Pending |
| CONT-01 | Phase 3 | Pending |
| CONT-02 | Phase 3 | Pending |
| CONT-03 | Phase 3 | Pending |
| CONT-04 | Phase 3 | Pending |
| CONT-05 | Phase 3 | Pending |
| SOCL-01 | Phase 4 | Pending |
| SOCL-02 | Phase 4 | Pending |
| SOCL-03 | Phase 4 | Pending |
| SOCL-04 | Phase 4 | Pending |
| SOCL-05 | Phase 4 | Pending |

**Coverage:**
- v1 requirements: 18 total
- Mapped to phases: 18
- Unmapped: 0 ✓

---
*Requirements defined: 2025-01-14*
*Last updated: 2025-01-14 after initial definition*
```

</example>

</document_content>
</document>
<document index="55">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\research.md</source>
<document_content>
﻿# Research Template

Template for `.planning/phases/XX-name/{phase}-RESEARCH.md` - comprehensive ecosystem research before planning.

**Purpose:** Document what Claude needs to know to implement a phase well - not just "which library" but "how do experts build this."

---

## File Template

```markdown
# Phase [X]: [Name] - Research

**Researched:** [date]
**Domain:** [primary technology/problem domain]
**Confidence:** [HIGH/MEDIUM/LOW]

<user_constraints>
## User Constraints (from CONTEXT.md)

**CRITICAL:** If CONTEXT.md exists from /GSI:discuss-phase, copy locked decisions here verbatim. These MUST be honored by the planner.

### Locked Decisions
[Copy from CONTEXT.md `## Decisions` section - these are NON-NEGOTIABLE]
- [Decision 1]
- [Decision 2]

### Claude's Discretion
[Copy from CONTEXT.md - areas where researcher/planner can choose]
- [Area 1]
- [Area 2]

### Deferred Ideas (OUT OF SCOPE)
[Copy from CONTEXT.md - do NOT research or plan these]
- [Deferred 1]
- [Deferred 2]

**If no CONTEXT.md exists:** Write "No user constraints - all decisions at Claude's discretion"
</user_constraints>

<research_summary>
## Summary

[2-3 paragraph executive summary]
- What was researched
- What the standard approach is
- Key recommendations

**Primary recommendation:** [one-liner actionable guidance]
</research_summary>

<standard_stack>
## Standard Stack

The established libraries/tools for this domain:

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| [name] | [ver] | [what it does] | [why experts use it] |
| [name] | [ver] | [what it does] | [why experts use it] |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| [name] | [ver] | [what it does] | [use case] |
| [name] | [ver] | [what it does] | [use case] |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| [standard] | [alternative] | [when alternative makes sense] |

**Installation:**
```bash
npm install [packages]
# or
yarn add [packages]
```
</standard_stack>

<architecture_patterns>
## Architecture Patterns

### Recommended Project Structure
```
src/
├── [folder]/        # [purpose]
├── [folder]/        # [purpose]
└── [folder]/        # [purpose]
```

### Pattern 1: [Pattern Name]
**What:** [description]
**When to use:** [conditions]
**Example:**
```typescript
// [code example from Context7/official docs]
```

### Pattern 2: [Pattern Name]
**What:** [description]
**When to use:** [conditions]
**Example:**
```typescript
// [code example]
```

### Anti-Patterns to Avoid
- **[Anti-pattern]:** [why it's bad, what to do instead]
- **[Anti-pattern]:** [why it's bad, what to do instead]
</architecture_patterns>

<dont_hand_roll>
## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| [problem] | [what you'd build] | [library] | [edge cases, complexity] |
| [problem] | [what you'd build] | [library] | [edge cases, complexity] |
| [problem] | [what you'd build] | [library] | [edge cases, complexity] |

**Key insight:** [why custom solutions are worse in this domain]
</dont_hand_roll>

<common_pitfalls>
## Common Pitfalls

### Pitfall 1: [Name]
**What goes wrong:** [description]
**Why it happens:** [root cause]
**How to avoid:** [prevention strategy]
**Warning signs:** [how to detect early]

### Pitfall 2: [Name]
**What goes wrong:** [description]
**Why it happens:** [root cause]
**How to avoid:** [prevention strategy]
**Warning signs:** [how to detect early]

### Pitfall 3: [Name]
**What goes wrong:** [description]
**Why it happens:** [root cause]
**How to avoid:** [prevention strategy]
**Warning signs:** [how to detect early]
</common_pitfalls>

<code_examples>
## Code Examples

Verified patterns from official sources:

### [Common Operation 1]
```typescript
// Source: [Context7/official docs URL]
[code]
```

### [Common Operation 2]
```typescript
// Source: [Context7/official docs URL]
[code]
```

### [Common Operation 3]
```typescript
// Source: [Context7/official docs URL]
[code]
```
</code_examples>

<sota_updates>
## State of the Art (2024-2025)

What's changed recently:

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| [old] | [new] | [date/version] | [what it means for implementation] |

**New tools/patterns to consider:**
- [Tool/Pattern]: [what it enables, when to use]
- [Tool/Pattern]: [what it enables, when to use]

**Deprecated/outdated:**
- [Thing]: [why it's outdated, what replaced it]
</sota_updates>

<open_questions>
## Open Questions

Things that couldn't be fully resolved:

1. **[Question]**
   - What we know: [partial info]
   - What's unclear: [the gap]
   - Recommendation: [how to handle during planning/execution]

2. **[Question]**
   - What we know: [partial info]
   - What's unclear: [the gap]
   - Recommendation: [how to handle]
</open_questions>

<sources>
## Sources

### Primary (HIGH confidence)
- [Context7 library ID] - [topics fetched]
- [Official docs URL] - [what was checked]

### Secondary (MEDIUM confidence)
- [WebSearch verified with official source] - [finding + verification]

### Tertiary (LOW confidence - needs validation)
- [WebSearch only] - [finding, marked for validation during implementation]
</sources>

<metadata>
## Metadata

**Research scope:**
- Core technology: [what]
- Ecosystem: [libraries explored]
- Patterns: [patterns researched]
- Pitfalls: [areas checked]

**Confidence breakdown:**
- Standard stack: [HIGH/MEDIUM/LOW] - [reason]
- Architecture: [HIGH/MEDIUM/LOW] - [reason]
- Pitfalls: [HIGH/MEDIUM/LOW] - [reason]
- Code examples: [HIGH/MEDIUM/LOW] - [reason]

**Research date:** [date]
**Valid until:** [estimate - 30 days for stable tech, 7 days for fast-moving]
</metadata>

---

*Phase: XX-name*
*Research completed: [date]*
*Ready for planning: [yes/no]*
```

---

## Good Example

```markdown
# Phase 3: 3D City Driving - Research

**Researched:** 2025-01-20
**Domain:** Three.js 3D web game with driving mechanics
**Confidence:** HIGH

<research_summary>
## Summary

Researched the Three.js ecosystem for building a 3D city driving game. The standard approach uses Three.js with React Three Fiber for component architecture, Rapier for physics, and drei for common helpers.

Key finding: Don't hand-roll physics or collision detection. Rapier (via @react-three/rapier) handles vehicle physics, terrain collision, and city object interactions efficiently. Custom physics code leads to bugs and performance issues.

**Primary recommendation:** Use R3F + Rapier + drei stack. Start with vehicle controller from drei, add Rapier vehicle physics, build city with instanced meshes for performance.
</research_summary>

<standard_stack>
## Standard Stack

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| three | 0.160.0 | 3D rendering | The standard for web 3D |
| @react-three/fiber | 8.15.0 | React renderer for Three.js | Declarative 3D, better DX |
| @react-three/drei | 9.92.0 | Helpers and abstractions | Solves common problems |
| @react-three/rapier | 1.2.1 | Physics engine bindings | Best physics for R3F |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| @react-three/postprocessing | 2.16.0 | Visual effects | Bloom, DOF, motion blur |
| leva | 0.9.35 | Debug UI | Tweaking parameters |
| zustand | 4.4.7 | State management | Game state, UI state |
| use-sound | 4.0.1 | Audio | Engine sounds, ambient |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| Rapier | Cannon.js | Cannon simpler but less performant for vehicles |
| R3F | Vanilla Three | Vanilla if no React, but R3F DX is much better |
| drei | Custom helpers | drei is battle-tested, don't reinvent |

**Installation:**
```bash
npm install three @react-three/fiber @react-three/drei @react-three/rapier zustand
```
</standard_stack>

<architecture_patterns>
## Architecture Patterns

### Recommended Project Structure
```
src/
├── components/
│   ├── Vehicle/          # Player car with physics
│   ├── City/             # City generation and buildings
│   ├── Road/             # Road network
│   └── Environment/      # Sky, lighting, fog
├── hooks/
│   ├── useVehicleControls.ts
│   └── useGameState.ts
├── stores/
│   └── gameStore.ts      # Zustand state
└── utils/
    └── cityGenerator.ts  # Procedural generation helpers
```

### Pattern 1: Vehicle with Rapier Physics
**What:** Use RigidBody with vehicle-specific settings, not custom physics
**When to use:** Any ground vehicle
**Example:**
```typescript
// Source: @react-three/rapier docs
import { RigidBody, useRapier } from '@react-three/rapier'

function Vehicle() {
  const rigidBody = useRef()

  return (
    <RigidBody
      ref={rigidBody}
      type="dynamic"
      colliders="hull"
      mass={1500}
      linearDamping={0.5}
      angularDamping={0.5}
    >
      <mesh>
        <boxGeometry args={[2, 1, 4]} />
        <meshStandardMaterial />
      </mesh>
    </RigidBody>
  )
}
```

### Pattern 2: Instanced Meshes for City
**What:** Use InstancedMesh for repeated objects (buildings, trees, props)
**When to use:** >100 similar objects
**Example:**
```typescript
// Source: drei docs
import { Instances, Instance } from '@react-three/drei'

function Buildings({ positions }) {
  return (
    <Instances limit={1000}>
      <boxGeometry />
      <meshStandardMaterial />
      {positions.map((pos, i) => (
        <Instance key={i} position={pos} scale={[1, Math.random() * 5 + 1, 1]} />
      ))}
    </Instances>
  )
}
```

### Anti-Patterns to Avoid
- **Creating meshes in render loop:** Create once, update transforms only
- **Not using InstancedMesh:** Individual meshes for buildings kills performance
- **Custom physics math:** Rapier handles it better, every time
</architecture_patterns>

<dont_hand_roll>
## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Vehicle physics | Custom velocity/acceleration | Rapier RigidBody | Wheel friction, suspension, collisions are complex |
| Collision detection | Raycasting everything | Rapier colliders | Performance, edge cases, tunneling |
| Camera follow | Manual lerp | drei CameraControls or custom with useFrame | Smooth interpolation, bounds |
| City generation | Pure random placement | Grid-based with noise for variation | Random looks wrong, grid is predictable |
| LOD | Manual distance checks | drei <Detailed> | Handles transitions, hysteresis |

**Key insight:** 3D game development has 40+ years of solved problems. Rapier implements proper physics simulation. drei implements proper 3D helpers. Fighting these leads to bugs that look like "game feel" issues but are actually physics edge cases.
</dont_hand_roll>

<common_pitfalls>
## Common Pitfalls

### Pitfall 1: Physics Tunneling
**What goes wrong:** Fast objects pass through walls
**Why it happens:** Default physics step too large for velocity
**How to avoid:** Use CCD (Continuous Collision Detection) in Rapier
**Warning signs:** Objects randomly appearing outside buildings

### Pitfall 2: Performance Death by Draw Calls
**What goes wrong:** Game stutters with many buildings
**Why it happens:** Each mesh = 1 draw call, hundreds of buildings = hundreds of calls
**How to avoid:** InstancedMesh for similar objects, merge static geometry
**Warning signs:** GPU bound, low FPS despite simple scene

### Pitfall 3: Vehicle "Floaty" Feel
**What goes wrong:** Car doesn't feel grounded
**Why it happens:** Missing proper wheel/suspension simulation
**How to avoid:** Use Rapier vehicle controller or tune mass/damping carefully
**Warning signs:** Car bounces oddly, doesn't grip corners
</common_pitfalls>

<code_examples>
## Code Examples

### Basic R3F + Rapier Setup
```typescript
// Source: @react-three/rapier getting started
import { Canvas } from '@react-three/fiber'
import { Physics } from '@react-three/rapier'

function Game() {
  return (
    <Canvas>
      <Physics gravity={[0, -9.81, 0]}>
        <Vehicle />
        <City />
        <Ground />
      </Physics>
    </Canvas>
  )
}
```

### Vehicle Controls Hook
```typescript
// Source: Community pattern, verified with drei docs
import { useFrame } from '@react-three/fiber'
import { useKeyboardControls } from '@react-three/drei'

function useVehicleControls(rigidBodyRef) {
  const [, getKeys] = useKeyboardControls()

  useFrame(() => {
    const { forward, back, left, right } = getKeys()
    const body = rigidBodyRef.current
    if (!body) return

    const impulse = { x: 0, y: 0, z: 0 }
    if (forward) impulse.z -= 10
    if (back) impulse.z += 5

    body.applyImpulse(impulse, true)

    if (left) body.applyTorqueImpulse({ x: 0, y: 2, z: 0 }, true)
    if (right) body.applyTorqueImpulse({ x: 0, y: -2, z: 0 }, true)
  })
}
```
</code_examples>

<sota_updates>
## State of the Art (2024-2025)

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| cannon-es | Rapier | 2023 | Rapier is faster, better maintained |
| vanilla Three.js | React Three Fiber | 2020+ | R3F is now standard for React apps |
| Manual InstancedMesh | drei <Instances> | 2022 | Simpler API, handles updates |

**New tools/patterns to consider:**
- **WebGPU:** Coming but not production-ready for games yet (2025)
- **drei Gltf helpers:** <useGLTF.preload> for loading screens

**Deprecated/outdated:**
- **cannon.js (original):** Use cannon-es fork or better, Rapier
- **Manual raycasting for physics:** Just use Rapier colliders
</sota_updates>

<sources>
## Sources

### Primary (HIGH confidence)
- /pmndrs/react-three-fiber - getting started, hooks, performance
- /pmndrs/drei - instances, controls, helpers
- /dimforge/rapier-js - physics setup, vehicle physics

### Secondary (MEDIUM confidence)
- Three.js discourse "city driving game" threads - verified patterns against docs
- R3F examples repository - verified code works

### Tertiary (LOW confidence - needs validation)
- None - all findings verified
</sources>

<metadata>
## Metadata

**Research scope:**
- Core technology: Three.js + React Three Fiber
- Ecosystem: Rapier, drei, zustand
- Patterns: Vehicle physics, instancing, city generation
- Pitfalls: Performance, physics, feel

**Confidence breakdown:**
- Standard stack: HIGH - verified with Context7, widely used
- Architecture: HIGH - from official examples
- Pitfalls: HIGH - documented in discourse, verified in docs
- Code examples: HIGH - from Context7/official sources

**Research date:** 2025-01-20
**Valid until:** 2025-02-20 (30 days - R3F ecosystem stable)
</metadata>

---

*Phase: 03-city-driving*
*Research completed: 2025-01-20*
*Ready for planning: yes*
```

---

## Guidelines

**When to create:**
- Before planning phases in niche/complex domains
- When Claude's training data is likely stale or sparse
- When "how do experts do this" matters more than "which library"

**Structure:**
- Use XML tags for section markers (matches GSI templates)
- Seven core sections: summary, standard_stack, architecture_patterns, dont_hand_roll, common_pitfalls, code_examples, sources
- All sections required (drives comprehensive research)

**Content quality:**
- Standard stack: Specific versions, not just names
- Architecture: Include actual code examples from authoritative sources
- Don't hand-roll: Be explicit about what problems to NOT solve yourself
- Pitfalls: Include warning signs, not just "don't do this"
- Sources: Mark confidence levels honestly

**Integration with planning:**
- RESEARCH.md loaded as @context reference in PLAN.md
- Standard stack informs library choices
- Don't hand-roll prevents custom solutions
- Pitfalls inform verification criteria
- Code examples can be referenced in task actions

**After creation:**
- File lives in phase directory: `.planning/phases/XX-name/{phase}-RESEARCH.md`
- Referenced during planning workflow
- plan-phase loads it automatically when present

</document_content>
</document>
<document index="56">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\roadmap.md</source>
<document_content>
# Roadmap Template

Template for `.planning/ROADMAP.md`.

## Initial Roadmap (v1.0 Greenfield)

```markdown
# Roadmap: [Project Name]

## Overview

[One paragraph describing the journey from start to finish]

## Phases

**Phase Numbering:**
- Integer phases (1, 2, 3): Planned milestone work
- Decimal phases (2.1, 2.2): Urgent insertions (marked with INSERTED)

Decimal phases appear between their surrounding integers in numeric order.

- [ ] **Phase 1: [Name]** - [One-line description]
- [ ] **Phase 2: [Name]** - [One-line description]
- [ ] **Phase 3: [Name]** - [One-line description]
- [ ] **Phase 4: [Name]** - [One-line description]

## Phase Details

### Phase 1: [Name]
**Goal**: [What this phase delivers]
**Depends on**: Nothing (first phase)
**Requirements**: [REQ-01, REQ-02, REQ-03]
**Success Criteria** (what must be TRUE):
  1. [Observable behavior from user perspective]
  2. [Observable behavior from user perspective]
  3. [Observable behavior from user perspective]
**Plans**: [Number of plans, e.g., "3 plans" or "TBD"]

Plans:
- [ ] 01-01: [Brief description of first plan]
- [ ] 01-02: [Brief description of second plan]
- [ ] 01-03: [Brief description of third plan]

### Phase 2: [Name]
**Goal**: [What this phase delivers]
**Depends on**: Phase 1
**Requirements**: [REQ-04, REQ-05]
**Success Criteria** (what must be TRUE):
  1. [Observable behavior from user perspective]
  2. [Observable behavior from user perspective]
**Plans**: [Number of plans]

Plans:
- [ ] 02-01: [Brief description]
- [ ] 02-02: [Brief description]

### Phase 2.1: Critical Fix (INSERTED)
**Goal**: [Urgent work inserted between phases]
**Depends on**: Phase 2
**Success Criteria** (what must be TRUE):
  1. [What the fix achieves]
**Plans**: 1 plan

Plans:
- [ ] 02.1-01: [Description]

### Phase 3: [Name]
**Goal**: [What this phase delivers]
**Depends on**: Phase 2
**Requirements**: [REQ-06, REQ-07, REQ-08]
**Success Criteria** (what must be TRUE):
  1. [Observable behavior from user perspective]
  2. [Observable behavior from user perspective]
  3. [Observable behavior from user perspective]
**Plans**: [Number of plans]

Plans:
- [ ] 03-01: [Brief description]
- [ ] 03-02: [Brief description]

### Phase 4: [Name]
**Goal**: [What this phase delivers]
**Depends on**: Phase 3
**Requirements**: [REQ-09, REQ-10]
**Success Criteria** (what must be TRUE):
  1. [Observable behavior from user perspective]
  2. [Observable behavior from user perspective]
**Plans**: [Number of plans]

Plans:
- [ ] 04-01: [Brief description]

## Progress

**Execution Order:**
Phases execute in numeric order: 2 → 2.1 → 2.2 → 3 → 3.1 → 4

| Phase | Plans Complete | Status | Completed |
|-------|----------------|--------|-----------|
| 1. [Name] | 0/3 | Not started | - |
| 2. [Name] | 0/2 | Not started | - |
| 3. [Name] | 0/2 | Not started | - |
| 4. [Name] | 0/1 | Not started | - |
```

<guidelines>
**Initial planning (v1.0):**
- Phase count depends on depth setting (quick: 3-5, standard: 5-8, comprehensive: 8-12)
- Each phase delivers something coherent
- Phases can have 1+ plans (split if >3 tasks or multiple subsystems)
- Plans use naming: {phase}-{plan}-PLAN.md (e.g., 01-02-PLAN.md)
- No time estimates (this isn't enterprise PM)
- Progress table updated by execute workflow
- Plan count can be "TBD" initially, refined during planning

**Success criteria:**
- 2-5 observable behaviors per phase (from user's perspective)
- Cross-checked against requirements during roadmap creation
- Flow downstream to `must_haves` in plan-phase
- Verified by verify-phase after execution
- Format: "User can [action]" or "[Thing] works/exists"

**After milestones ship:**
- Collapse completed milestones in `<details>` tags
- Add new milestone sections for upcoming work
- Keep continuous phase numbering (never restart at 01)
</guidelines>

<status_values>
- `Not started` - Haven't begun
- `In progress` - Currently working
- `Complete` - Done (add completion date)
- `Deferred` - Pushed to later (with reason)
</status_values>

## Milestone-Grouped Roadmap (After v1.0 Ships)

After completing first milestone, reorganize with milestone groupings:

```markdown
# Roadmap: [Project Name]

## Milestones

- ✅ **v1.0 MVP** - Phases 1-4 (shipped YYYY-MM-DD)
- 🚧 **v1.1 [Name]** - Phases 5-6 (in progress)
- 📋 **v2.0 [Name]** - Phases 7-10 (planned)

## Phases

<details>
<summary>✅ v1.0 MVP (Phases 1-4) - SHIPPED YYYY-MM-DD</summary>

### Phase 1: [Name]
**Goal**: [What this phase delivers]
**Plans**: 3 plans

Plans:
- [x] 01-01: [Brief description]
- [x] 01-02: [Brief description]
- [x] 01-03: [Brief description]

[... remaining v1.0 phases ...]

</details>

### 🚧 v1.1 [Name] (In Progress)

**Milestone Goal:** [What v1.1 delivers]

#### Phase 5: [Name]
**Goal**: [What this phase delivers]
**Depends on**: Phase 4
**Plans**: 2 plans

Plans:
- [ ] 05-01: [Brief description]
- [ ] 05-02: [Brief description]

[... remaining v1.1 phases ...]

### 📋 v2.0 [Name] (Planned)

**Milestone Goal:** [What v2.0 delivers]

[... v2.0 phases ...]

## Progress

| Phase | Milestone | Plans Complete | Status | Completed |
|-------|-----------|----------------|--------|-----------|
| 1. Foundation | v1.0 | 3/3 | Complete | YYYY-MM-DD |
| 2. Features | v1.0 | 2/2 | Complete | YYYY-MM-DD |
| 5. Security | v1.1 | 0/2 | Not started | - |
```

**Notes:**
- Milestone emoji: ✅ shipped, 🚧 in progress, 📋 planned
- Completed milestones collapsed in `<details>` for readability
- Current/future milestones expanded
- Continuous phase numbering (01-99)
- Progress table includes milestone column

</document_content>
</document>
<document index="57">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\state.md</source>
<document_content>
﻿# State Template

Template for `.planning/STATE.md` — the project's living memory.

---

## File Template

```markdown
# Project State

## Project Reference

See: .planning/PROJECT.md (updated [date])

**Core value:** [One-liner from PROJECT.md Core Value section]
**Current focus:** [Current phase name]

## Current Position

Phase: [X] of [Y] ([Phase name])
Plan: [A] of [B] in current phase
Status: [Ready to plan / Planning / Ready to execute / In progress / Phase complete]
Last activity: [YYYY-MM-DD] — [What happened]

Progress: [░░░░░░░░░░] 0%

## Performance Metrics

**Velocity:**
- Total plans completed: [N]
- Average duration: [X] min
- Total execution time: [X.X] hours

**By Phase:**

| Phase | Plans | Total | Avg/Plan |
|-------|-------|-------|----------|
| - | - | - | - |

**Recent Trend:**
- Last 5 plans: [durations]
- Trend: [Improving / Stable / Degrading]

*Updated after each plan completion*

## Accumulated Context

### Decisions

Decisions are logged in PROJECT.md Key Decisions table.
Recent decisions affecting current work:

- [Phase X]: [Decision summary]
- [Phase Y]: [Decision summary]

### Pending Todos

[From .planning/todos/pending/ — ideas captured during sessions]

None yet.

### Blockers/Concerns

[Issues that affect future work]

None yet.

## Session Continuity

Last session: [YYYY-MM-DD HH:MM]
Stopped at: [Description of last completed action]
Resume file: [Path to .continue-here*.md if exists, otherwise "None"]
```

<purpose>

STATE.md is the project's short-term memory spanning all phases and sessions.

**Problem it solves:** Information is captured in summaries, issues, and decisions but not systematically consumed. Sessions start without context.

**Solution:** A single, small file that's:
- Read first in every workflow
- Updated after every significant action
- Contains digest of accumulated context
- Enables instant session restoration

</purpose>

<lifecycle>

**Creation:** After ROADMAP.md is created (during init)
- Reference PROJECT.md (read it for current context)
- Initialize empty accumulated context sections
- Set position to "Phase 1 ready to plan"

**Reading:** First step of every workflow
- progress: Present status to user
- plan: Inform planning decisions
- execute: Know current position
- transition: Know what's complete

**Writing:** After every significant action
- execute: After SUMMARY.md created
  - Update position (phase, plan, status)
  - Note new decisions (detail in PROJECT.md)
  - Add blockers/concerns
- transition: After phase marked complete
  - Update progress bar
  - Clear resolved blockers
  - Refresh Project Reference date

</lifecycle>

<sections>

### Project Reference
Points to PROJECT.md for full context. Includes:
- Core value (the ONE thing that matters)
- Current focus (which phase)
- Last update date (triggers re-read if stale)

Claude reads PROJECT.md directly for requirements, constraints, and decisions.

### Current Position
Where we are right now:
- Phase X of Y — which phase
- Plan A of B — which plan within phase
- Status — current state
- Last activity — what happened most recently
- Progress bar — visual indicator of overall completion

Progress calculation: (completed plans) / (total plans across all phases) × 100%

### Performance Metrics
Track velocity to understand execution patterns:
- Total plans completed
- Average duration per plan
- Per-phase breakdown
- Recent trend (improving/stable/degrading)

Updated after each plan completion.

### Accumulated Context

**Decisions:** Reference to PROJECT.md Key Decisions table, plus recent decisions summary for quick access. Full decision log lives in PROJECT.md.

**Pending Todos:** Ideas captured via /GSI:add-todo
- Count of pending todos
- Reference to .planning/todos/pending/
- Brief list if few, count if many (e.g., "5 pending todos — see /GSI:check-todos")

**Blockers/Concerns:** From "Next Phase Readiness" sections
- Issues that affect future work
- Prefix with originating phase
- Cleared when addressed

### Session Continuity
Enables instant resumption:
- When was last session
- What was last completed
- Is there a .continue-here file to resume from

</sections>

<size_constraint>

Keep STATE.md under 100 lines.

It's a DIGEST, not an archive. If accumulated context grows too large:
- Keep only 3-5 recent decisions in summary (full log in PROJECT.md)
- Keep only active blockers, remove resolved ones

The goal is "read once, know where we are" — if it's too long, that fails.

</size_constraint>

</document_content>
</document>
<document index="58">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\summary-complex.md</source>
<document_content>
﻿---
phase: XX-name
plan: YY
subsystem: [primary category]
tags: [searchable tech]
requires:
  - phase: [prior phase]
    provides: [what that phase built]
provides:
  - [bullet list of what was built/delivered]
affects: [list of phase names or keywords]
tech-stack:
  added: [libraries/tools]
  patterns: [architectural/code patterns]
key-files:
  created: [important files created]
  modified: [important files modified]
key-decisions:
  - "Decision 1"
patterns-established:
  - "Pattern 1: description"
duration: Xmin
completed: YYYY-MM-DD
---

# Phase [X]: [Name] Summary (Complex)

**[Substantive one-liner describing outcome]**

## Performance
- **Duration:** [time]
- **Tasks:** [count completed]
- **Files modified:** [count]

## Accomplishments
- [Key outcome 1]
- [Key outcome 2]

## Task Commits
1. **Task 1: [task name]** - `hash`
2. **Task 2: [task name]** - `hash`
3. **Task 3: [task name]** - `hash`

## Files Created/Modified
- `path/to/file.ts` - What it does
- `path/to/another.ts` - What it does

## Decisions Made
[Key decisions with brief rationale]

## Deviations from Plan (Auto-fixed)
[Detailed auto-fix records per GSI deviation rules]

## Issues Encountered
[Problems during planned work and resolutions]

## Next Phase Readiness
[What's ready for next phase]
[Blockers or concerns]

</document_content>
</document>
<document index="59">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\summary-minimal.md</source>
<document_content>
---
phase: XX-name
plan: YY
subsystem: [primary category]
tags: [searchable tech]
provides:
  - [bullet list of what was built/delivered]
affects: [list of phase names or keywords]
tech-stack:
  added: [libraries/tools]
  patterns: [architectural/code patterns]
key-files:
  created: [important files created]
  modified: [important files modified]
key-decisions: []
duration: Xmin
completed: YYYY-MM-DD
---

# Phase [X]: [Name] Summary (Minimal)

**[Substantive one-liner describing outcome]**

## Performance
- **Duration:** [time]
- **Tasks:** [count]
- **Files modified:** [count]

## Accomplishments
- [Most important outcome]
- [Second key accomplishment]

## Task Commits
1. **Task 1: [task name]** - `hash`
2. **Task 2: [task name]** - `hash`

## Files Created/Modified
- `path/to/file.ts` - What it does

## Next Phase Readiness
[Ready for next phase]

</document_content>
</document>
<document index="60">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\summary-standard.md</source>
<document_content>
---
phase: XX-name
plan: YY
subsystem: [primary category]
tags: [searchable tech]
provides:
  - [bullet list of what was built/delivered]
affects: [list of phase names or keywords]
tech-stack:
  added: [libraries/tools]
  patterns: [architectural/code patterns]
key-files:
  created: [important files created]
  modified: [important files modified]
key-decisions:
  - "Decision 1"
duration: Xmin
completed: YYYY-MM-DD
---

# Phase [X]: [Name] Summary

**[Substantive one-liner describing outcome]**

## Performance
- **Duration:** [time]
- **Tasks:** [count completed]
- **Files modified:** [count]

## Accomplishments
- [Key outcome 1]
- [Key outcome 2]

## Task Commits
1. **Task 1: [task name]** - `hash`
2. **Task 2: [task name]** - `hash`
3. **Task 3: [task name]** - `hash`

## Files Created/Modified
- `path/to/file.ts` - What it does
- `path/to/another.ts` - What it does

## Decisions & Deviations
[Key decisions or "None - followed plan as specified"]
[Minor deviations if any, or "None"]

## Next Phase Readiness
[What's ready for next phase]

</document_content>
</document>
<document index="61">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\summary.md</source>
<document_content>
# Summary Template

Template for `.planning/phases/XX-name/{phase}-{plan}-SUMMARY.md` - phase completion documentation.

---

## File Template

```markdown
---
phase: XX-name
plan: YY
subsystem: [primary category: auth, payments, ui, api, database, infra, testing, etc.]
tags: [searchable tech: jwt, stripe, react, postgres, prisma]

# Dependency graph
requires:
  - phase: [prior phase this depends on]
    provides: [what that phase built that this uses]
provides:
  - [bullet list of what this phase built/delivered]
affects: [list of phase names or keywords that will need this context]

# Tech tracking
tech-stack:
  added: [libraries/tools added in this phase]
  patterns: [architectural/code patterns established]

key-files:
  created: [important files created]
  modified: [important files modified]

key-decisions:
  - "Decision 1"
  - "Decision 2"

patterns-established:
  - "Pattern 1: description"
  - "Pattern 2: description"

# Metrics
duration: Xmin
completed: YYYY-MM-DD
---

# Phase [X]: [Name] Summary

**[Substantive one-liner describing outcome - NOT "phase complete" or "implementation finished"]**

## Performance

- **Duration:** [time] (e.g., 23 min, 1h 15m)
- **Started:** [ISO timestamp]
- **Completed:** [ISO timestamp]
- **Tasks:** [count completed]
- **Files modified:** [count]

## Accomplishments
- [Most important outcome]
- [Second key accomplishment]
- [Third if applicable]

## Task Commits

Each task was committed atomically:

1. **Task 1: [task name]** - `abc123f` (feat/fix/test/refactor)
2. **Task 2: [task name]** - `def456g` (feat/fix/test/refactor)
3. **Task 3: [task name]** - `hij789k` (feat/fix/test/refactor)

**Plan metadata:** `lmn012o` (docs: complete plan)

_Note: TDD tasks may have multiple commits (test → feat → refactor)_

## Files Created/Modified
- `path/to/file.ts` - What it does
- `path/to/another.ts` - What it does

## Decisions Made
[Key decisions with brief rationale, or "None - followed plan as specified"]

## Deviations from Plan

[If no deviations: "None - plan executed exactly as written"]

[If deviations occurred:]

### Auto-fixed Issues

**1. [Rule X - Category] Brief description**
- **Found during:** Task [N] ([task name])
- **Issue:** [What was wrong]
- **Fix:** [What was done]
- **Files modified:** [file paths]
- **Verification:** [How it was verified]
- **Committed in:** [hash] (part of task commit)

[... repeat for each auto-fix ...]

---

**Total deviations:** [N] auto-fixed ([breakdown by rule])
**Impact on plan:** [Brief assessment - e.g., "All auto-fixes necessary for correctness/security. No scope creep."]

## Issues Encountered
[Problems and how they were resolved, or "None"]

[Note: "Deviations from Plan" documents unplanned work that was handled automatically via deviation rules. "Issues Encountered" documents problems during planned work that required problem-solving.]

## User Setup Required

[If USER-SETUP.md was generated:]
**External services require manual configuration.** See [{phase}-USER-SETUP.md](./{phase}-USER-SETUP.md) for:
- Environment variables to add
- Dashboard configuration steps
- Verification commands

[If no USER-SETUP.md:]
None - no external service configuration required.

## Next Phase Readiness
[What's ready for next phase]
[Any blockers or concerns]

---
*Phase: XX-name*
*Completed: [date]*
```

<frontmatter_guidance>
**Purpose:** Enable automatic context assembly via dependency graph. Frontmatter makes summary metadata machine-readable so plan-phase can scan all summaries quickly and select relevant ones based on dependencies.

**Fast scanning:** Frontmatter is first ~25 lines, cheap to scan across all summaries without reading full content.

**Dependency graph:** `requires`/`provides`/`affects` create explicit links between phases, enabling transitive closure for context selection.

**Subsystem:** Primary categorization (auth, payments, ui, api, database, infra, testing) for detecting related phases.

**Tags:** Searchable technical keywords (libraries, frameworks, tools) for tech stack awareness.

**Key-files:** Important files for @context references in PLAN.md.

**Patterns:** Established conventions future phases should maintain.

**Population:** Frontmatter is populated during summary creation in execute-plan.md. See `<step name="create_summary">` for field-by-field guidance.
</frontmatter_guidance>

<one_liner_rules>
The one-liner MUST be substantive:

**Good:**
- "JWT auth with refresh rotation using jose library"
- "Prisma schema with User, Session, and Product models"
- "Dashboard with real-time metrics via Server-Sent Events"

**Bad:**
- "Phase complete"
- "Authentication implemented"
- "Foundation finished"
- "All tasks done"

The one-liner should tell someone what actually shipped.
</one_liner_rules>

<example>
```markdown
# Phase 1: Foundation Summary

**JWT auth with refresh rotation using jose library, Prisma User model, and protected API middleware**

## Performance

- **Duration:** 28 min
- **Started:** 2025-01-15T14:22:10Z
- **Completed:** 2025-01-15T14:50:33Z
- **Tasks:** 5
- **Files modified:** 8

## Accomplishments
- User model with email/password auth
- Login/logout endpoints with httpOnly JWT cookies
- Protected route middleware checking token validity
- Refresh token rotation on each request

## Files Created/Modified
- `prisma/schema.prisma` - User and Session models
- `src/app/api/auth/login/route.ts` - Login endpoint
- `src/app/api/auth/logout/route.ts` - Logout endpoint
- `src/middleware.ts` - Protected route checks
- `src/lib/auth.ts` - JWT helpers using jose

## Decisions Made
- Used jose instead of jsonwebtoken (ESM-native, Edge-compatible)
- 15-min access tokens with 7-day refresh tokens
- Storing refresh tokens in database for revocation capability

## Deviations from Plan

### Auto-fixed Issues

**1. [Rule 2 - Missing Critical] Added password hashing with bcrypt**
- **Found during:** Task 2 (Login endpoint implementation)
- **Issue:** Plan didn't specify password hashing - storing plaintext would be critical security flaw
- **Fix:** Added bcrypt hashing on registration, comparison on login with salt rounds 10
- **Files modified:** src/app/api/auth/login/route.ts, src/lib/auth.ts
- **Verification:** Password hash test passes, plaintext never stored
- **Committed in:** abc123f (Task 2 commit)

**2. [Rule 3 - Blocking] Installed missing jose dependency**
- **Found during:** Task 4 (JWT token generation)
- **Issue:** jose package not in package.json, import failing
- **Fix:** Ran `npm install jose`
- **Files modified:** package.json, package-lock.json
- **Verification:** Import succeeds, build passes
- **Committed in:** def456g (Task 4 commit)

---

**Total deviations:** 2 auto-fixed (1 missing critical, 1 blocking)
**Impact on plan:** Both auto-fixes essential for security and functionality. No scope creep.

## Issues Encountered
- jsonwebtoken CommonJS import failed in Edge runtime - switched to jose (planned library change, worked as expected)

## Next Phase Readiness
- Auth foundation complete, ready for feature development
- User registration endpoint needed before public launch

---
*Phase: 01-foundation*
*Completed: 2025-01-15*
```
</example>

<guidelines>
**Frontmatter:** MANDATORY - complete all fields. Enables automatic context assembly for future planning.

**One-liner:** Must be substantive. "JWT auth with refresh rotation using jose library" not "Authentication implemented".

**Decisions section:**
- Key decisions made during execution with rationale
- Extracted to STATE.md accumulated context
- Use "None - followed plan as specified" if no deviations

**After creation:** STATE.md updated with position, decisions, issues.
</guidelines>

</document_content>
</document>
<document index="62">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\user-setup.md</source>
<document_content>
# User Setup Template

Template for `.planning/phases/XX-name/{phase}-USER-SETUP.md` - human-required configuration that Claude cannot automate.

**Purpose:** Document setup tasks that literally require human action - account creation, dashboard configuration, secret retrieval. Claude automates everything possible; this file captures only what remains.

---

## File Template

```markdown
# Phase {X}: User Setup Required

**Generated:** [YYYY-MM-DD]
**Phase:** {phase-name}
**Status:** Incomplete

Complete these items for the integration to function. Claude automated everything possible; these items require human access to external dashboards/accounts.

## Environment Variables

| Status | Variable | Source | Add to |
|--------|----------|--------|--------|
| [ ] | `ENV_VAR_NAME` | [Service Dashboard → Path → To → Value] | `.env.local` |
| [ ] | `ANOTHER_VAR` | [Service Dashboard → Path → To → Value] | `.env.local` |

## Account Setup

[Only if new account creation is required]

- [ ] **Create [Service] account**
  - URL: [signup URL]
  - Skip if: Already have account

## Dashboard Configuration

[Only if dashboard configuration is required]

- [ ] **[Configuration task]**
  - Location: [Service Dashboard → Path → To → Setting]
  - Set to: [Required value or configuration]
  - Notes: [Any important details]

## Verification

After completing setup, verify with:

```bash
# [Verification commands]
```

Expected results:
- [What success looks like]

---

**Once all items complete:** Mark status as "Complete" at top of file.
```

---

## When to Generate

Generate `{phase}-USER-SETUP.md` when plan frontmatter contains `user_setup` field.

**Trigger:** `user_setup` exists in PLAN.md frontmatter and has items.

**Location:** Same directory as PLAN.md and SUMMARY.md.

**Timing:** Generated during execute-plan.md after tasks complete, before SUMMARY.md creation.

---

## Frontmatter Schema

In PLAN.md, `user_setup` declares human-required configuration:

```yaml
user_setup:
  - service: stripe
    why: "Payment processing requires API keys"
    env_vars:
      - name: STRIPE_SECRET_KEY
        source: "Stripe Dashboard → Developers → API keys → Secret key"
      - name: STRIPE_WEBHOOK_SECRET
        source: "Stripe Dashboard → Developers → Webhooks → Signing secret"
    dashboard_config:
      - task: "Create webhook endpoint"
        location: "Stripe Dashboard → Developers → Webhooks → Add endpoint"
        details: "URL: https://[your-domain]/api/webhooks/stripe, Events: checkout.session.completed, customer.subscription.*"
    local_dev:
      - "Run: stripe listen --forward-to localhost:3000/api/webhooks/stripe"
      - "Use the webhook secret from CLI output for local testing"
```

---

## The Automation-First Rule

**USER-SETUP.md contains ONLY what Claude literally cannot do.**

| Claude CAN Do (not in USER-SETUP) | Claude CANNOT Do (→ USER-SETUP) |
|-----------------------------------|--------------------------------|
| `npm install stripe` | Create Stripe account |
| Write webhook handler code | Get API keys from dashboard |
| Create `.env.local` file structure | Copy actual secret values |
| Run `stripe listen` | Authenticate Stripe CLI (browser OAuth) |
| Configure package.json | Access external service dashboards |
| Write any code | Retrieve secrets from third-party systems |

**The test:** "Does this require a human in a browser, accessing an account Claude doesn't have credentials for?"
- Yes → USER-SETUP.md
- No → Claude does it automatically

---

## Service-Specific Examples

<stripe_example>
```markdown
# Phase 10: User Setup Required

**Generated:** 2025-01-14
**Phase:** 10-monetization
**Status:** Incomplete

Complete these items for Stripe integration to function.

## Environment Variables

| Status | Variable | Source | Add to |
|--------|----------|--------|--------|
| [ ] | `STRIPE_SECRET_KEY` | Stripe Dashboard → Developers → API keys → Secret key | `.env.local` |
| [ ] | `NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY` | Stripe Dashboard → Developers → API keys → Publishable key | `.env.local` |
| [ ] | `STRIPE_WEBHOOK_SECRET` | Stripe Dashboard → Developers → Webhooks → [endpoint] → Signing secret | `.env.local` |

## Account Setup

- [ ] **Create Stripe account** (if needed)
  - URL: https://dashboard.stripe.com/register
  - Skip if: Already have Stripe account

## Dashboard Configuration

- [ ] **Create webhook endpoint**
  - Location: Stripe Dashboard → Developers → Webhooks → Add endpoint
  - Endpoint URL: `https://[your-domain]/api/webhooks/stripe`
  - Events to send:
    - `checkout.session.completed`
    - `customer.subscription.created`
    - `customer.subscription.updated`
    - `customer.subscription.deleted`

- [ ] **Create products and prices** (if using subscription tiers)
  - Location: Stripe Dashboard → Products → Add product
  - Create each subscription tier
  - Copy Price IDs to:
    - `STRIPE_STARTER_PRICE_ID`
    - `STRIPE_PRO_PRICE_ID`

## Local Development

For local webhook testing:
```bash
stripe listen --forward-to localhost:3000/api/webhooks/stripe
```
Use the webhook signing secret from CLI output (starts with `whsec_`).

## Verification

After completing setup:

```bash
# Check env vars are set
grep STRIPE .env.local

# Verify build passes
npm run build

# Test webhook endpoint (should return 400 bad signature, not 500 crash)
curl -X POST http://localhost:3000/api/webhooks/stripe \
  -H "Content-Type: application/json" \
  -d '{}'
```

Expected: Build passes, webhook returns 400 (signature validation working).

---

**Once all items complete:** Mark status as "Complete" at top of file.
```
</stripe_example>

<supabase_example>
```markdown
# Phase 2: User Setup Required

**Generated:** 2025-01-14
**Phase:** 02-authentication
**Status:** Incomplete

Complete these items for Supabase Auth to function.

## Environment Variables

| Status | Variable | Source | Add to |
|--------|----------|--------|--------|
| [ ] | `NEXT_PUBLIC_SUPABASE_URL` | Supabase Dashboard → Settings → API → Project URL | `.env.local` |
| [ ] | `NEXT_PUBLIC_SUPABASE_ANON_KEY` | Supabase Dashboard → Settings → API → anon public | `.env.local` |
| [ ] | `SUPABASE_SERVICE_ROLE_KEY` | Supabase Dashboard → Settings → API → service_role | `.env.local` |

## Account Setup

- [ ] **Create Supabase project**
  - URL: https://supabase.com/dashboard/new
  - Skip if: Already have project for this app

## Dashboard Configuration

- [ ] **Enable Email Auth**
  - Location: Supabase Dashboard → Authentication → Providers
  - Enable: Email provider
  - Configure: Confirm email (on/off based on preference)

- [ ] **Configure OAuth providers** (if using social login)
  - Location: Supabase Dashboard → Authentication → Providers
  - For Google: Add Client ID and Secret from Google Cloud Console
  - For GitHub: Add Client ID and Secret from GitHub OAuth Apps

## Verification

After completing setup:

```bash
# Check env vars
grep SUPABASE .env.local

# Verify connection (run in project directory)
npx supabase status
```

---

**Once all items complete:** Mark status as "Complete" at top of file.
```
</supabase_example>

<sendgrid_example>
```markdown
# Phase 5: User Setup Required

**Generated:** 2025-01-14
**Phase:** 05-notifications
**Status:** Incomplete

Complete these items for SendGrid email to function.

## Environment Variables

| Status | Variable | Source | Add to |
|--------|----------|--------|--------|
| [ ] | `SENDGRID_API_KEY` | SendGrid Dashboard → Settings → API Keys → Create API Key | `.env.local` |
| [ ] | `SENDGRID_FROM_EMAIL` | Your verified sender email address | `.env.local` |

## Account Setup

- [ ] **Create SendGrid account**
  - URL: https://signup.sendgrid.com/
  - Skip if: Already have account

## Dashboard Configuration

- [ ] **Verify sender identity**
  - Location: SendGrid Dashboard → Settings → Sender Authentication
  - Option 1: Single Sender Verification (quick, for dev)
  - Option 2: Domain Authentication (production)

- [ ] **Create API Key**
  - Location: SendGrid Dashboard → Settings → API Keys → Create API Key
  - Permission: Restricted Access → Mail Send (Full Access)
  - Copy key immediately (shown only once)

## Verification

After completing setup:

```bash
# Check env var
grep SENDGRID .env.local

# Test email sending (replace with your test email)
curl -X POST http://localhost:3000/api/test-email \
  -H "Content-Type: application/json" \
  -d '{"to": "your@email.com"}'
```

---

**Once all items complete:** Mark status as "Complete" at top of file.
```
</sendgrid_example>

---

## Guidelines

**Never include:** Actual secret values. Steps Claude can automate (package installs, code changes).

**Naming:** `{phase}-USER-SETUP.md` matches the phase number pattern.
**Status tracking:** User marks checkboxes and updates status line when complete.
**Searchability:** `grep -r "USER-SETUP" .planning/` finds all phases with user requirements.

</document_content>
</document>
<document index="63">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\verification-report.md</source>
<document_content>
# Verification Report Template

Template for `.planning/phases/XX-name/{phase}-VERIFICATION.md` — phase goal verification results.

---

## File Template

```markdown
---
phase: XX-name
verified: YYYY-MM-DDTHH:MM:SSZ
status: passed | gaps_found | human_needed
score: N/M must-haves verified
---

# Phase {X}: {Name} Verification Report

**Phase Goal:** {goal from ROADMAP.md}
**Verified:** {timestamp}
**Status:** {passed | gaps_found | human_needed}

## Goal Achievement

### Observable Truths

| # | Truth | Status | Evidence |
|---|-------|--------|----------|
| 1 | {truth from must_haves} | ✓ VERIFIED | {what confirmed it} |
| 2 | {truth from must_haves} | ✗ FAILED | {what's wrong} |
| 3 | {truth from must_haves} | ? UNCERTAIN | {why can't verify} |

**Score:** {N}/{M} truths verified

### Required Artifacts

| Artifact | Expected | Status | Details |
|----------|----------|--------|---------|
| `src/components/Chat.tsx` | Message list component | ✓ EXISTS + SUBSTANTIVE | Exports ChatList, renders Message[], no stubs |
| `src/app/api/chat/route.ts` | Message CRUD | ✗ STUB | File exists but POST returns placeholder |
| `prisma/schema.prisma` | Message model | ✓ EXISTS + SUBSTANTIVE | Model defined with all fields |

**Artifacts:** {N}/{M} verified

### Key Link Verification

| From | To | Via | Status | Details |
|------|----|----|--------|---------|
| Chat.tsx | /api/chat | fetch in useEffect | ✓ WIRED | Line 23: `fetch('/api/chat')` with response handling |
| ChatInput | /api/chat POST | onSubmit handler | ✗ NOT WIRED | onSubmit only calls console.log |
| /api/chat POST | database | prisma.message.create | ✗ NOT WIRED | Returns hardcoded response, no DB call |

**Wiring:** {N}/{M} connections verified

## Requirements Coverage

| Requirement | Status | Blocking Issue |
|-------------|--------|----------------|
| {REQ-01}: {description} | ✓ SATISFIED | - |
| {REQ-02}: {description} | ✗ BLOCKED | API route is stub |
| {REQ-03}: {description} | ? NEEDS HUMAN | Can't verify WebSocket programmatically |

**Coverage:** {N}/{M} requirements satisfied

## Anti-Patterns Found

| File | Line | Pattern | Severity | Impact |
|------|------|---------|----------|--------|
| src/app/api/chat/route.ts | 12 | `// TODO: implement` | ⚠️ Warning | Indicates incomplete |
| src/components/Chat.tsx | 45 | `return <div>Placeholder</div>` | 🛑 Blocker | Renders no content |
| src/hooks/useChat.ts | - | File missing | 🛑 Blocker | Expected hook doesn't exist |

**Anti-patterns:** {N} found ({blockers} blockers, {warnings} warnings)

## Human Verification Required

{If no human verification needed:}
None — all verifiable items checked programmatically.

{If human verification needed:}

### 1. {Test Name}
**Test:** {What to do}
**Expected:** {What should happen}
**Why human:** {Why can't verify programmatically}

### 2. {Test Name}
**Test:** {What to do}
**Expected:** {What should happen}
**Why human:** {Why can't verify programmatically}

## Gaps Summary

{If no gaps:}
**No gaps found.** Phase goal achieved. Ready to proceed.

{If gaps found:}

### Critical Gaps (Block Progress)

1. **{Gap name}**
   - Missing: {what's missing}
   - Impact: {why this blocks the goal}
   - Fix: {what needs to happen}

2. **{Gap name}**
   - Missing: {what's missing}
   - Impact: {why this blocks the goal}
   - Fix: {what needs to happen}

### Non-Critical Gaps (Can Defer)

1. **{Gap name}**
   - Issue: {what's wrong}
   - Impact: {limited impact because...}
   - Recommendation: {fix now or defer}

## Recommended Fix Plans

{If gaps found, generate fix plan recommendations:}

### {phase}-{next}-PLAN.md: {Fix Name}

**Objective:** {What this fixes}

**Tasks:**
1. {Task to fix gap 1}
2. {Task to fix gap 2}
3. {Verification task}

**Estimated scope:** {Small / Medium}

---

### {phase}-{next+1}-PLAN.md: {Fix Name}

**Objective:** {What this fixes}

**Tasks:**
1. {Task}
2. {Task}

**Estimated scope:** {Small / Medium}

---

## Verification Metadata

**Verification approach:** Goal-backward (derived from phase goal)
**Must-haves source:** {PLAN.md frontmatter | derived from ROADMAP.md goal}
**Automated checks:** {N} passed, {M} failed
**Human checks required:** {N}
**Total verification time:** {duration}

---
*Verified: {timestamp}*
*Verifier: Claude (subagent)*
```

---

## Guidelines

**Status values:**
- `passed` — All must-haves verified, no blockers
- `gaps_found` — One or more critical gaps found
- `human_needed` — Automated checks pass but human verification required

**Evidence types:**
- For EXISTS: "File at path, exports X"
- For SUBSTANTIVE: "N lines, has patterns X, Y, Z"
- For WIRED: "Line N: code that connects A to B"
- For FAILED: "Missing because X" or "Stub because Y"

**Severity levels:**
- 🛑 Blocker: Prevents goal achievement, must fix
- ⚠️ Warning: Indicates incomplete but doesn't block
- ℹ️ Info: Notable but not problematic

**Fix plan generation:**
- Only generate if gaps_found
- Group related fixes into single plans
- Keep to 2-3 tasks per plan
- Include verification task in each plan

---

## Example

```markdown
---
phase: 03-chat
verified: 2025-01-15T14:30:00Z
status: gaps_found
score: 2/5 must-haves verified
---

# Phase 3: Chat Interface Verification Report

**Phase Goal:** Working chat interface where users can send and receive messages
**Verified:** 2025-01-15T14:30:00Z
**Status:** gaps_found

## Goal Achievement

### Observable Truths

| # | Truth | Status | Evidence |
|---|-------|--------|----------|
| 1 | User can see existing messages | ✗ FAILED | Component renders placeholder, not message data |
| 2 | User can type a message | ✓ VERIFIED | Input field exists with onChange handler |
| 3 | User can send a message | ✗ FAILED | onSubmit handler is console.log only |
| 4 | Sent message appears in list | ✗ FAILED | No state update after send |
| 5 | Messages persist across refresh | ? UNCERTAIN | Can't verify - send doesn't work |

**Score:** 1/5 truths verified

### Required Artifacts

| Artifact | Expected | Status | Details |
|----------|----------|--------|---------|
| `src/components/Chat.tsx` | Message list component | ✗ STUB | Returns `<div>Chat will be here</div>` |
| `src/components/ChatInput.tsx` | Message input | ✓ EXISTS + SUBSTANTIVE | Form with input, submit button, handlers |
| `src/app/api/chat/route.ts` | Message CRUD | ✗ STUB | GET returns [], POST returns { ok: true } |
| `prisma/schema.prisma` | Message model | ✓ EXISTS + SUBSTANTIVE | Message model with id, content, userId, createdAt |

**Artifacts:** 2/4 verified

### Key Link Verification

| From | To | Via | Status | Details |
|------|----|----|--------|---------|
| Chat.tsx | /api/chat GET | fetch | ✗ NOT WIRED | No fetch call in component |
| ChatInput | /api/chat POST | onSubmit | ✗ NOT WIRED | Handler only logs, doesn't fetch |
| /api/chat GET | database | prisma.message.findMany | ✗ NOT WIRED | Returns hardcoded [] |
| /api/chat POST | database | prisma.message.create | ✗ NOT WIRED | Returns { ok: true }, no DB call |

**Wiring:** 0/4 connections verified

## Requirements Coverage

| Requirement | Status | Blocking Issue |
|-------------|--------|----------------|
| CHAT-01: User can send message | ✗ BLOCKED | API POST is stub |
| CHAT-02: User can view messages | ✗ BLOCKED | Component is placeholder |
| CHAT-03: Messages persist | ✗ BLOCKED | No database integration |

**Coverage:** 0/3 requirements satisfied

## Anti-Patterns Found

| File | Line | Pattern | Severity | Impact |
|------|------|---------|----------|--------|
| src/components/Chat.tsx | 8 | `<div>Chat will be here</div>` | 🛑 Blocker | No actual content |
| src/app/api/chat/route.ts | 5 | `return Response.json([])` | 🛑 Blocker | Hardcoded empty |
| src/app/api/chat/route.ts | 12 | `// TODO: save to database` | ⚠️ Warning | Incomplete |

**Anti-patterns:** 3 found (2 blockers, 1 warning)

## Human Verification Required

None needed until automated gaps are fixed.

## Gaps Summary

### Critical Gaps (Block Progress)

1. **Chat component is placeholder**
   - Missing: Actual message list rendering
   - Impact: Users see "Chat will be here" instead of messages
   - Fix: Implement Chat.tsx to fetch and render messages

2. **API routes are stubs**
   - Missing: Database integration in GET and POST
   - Impact: No data persistence, no real functionality
   - Fix: Wire prisma calls in route handlers

3. **No wiring between frontend and backend**
   - Missing: fetch calls in components
   - Impact: Even if API worked, UI wouldn't call it
   - Fix: Add useEffect fetch in Chat, onSubmit fetch in ChatInput

## Recommended Fix Plans

### 03-04-PLAN.md: Implement Chat API

**Objective:** Wire API routes to database

**Tasks:**
1. Implement GET /api/chat with prisma.message.findMany
2. Implement POST /api/chat with prisma.message.create
3. Verify: API returns real data, POST creates records

**Estimated scope:** Small

---

### 03-05-PLAN.md: Implement Chat UI

**Objective:** Wire Chat component to API

**Tasks:**
1. Implement Chat.tsx with useEffect fetch and message rendering
2. Wire ChatInput onSubmit to POST /api/chat
3. Verify: Messages display, new messages appear after send

**Estimated scope:** Small

---

## Verification Metadata

**Verification approach:** Goal-backward (derived from phase goal)
**Must-haves source:** 03-01-PLAN.md frontmatter
**Automated checks:** 2 passed, 8 failed
**Human checks required:** 0 (blocked by automated failures)
**Total verification time:** 2 min

---
*Verified: 2025-01-15T14:30:00Z*
*Verifier: Claude (subagent)*
```

</document_content>
</document>
<document index="64">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\codebase\architecture.md</source>
<document_content>
﻿# Architecture Template

Template for `.planning/codebase/ARCHITECTURE.md` - captures conceptual code organization.

**Purpose:** Document how the code is organized at a conceptual level. Complements STRUCTURE.md (which shows physical file locations).

---

## File Template

```markdown
# Architecture

**Analysis Date:** [YYYY-MM-DD]

## Model Circle (Architecture) Thinking

Since architecture analysis is a Model Circle task, use Tractatus thinking for structural analysis:

**Tractatus Operations:**
1. **start**: Begin with overall architectural pattern
2. **add**: Add components incrementally
3. **analyze**: Verify relationships and integrity

**Operation Sequence:**
```
1. Start: Identify architectural pattern
   - Single executable vs distributed
   - Layered vs event-driven
   - Monolithic vs microservices

2. Add: Define components
   - Entry points
   - Service layers
   - Data stores
   - External integrations

3. Add: Map relationships
   - Dependencies between components
   - Data flow patterns
   - Communication protocols

4. Analyze: Validate structure
   - Clear separation of concerns
   - No circular dependencies
   - Scalability considerations
   - Maintainability factors
```

## Pattern Overview

**Overall:** [Pattern name: e.g., "Monolithic CLI", "Serverless API", "Full-stack MVC"]

**Key Characteristics:**
- [Characteristic 1: e.g., "Single executable"]
- [Characteristic 2: e.g., "Stateless request handling"]
- [Characteristic 3: e.g., "Event-driven"]

## Layers

[Describe the conceptual layers and their responsibilities]

**[Layer Name]:**
- Purpose: [What this layer does]
- Contains: [Types of code: e.g., "route handlers", "business logic"]
- Depends on: [What it uses: e.g., "data layer only"]
- Used by: [What uses it: e.g., "API routes"]

**[Layer Name]:**
- Purpose: [What this layer does]
- Contains: [Types of code]
- Depends on: [What it uses]
- Used by: [What uses it]

## Data Flow

[Describe the typical request/execution lifecycle]

**[Flow Name] (e.g., "HTTP Request", "CLI Command", "Event Processing"):**

1. [Entry point: e.g., "User runs command"]
2. [Processing step: e.g., "Router matches path"]
3. [Processing step: e.g., "Controller validates input"]
4. [Processing step: e.g., "Service executes logic"]
5. [Output: e.g., "Response returned"]

**State Management:**
- [How state is handled: e.g., "Stateless - no persistent state", "Database per request", "In-memory cache"]

## Key Abstractions

[Core concepts/patterns used throughout the codebase]

**[Abstraction Name]:**
- Purpose: [What it represents]
- Examples: [e.g., "UserService, ProjectService"]
- Pattern: [e.g., "Singleton", "Factory", "Repository"]

**[Abstraction Name]:**
- Purpose: [What it represents]
- Examples: [Concrete examples]
- Pattern: [Pattern used]

## Entry Points

[Where execution begins]

**[Entry Point]:**
- Location: [Brief: e.g., "src/index.ts", "API Gateway triggers"]
- Triggers: [What invokes it: e.g., "CLI invocation", "HTTP request"]
- Responsibilities: [What it does: e.g., "Parse args, route to command"]

## Error Handling

**Strategy:** [How errors are handled: e.g., "Exception bubbling to top-level handler", "Per-route error middleware"]

**Patterns:**
- [Pattern: e.g., "try/catch at controller level"]
- [Pattern: e.g., "Error codes returned to user"]

## Cross-Cutting Concerns

[Aspects that affect multiple layers]

**Logging:**
- [Approach: e.g., "Winston logger, injected per-request"]

**Validation:**
- [Approach: e.g., "Zod schemas at API boundary"]

**Authentication:**
- [Approach: e.g., "JWT middleware on protected routes"]

---

*Architecture analysis: [date]*
*Update when major patterns change*
```

<good_examples>
```markdown
# Architecture

**Analysis Date:** 2025-01-20

## Pattern Overview

**Overall:** CLI Application with Plugin System

**Key Characteristics:**
- Single executable with subcommands
- Plugin-based extensibility
- File-based state (no database)
- Synchronous execution model

## Layers

**Command Layer:**
- Purpose: Parse user input and route to appropriate handler
- Contains: Command definitions, argument parsing, help text
- Location: `src/commands/*.ts`
- Depends on: Service layer for business logic
- Used by: CLI entry point (`src/index.ts`)

**Service Layer:**
- Purpose: Core business logic
- Contains: FileService, TemplateService, InstallService
- Location: `src/services/*.ts`
- Depends on: File system utilities, external tools
- Used by: Command handlers

**Utility Layer:**
- Purpose: Shared helpers and abstractions
- Contains: File I/O wrappers, path resolution, string formatting
- Location: `src/utils/*.ts`
- Depends on: Node.js built-ins only
- Used by: Service layer

## Data Flow

**CLI Command Execution:**

1. User runs: `GSI new-project`
2. Commander parses args and flags
3. Command handler invoked (`src/commands/new-project.ts`)
4. Handler calls service methods (`src/services/project.ts` → `create()`)
5. Service reads templates, processes files, writes output
6. Results logged to console
7. Process exits with status code

**State Management:**
- File-based: All state lives in `.planning/` directory
- No persistent in-memory state
- Each command execution is independent

## Key Abstractions

**Service:**
- Purpose: Encapsulate business logic for a domain
- Examples: `src/services/file.ts`, `src/services/template.ts`, `src/services/project.ts`
- Pattern: Singleton-like (imported as modules, not instantiated)

**Command:**
- Purpose: CLI command definition
- Examples: `src/commands/new-project.ts`, `src/commands/plan-phase.ts`
- Pattern: Commander.js command registration

**Template:**
- Purpose: Reusable document structures
- Examples: PROJECT.md, PLAN.md templates
- Pattern: Markdown files with substitution variables

## Entry Points

**CLI Entry:**
- Location: `src/index.ts`
- Triggers: User runs `GSI <command>`
- Responsibilities: Register commands, parse args, display help

**Commands:**
- Location: `src/commands/*.ts`
- Triggers: Matched command from CLI
- Responsibilities: Validate input, call services, format output

## Error Handling

**Strategy:** Throw exceptions, catch at command level, log and exit

**Patterns:**
- Services throw Error with descriptive messages
- Command handlers catch, log error to stderr, exit(1)
- Validation errors shown before execution (fail fast)

## Cross-Cutting Concerns

**Logging:**
- Console.log for normal output
- Console.error for errors
- Chalk for colored output

**Validation:**
- Zod schemas for config file parsing
- Manual validation in command handlers
- Fail fast on invalid input

**File Operations:**
- FileService abstraction over fs-extra
- All paths validated before operations
- Atomic writes (temp file + rename)

---

*Architecture analysis: 2025-01-20*
*Update when major patterns change*
```
</good_examples>

<guidelines>
**What belongs in ARCHITECTURE.md:**
- Overall architectural pattern (monolith, microservices, layered, etc.)
- Conceptual layers and their relationships
- Data flow / request lifecycle
- Key abstractions and patterns
- Entry points
- Error handling strategy
- Cross-cutting concerns (logging, auth, validation)

**What does NOT belong here:**
- Exhaustive file listings (that's STRUCTURE.md)
- Technology choices (that's STACK.md)
- Line-by-line code walkthrough (defer to code reading)
- Implementation details of specific features

**File paths ARE welcome:**
Include file paths as concrete examples of abstractions. Use backtick formatting: `src/services/user.ts`. This makes the architecture document actionable for Claude when planning.

**When filling this template:**
- Read main entry points (index, server, main)
- Identify layers by reading imports/dependencies
- Trace a typical request/command execution
- Note recurring patterns (services, controllers, repositories)
- Keep descriptions conceptual, not mechanical

**Useful for phase planning when:**
- Adding new features (where does it fit in the layers?)
- Refactoring (understanding current patterns)
- Identifying where to add code (which layer handles X?)
- Understanding dependencies between components
</guidelines>

</document_content>
</document>
<document index="65">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\codebase\concerns.md</source>
<document_content>
# Codebase Concerns Template

Template for `.planning/codebase/CONCERNS.md` - captures known issues and areas requiring care.

**Purpose:** Surface actionable warnings about the codebase. Focused on "what to watch out for when making changes."

---

## File Template

```markdown
# Codebase Concerns

**Analysis Date:** [YYYY-MM-DD]

## Tech Debt

**[Area/Component]:**
- Issue: [What's the shortcut/workaround]
- Why: [Why it was done this way]
- Impact: [What breaks or degrades because of it]
- Fix approach: [How to properly address it]

**[Area/Component]:**
- Issue: [What's the shortcut/workaround]
- Why: [Why it was done this way]
- Impact: [What breaks or degrades because of it]
- Fix approach: [How to properly address it]

## Known Bugs

**[Bug description]:**
- Symptoms: [What happens]
- Trigger: [How to reproduce]
- Workaround: [Temporary mitigation if any]
- Root cause: [If known]
- Blocked by: [If waiting on something]

**[Bug description]:**
- Symptoms: [What happens]
- Trigger: [How to reproduce]
- Workaround: [Temporary mitigation if any]
- Root cause: [If known]

## Security Considerations

**[Area requiring security care]:**
- Risk: [What could go wrong]
- Current mitigation: [What's in place now]
- Recommendations: [What should be added]

**[Area requiring security care]:**
- Risk: [What could go wrong]
- Current mitigation: [What's in place now]
- Recommendations: [What should be added]

## Performance Bottlenecks

**[Slow operation/endpoint]:**
- Problem: [What's slow]
- Measurement: [Actual numbers: "500ms p95", "2s load time"]
- Cause: [Why it's slow]
- Improvement path: [How to speed it up]

**[Slow operation/endpoint]:**
- Problem: [What's slow]
- Measurement: [Actual numbers]
- Cause: [Why it's slow]
- Improvement path: [How to speed it up]

## Fragile Areas

**[Component/Module]:**
- Why fragile: [What makes it break easily]
- Common failures: [What typically goes wrong]
- Safe modification: [How to change it without breaking]
- Test coverage: [Is it tested? Gaps?]

**[Component/Module]:**
- Why fragile: [What makes it break easily]
- Common failures: [What typically goes wrong]
- Safe modification: [How to change it without breaking]
- Test coverage: [Is it tested? Gaps?]

## Scaling Limits

**[Resource/System]:**
- Current capacity: [Numbers: "100 req/sec", "10k users"]
- Limit: [Where it breaks]
- Symptoms at limit: [What happens]
- Scaling path: [How to increase capacity]

## Dependencies at Risk

**[Package/Service]:**
- Risk: [e.g., "deprecated", "unmaintained", "breaking changes coming"]
- Impact: [What breaks if it fails]
- Migration plan: [Alternative or upgrade path]

## Missing Critical Features

**[Feature gap]:**
- Problem: [What's missing]
- Current workaround: [How users cope]
- Blocks: [What can't be done without it]
- Implementation complexity: [Rough effort estimate]

## Test Coverage Gaps

**[Untested area]:**
- What's not tested: [Specific functionality]
- Risk: [What could break unnoticed]
- Priority: [High/Medium/Low]
- Difficulty to test: [Why it's not tested yet]

---

*Concerns audit: [date]*
*Update as issues are fixed or new ones discovered*
```

<good_examples>
```markdown
# Codebase Concerns

**Analysis Date:** 2025-01-20

## Tech Debt

**Database queries in React components:**
- Issue: Direct Supabase queries in 15+ page components instead of server actions
- Files: `app/dashboard/page.tsx`, `app/profile/page.tsx`, `app/courses/[id]/page.tsx`, `app/settings/page.tsx` (and 11 more in `app/`)
- Why: Rapid prototyping during MVP phase
- Impact: Can't implement RLS properly, exposes DB structure to client
- Fix approach: Move all queries to server actions in `app/actions/`, add proper RLS policies

**Manual webhook signature validation:**
- Issue: Copy-pasted Stripe webhook verification code in 3 different endpoints
- Files: `app/api/webhooks/stripe/route.ts`, `app/api/webhooks/checkout/route.ts`, `app/api/webhooks/subscription/route.ts`
- Why: Each webhook added ad-hoc without abstraction
- Impact: Easy to miss verification in new webhooks (security risk)
- Fix approach: Create shared `lib/stripe/validate-webhook.ts` middleware

## Known Bugs

**Race condition in subscription updates:**
- Symptoms: User shows as "free" tier for 5-10 seconds after successful payment
- Trigger: Fast navigation after Stripe checkout redirect, before webhook processes
- Files: `app/checkout/success/page.tsx` (redirect handler), `app/api/webhooks/stripe/route.ts` (webhook)
- Workaround: Stripe webhook eventually updates status (self-heals)
- Root cause: Webhook processing slower than user navigation, no optimistic UI update
- Fix: Add polling in `app/checkout/success/page.tsx` after redirect

**Inconsistent session state after logout:**
- Symptoms: User redirected to /dashboard after logout instead of /login
- Trigger: Logout via button in mobile nav (desktop works fine)
- File: `components/MobileNav.tsx` (line ~45, logout handler)
- Workaround: Manual URL navigation to /login works
- Root cause: Mobile nav component not awaiting supabase.auth.signOut()
- Fix: Add await to logout handler in `components/MobileNav.tsx`

## Security Considerations

**Admin role check client-side only:**
- Risk: Admin dashboard pages check isAdmin from Supabase client, no server verification
- Files: `app/admin/page.tsx`, `app/admin/users/page.tsx`, `components/AdminGuard.tsx`
- Current mitigation: None (relying on UI hiding)
- Recommendations: Add middleware to admin routes in `middleware.ts`, verify role server-side

**Unvalidated file uploads:**
- Risk: Users can upload any file type to avatar bucket (no size/type validation)
- File: `components/AvatarUpload.tsx` (upload handler)
- Current mitigation: Supabase bucket limits to 2MB (configured in dashboard)
- Recommendations: Add file type validation (image/* only) in `lib/storage/validate.ts`

## Performance Bottlenecks

**/api/courses endpoint:**
- Problem: Fetching all courses with nested lessons and authors
- File: `app/api/courses/route.ts`
- Measurement: 1.2s p95 response time with 50+ courses
- Cause: N+1 query pattern (separate query per course for lessons)
- Improvement path: Use Prisma include to eager-load lessons in `lib/db/courses.ts`, add Redis caching

**Dashboard initial load:**
- Problem: Waterfall of 5 serial API calls on mount
- File: `app/dashboard/page.tsx`
- Measurement: 3.5s until interactive on slow 3G
- Cause: Each component fetches own data independently
- Improvement path: Convert to Server Component with single parallel fetch

## Fragile Areas

**Authentication middleware chain:**
- File: `middleware.ts`
- Why fragile: 4 different middleware functions run in specific order (auth -> role -> subscription -> logging)
- Common failures: Middleware order change breaks everything, hard to debug
- Safe modification: Add tests before changing order, document dependencies in comments
- Test coverage: No integration tests for middleware chain (only unit tests)

**Stripe webhook event handling:**
- File: `app/api/webhooks/stripe/route.ts`
- Why fragile: Giant switch statement with 12 event types, shared transaction logic
- Common failures: New event type added without handling, partial DB updates on error
- Safe modification: Extract each event handler to `lib/stripe/handlers/*.ts`
- Test coverage: Only 3 of 12 event types have tests

## Scaling Limits

**Supabase Free Tier:**
- Current capacity: 500MB database, 1GB file storage, 2GB bandwidth/month
- Limit: ~5000 users estimated before hitting limits
- Symptoms at limit: 429 rate limit errors, DB writes fail
- Scaling path: Upgrade to Pro ($25/mo) extends to 8GB DB, 100GB storage

**Server-side render blocking:**
- Current capacity: ~50 concurrent users before slowdown
- Limit: Vercel Hobby plan (10s function timeout, 100GB-hrs/mo)
- Symptoms at limit: 504 gateway timeouts on course pages
- Scaling path: Upgrade to Vercel Pro ($20/mo), add edge caching

## Dependencies at Risk

**react-hot-toast:**
- Risk: Unmaintained (last update 18 months ago), React 19 compatibility unknown
- Impact: Toast notifications break, no graceful degradation
- Migration plan: Switch to sonner (actively maintained, similar API)

## Missing Critical Features

**Payment failure handling:**
- Problem: No retry mechanism or user notification when subscription payment fails
- Current workaround: Users manually re-enter payment info (if they notice)
- Blocks: Can't retain users with expired cards, no dunning process
- Implementation complexity: Medium (Stripe webhooks + email flow + UI)

**Course progress tracking:**
- Problem: No persistent state for which lessons completed
- Current workaround: Users manually track progress
- Blocks: Can't show completion percentage, can't recommend next lesson
- Implementation complexity: Low (add completed_lessons junction table)

## Test Coverage Gaps

**Payment flow end-to-end:**
- What's not tested: Full Stripe checkout -> webhook -> subscription activation flow
- Risk: Payment processing could break silently (has happened twice)
- Priority: High
- Difficulty to test: Need Stripe test fixtures and webhook simulation setup

**Error boundary behavior:**
- What's not tested: How app behaves when components throw errors
- Risk: White screen of death for users, no error reporting
- Priority: Medium
- Difficulty to test: Need to intentionally trigger errors in test environment

---

*Concerns audit: 2025-01-20*
*Update as issues are fixed or new ones discovered*
```
</good_examples>

<guidelines>
**What belongs in CONCERNS.md:**
- Tech debt with clear impact and fix approach
- Known bugs with reproduction steps
- Security gaps and mitigation recommendations
- Performance bottlenecks with measurements
- Fragile code that breaks easily
- Scaling limits with numbers
- Dependencies that need attention
- Missing features that block workflows
- Test coverage gaps

**What does NOT belong here:**
- Opinions without evidence ("code is messy")
- Complaints without solutions ("auth sucks")
- Future feature ideas (that's for product planning)
- Normal TODOs (those live in code comments)
- Architectural decisions that are working fine
- Minor code style issues

**When filling this template:**
- **Always include file paths** - Concerns without locations are not actionable. Use backticks: `src/file.ts`
- Be specific with measurements ("500ms p95" not "slow")
- Include reproduction steps for bugs
- Suggest fix approaches, not just problems
- Focus on actionable items
- Prioritize by risk/impact
- Update as issues get resolved
- Add new concerns as discovered

**Tone guidelines:**
- Professional, not emotional ("N+1 query pattern" not "terrible queries")
- Solution-oriented ("Fix: add index" not "needs fixing")
- Risk-focused ("Could expose user data" not "security is bad")
- Factual ("3.5s load time" not "really slow")

**Useful for phase planning when:**
- Deciding what to work on next
- Estimating risk of changes
- Understanding where to be careful
- Prioritizing improvements
- Onboarding new Claude contexts
- Planning refactoring work

**How this gets populated:**
Explore agents detect these during codebase mapping. Manual additions welcome for human-discovered issues. This is living documentation, not a complaint list.
</guidelines>

</document_content>
</document>
<document index="66">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\codebase\conventions.md</source>
<document_content>
# Coding Conventions Template

Template for `.planning/codebase/CONVENTIONS.md` - captures coding style and patterns.

**Purpose:** Document how code is written in this codebase. Prescriptive guide for Claude to match existing style.

---

## File Template

```markdown
# Coding Conventions

**Analysis Date:** [YYYY-MM-DD]

## Naming Patterns

**Files:**
- [Pattern: e.g., "kebab-case for all files"]
- [Test files: e.g., "*.test.ts alongside source"]
- [Components: e.g., "PascalCase.tsx for React components"]

**Functions:**
- [Pattern: e.g., "camelCase for all functions"]
- [Async: e.g., "no special prefix for async functions"]
- [Handlers: e.g., "handleEventName for event handlers"]

**Variables:**
- [Pattern: e.g., "camelCase for variables"]
- [Constants: e.g., "UPPER_SNAKE_CASE for constants"]
- [Private: e.g., "_prefix for private members" or "no prefix"]

**Types:**
- [Interfaces: e.g., "PascalCase, no I prefix"]
- [Types: e.g., "PascalCase for type aliases"]
- [Enums: e.g., "PascalCase for enum name, UPPER_CASE for values"]

## Code Style

**Formatting:**
- [Tool: e.g., "Prettier with config in .prettierrc"]
- [Line length: e.g., "100 characters max"]
- [Quotes: e.g., "single quotes for strings"]
- [Semicolons: e.g., "required" or "omitted"]

**Linting:**
- [Tool: e.g., "ESLint with eslint.config.js"]
- [Rules: e.g., "extends airbnb-base, no console in production"]
- [Run: e.g., "npm run lint"]

## Import Organization

**Order:**
1. [e.g., "External packages (react, express, etc.)"]
2. [e.g., "Internal modules (@/lib, @/components)"]
3. [e.g., "Relative imports (., ..)"]
4. [e.g., "Type imports (import type {})"]

**Grouping:**
- [Blank lines: e.g., "blank line between groups"]
- [Sorting: e.g., "alphabetical within each group"]

**Path Aliases:**
- [Aliases used: e.g., "@/ for src/, @components/ for src/components/"]

## Error Handling

**Patterns:**
- [Strategy: e.g., "throw errors, catch at boundaries"]
- [Custom errors: e.g., "extend Error class, named *Error"]
- [Async: e.g., "use try/catch, no .catch() chains"]

**Error Types:**
- [When to throw: e.g., "invalid input, missing dependencies"]
- [When to return: e.g., "expected failures return Result<T, E>"]
- [Logging: e.g., "log error with context before throwing"]

## Logging

**Framework:**
- [Tool: e.g., "console.log, pino, winston"]
- [Levels: e.g., "debug, info, warn, error"]

**Patterns:**
- [Format: e.g., "structured logging with context object"]
- [When: e.g., "log state transitions, external calls"]
- [Where: e.g., "log at service boundaries, not in utils"]

## Comments

**When to Comment:**
- [e.g., "explain why, not what"]
- [e.g., "document business logic, algorithms, edge cases"]
- [e.g., "avoid obvious comments like // increment counter"]

**JSDoc/TSDoc:**
- [Usage: e.g., "required for public APIs, optional for internal"]
- [Format: e.g., "use @param, @returns, @throws tags"]

**TODO Comments:**
- [Pattern: e.g., "// TODO(username): description"]
- [Tracking: e.g., "link to issue number if available"]

## Function Design

**Size:**
- [e.g., "keep under 50 lines, extract helpers"]

**Parameters:**
- [e.g., "max 3 parameters, use object for more"]
- [e.g., "destructure objects in parameter list"]

**Return Values:**
- [e.g., "explicit returns, no implicit undefined"]
- [e.g., "return early for guard clauses"]

## Module Design

**Exports:**
- [e.g., "named exports preferred, default exports for React components"]
- [e.g., "export from index.ts for public API"]

**Barrel Files:**
- [e.g., "use index.ts to re-export public API"]
- [e.g., "avoid circular dependencies"]

---

*Convention analysis: [date]*
*Update when patterns change*
```

<good_examples>
```markdown
# Coding Conventions

**Analysis Date:** 2025-01-20

## Naming Patterns

**Files:**
- kebab-case for all files (command-handler.ts, user-service.ts)
- *.test.ts alongside source files
- index.ts for barrel exports

**Functions:**
- camelCase for all functions
- No special prefix for async functions
- handleEventName for event handlers (handleClick, handleSubmit)

**Variables:**
- camelCase for variables
- UPPER_SNAKE_CASE for constants (MAX_RETRIES, API_BASE_URL)
- No underscore prefix (no private marker in TS)

**Types:**
- PascalCase for interfaces, no I prefix (User, not IUser)
- PascalCase for type aliases (UserConfig, ResponseData)
- PascalCase for enum names, UPPER_CASE for values (Status.PENDING)

## Code Style

**Formatting:**
- Prettier with .prettierrc
- 100 character line length
- Single quotes for strings
- Semicolons required
- 2 space indentation

**Linting:**
- ESLint with eslint.config.js
- Extends @typescript-eslint/recommended
- No console.log in production code (use logger)
- Run: npm run lint

## Import Organization

**Order:**
1. External packages (react, express, commander)
2. Internal modules (@/lib, @/services)
3. Relative imports (./utils, ../types)
4. Type imports (import type { User })

**Grouping:**
- Blank line between groups
- Alphabetical within each group
- Type imports last within each group

**Path Aliases:**
- @/ maps to src/
- No other aliases defined

## Error Handling

**Patterns:**
- Throw errors, catch at boundaries (route handlers, main functions)
- Extend Error class for custom errors (ValidationError, NotFoundError)
- Async functions use try/catch, no .catch() chains

**Error Types:**
- Throw on invalid input, missing dependencies, invariant violations
- Log error with context before throwing: logger.error({ err, userId }, 'Failed to process')
- Include cause in error message: new Error('Failed to X', { cause: originalError })

## Logging

**Framework:**
- pino logger instance exported from lib/logger.ts
- Levels: debug, info, warn, error (no trace)

**Patterns:**
- Structured logging with context: logger.info({ userId, action }, 'User action')
- Log at service boundaries, not in utility functions
- Log state transitions, external API calls, errors
- No console.log in committed code

## Comments

**When to Comment:**
- Explain why, not what: // Retry 3 times because API has transient failures
- Document business rules: // Users must verify email within 24 hours
- Explain non-obvious algorithms or workarounds
- Avoid obvious comments: // set count to 0

**JSDoc/TSDoc:**
- Required for public API functions
- Optional for internal functions if signature is self-explanatory
- Use @param, @returns, @throws tags

**TODO Comments:**
- Format: // TODO: description (no username, using git blame)
- Link to issue if exists: // TODO: Fix race condition (issue #123)

## Function Design

**Size:**
- Keep under 50 lines
- Extract helpers for complex logic
- One level of abstraction per function

**Parameters:**
- Max 3 parameters
- Use options object for 4+ parameters: function create(options: CreateOptions)
- Destructure in parameter list: function process({ id, name }: ProcessParams)

**Return Values:**
- Explicit return statements
- Return early for guard clauses
- Use Result<T, E> type for expected failures

## Module Design

**Exports:**
- Named exports preferred
- Default exports only for React components
- Export public API from index.ts barrel files

**Barrel Files:**
- index.ts re-exports public API
- Keep internal helpers private (don't export from index)
- Avoid circular dependencies (import from specific files if needed)

---

*Convention analysis: 2025-01-20*
*Update when patterns change*
```
</good_examples>

<guidelines>
**What belongs in CONVENTIONS.md:**
- Naming patterns observed in the codebase
- Formatting rules (Prettier config, linting rules)
- Import organization patterns
- Error handling strategy
- Logging approach
- Comment conventions
- Function and module design patterns

**What does NOT belong here:**
- Architecture decisions (that's ARCHITECTURE.md)
- Technology choices (that's STACK.md)
- Test patterns (that's TESTING.md)
- File organization (that's STRUCTURE.md)

**When filling this template:**
- Check .prettierrc, .eslintrc, or similar config files
- Examine 5-10 representative source files for patterns
- Look for consistency: if 80%+ follows a pattern, document it
- Be prescriptive: "Use X" not "Sometimes Y is used"
- Note deviations: "Legacy code uses Y, new code should use X"
- Keep under ~150 lines total

**Useful for phase planning when:**
- Writing new code (match existing style)
- Adding features (follow naming patterns)
- Refactoring (apply consistent conventions)
- Code review (check against documented patterns)
- Onboarding (understand style expectations)

**Analysis approach:**
- Scan src/ directory for file naming patterns
- Check package.json scripts for lint/format commands
- Read 5-10 files to identify function naming, error handling
- Look for config files (.prettierrc, eslint.config.js)
- Note patterns in imports, comments, function signatures
</guidelines>

</document_content>
</document>
<document index="67">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\codebase\integrations.md</source>
<document_content>
# External Integrations Template

Template for `.planning/codebase/INTEGRATIONS.md` - captures external service dependencies.

**Purpose:** Document what external systems this codebase communicates with. Focused on "what lives outside our code that we depend on."

---

## File Template

```markdown
# External Integrations

**Analysis Date:** [YYYY-MM-DD]

## APIs & External Services

**Payment Processing:**
- [Service] - [What it's used for: e.g., "subscription billing, one-time payments"]
  - SDK/Client: [e.g., "stripe npm package v14.x"]
  - Auth: [e.g., "API key in STRIPE_SECRET_KEY env var"]
  - Endpoints used: [e.g., "checkout sessions, webhooks"]

**Email/SMS:**
- [Service] - [What it's used for: e.g., "transactional emails"]
  - SDK/Client: [e.g., "sendgrid/mail v8.x"]
  - Auth: [e.g., "API key in SENDGRID_API_KEY env var"]
  - Templates: [e.g., "managed in SendGrid dashboard"]

**External APIs:**
- [Service] - [What it's used for]
  - Integration method: [e.g., "REST API via fetch", "GraphQL client"]
  - Auth: [e.g., "OAuth2 token in AUTH_TOKEN env var"]
  - Rate limits: [if applicable]

## Data Storage

**Databases:**
- [Type/Provider] - [e.g., "PostgreSQL on Supabase"]
  - Connection: [e.g., "via DATABASE_URL env var"]
  - Client: [e.g., "Prisma ORM v5.x"]
  - Migrations: [e.g., "prisma migrate in migrations/"]

**File Storage:**
- [Service] - [e.g., "AWS S3 for user uploads"]
  - SDK/Client: [e.g., "@aws-sdk/client-s3"]
  - Auth: [e.g., "IAM credentials in AWS_* env vars"]
  - Buckets: [e.g., "prod-uploads, dev-uploads"]

**Caching:**
- [Service] - [e.g., "Redis for session storage"]
  - Connection: [e.g., "REDIS_URL env var"]
  - Client: [e.g., "ioredis v5.x"]

## Authentication & Identity

**Auth Provider:**
- [Service] - [e.g., "Supabase Auth", "Auth0", "custom JWT"]
  - Implementation: [e.g., "Supabase client SDK"]
  - Token storage: [e.g., "httpOnly cookies", "localStorage"]
  - Session management: [e.g., "JWT refresh tokens"]

**OAuth Integrations:**
- [Provider] - [e.g., "Google OAuth for sign-in"]
  - Credentials: [e.g., "GOOGLE_CLIENT_ID, GOOGLE_CLIENT_SECRET"]
  - Scopes: [e.g., "email, profile"]

## Monitoring & Observability

**Error Tracking:**
- [Service] - [e.g., "Sentry"]
  - DSN: [e.g., "SENTRY_DSN env var"]
  - Release tracking: [e.g., "via SENTRY_RELEASE"]

**Analytics:**
- [Service] - [e.g., "Mixpanel for product analytics"]
  - Token: [e.g., "MIXPANEL_TOKEN env var"]
  - Events tracked: [e.g., "user actions, page views"]

**Logs:**
- [Service] - [e.g., "CloudWatch", "Datadog", "none (stdout only)"]
  - Integration: [e.g., "AWS Lambda built-in"]

## CI/CD & Deployment

**Hosting:**
- [Platform] - [e.g., "Vercel", "AWS Lambda", "Docker on ECS"]
  - Deployment: [e.g., "automatic on main branch push"]
  - Environment vars: [e.g., "configured in Vercel dashboard"]

**CI Pipeline:**
- [Service] - [e.g., "GitHub Actions"]
  - Workflows: [e.g., "test.yml, deploy.yml"]
  - Secrets: [e.g., "stored in GitHub repo secrets"]

## Environment Configuration

**Development:**
- Required env vars: [List critical vars]
- Secrets location: [e.g., ".env.local (gitignored)", "1Password vault"]
- Mock/stub services: [e.g., "Stripe test mode", "local PostgreSQL"]

**Staging:**
- Environment-specific differences: [e.g., "uses staging Stripe account"]
- Data: [e.g., "separate staging database"]

**Production:**
- Secrets management: [e.g., "Vercel environment variables"]
- Failover/redundancy: [e.g., "multi-region DB replication"]

## Webhooks & Callbacks

**Incoming:**
- [Service] - [Endpoint: e.g., "/api/webhooks/stripe"]
  - Verification: [e.g., "signature validation via stripe.webhooks.constructEvent"]
  - Events: [e.g., "payment_intent.succeeded, customer.subscription.updated"]

**Outgoing:**
- [Service] - [What triggers it]
  - Endpoint: [e.g., "external CRM webhook on user signup"]
  - Retry logic: [if applicable]

---

*Integration audit: [date]*
*Update when adding/removing external services*
```

<good_examples>
```markdown
# External Integrations

**Analysis Date:** 2025-01-20

## APIs & External Services

**Payment Processing:**
- Stripe - Subscription billing and one-time course payments
  - SDK/Client: stripe npm package v14.8
  - Auth: API key in STRIPE_SECRET_KEY env var
  - Endpoints used: checkout sessions, customer portal, webhooks

**Email/SMS:**
- SendGrid - Transactional emails (receipts, password resets)
  - SDK/Client: @sendgrid/mail v8.1
  - Auth: API key in SENDGRID_API_KEY env var
  - Templates: Managed in SendGrid dashboard (template IDs in code)

**External APIs:**
- OpenAI API - Course content generation
  - Integration method: REST API via openai npm package v4.x
  - Auth: Bearer token in OPENAI_API_KEY env var
  - Rate limits: 3500 requests/min (tier 3)

## Data Storage

**Databases:**
- PostgreSQL on Supabase - Primary data store
  - Connection: via DATABASE_URL env var
  - Client: Prisma ORM v5.8
  - Migrations: prisma migrate in prisma/migrations/

**File Storage:**
- Supabase Storage - User uploads (profile images, course materials)
  - SDK/Client: @supabase/supabase-js v2.x
  - Auth: Service role key in SUPABASE_SERVICE_ROLE_KEY
  - Buckets: avatars (public), course-materials (private)

**Caching:**
- None currently (all database queries, no Redis)

## Authentication & Identity

**Auth Provider:**
- Supabase Auth - Email/password + OAuth
  - Implementation: Supabase client SDK with server-side session management
  - Token storage: httpOnly cookies via @supabase/ssr
  - Session management: JWT refresh tokens handled by Supabase

**OAuth Integrations:**
- Google OAuth - Social sign-in
  - Credentials: GOOGLE_CLIENT_ID, GOOGLE_CLIENT_SECRET (Supabase dashboard)
  - Scopes: email, profile

## Monitoring & Observability

**Error Tracking:**
- Sentry - Server and client errors
  - DSN: SENTRY_DSN env var
  - Release tracking: Git commit SHA via SENTRY_RELEASE

**Analytics:**
- None (planned: Mixpanel)

**Logs:**
- Vercel logs - stdout/stderr only
  - Retention: 7 days on Pro plan

## CI/CD & Deployment

**Hosting:**
- Vercel - Next.js app hosting
  - Deployment: Automatic on main branch push
  - Environment vars: Configured in Vercel dashboard (synced to .env.example)

**CI Pipeline:**
- GitHub Actions - Tests and type checking
  - Workflows: .github/workflows/ci.yml
  - Secrets: None needed (public repo tests only)

## Environment Configuration

**Development:**
- Required env vars: DATABASE_URL, NEXT_PUBLIC_SUPABASE_URL, NEXT_PUBLIC_SUPABASE_ANON_KEY
- Secrets location: .env.local (gitignored), team shared via 1Password vault
- Mock/stub services: Stripe test mode, Supabase local dev project

**Staging:**
- Uses separate Supabase staging project
- Stripe test mode
- Same Vercel account, different environment

**Production:**
- Secrets management: Vercel environment variables
- Database: Supabase production project with daily backups

## Webhooks & Callbacks

**Incoming:**
- Stripe - /api/webhooks/stripe
  - Verification: Signature validation via stripe.webhooks.constructEvent
  - Events: payment_intent.succeeded, customer.subscription.updated, customer.subscription.deleted

**Outgoing:**
- None

---

*Integration audit: 2025-01-20*
*Update when adding/removing external services*
```
</good_examples>

<guidelines>
**What belongs in INTEGRATIONS.md:**
- External services the code communicates with
- Authentication patterns (where secrets live, not the secrets themselves)
- SDKs and client libraries used
- Environment variable names (not values)
- Webhook endpoints and verification methods
- Database connection patterns
- File storage locations
- Monitoring and logging services

**What does NOT belong here:**
- Actual API keys or secrets (NEVER write these)
- Internal architecture (that's ARCHITECTURE.md)
- Code patterns (that's PATTERNS.md)
- Technology choices (that's STACK.md)
- Performance issues (that's CONCERNS.md)

**When filling this template:**
- Check .env.example or .env.template for required env vars
- Look for SDK imports (stripe, @sendgrid/mail, etc.)
- Check for webhook handlers in routes/endpoints
- Note where secrets are managed (not the secrets)
- Document environment-specific differences (dev/staging/prod)
- Include auth patterns for each service

**Useful for phase planning when:**
- Adding new external service integrations
- Debugging authentication issues
- Understanding data flow outside the application
- Setting up new environments
- Auditing third-party dependencies
- Planning for service outages or migrations

**Security note:**
Document WHERE secrets live (env vars, Vercel dashboard, 1Password), never WHAT the secrets are.
</guidelines>

</document_content>
</document>
<document index="68">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\codebase\stack.md</source>
<document_content>
# Technology Stack Template

Template for `.planning/codebase/STACK.md` - captures the technology foundation.

**Purpose:** Document what technologies run this codebase. Focused on "what executes when you run the code."

---

## File Template

```markdown
# Technology Stack

**Analysis Date:** [YYYY-MM-DD]

## Languages

**Primary:**
- [Language] [Version] - [Where used: e.g., "all application code"]

**Secondary:**
- [Language] [Version] - [Where used: e.g., "build scripts, tooling"]

## Runtime

**Environment:**
- [Runtime] [Version] - [e.g., "Node.js 20.x"]
- [Additional requirements if any]

**Package Manager:**
- [Manager] [Version] - [e.g., "npm 10.x"]
- Lockfile: [e.g., "package-lock.json present"]

## Frameworks

**Core:**
- [Framework] [Version] - [Purpose: e.g., "web server", "UI framework"]

**Testing:**
- [Framework] [Version] - [e.g., "Jest for unit tests"]
- [Framework] [Version] - [e.g., "Playwright for E2E"]

**Build/Dev:**
- [Tool] [Version] - [e.g., "Vite for bundling"]
- [Tool] [Version] - [e.g., "TypeScript compiler"]

## Key Dependencies

[Only include dependencies critical to understanding the stack - limit to 5-10 most important]

**Critical:**
- [Package] [Version] - [Why it matters: e.g., "authentication", "database access"]
- [Package] [Version] - [Why it matters]

**Infrastructure:**
- [Package] [Version] - [e.g., "Express for HTTP routing"]
- [Package] [Version] - [e.g., "PostgreSQL client"]

## Configuration

**Environment:**
- [How configured: e.g., ".env files", "environment variables"]
- [Key configs: e.g., "DATABASE_URL, API_KEY required"]

**Build:**
- [Build config files: e.g., "vite.config.ts, tsconfig.json"]

## Platform Requirements

**Development:**
- [OS requirements or "any platform"]
- [Additional tooling: e.g., "Docker for local DB"]

**Production:**
- [Deployment target: e.g., "Vercel", "AWS Lambda", "Docker container"]
- [Version requirements]

---

*Stack analysis: [date]*
*Update after major dependency changes*
```

<good_examples>
```markdown
# Technology Stack

**Analysis Date:** 2025-01-20

## Languages

**Primary:**
- TypeScript 5.3 - All application code

**Secondary:**
- JavaScript - Build scripts, config files

## Runtime

**Environment:**
- Node.js 20.x (LTS)
- No browser runtime (CLI tool only)

**Package Manager:**
- npm 10.x
- Lockfile: `package-lock.json` present

## Frameworks

**Core:**
- None (vanilla Node.js CLI)

**Testing:**
- Vitest 1.0 - Unit tests
- tsx - TypeScript execution without build step

**Build/Dev:**
- TypeScript 5.3 - Compilation to JavaScript
- esbuild - Used by Vitest for fast transforms

## Key Dependencies

**Critical:**
- commander 11.x - CLI argument parsing and command structure
- chalk 5.x - Terminal output styling
- fs-extra 11.x - Extended file system operations

**Infrastructure:**
- Node.js built-ins - fs, path, child_process for file operations

## Configuration

**Environment:**
- No environment variables required
- Configuration via CLI flags only

**Build:**
- `tsconfig.json` - TypeScript compiler options
- `vitest.config.ts` - Test runner configuration

## Platform Requirements

**Development:**
- macOS/Linux/Windows (any platform with Node.js)
- No external dependencies

**Production:**
- Distributed as npm package
- Installed globally via npm install -g
- Runs on user's Node.js installation

---

*Stack analysis: 2025-01-20*
*Update after major dependency changes*
```
</good_examples>

<guidelines>
**What belongs in STACK.md:**
- Languages and versions
- Runtime requirements (Node, Bun, Deno, browser)
- Package manager and lockfile
- Framework choices
- Critical dependencies (limit to 5-10 most important)
- Build tooling
- Platform/deployment requirements

**What does NOT belong here:**
- File structure (that's STRUCTURE.md)
- Architectural patterns (that's ARCHITECTURE.md)
- Every dependency in package.json (only critical ones)
- Implementation details (defer to code)

**When filling this template:**
- Check package.json for dependencies
- Note runtime version from .nvmrc or package.json engines
- Include only dependencies that affect understanding (not every utility)
- Specify versions only when version matters (breaking changes, compatibility)

**Useful for phase planning when:**
- Adding new dependencies (check compatibility)
- Upgrading frameworks (know what's in use)
- Choosing implementation approach (must work with existing stack)
- Understanding build requirements
</guidelines>

</document_content>
</document>
<document index="69">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\codebase\structure.md</source>
<document_content>
﻿# Structure Template

Template for `.planning/codebase/STRUCTURE.md` - captures physical file organization.

**Purpose:** Document where things physically live in the codebase. Answers "where do I put X?"

---

## File Template

```markdown
# Codebase Structure

**Analysis Date:** [YYYY-MM-DD]

## Directory Layout

[ASCII box-drawing tree of top-level directories with purpose - use ├── └── │ characters for tree structure only]

```
[project-root]/
├── [dir]/          # [Purpose]
├── [dir]/          # [Purpose]
├── [dir]/          # [Purpose]
└── [file]          # [Purpose]
```

## Directory Purposes

**[Directory Name]:**
- Purpose: [What lives here]
- Contains: [Types of files: e.g., "*.ts source files", "component directories"]
- Key files: [Important files in this directory]
- Subdirectories: [If nested, describe structure]

**[Directory Name]:**
- Purpose: [What lives here]
- Contains: [Types of files]
- Key files: [Important files]
- Subdirectories: [Structure]

## Key File Locations

**Entry Points:**
- [Path]: [Purpose: e.g., "CLI entry point"]
- [Path]: [Purpose: e.g., "Server startup"]

**Configuration:**
- [Path]: [Purpose: e.g., "TypeScript config"]
- [Path]: [Purpose: e.g., "Build configuration"]
- [Path]: [Purpose: e.g., "Environment variables"]

**Core Logic:**
- [Path]: [Purpose: e.g., "Business services"]
- [Path]: [Purpose: e.g., "Database models"]
- [Path]: [Purpose: e.g., "API routes"]

**Testing:**
- [Path]: [Purpose: e.g., "Unit tests"]
- [Path]: [Purpose: e.g., "Test fixtures"]

**Documentation:**
- [Path]: [Purpose: e.g., "User-facing docs"]
- [Path]: [Purpose: e.g., "Developer guide"]

## Naming Conventions

**Files:**
- [Pattern]: [Example: e.g., "kebab-case.ts for modules"]
- [Pattern]: [Example: e.g., "PascalCase.tsx for React components"]
- [Pattern]: [Example: e.g., "*.test.ts for test files"]

**Directories:**
- [Pattern]: [Example: e.g., "kebab-case for feature directories"]
- [Pattern]: [Example: e.g., "plural names for collections"]

**Special Patterns:**
- [Pattern]: [Example: e.g., "index.ts for directory exports"]
- [Pattern]: [Example: e.g., "__tests__ for test directories"]

## Where to Add New Code

**New Feature:**
- Primary code: [Directory path]
- Tests: [Directory path]
- Config if needed: [Directory path]

**New Component/Module:**
- Implementation: [Directory path]
- Types: [Directory path]
- Tests: [Directory path]

**New Route/Command:**
- Definition: [Directory path]
- Handler: [Directory path]
- Tests: [Directory path]

**Utilities:**
- Shared helpers: [Directory path]
- Type definitions: [Directory path]

## Special Directories

[Any directories with special meaning or generation]

**[Directory]:**
- Purpose: [e.g., "Generated code", "Build output"]
- Source: [e.g., "Auto-generated by X", "Build artifacts"]
- Committed: [Yes/No - in .gitignore?]

---

*Structure analysis: [date]*
*Update when directory structure changes*
```

<good_examples>
```markdown
# Codebase Structure

**Analysis Date:** 2025-01-20

## Directory Layout

```
get-shit-indexed/
├── bin/                # Executable entry points
├── commands/           # Slash command definitions
│   └── GSI/           # GSI-specific commands
├── get-shit-indexed/     # Skill resources
│   ├── references/    # Principle documents
│   ├── templates/     # File templates
│   └── workflows/     # Multi-step procedures
├── src/               # Source code (if applicable)
├── tests/             # Test files
├── package.json       # Project manifest
└── README.md          # User documentation
```

## Directory Purposes

**bin/**
- Purpose: CLI entry points
- Contains: install.js (installer script)
- Key files: install.js - handles npx installation
- Subdirectories: None

**commands/GSI/**
- Purpose: Slash command definitions for Claude Code
- Contains: *.md files (one per command)
- Key files: new-project.md, plan-phase.md, execute-plan.md
- Subdirectories: None (flat structure)

**get-shit-indexed/references/**
- Purpose: Core philosophy and guidance documents
- Contains: principles.md, questioning.md, plan-format.md
- Key files: principles.md - system philosophy
- Subdirectories: None

**get-shit-indexed/templates/**
- Purpose: Document templates for .planning/ files
- Contains: Template definitions with frontmatter
- Key files: project.md, roadmap.md, plan.md, summary.md
- Subdirectories: codebase/ (new - for stack/architecture/structure templates)

**get-shit-indexed/workflows/**
- Purpose: Reusable multi-step procedures
- Contains: Workflow definitions called by commands
- Key files: execute-plan.md, research-phase.md
- Subdirectories: None

## Key File Locations

**Entry Points:**
- `bin/install.js` - Installation script (npx entry)

**Configuration:**
- `package.json` - Project metadata, dependencies, bin entry
- `.gitignore` - Excluded files

**Core Logic:**
- `bin/install.js` - All installation logic (file copying, path replacement)

**Testing:**
- `tests/` - Test files (if present)

**Documentation:**
- `README.md` - User-facing installation and usage guide
- `CLAUDE.md` - Instructions for Claude Code when working in this repo

## Naming Conventions

**Files:**
- kebab-case.md: Markdown documents
- kebab-case.js: JavaScript source files
- UPPERCASE.md: Important project files (README, CLAUDE, CHANGELOG)

**Directories:**
- kebab-case: All directories
- Plural for collections: templates/, commands/, workflows/

**Special Patterns:**
- {command-name}.md: Slash command definition
- *-template.md: Could be used but templates/ directory preferred

## Where to Add New Code

**New Slash Command:**
- Primary code: `commands/GSI/{command-name}.md`
- Tests: `tests/commands/{command-name}.test.js` (if testing implemented)
- Documentation: Update `README.md` with new command

**New Template:**
- Implementation: `get-shit-indexed/templates/{name}.md`
- Documentation: Template is self-documenting (includes guidelines)

**New Workflow:**
- Implementation: `get-shit-indexed/workflows/{name}.md`
- Usage: Reference from command with `@~/.claude/get-shit-indexed/workflows/{name}.md`

**New Reference Document:**
- Implementation: `get-shit-indexed/references/{name}.md`
- Usage: Reference from commands/workflows as needed

**Utilities:**
- No utilities yet (`install.js` is monolithic)
- If extracted: `src/utils/`

## Special Directories

**get-shit-indexed/**
- Purpose: Resources installed to ~/.claude/
- Source: Copied by bin/install.js during installation
- Committed: Yes (source of truth)

**commands/**
- Purpose: Slash commands installed to ~/.claude/commands/
- Source: Copied by bin/install.js during installation
- Committed: Yes (source of truth)

---

*Structure analysis: 2025-01-20*
*Update when directory structure changes*
```
</good_examples>

<guidelines>
**What belongs in STRUCTURE.md:**
- Directory layout (ASCII box-drawing tree for structure visualization)
- Purpose of each directory
- Key file locations (entry points, configs, core logic)
- Naming conventions
- Where to add new code (by type)
- Special/generated directories

**What does NOT belong here:**
- Conceptual architecture (that's ARCHITECTURE.md)
- Technology stack (that's STACK.md)
- Code implementation details (defer to code reading)
- Every single file (focus on directories and key files)

**When filling this template:**
- Use `tree -L 2` or similar to visualize structure
- Identify top-level directories and their purposes
- Note naming patterns by observing existing files
- Locate entry points, configs, and main logic areas
- Keep directory tree concise (max 2-3 levels)

**Tree format (ASCII box-drawing characters for structure only):**
```
root/
├── dir1/           # Purpose
│   ├── subdir/    # Purpose
│   └── file.ts    # Purpose
├── dir2/          # Purpose
└── file.ts        # Purpose
```

**Useful for phase planning when:**
- Adding new features (where should files go?)
- Understanding project organization
- Finding where specific logic lives
- Following existing conventions
</guidelines>

</document_content>
</document>
<document index="70">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\codebase\testing.md</source>
<document_content>
# Testing Patterns Template

Template for `.planning/codebase/TESTING.md` - captures test framework and patterns.

**Purpose:** Document how tests are written and run. Guide for adding tests that match existing patterns.

---

## File Template

```markdown
# Testing Patterns

**Analysis Date:** [YYYY-MM-DD]

## Test Framework

**Runner:**
- [Framework: e.g., "Jest 29.x", "Vitest 1.x"]
- [Config: e.g., "jest.config.js in project root"]

**Assertion Library:**
- [Library: e.g., "built-in expect", "chai"]
- [Matchers: e.g., "toBe, toEqual, toThrow"]

**Run Commands:**
```bash
[e.g., "npm test" or "npm run test"]              # Run all tests
[e.g., "npm test -- --watch"]                     # Watch mode
[e.g., "npm test -- path/to/file.test.ts"]       # Single file
[e.g., "npm run test:coverage"]                   # Coverage report
```

## Test File Organization

**Location:**
- [Pattern: e.g., "*.test.ts alongside source files"]
- [Alternative: e.g., "__tests__/ directory" or "separate tests/ tree"]

**Naming:**
- [Unit tests: e.g., "module-name.test.ts"]
- [Integration: e.g., "feature-name.integration.test.ts"]
- [E2E: e.g., "user-flow.e2e.test.ts"]

**Structure:**
```
[Show actual directory pattern, e.g.:
src/
  lib/
    utils.ts
    utils.test.ts
  services/
    user-service.ts
    user-service.test.ts
]
```

## Test Structure

**Suite Organization:**
```typescript
[Show actual pattern used, e.g.:

describe('ModuleName', () => {
  describe('functionName', () => {
    it('should handle success case', () => {
      // arrange
      // act
      // assert
    });

    it('should handle error case', () => {
      // test code
    });
  });
});
]
```

**Patterns:**
- [Setup: e.g., "beforeEach for shared setup, avoid beforeAll"]
- [Teardown: e.g., "afterEach to clean up, restore mocks"]
- [Structure: e.g., "arrange/act/assert pattern required"]

## Mocking

**Framework:**
- [Tool: e.g., "Jest built-in mocking", "Vitest vi", "Sinon"]
- [Import mocking: e.g., "vi.mock() at top of file"]

**Patterns:**
```typescript
[Show actual mocking pattern, e.g.:

// Mock external dependency
vi.mock('./external-service', () => ({
  fetchData: vi.fn()
}));

// Mock in test
const mockFetch = vi.mocked(fetchData);
mockFetch.mockResolvedValue({ data: 'test' });
]
```

**What to Mock:**
- [e.g., "External APIs, file system, database"]
- [e.g., "Time/dates (use vi.useFakeTimers)"]
- [e.g., "Network calls (use mock fetch)"]

**What NOT to Mock:**
- [e.g., "Pure functions, utilities"]
- [e.g., "Internal business logic"]

## Fixtures and Factories

**Test Data:**
```typescript
[Show pattern for creating test data, e.g.:

// Factory pattern
function createTestUser(overrides?: Partial<User>): User {
  return {
    id: 'test-id',
    name: 'Test User',
    email: 'test@example.com',
    ...overrides
  };
}

// Fixture file
// tests/fixtures/users.ts
export const mockUsers = [/* ... */];
]
```

**Location:**
- [e.g., "tests/fixtures/ for shared fixtures"]
- [e.g., "factory functions in test file or tests/factories/"]

## Coverage

**Requirements:**
- [Target: e.g., "80% line coverage", "no specific target"]
- [Enforcement: e.g., "CI blocks <80%", "coverage for awareness only"]

**Configuration:**
- [Tool: e.g., "built-in coverage via --coverage flag"]
- [Exclusions: e.g., "exclude *.test.ts, config files"]

**View Coverage:**
```bash
[e.g., "npm run test:coverage"]
[e.g., "open coverage/index.html"]
```

## Test Types

**Unit Tests:**
- [Scope: e.g., "test single function/class in isolation"]
- [Mocking: e.g., "mock all external dependencies"]
- [Speed: e.g., "must run in <1s per test"]

**Integration Tests:**
- [Scope: e.g., "test multiple modules together"]
- [Mocking: e.g., "mock external services, use real internal modules"]
- [Setup: e.g., "use test database, seed data"]

**E2E Tests:**
- [Framework: e.g., "Playwright for E2E"]
- [Scope: e.g., "test full user flows"]
- [Location: e.g., "e2e/ directory separate from unit tests"]

## Common Patterns

**Async Testing:**
```typescript
[Show pattern, e.g.:

it('should handle async operation', async () => {
  const result = await asyncFunction();
  expect(result).toBe('expected');
});
]
```

**Error Testing:**
```typescript
[Show pattern, e.g.:

it('should throw on invalid input', () => {
  expect(() => functionCall()).toThrow('error message');
});

// Async error
it('should reject on failure', async () => {
  await expect(asyncCall()).rejects.toThrow('error message');
});
]
```

**Snapshot Testing:**
- [Usage: e.g., "for React components only" or "not used"]
- [Location: e.g., "__snapshots__/ directory"]

---

*Testing analysis: [date]*
*Update when test patterns change*
```

<good_examples>
```markdown
# Testing Patterns

**Analysis Date:** 2025-01-20

## Test Framework

**Runner:**
- Vitest 1.0.4
- Config: vitest.config.ts in project root

**Assertion Library:**
- Vitest built-in expect
- Matchers: toBe, toEqual, toThrow, toMatchObject

**Run Commands:**
```bash
npm test                              # Run all tests
npm test -- --watch                   # Watch mode
npm test -- path/to/file.test.ts     # Single file
npm run test:coverage                 # Coverage report
```

## Test File Organization

**Location:**
- *.test.ts alongside source files
- No separate tests/ directory

**Naming:**
- unit-name.test.ts for all tests
- No distinction between unit/integration in filename

**Structure:**
```
src/
  lib/
    parser.ts
    parser.test.ts
  services/
    install-service.ts
    install-service.test.ts
  bin/
    install.ts
    (no test - integration tested via CLI)
```

## Test Structure

**Suite Organization:**
```typescript
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';

describe('ModuleName', () => {
  describe('functionName', () => {
    beforeEach(() => {
      // reset state
    });

    it('should handle valid input', () => {
      // arrange
      const input = createTestInput();

      // act
      const result = functionName(input);

      // assert
      expect(result).toEqual(expectedOutput);
    });

    it('should throw on invalid input', () => {
      expect(() => functionName(null)).toThrow('Invalid input');
    });
  });
});
```

**Patterns:**
- Use beforeEach for per-test setup, avoid beforeAll
- Use afterEach to restore mocks: vi.restoreAllMocks()
- Explicit arrange/act/assert comments in complex tests
- One assertion focus per test (but multiple expects OK)

## Mocking

**Framework:**
- Vitest built-in mocking (vi)
- Module mocking via vi.mock() at top of test file

**Patterns:**
```typescript
import { vi } from 'vitest';
import { externalFunction } from './external';

// Mock module
vi.mock('./external', () => ({
  externalFunction: vi.fn()
}));

describe('test suite', () => {
  it('mocks function', () => {
    const mockFn = vi.mocked(externalFunction);
    mockFn.mockReturnValue('mocked result');

    // test code using mocked function

    expect(mockFn).toHaveBeenCalledWith('expected arg');
  });
});
```

**What to Mock:**
- File system operations (fs-extra)
- Child process execution (child_process.exec)
- External API calls
- Environment variables (process.env)

**What NOT to Mock:**
- Internal pure functions
- Simple utilities (string manipulation, array helpers)
- TypeScript types

## Fixtures and Factories

**Test Data:**
```typescript
// Factory functions in test file
function createTestConfig(overrides?: Partial<Config>): Config {
  return {
    targetDir: '/tmp/test',
    global: false,
    ...overrides
  };
}

// Shared fixtures in tests/fixtures/
// tests/fixtures/sample-command.md
export const sampleCommand = `---
description: Test command
---
Content here`;
```

**Location:**
- Factory functions: define in test file near usage
- Shared fixtures: tests/fixtures/ (for multi-file test data)
- Mock data: inline in test when simple, factory when complex

## Coverage

**Requirements:**
- No enforced coverage target
- Coverage tracked for awareness
- Focus on critical paths (parsers, service logic)

**Configuration:**
- Vitest coverage via c8 (built-in)
- Excludes: *.test.ts, bin/install.ts, config files

**View Coverage:**
```bash
npm run test:coverage
open coverage/index.html
```

## Test Types

**Unit Tests:**
- Test single function in isolation
- Mock all external dependencies (fs, child_process)
- Fast: each test <100ms
- Examples: parser.test.ts, validator.test.ts

**Integration Tests:**
- Test multiple modules together
- Mock only external boundaries (file system, process)
- Examples: install-service.test.ts (tests service + parser)

**E2E Tests:**
- Not currently used
- CLI integration tested manually

## Common Patterns

**Async Testing:**
```typescript
it('should handle async operation', async () => {
  const result = await asyncFunction();
  expect(result).toBe('expected');
});
```

**Error Testing:**
```typescript
it('should throw on invalid input', () => {
  expect(() => parse(null)).toThrow('Cannot parse null');
});

// Async error
it('should reject on file not found', async () => {
  await expect(readConfig('invalid.txt')).rejects.toThrow('ENOENT');
});
```

**File System Mocking:**
```typescript
import { vi } from 'vitest';
import * as fs from 'fs-extra';

vi.mock('fs-extra');

it('mocks file system', () => {
  vi.mocked(fs.readFile).mockResolvedValue('file content');
  // test code
});
```

**Snapshot Testing:**
- Not used in this codebase
- Prefer explicit assertions for clarity

---

*Testing analysis: 2025-01-20*
*Update when test patterns change*
```
</good_examples>

<guidelines>
**What belongs in TESTING.md:**
- Test framework and runner configuration
- Test file location and naming patterns
- Test structure (describe/it, beforeEach patterns)
- Mocking approach and examples
- Fixture/factory patterns
- Coverage requirements
- How to run tests (commands)
- Common testing patterns in actual code

**What does NOT belong here:**
- Specific test cases (defer to actual test files)
- Technology choices (that's STACK.md)
- CI/CD setup (that's deployment docs)

**When filling this template:**
- Check package.json scripts for test commands
- Find test config file (jest.config.js, vitest.config.ts)
- Read 3-5 existing test files to identify patterns
- Look for test utilities in tests/ or test-utils/
- Check for coverage configuration
- Document actual patterns used, not ideal patterns

**Useful for phase planning when:**
- Adding new features (write matching tests)
- Refactoring (maintain test patterns)
- Fixing bugs (add regression tests)
- Understanding verification approach
- Setting up test infrastructure

**Analysis approach:**
- Check package.json for test framework and scripts
- Read test config file for coverage, setup
- Examine test file organization (collocated vs separate)
- Review 5 test files for patterns (mocking, structure, assertions)
- Look for test utilities, fixtures, factories
- Note any test types (unit, integration, e2e)
- Document commands for running tests
</guidelines>

</document_content>
</document>
<document index="71">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\research-project\ARCHITECTURE.md</source>
<document_content>
# Architecture Research Template

Template for `.planning/research/ARCHITECTURE.md` — system structure patterns for the project domain.

<template>

```markdown
# Architecture Research

**Domain:** [domain type]
**Researched:** [date]
**Confidence:** [HIGH/MEDIUM/LOW]

## Standard Architecture

### System Overview

```
┌─────────────────────────────────────────────────────────────┐
│                        [Layer Name]                          │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐        │
│  │ [Comp]  │  │ [Comp]  │  │ [Comp]  │  │ [Comp]  │        │
│  └────┬────┘  └────┬────┘  └────┬────┘  └────┬────┘        │
│       │            │            │            │              │
├───────┴────────────┴────────────┴────────────┴──────────────┤
│                        [Layer Name]                          │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────────────────────────────────────────────┐    │
│  │                    [Component]                       │    │
│  └─────────────────────────────────────────────────────┘    │
├─────────────────────────────────────────────────────────────┤
│                        [Layer Name]                          │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐                   │
│  │ [Store]  │  │ [Store]  │  │ [Store]  │                   │
│  └──────────┘  └──────────┘  └──────────┘                   │
└─────────────────────────────────────────────────────────────┘
```

### Component Responsibilities

| Component | Responsibility | Typical Implementation |
|-----------|----------------|------------------------|
| [name] | [what it owns] | [how it's usually built] |
| [name] | [what it owns] | [how it's usually built] |
| [name] | [what it owns] | [how it's usually built] |

## Recommended Project Structure

```
src/
├── [folder]/           # [purpose]
│   ├── [subfolder]/    # [purpose]
│   └── [file].ts       # [purpose]
├── [folder]/           # [purpose]
│   ├── [subfolder]/    # [purpose]
│   └── [file].ts       # [purpose]
├── [folder]/           # [purpose]
└── [folder]/           # [purpose]
```

### Structure Rationale

- **[folder]/:** [why organized this way]
- **[folder]/:** [why organized this way]

## Architectural Patterns

### Pattern 1: [Pattern Name]

**What:** [description]
**When to use:** [conditions]
**Trade-offs:** [pros and cons]

**Example:**
```typescript
// [Brief code example showing the pattern]
```

### Pattern 2: [Pattern Name]

**What:** [description]
**When to use:** [conditions]
**Trade-offs:** [pros and cons]

**Example:**
```typescript
// [Brief code example showing the pattern]
```

### Pattern 3: [Pattern Name]

**What:** [description]
**When to use:** [conditions]
**Trade-offs:** [pros and cons]

## Data Flow

### Request Flow

```
[User Action]
    ↓
[Component] → [Handler] → [Service] → [Data Store]
    ↓              ↓           ↓            ↓
[Response] ← [Transform] ← [Query] ← [Database]
```

### State Management

```
[State Store]
    ↓ (subscribe)
[Components] ←→ [Actions] → [Reducers/Mutations] → [State Store]
```

### Key Data Flows

1. **[Flow name]:** [description of how data moves]
2. **[Flow name]:** [description of how data moves]

## Scaling Considerations

| Scale | Architecture Adjustments |
|-------|--------------------------|
| 0-1k users | [approach — usually monolith is fine] |
| 1k-100k users | [approach — what to optimize first] |
| 100k+ users | [approach — when to consider splitting] |

### Scaling Priorities

1. **First bottleneck:** [what breaks first, how to fix]
2. **Second bottleneck:** [what breaks next, how to fix]

## Anti-Patterns

### Anti-Pattern 1: [Name]

**What people do:** [the mistake]
**Why it's wrong:** [the problem it causes]
**Do this instead:** [the correct approach]

### Anti-Pattern 2: [Name]

**What people do:** [the mistake]
**Why it's wrong:** [the problem it causes]
**Do this instead:** [the correct approach]

## Integration Points

### External Services

| Service | Integration Pattern | Notes |
|---------|---------------------|-------|
| [service] | [how to connect] | [gotchas] |
| [service] | [how to connect] | [gotchas] |

### Internal Boundaries

| Boundary | Communication | Notes |
|----------|---------------|-------|
| [module A ↔ module B] | [API/events/direct] | [considerations] |

## Sources

- [Architecture references]
- [Official documentation]
- [Case studies]

---
*Architecture research for: [domain]*
*Researched: [date]*
```

</template>

<guidelines>

**System Overview:**
- Use ASCII box-drawing diagrams for clarity (├── └── │ ─ for structure visualization only)
- Show major components and their relationships
- Don't over-detail — this is conceptual, not implementation

**Project Structure:**
- Be specific about folder organization
- Explain the rationale for grouping
- Match conventions of the chosen stack

**Patterns:**
- Include code examples where helpful
- Explain trade-offs honestly
- Note when patterns are overkill for small projects

**Scaling Considerations:**
- Be realistic — most projects don't need to scale to millions
- Focus on "what breaks first" not theoretical limits
- Avoid premature optimization recommendations

**Anti-Patterns:**
- Specific to this domain
- Include what to do instead
- Helps prevent common mistakes during implementation

</guidelines>

</document_content>
</document>
<document index="72">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\research-project\FEATURES.md</source>
<document_content>
# Features Research Template

Template for `.planning/research/FEATURES.md` — feature landscape for the project domain.

<template>

```markdown
# Feature Research

**Domain:** [domain type]
**Researched:** [date]
**Confidence:** [HIGH/MEDIUM/LOW]

## Feature Landscape

### Table Stakes (Users Expect These)

Features users assume exist. Missing these = product feels incomplete.

| Feature | Why Expected | Complexity | Notes |
|---------|--------------|------------|-------|
| [feature] | [user expectation] | LOW/MEDIUM/HIGH | [implementation notes] |
| [feature] | [user expectation] | LOW/MEDIUM/HIGH | [implementation notes] |
| [feature] | [user expectation] | LOW/MEDIUM/HIGH | [implementation notes] |

### Differentiators (Competitive Advantage)

Features that set the product apart. Not required, but valuable.

| Feature | Value Proposition | Complexity | Notes |
|---------|-------------------|------------|-------|
| [feature] | [why it matters] | LOW/MEDIUM/HIGH | [implementation notes] |
| [feature] | [why it matters] | LOW/MEDIUM/HIGH | [implementation notes] |
| [feature] | [why it matters] | LOW/MEDIUM/HIGH | [implementation notes] |

### Anti-Features (Commonly Requested, Often Problematic)

Features that seem good but create problems.

| Feature | Why Requested | Why Problematic | Alternative |
|---------|---------------|-----------------|-------------|
| [feature] | [surface appeal] | [actual problems] | [better approach] |
| [feature] | [surface appeal] | [actual problems] | [better approach] |

## Feature Dependencies

```
[Feature A]
    └──requires──> [Feature B]
                       └──requires──> [Feature C]

[Feature D] ──enhances──> [Feature A]

[Feature E] ──conflicts──> [Feature F]
```

### Dependency Notes

- **[Feature A] requires [Feature B]:** [why the dependency exists]
- **[Feature D] enhances [Feature A]:** [how they work together]
- **[Feature E] conflicts with [Feature F]:** [why they're incompatible]

## MVP Definition

### Launch With (v1)

Minimum viable product — what's needed to validate the concept.

- [ ] [Feature] — [why essential]
- [ ] [Feature] — [why essential]
- [ ] [Feature] — [why essential]

### Add After Validation (v1.x)

Features to add once core is working.

- [ ] [Feature] — [trigger for adding]
- [ ] [Feature] — [trigger for adding]

### Future Consideration (v2+)

Features to defer until product-market fit is established.

- [ ] [Feature] — [why defer]
- [ ] [Feature] — [why defer]

## Feature Prioritization Matrix

| Feature | User Value | Implementation Cost | Priority |
|---------|------------|---------------------|----------|
| [feature] | HIGH/MEDIUM/LOW | HIGH/MEDIUM/LOW | P1/P2/P3 |
| [feature] | HIGH/MEDIUM/LOW | HIGH/MEDIUM/LOW | P1/P2/P3 |
| [feature] | HIGH/MEDIUM/LOW | HIGH/MEDIUM/LOW | P1/P2/P3 |

**Priority key:**
- P1: Must have for launch
- P2: Should have, add when possible
- P3: Nice to have, future consideration

## Competitor Feature Analysis

| Feature | Competitor A | Competitor B | Our Approach |
|---------|--------------|--------------|--------------|
| [feature] | [how they do it] | [how they do it] | [our plan] |
| [feature] | [how they do it] | [how they do it] | [our plan] |

## Sources

- [Competitor products analyzed]
- [User research or feedback sources]
- [Industry standards referenced]

---
*Feature research for: [domain]*
*Researched: [date]*
```

</template>

<guidelines>

**Table Stakes:**
- These are non-negotiable for launch
- Users don't give credit for having them, but penalize for missing them
- Example: A community platform without user profiles is broken

**Differentiators:**
- These are where you compete
- Should align with the Core Value from PROJECT.md
- Don't try to differentiate on everything

**Anti-Features:**
- Prevent scope creep by documenting what seems good but isn't
- Include the alternative approach
- Example: "Real-time everything" often creates complexity without value

**Feature Dependencies:**
- Critical for roadmap phase ordering
- If A requires B, B must be in an earlier phase
- Conflicts inform what NOT to combine in same phase

**MVP Definition:**
- Be ruthless about what's truly minimum
- "Nice to have" is not MVP
- Launch with less, validate, then expand

</guidelines>

</document_content>
</document>
<document index="73">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\research-project\PITFALLS.md</source>
<document_content>
# Pitfalls Research Template

Template for `.planning/research/PITFALLS.md` — common mistakes to avoid in the project domain.

<template>

```markdown
# Pitfalls Research

**Domain:** [domain type]
**Researched:** [date]
**Confidence:** [HIGH/MEDIUM/LOW]

## Critical Pitfalls

### Pitfall 1: [Name]

**What goes wrong:**
[Description of the failure mode]

**Why it happens:**
[Root cause — why developers make this mistake]

**How to avoid:**
[Specific prevention strategy]

**Warning signs:**
[How to detect this early before it becomes a problem]

**Phase to address:**
[Which roadmap phase should prevent this]

---

### Pitfall 2: [Name]

**What goes wrong:**
[Description of the failure mode]

**Why it happens:**
[Root cause — why developers make this mistake]

**How to avoid:**
[Specific prevention strategy]

**Warning signs:**
[How to detect this early before it becomes a problem]

**Phase to address:**
[Which roadmap phase should prevent this]

---

### Pitfall 3: [Name]

**What goes wrong:**
[Description of the failure mode]

**Why it happens:**
[Root cause — why developers make this mistake]

**How to avoid:**
[Specific prevention strategy]

**Warning signs:**
[How to detect this early before it becomes a problem]

**Phase to address:**
[Which roadmap phase should prevent this]

---

[Continue for all critical pitfalls...]

## Technical Debt Patterns

Shortcuts that seem reasonable but create long-term problems.

| Shortcut | Immediate Benefit | Long-term Cost | When Acceptable |
|----------|-------------------|----------------|-----------------|
| [shortcut] | [benefit] | [cost] | [conditions, or "never"] |
| [shortcut] | [benefit] | [cost] | [conditions, or "never"] |
| [shortcut] | [benefit] | [cost] | [conditions, or "never"] |

## Integration Gotchas

Common mistakes when connecting to external services.

| Integration | Common Mistake | Correct Approach |
|-------------|----------------|------------------|
| [service] | [what people do wrong] | [what to do instead] |
| [service] | [what people do wrong] | [what to do instead] |
| [service] | [what people do wrong] | [what to do instead] |

## Performance Traps

Patterns that work at small scale but fail as usage grows.

| Trap | Symptoms | Prevention | When It Breaks |
|------|----------|------------|----------------|
| [trap] | [how you notice] | [how to avoid] | [scale threshold] |
| [trap] | [how you notice] | [how to avoid] | [scale threshold] |
| [trap] | [how you notice] | [how to avoid] | [scale threshold] |

## Security Mistakes

Domain-specific security issues beyond general web security.

| Mistake | Risk | Prevention |
|---------|------|------------|
| [mistake] | [what could happen] | [how to avoid] |
| [mistake] | [what could happen] | [how to avoid] |
| [mistake] | [what could happen] | [how to avoid] |

## UX Pitfalls

Common user experience mistakes in this domain.

| Pitfall | User Impact | Better Approach |
|---------|-------------|-----------------|
| [pitfall] | [how users suffer] | [what to do instead] |
| [pitfall] | [how users suffer] | [what to do instead] |
| [pitfall] | [how users suffer] | [what to do instead] |

## "Looks Done But Isn't" Checklist

Things that appear complete but are missing critical pieces.

- [ ] **[Feature]:** Often missing [thing] — verify [check]
- [ ] **[Feature]:** Often missing [thing] — verify [check]
- [ ] **[Feature]:** Often missing [thing] — verify [check]
- [ ] **[Feature]:** Often missing [thing] — verify [check]

## Recovery Strategies

When pitfalls occur despite prevention, how to recover.

| Pitfall | Recovery Cost | Recovery Steps |
|---------|---------------|----------------|
| [pitfall] | LOW/MEDIUM/HIGH | [what to do] |
| [pitfall] | LOW/MEDIUM/HIGH | [what to do] |
| [pitfall] | LOW/MEDIUM/HIGH | [what to do] |

## Pitfall-to-Phase Mapping

How roadmap phases should address these pitfalls.

| Pitfall | Prevention Phase | Verification |
|---------|------------------|--------------|
| [pitfall] | Phase [X] | [how to verify prevention worked] |
| [pitfall] | Phase [X] | [how to verify prevention worked] |
| [pitfall] | Phase [X] | [how to verify prevention worked] |

## Sources

- [Post-mortems referenced]
- [Community discussions]
- [Official "gotchas" documentation]
- [Personal experience / known issues]

---
*Pitfalls research for: [domain]*
*Researched: [date]*
```

</template>

<guidelines>

**Critical Pitfalls:**
- Focus on domain-specific issues, not generic mistakes
- Include warning signs — early detection prevents disasters
- Link to specific phases — makes pitfalls actionable

**Technical Debt:**
- Be realistic — some shortcuts are acceptable
- Note when shortcuts are "never acceptable" vs. "only in MVP"
- Include the long-term cost to inform tradeoff decisions

**Performance Traps:**
- Include scale thresholds ("breaks at 10k users")
- Focus on what's relevant for this project's expected scale
- Don't over-engineer for hypothetical scale

**Security Mistakes:**
- Beyond OWASP basics — domain-specific issues
- Example: Community platforms have different security concerns than e-commerce
- Include risk level to prioritize

**"Looks Done But Isn't":**
- Checklist format for verification during execution
- Common in demos vs. production
- Prevents "it works on my machine" issues

**Pitfall-to-Phase Mapping:**
- Critical for roadmap creation
- Each pitfall should map to a phase that prevents it
- Informs phase ordering and success criteria

</guidelines>

</document_content>
</document>
<document index="74">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\research-project\STACK.md</source>
<document_content>
# Stack Research Template

Template for `.planning/research/STACK.md` — recommended technologies for the project domain.

<template>

```markdown
# Stack Research

**Domain:** [domain type]
**Researched:** [date]
**Confidence:** [HIGH/MEDIUM/LOW]

## Recommended Stack

### Core Technologies

| Technology | Version | Purpose | Why Recommended |
|------------|---------|---------|-----------------|
| [name] | [version] | [what it does] | [why experts use it for this domain] |
| [name] | [version] | [what it does] | [why experts use it for this domain] |
| [name] | [version] | [what it does] | [why experts use it for this domain] |

### Supporting Libraries

| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| [name] | [version] | [what it does] | [specific use case] |
| [name] | [version] | [what it does] | [specific use case] |
| [name] | [version] | [what it does] | [specific use case] |

### Development Tools

| Tool | Purpose | Notes |
|------|---------|-------|
| [name] | [what it does] | [configuration tips] |
| [name] | [what it does] | [configuration tips] |

## Installation

```bash
# Core
npm install [packages]

# Supporting
npm install [packages]

# Dev dependencies
npm install -D [packages]
```

## Alternatives Considered

| Recommended | Alternative | When to Use Alternative |
|-------------|-------------|-------------------------|
| [our choice] | [other option] | [conditions where alternative is better] |
| [our choice] | [other option] | [conditions where alternative is better] |

## What NOT to Use

| Avoid | Why | Use Instead |
|-------|-----|-------------|
| [technology] | [specific problem] | [recommended alternative] |
| [technology] | [specific problem] | [recommended alternative] |

## Stack Patterns by Variant

**If [condition]:**
- Use [variation]
- Because [reason]

**If [condition]:**
- Use [variation]
- Because [reason]

## Version Compatibility

| Package A | Compatible With | Notes |
|-----------|-----------------|-------|
| [package@version] | [package@version] | [compatibility notes] |

## Sources

- [Context7 library ID] — [topics fetched]
- [Official docs URL] — [what was verified]
- [Other source] — [confidence level]

---
*Stack research for: [domain]*
*Researched: [date]*
```

</template>

<guidelines>

**Core Technologies:**
- Include specific version numbers
- Explain why this is the standard choice, not just what it does
- Focus on technologies that affect architecture decisions

**Supporting Libraries:**
- Include libraries commonly needed for this domain
- Note when each is needed (not all projects need all libraries)

**Alternatives:**
- Don't just dismiss alternatives
- Explain when alternatives make sense
- Helps user make informed decisions if they disagree

**What NOT to Use:**
- Actively warn against outdated or problematic choices
- Explain the specific problem, not just "it's old"
- Provide the recommended alternative

**Version Compatibility:**
- Note any known compatibility issues
- Critical for avoiding debugging time later

</guidelines>

</document_content>
</document>
<document index="75">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\research-project\SUMMARY.md</source>
<document_content>
# Research Summary Template

Template for `.planning/research/SUMMARY.md` — executive summary of project research with roadmap implications.

<template>

```markdown
# Project Research Summary

**Project:** [name from PROJECT.md]
**Domain:** [inferred domain type]
**Researched:** [date]
**Confidence:** [HIGH/MEDIUM/LOW]

## Executive Summary

[2-3 paragraph overview of research findings]

- What type of product this is and how experts build it
- The recommended approach based on research
- Key risks and how to mitigate them

## Key Findings

### Recommended Stack

[Summary from STACK.md — 1-2 paragraphs]

**Core technologies:**
- [Technology]: [purpose] — [why recommended]
- [Technology]: [purpose] — [why recommended]
- [Technology]: [purpose] — [why recommended]

### Expected Features

[Summary from FEATURES.md]

**Must have (table stakes):**
- [Feature] — users expect this
- [Feature] — users expect this

**Should have (competitive):**
- [Feature] — differentiator
- [Feature] — differentiator

**Defer (v2+):**
- [Feature] — not essential for launch

### Architecture Approach

[Summary from ARCHITECTURE.md — 1 paragraph]

**Major components:**
1. [Component] — [responsibility]
2. [Component] — [responsibility]
3. [Component] — [responsibility]

### Critical Pitfalls

[Top 3-5 from PITFALLS.md]

1. **[Pitfall]** — [how to avoid]
2. **[Pitfall]** — [how to avoid]
3. **[Pitfall]** — [how to avoid]

## Implications for Roadmap

Based on research, suggested phase structure:

### Phase 1: [Name]
**Rationale:** [why this comes first based on research]
**Delivers:** [what this phase produces]
**Addresses:** [features from FEATURES.md]
**Avoids:** [pitfall from PITFALLS.md]

### Phase 2: [Name]
**Rationale:** [why this order]
**Delivers:** [what this phase produces]
**Uses:** [stack elements from STACK.md]
**Implements:** [architecture component]

### Phase 3: [Name]
**Rationale:** [why this order]
**Delivers:** [what this phase produces]

[Continue for suggested phases...]

### Phase Ordering Rationale

- [Why this order based on dependencies discovered]
- [Why this grouping based on architecture patterns]
- [How this avoids pitfalls from research]

### Research Flags

Phases likely needing deeper research during planning:
- **Phase [X]:** [reason — e.g., "complex integration, needs API research"]
- **Phase [Y]:** [reason — e.g., "niche domain, sparse documentation"]

Phases with standard patterns (skip research-phase):
- **Phase [X]:** [reason — e.g., "well-documented, established patterns"]

## Confidence Assessment

| Area | Confidence | Notes |
|------|------------|-------|
| Stack | [HIGH/MEDIUM/LOW] | [reason] |
| Features | [HIGH/MEDIUM/LOW] | [reason] |
| Architecture | [HIGH/MEDIUM/LOW] | [reason] |
| Pitfalls | [HIGH/MEDIUM/LOW] | [reason] |

**Overall confidence:** [HIGH/MEDIUM/LOW]

### Gaps to Address

[Any areas where research was inconclusive or needs validation during implementation]

- [Gap]: [how to handle during planning/execution]
- [Gap]: [how to handle during planning/execution]

## Sources

### Primary (HIGH confidence)
- [Context7 library ID] — [topics]
- [Official docs URL] — [what was checked]

### Secondary (MEDIUM confidence)
- [Source] — [finding]

### Tertiary (LOW confidence)
- [Source] — [finding, needs validation]

---
*Research completed: [date]*
*Ready for roadmap: yes*
```

</template>

<guidelines>

**Executive Summary:**
- Write for someone who will only read this section
- Include the key recommendation and main risk
- 2-3 paragraphs maximum

**Key Findings:**
- Summarize, don't duplicate full documents
- Link to detailed docs (STACK.md, FEATURES.md, etc.)
- Focus on what matters for roadmap decisions

**Implications for Roadmap:**
- This is the most important section
- Directly informs roadmap creation
- Be explicit about phase suggestions and rationale
- Include research flags for each suggested phase

**Confidence Assessment:**
- Be honest about uncertainty
- Note gaps that need resolution during planning
- HIGH = verified with official sources
- MEDIUM = community consensus, multiple sources agree
- LOW = single source or inference

**Integration with roadmap creation:**
- This file is loaded as context during roadmap creation
- Phase suggestions here become starting point for roadmap
- Research flags inform phase planning

</guidelines>

</document_content>
</document>
<document index="76">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\thinking\COMPREHENSIVE.yaml</source>
<document_content>
# COMPREHENSIVE Thinking Template
# Use for: Complex debugging, architecture design, multi-phase integration
# Complexity: 13+

mode: COMPREHENSIVE
servers:
  - sequential
  - tractatus
  - debug
bmad_enabled: true
timeout: 9000
max_thoughts: 10

rationale_template: "Complex operation requiring step sequencing (Sequential), structural analysis (Tractatus), and problem-solving (Debug)"

selection_rules:
  - command_type: complex
    keywords:
      - debug
      - troubleshoot
      - integrate
      - migrate
      - refactor
  - tool_count: 11+
  - process_steps: 8+

complexity_indicators:
  min_score: 13
  max_score: 100
  factors:
    - name: debug_keywords
      keywords:
        - debug
        - troubleshoot
        - fix
        - resolve
      score: 4
    - name: complex_integration
      keywords:
        - integrate
        - migrate
        - refactor
        - architect
      score: 4
    - name: multi_phase
      condition: "Operation spans multiple phases or components"
      score: 3
    - name: critical_path
      keywords:
        - critical
        - breaking
        - production
        - urgent
      score: 3
    - name: subagent_delegation
      condition: "Command spawns multiple subagents"
      score: 3

server_config:
  sequential:
    enabled: true
    priority: 1
    max_thoughts: 10
    focus_areas:
      - complex-planning
      - multi-step-sequencing
      - dependency-graphs
    prompt_template: |
      Analyze the command for complex multi-step planning.
      Command: {command}
      Description: {description}
      Objective: {objective}
      Context: {context}
      
      Provide up to {max_thoughts} thoughts on execution strategy and dependencies.

  tractatus:
    enabled: true
    priority: 2
    max_thoughts: 10
    focus_areas:
      - deep-structural-analysis
      - logical-foundations
      - system-architecture
    prompt_template: |
      Perform deep structural analysis of the command context.
      Command: {command}
      Description: {description}
      
      Analyze logical foundations and system architecture implications.

  debug:
    enabled: true
    priority: 3
    max_thoughts: 10
    focus_areas:
      - problem-isolation
      - hypothesis-testing
      - root-cause-analysis
    prompt_template: |
      Analyze for potential issues and problem-solving strategies.
      Command: {command}
      Description: {description}
      Symptoms: {symptoms}
      
      Generate hypotheses and verification strategies.

parallel_execution:
  enabled: true
  strategy: parallel
  merge_strategy: consensus
  timeout_per_server: 5000

bmad_integration:
  enabled: true
  circles:
    - method    # Implementation correctness
    - mad       # Integration completeness
    - model     # Architecture alignment
    - mode      # Pattern consistency
    - mod       # Maintainability standards
    - modd      # Extensibility verification
    - methodd   # Documentation quality
  verification_gates: true

error_handling:
  retry_count: 3
  fallback_mode: STANDARD
  partial_results: true

examples:
  - command: "gsi debug --complex \"Production issue\""
    complexity: 15
    rationale: "Complex debugging requiring all three thinking servers"
    thinking_phase:
      mode: COMPREHENSIVE
      servers: [sequential, tractatus, debug]
      bmad_enabled: true
      timeout: 12000
      
  - command: "gsi new-project --comprehensive"
    complexity: 14
    rationale: "Comprehensive project setup requiring architecture analysis"
    thinking_phase:
      mode: COMPREHENSIVE
      servers: [sequential, tractatus, debug]
      bmad_enabled: true
      timeout: 10000
      
  - command: "gsi verify-work 20 --deep"
    complexity: 13
    rationale: "Deep verification requiring thorough analysis"
    thinking_phase:
      mode: COMPREHENSIVE
      servers: [sequential, tractatus, debug]
      bmad_enabled: true
      timeout: 9000

</document_content>
</document>
<document index="77">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\thinking\LIGHTWEIGHT.yaml</source>
<document_content>
# LIGHTWEIGHT Thinking Template
# Use for: Quick operations, single-step modifications, simple queries
# Complexity: 3-6

mode: LIGHTWEIGHT
servers:
  - sequential
bmad_enabled: false
timeout: 2000
max_thoughts: 3

rationale_template: "Quick operation requiring basic step planning (Sequential)"

selection_rules:
  - command_type: simple_operation
    keywords:
      - add
      - update
      - remove
      - set
      - toggle
  - tool_count: 3-5
  - process_steps: 2-3

complexity_indicators:
  min_score: 3
  max_score: 6
  factors:
    - name: simple_modification
      keywords:
        - add
        - update
        - remove
        - modify
      score: 2
    - name: single_target
      condition: "Operation targets single file or entity"
      score: 1
    - name: quick_keywords
      keywords:
        - quick
        - simple
        - fast
      score: -1

server_config:
  sequential:
    enabled: true
    priority: 1
    max_thoughts: 3
    focus_areas:
      - step-ordering
      - basic-planning
    prompt_template: |
      Analyze the command for basic step sequencing.
      Command: {command}
      Description: {description}
      
      Provide up to {max_thoughts} thoughts on execution order.

examples:
  - command: "gsi add-phase 25 \"New feature\""
    complexity: 4
    rationale: "Single operation to add a new phase"
  - command: "gsi set-profile quick"
    complexity: 3
    rationale: "Quick configuration change"
  - command: "gsi add-todo \"Fix bug\""
    complexity: 3
    rationale: "Single todo item creation"

</document_content>
</document>
<document index="78">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\thinking\NONE.yaml</source>
<document_content>
# NONE Thinking Template
# Use for: Simple display commands, status checks, quick lookups
# Complexity: 0-2

mode: NONE
servers: []
bmad_enabled: false
timeout: 0
max_thoughts: 0

rationale_template: "Simple operation requiring no thinking assistance"

selection_rules:
  - command_type: display
    keywords:
      - show
      - display
      - list
      - get
      - status
      - help
  - tool_count: 0-2
  - process_steps: 0-1

complexity_indicators:
  max_score: 2
  factors:
    - name: simple_keywords
      keywords:
        - quick
        - simple
        - display
        - status
        - list
      score: -2
    - name: no_execution_tools
      condition: "No Bash, process, or execute tools"
      score: -1

examples:
  - command: "gsi help"
    complexity: 0
    rationale: "Display command reference"
  - command: "gsi progress"
    complexity: 1
    rationale: "Display progress bar"
  - command: "gsi state get"
    complexity: 1
    rationale: "Display state information"

</document_content>
</document>
<document index="79">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\templates\thinking\STANDARD.yaml</source>
<document_content>
# STANDARD Thinking Template
# Use for: Planning operations, multi-step workflows, code analysis
# Complexity: 7-12

mode: STANDARD
servers:
  - sequential
  - tractatus
bmad_enabled: true
timeout: 5000
max_thoughts: 5

rationale_template: "Planning task requiring step sequencing (Sequential) and structural analysis (Tractatus)"

selection_rules:
  - command_type: planning
    keywords:
      - plan
      - execute
      - research
      - analyze
      - verify
  - tool_count: 6-10
  - process_steps: 4-7

complexity_indicators:
  min_score: 7
  max_score: 12
  factors:
    - name: planning_keywords
      keywords:
        - plan
        - design
        - architect
        - analyze
      score: 3
    - name: multi_step
      condition: "Multiple sequential steps required"
      score: 2
    - name: file_modification
      keywords:
        - write
        - edit
        - create
        - modify
      score: 2
    - name: code_analysis
      keywords:
        - analyze
        - review
        - understand
        - investigate
      score: 2

server_config:
  sequential:
    enabled: true
    priority: 1
    max_thoughts: 5
    focus_areas:
      - step-planning
      - execution-order
      - dependency-resolution
    prompt_template: |
      Analyze the command for step sequencing and dependencies.
      Command: {command}
      Description: {description}
      Objective: {objective}
      
      Provide up to {max_thoughts} thoughts on execution order and dependencies.

  tractatus:
    enabled: true
    priority: 2
    max_thoughts: 5
    focus_areas:
      - structural-analysis
      - logical-dependencies
      - architecture
    prompt_template: |
      Analyze the command for structural relationships and logical dependencies.
      Command: {command}
      Description: {description}
      
      Provide up to {max_thoughts} thoughts on structure and relationships.

bmad_integration:
  enabled: true
  circles:
    - method  # Implementation correctness
    - mad     # Integration completeness
    - model   # Architecture alignment
    - mode    # Pattern consistency

examples:
  - command: "gsi plan-phase 20"
    complexity: 8
    rationale: "Planning operation requiring step sequencing and structural analysis"
    thinking_phase:
      mode: STANDARD
      servers: [sequential, tractatus]
      bmad_enabled: true
      timeout: 7000
  - command: "gsi execute-phase 20-01"
    complexity: 10
    rationale: "Execution requiring dependency resolution and verification"
    thinking_phase:
      mode: STANDARD
      servers: [sequential, tractatus]
      bmad_enabled: true
      timeout: 8000
  - command: "gsi research-phase 21"
    complexity: 7
    rationale: "Research requiring analysis and documentation"
    thinking_phase:
      mode: STANDARD
      servers: [sequential, tractatus]
      bmad_enabled: true
      timeout: 6000

</document_content>
</document>
<document index="80">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflow-templates\full-cycle.json</source>
<document_content>
{
  "name": "full-cycle",
  "description": "Research -> Plan -> Execute -> Verify - Complete development cycle",
  "chain": [
    {
      "command": "gsi:research-phase",
      "args": "${phase}",
      "description": "Research phase requirements and context"
    },
    {
      "command": "gsi:plan-phase",
      "args": "${phase}",
      "description": "Create detailed execution plan"
    },
    {
      "command": "gsi:execute-phase",
      "args": "${phase}",
      "description": "Execute the plan and implement changes"
    },
    {
      "command": "gsi:verify-work",
      "args": "${phase}",
      "description": "Verify implementation meets requirements"
    }
  ],
  "checkpoint": "after-each",
  "rollback": true,
  "metadata": {
    "category": "development",
    "estimated_duration": "2-4 hours",
    "use_case": "Use for new features or significant changes requiring full analysis"
  }
}

</document_content>
</document>
<document index="81">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflow-templates\milestone-complete.json</source>
<document_content>
{
  "name": "milestone-complete",
  "description": "Complete current milestone and prepare next milestone",
  "chain": [
    {
      "command": "gsi:audit-milestone",
      "description": "Audit milestone for completeness"
    },
    {
      "command": "gsi:verify-work",
      "args": "--all",
      "description": "Verify all phases are complete"
    },
    {
      "command": "gsi:complete-milestone",
      "description": "Archive current milestone"
    },
    {
      "command": "gsi:new-milestone",
      "description": "Create next milestone"
    }
  ],
  "checkpoint": "manual",
  "rollback": true,
  "dependencies": {
    "gsi:complete-milestone": ["gsi:verify-work"],
    "gsi:new-milestone": ["gsi:complete-milestone"]
  },
  "metadata": {
    "category": "milestone",
    "estimated_duration": "1-2 hours",
    "use_case": "Use when finishing a milestone and preparing for the next"
  }
}

</document_content>
</document>
<document index="82">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflow-templates\project-setup.json</source>
<document_content>
{
  "name": "project-setup",
  "description": "Initialize new project with all phases and initial configuration",
  "chain": [
    {
      "command": "gsi:new-project",
      "description": "Initialize project structure and configuration"
    },
    {
      "command": "gsi:map-codebase",
      "description": "Analyze and document existing codebase"
    },
    {
      "command": "gsi:add-phase",
      "args": "\"Foundation\"",
      "description": "Create first foundation phase"
    },
    {
      "command": "gsi:plan-phase",
      "args": "01",
      "description": "Plan foundation phase implementation"
    }
  ],
  "parallel": [
    {
      "name": "status-check",
      "steps": [
        {
          "command": "gsi:check-todos",
          "description": "Check todo status"
        },
        {
          "command": "gsi:progress",
          "description": "Show project progress"
        }
      ]
    }
  ],
  "checkpoint": "after-phase",
  "rollback": false,
  "metadata": {
    "category": "setup",
    "estimated_duration": "1-2 hours",
    "use_case": "Use when starting a new GSI-managed project"
  }
}

</document_content>
</document>
<document index="83">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflow-templates\quick-fix.json</source>
<document_content>
{
  "name": "quick-fix",
  "description": "Plan -> Execute -> Verify - Quick fix cycle skipping research",
  "chain": [
    {
      "command": "gsi:plan-phase",
      "args": "${phase} --skip-research",
      "description": "Create execution plan (research skipped)"
    },
    {
      "command": "gsi:execute-phase",
      "args": "${phase}",
      "description": "Execute the fix"
    },
    {
      "command": "gsi:verify-work",
      "args": "${phase}",
      "description": "Verify the fix works correctly"
    }
  ],
  "checkpoint": "before-execute",
  "rollback": true,
  "metadata": {
    "category": "bugfix",
    "estimated_duration": "30-60 minutes",
    "use_case": "Use for simple fixes where requirements are already known"
  }
}

</document_content>
</document>
<document index="84">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflow-templates\discovered\README.md</source>
<document_content>
# Discovered Workflow Templates

This directory contains workflow templates that were automatically discovered from command history patterns.

## How Templates are Generated

1. **Usage Tracking**: The system tracks all GSI command executions and sequences
2. **Pattern Mining**: Common command sequences are identified and analyzed
3. **Scoring**: Patterns are scored based on:
   - Frequency (how often the sequence occurs)
   - Success rate (percentage of successful executions)
   - Time savings (potential efficiency gains)
   - Quality score (combined metric)
4. **Template Generation**: High-quality patterns are converted to reusable templates

## Template Format

Each template is a JSON file following the WorkflowChain format:

```json
{
  "name": "pattern-name",
  "description": "Discovered pattern: command sequence",
  "chain": [
    { "command": "gsi:command1", "args": "${phase}", "checkpoint": true },
    { "command": "gsi:command2", "args": "${phase}" }
  ],
  "checkpoint": "after-each",
  "rollback": true,
  "metadata": {
    "pattern_id": "pattern-abc123",
    "frequency": 10,
    "success_rate": 0.95,
    "quality_score": 85,
    "discovered_at": "2025-02-18T...",
    "auto_generated": true
  }
}
```

## Using Discovered Templates

```bash
# List all templates (including discovered)
gsi workflow list

# Run a discovered template
gsi workflow run discovered/pattern-name --vars '{"phase": "01"}'
```

## Managing Templates

```bash
# Discover new patterns
gsi workflow discover --min-frequency 2 --min-quality 50

# Get recommendations for current context
gsi workflow recommend

# Export a pattern as a template
gsi workflow export pattern-abc123
```

## Directory Structure

```
discovered/
├── README.md (this file)
├── .gitkeep
└── pattern-*.json (auto-generated templates)
```

## Notes

- Templates in this directory are auto-generated and may be overwritten during pattern discovery
- To preserve a discovered template, copy it to the parent `workflow-templates/` directory
- Quality scores range from 0-100, with higher scores indicating more reliable patterns
- Templates with success rates below 50% are not generated

</document_content>
</document>
<document index="85">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\add-phase.md</source>
<document_content>
﻿<thinking>auto</thinking>

<purpose>
Add a new integer phase to the end of the current milestone in the roadmap. Automatically calculates the next phase number, creates the phase directory, and updates the roadmap structure.
</purpose>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "list_directory", "create_directory"]
  priority: 1
  rationale: "Primary workflow for reading roadmap, writing phase files, creating directories, and listing contents"
code_index:
  tools: ["find_files"]
  priority: 2
  rationale: "Secondary use for discovering existing phase files and planning documents"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<required_reading>
Read all files referenced by the invoking prompt's execution_context before starting.
</required_reading>

<process>

<step name="parse_arguments">
Parse the command arguments:
- All arguments become the phase description
- Example: `/GSI:add-phase Add authentication` → description = "Add authentication"
- Example: `/GSI:add-phase Fix critical performance issues` → description = "Fix critical performance issues"

If no arguments are provided:

```
ERROR: Phase description required
Usage: /GSI:add-phase <description>
Example: /GSI:add-phase Add authentication system
```

Exit.
</step>

<step name="init_context">
Load the phase operation context using MCP tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const INIT = await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js init phase-op \"0\"",
  timeout_ms: 10000
});
```

Check `roadmap_exists` from the init JSON. If false:
```
ERROR: No roadmap found (.planning/ROADMAP.md)
Run /GSI:new-project to initialize.
```
Exit.
</step>

<step name="add_phase">
**Delegate the phase addition to GSI-tools:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const RESULT = await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js phase add "${description}"`,
  timeout_ms: 15000
});
```

The CLI handles:
- Finding the highest existing integer phase number
- Calculating the next phase number (max + 1)
- Generating a slug from the description
- Creating the phase directory (`.planning/phases/{NN}-{slug}/`)
- Inserting the phase entry into ROADMAP.md with Goal, Depends on, and Plans sections

Extract from the result: `phase_number`, `padded`, `name`, `slug`, `directory`.
</step>

<step name="update_project_state">
Update STATE.md to reflect the new phase.

**Use MCP tool: mcp__desktop-commander__read_file**

```javascript
// Read current STATE.md
const stateContent = await mcp__desktop-commander__read_file({
  path: ".planning/STATE.md"
});
```

**Use MCP tool: mcp__desktop-commander__edit_block**

Then update the "## Accumulated Context" → "### Roadmap Evolution" section:
   ```
   - Phase {N} added: {description}
   ```

If the "Roadmap Evolution" section doesn't exist, create it.
</step>

<step name="completion">
Present the completion summary:

```
Phase {N} added to the current milestone:
- Description: {description}
- Directory: .planning/phases/{phase-num}-{slug}/
- Status: Not planned yet

Roadmap updated: .planning/ROADMAP.md

---

## ▶ Next Up

**Phase {N}: {description}**

`/GSI:plan-phase {N}`

<sub>`/clear` first → fresh context window</sub>

---

**Also available:**
- `/GSI:add-phase <description>` — add another phase
- Review the roadmap

---
```
</step>

</process>

<success_criteria>
- [ ] `GSI-tools phase add` executed successfully
- [ ] Phase directory created
- [ ] Roadmap updated with the new phase entry
- [ ] STATE.md updated with the roadmap evolution note
- [ ] User informed of the next steps
</success_criteria>

</document_content>
</document>
<document index="86">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\add-todo.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file"]
  priority: 1
  rationale: "Primary workflow for reading and writing todo files"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Capture an idea, task, or issue that surfaces during a GSI session as a structured todo for later work. Enables "thought → capture → continue" flow without losing context.
</purpose>

<required_reading>
Read all files referenced by the invoking prompt's execution_context before starting.
</required_reading>

<process>

<step name="init_context">
Load the todo context using MCP tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const INIT = await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js init todos",
  timeout_ms: 10000
});
```

Extract from the init JSON: `commit_docs`, `date`, `timestamp`, `todo_count`, `todos`, `pending_dir`, `todos_dir_exists`.

**Use MCP tool: mcp__desktop-commander__list_directory** to ensure directories exist:

```javascript
// MCP-based equivalent for checking directory structure
const pendingDir = await mcp__desktop-commander__list_directory({
  path: ".planning/todos/pending",
  depth: 1
});

const doneDir = await mcp__desktop-commander__list_directory({
  path: ".planning/todos/done",
  depth: 1
});

// Create directories if needed using MCP tool
if (!pendingDir.ok) {
  await mcp__desktop-commander__create_directory({
    path: ".planning/todos/pending"
  });
}
if (!doneDir.ok) {
  await mcp__desktop-commander__create_directory({
    path: ".planning/todos/done"
  });
}
```

Note existing areas from the todos array for consistency in the infer_area step.
</step>

<step name="extract_content">
**With arguments:** Use as the title/focus.
- `/GSI:add-todo Add auth token refresh` → title = "Add auth token refresh"

**Without arguments:** Analyze the recent conversation to extract:
- The specific problem, idea, or task discussed
- Relevant file paths mentioned
- Technical details (error messages, line numbers, constraints)

Formulate:
- `title`: 3-10 word descriptive title (action verb preferred)
- `problem`: What's wrong or why this is needed
- `solution`: Approach hints or "TBD" if just an idea
- `files`: Relevant paths with line numbers from conversation
</step>

<step name="infer_area">
Infer the area from file paths:

| Path pattern | Area |
|--------------|------|
| `src/api/*`, `api/*` | `api` |
| `src/components/*`, `src/ui/*` | `ui` |
| `src/auth/*`, `auth/*` | `auth` |
| `src/db/*`, `database/*` | `database` |
| `tests/*`, `__tests__/*` | `testing` |
| `docs/*` | `docs` |
| `.planning/*` | `planning` |
| `scripts/*`, `bin/*` | `tooling` |
| No files or unclear | `general` |

Use existing area from step 2 if a similar match exists.
</step>

<step name="check_duplicates">
**Use MCP tool: mcp__code-index-mcp__search_code_advanced** to search for existing todos

```javascript
// MCP-based equivalent for searching todos (80-90% token savings vs grep)
const results = await mcp__code-index-mcp__search_code_advanced({
  pattern: "[key words from title]",
  path: ".planning/todos/pending",
  filePattern: "*.md",
  contextLines: 2
});
```

If a potential duplicate is found:
1. Read the existing todo using mcp__desktop-commander__read_file
2. Compare the scope

If overlapping, use AskUserQuestion:
- header: "Duplicate?"
- question: "Similar todo exists: [title]. What would you like to do?"
- options:
  - "Skip" — keep the existing todo
  - "Replace" — update the existing with new context
  - "Add anyway" — create as a separate todo
</step>

<step name="create_file">
Use values from init context: `timestamp` and `date` are already available.

Generate a slug for the title using MCP process tool:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
const slug = await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js generate-slug "$title" --raw`,
  timeout_ms: 10000
});
```

**Use MCP tool: mcp__desktop-commander__write_file** to write the todo:

```javascript
// MCP-based equivalent for file writing
await mcp__desktop-commander__write_file({
  path: `.planning/todos/pending/${date}-${slug}.md`,
  content: `---
created: [timestamp]
title: [title]
area: [area]
files:
  - [file:lines]
---

## Problem

[problem description - enough context for future Claude to understand weeks later]

## Solution

[approach hints or "TBD"]
`
});
```
</step>

<step name="update_state">
If `.planning/STATE.md` exists:

1. Use `todo_count` from init context (or re-run `init todos` if count changed)
2. Update "### Pending Todos" under "## Accumulated Context"

**Use MCP tools: mcp__desktop-commander__read_file and mcp__desktop-commander__edit_block**

```javascript
// Read and update STATE.md
const stateContent = await mcp__desktop-commander__read_file({
  path: ".planning/STATE.md"
});

// Use edit_block to update the todo count section
await mcp__desktop-commander__edit_block({
  file_path: ".planning/STATE.md",
  old_string: "### Pending Todos\n[existing content]",
  new_string: "### Pending Todos\n[updated content with new count]"
});
```
</step>

<step name="git_commit">
Commit the todo and any updated state using MCP process tool:

**Use MCP tool: mcp__desktop-commander__start_process**

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs: capture todo - [title]" --files .planning/todos/pending/[filename] .planning/STATE.md
```

Tool respects `commit_docs` config and gitignore automatically.

Confirm: "Committed: docs: capture todo - [title]"
</step>

<step name="confirm">
```
Todo saved: .planning/todos/pending/[filename]

  [title]
  Area: [area]
  Files: [count] referenced

---

Would you like to:

1. Continue with current work
2. Add another todo
3. View all todos (/GSI:check-todos)
```
</step>

</process>

<success_criteria>
- [ ] Directory structure exists
- [ ] Todo file created with valid frontmatter
- [ ] Problem section has enough context for future Claude
- [ ] No duplicates (checked and resolved)
- [ ] Area consistent with existing todos
- [ ] STATE.md updated if exists
- [ ] Todo and state committed to git
</success_criteria>

</document_content>
</document>
<document index="87">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\audit-milestone.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file"]
  priority: 1
  rationale: "Primary workflow for reading and writing audit documents"
code_index:
  tools: ["find_files"]
  priority: 2
  rationale: "Secondary use for discovering phase plans and summaries to audit"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Verify that a milestone achieved its definition of done by aggregating phase verifications, checking cross-phase integration, and assessing requirements coverage. Reads existing VERIFICATION.md files (phases already verified during execute-phase), aggregates tech debt and deferred gaps, then spawns integration checker for cross-phase wiring.
</purpose>

<required_reading>
Read all files referenced by the invoking prompt's execution_context before starting.
</required_reading>

<process>

## 0. Initialize Milestone Context

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const INIT = await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js init milestone-op",
  timeout_ms: 10000
});
```

Extract from the init JSON: `milestone_version`, `milestone_name`, `phase_count`, `completed_phases`, `commit_docs`.

**Resolve integration checker model:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
const CHECKER_MODEL = await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js resolve-model GSI-integration-checker --raw",
  timeout_ms: 10000
});
```

## 1. Determine Milestone Scope

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// Get phases in milestone (sorted numerically, handles decimals)
const phases = await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js phases list",
  timeout_ms: 10000
});
```

- Parse version from arguments or detect current from ROADMAP.md
- Identify all phase directories in scope
- Extract milestone definition of done from ROADMAP.md
- Extract requirements mapped to this milestone from REQUIREMENTS.md

## 2. Read All Phase Verifications

For each phase directory, read VERIFICATION.md using MCP tools:

**Use MCP tool: mcp__desktop-commander__read_file** or **mcp__desktop-commander__read_multiple_files**

```javascript
// MCP-based equivalent for reading multiple files (80-90% token savings vs cat)
const verificationFiles = [
  ".planning/phases/01-*/01-*-VERIFICATION.md",
  ".planning/phases/02-*/02-*-VERIFICATION.md",
  // etc.
];

const verifications = await mcp__desktop-commander__read_multiple_files({
  paths: verificationFiles
});
```

From each VERIFICATION.md, extract:
- **Status:** passed | gaps_found
- **Critical gaps:** (if any — these are blockers)
- **Non-critical gaps:** tech debt, deferred items, warnings
- **Anti-patterns found:** TODOs, stubs, placeholders
- **Requirements coverage:** which requirements satisfied/blocked

If a phase is missing VERIFICATION.md, flag it as "unverified phase" — this is a blocker.

## 3. Spawn Integration Checker

With phase context collected:

```
Task(
  prompt="Check cross-phase integration and E2E flows.

Phases: {phase_dirs}
Phase exports: {from SUMMARYs}
API routes: {routes created}

Verify cross-phase wiring and E2E user flows.",
  subagent_type="GSI-integration-checker",
  model="{integration_checker_model}"
)
```

## 4. Collect Results

Combine:
- Phase-level gaps and tech debt (from step 2)
- Integration checker's report (wiring gaps, broken flows)

## 5. Check Requirements Coverage

For each requirement in REQUIREMENTS.md mapped to this milestone:
- Find owning phase
- Check phase verification status
- Determine: satisfied | partial | unsatisfied

## 6. Aggregate into v{version}-MILESTONE-AUDIT.md

**Use MCP tool: mcp__desktop-commander__write_file** to create the audit:

```javascript
// MCP-based equivalent for file writing
await mcp__desktop-commander__write_file({
  path: `.planning/v{version}-MILESTONE-AUDIT.md`,
  content: `---
milestone: {version}
audited: {timestamp}
status: passed | gaps_found | tech_debt
scores:
  requirements: N/M
  phases: N/M
  integration: N/M
  flows: N/M
gaps:  # Critical blockers
  requirements: [...]
  integration: [...]
  flows: [...]
tech_debt:  # Non-critical, deferred
  - phase: 01-auth
    items:
      - "TODO: add rate limiting"
      - "Warning: no password strength validation"
  - phase: 03-dashboard
    items:
      - "Deferred: mobile responsive layout"
---

[Plus full markdown report with tables for requirements, phases, integration, tech debt]
`
});
```

**Status values:**
- `passed` — all requirements met, no critical gaps, minimal tech debt
- `gaps_found` — critical blockers exist
- `tech_debt` — no blockers but accumulated deferred items need review

## 7. Present Results

Route by status (see `<offer_next>`).

</process>

<offer_next>
Output this markdown directly (not as a code block). Route based on status:

---

**If passed:**

## ✓ Milestone {version} — Audit Passed

**Score:** {N}/{M} requirements satisfied
**Report:** .planning/v{version}-MILESTONE-AUDIT.md

All requirements covered. Cross-phase integration verified. E2E flows complete.

───────────────────────────────────────────────────────────────

## ▶ Next Up

**Complete milestone** — archive and tag

/GSI:complete-milestone {version}

<sub>/clear first → fresh context window</sub>

───────────────────────────────────────────────────────────────

---

**If gaps_found:**

## ⚠ Milestone {version} — Gaps Found

**Score:** {N}/{M} requirements satisfied
**Report:** .planning/v{version}-MILESTONE-AUDIT.md

### Unsatisfied Requirements

{For each unsatisfied requirement:}
- **{REQ-ID}: {description}** (Phase {X})
  - {reason}

### Cross-Phase Issues

{For each integration gap:}
- **{from} → {to}:** {issue}

### Broken Flows

{For each flow gap:}
- **{flow name}:** breaks at {step}

───────────────────────────────────────────────────────────────

## ▶ Next Up

**Plan gap closure** — create phases to complete milestone

/GSI:plan-milestone-gaps

<sub>/clear first → fresh context window</sub>

───────────────────────────────────────────────────────────────

**Also available:**
- **Use MCP tool: mcp__desktop-commander__read_file** to view full report
- /GSI:complete-milestone {version} — proceed anyway (accept tech debt)

───────────────────────────────────────────────────────────────

---

**If tech_debt (no blockers but accumulated debt):**

## ⚡ Milestone {version} — Tech Debt Review

**Score:** {N}/{M} requirements satisfied
**Report:** .planning/v{version}-MILESTONE-AUDIT.md

All requirements met. No critical blockers. Accumulated tech debt needs review.

### Tech Debt by Phase

{For each phase with debt:}
**Phase {X}: {name}**
- {item 1}
- {item 2}

### Total: {N} items across {M} phases

───────────────────────────────────────────────────────────────

## ▶ Options

**A. Complete milestone** — accept debt, track in backlog

/GSI:complete-milestone {version}

**B. Plan cleanup phase** — address debt before completing

/GSI:plan-milestone-gaps

<sub>/clear first → fresh context window</sub>

───────────────────────────────────────────────────────────────
</offer_next>

<success_criteria>
- [ ] Milestone scope identified
- [ ] All phase VERIFICATION.md files read using MCP tools
- [ ] Tech debt and deferred gaps aggregated
- [ ] Integration checker spawned for cross-phase wiring
- [ ] v{version}-MILESTONE-AUDIT.md created using MCP write_file
- [ ] Results presented with actionable next steps
</success_criteria>

</document_content>
</document>
<document index="88">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\check-todos.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "list_directory"]
  priority: 1
  rationale: "Primary workflow for reading todos, writing status, and listing pending todos"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>List all pending todos, allow selection, load full context for selected todo, and route to appropriate action.
</purpose>

<required_reading>
Read all files referenced by the invoking prompt's execution_context before starting.
</required_reading>

<process>

<step name="init_context">
Load the todo context using MCP tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const INIT = await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js init todos",
  timeout_ms: 10000
});
```

Extract from the init JSON: `todo_count`, `todos`, `pending_dir`.

If `todo_count` is 0:
```
No pending todos.

Todos are captured during work sessions with /GSI:add-todo.

---

Would you like to:

1. Continue with current phase (/GSI:progress)
2. Add a todo now (/GSI:add-todo)
```
Exit.
</step>

<step name="parse_filter">
Check for area filter in arguments:
- `/GSI:check-todos` → show all
- `/GSI:check-todos api` → filter to area:api only
</step>

<step name="list_todos">
Use the `todos` array from init context (already filtered by area if specified).

Parse and display as a numbered list:

```
Pending Todos:

1. Add auth token refresh (api, 2d ago)
2. Fix modal z-index issue (ui, 1d ago)
3. Refactor database connection pool (database, 5h ago)

---

Reply with a number to view details, or:
- `/GSI:check-todos [area]` to filter by area
- `q` to exit
```

Format age as relative time from created timestamp.
</step>

<step name="handle_selection">
Wait for user to reply with a number.

If valid: load selected todo, proceed.
If invalid: "Invalid selection. Reply with a number (1-[N]) or `q` to exit."
</step>

<step name="load_context">
**Use MCP tool: mcp__desktop-commander__read_file** to read the todo file:

```javascript
// MCP-based equivalent for reading files
const todoContent = await mcp__desktop-commander__read_file({
  path: ".planning/todos/pending/[selected-todo].md"
});
```

Display:

```
## [title]

**Area:** [area]
**Created:** [date] ([relative time] ago)
**Files:** [list or "None"]

### Problem
[problem section content]

### Solution
[solution section content]
```

If `files` field has entries, use MCP tools to read and briefly summarize each.
</step>

<step name="check_roadmap">
Check for roadmap (can use init progress or directly check file existence):

**Use MCP tool: mcp__desktop-commander__list_directory** or **mcp__desktop-commander__read_file**

```javascript
// Check if ROADMAP.md exists using MCP tools
try {
  const roadmap = await mcp__desktop-commander__read_file({
    path: ".planning/ROADMAP.md"
  });
  // Process roadmap to check phase matches
} catch (e) {
  // No roadmap exists
}
```

If `.planning/ROADMAP.md` exists:
1. Check if todo's area matches an upcoming phase
2. Check if todo's files overlap with a phase's scope
3. Note any match for action options
</step>

<step name="offer_actions">
**If todo maps to a roadmap phase:**

Use AskUserQuestion:
- header: "Action"
- question: "This todo relates to Phase [N]: [name]. What would you like to do?"
- options:
  - "Work on it now" — move to done, start working
  - "Add to phase plan" — include when planning Phase [N]
  - "Brainstorm approach" — think through before deciding
  - "Put it back" — return to list

**If no roadmap match:**

Use AskUserQuestion:
- header: "Action"
- question: "What would you like to do with this todo?"
- options:
  - "Work on it now" — move to done, start working
  - "Create a phase" — /GSI:add-phase with this scope
  - "Brainstorm approach" — think through before deciding
  - "Put it back" — return to list
</step>

<step name="execute_action">
**Work on it now:**

**Use MCP tool: mcp__desktop-commander__move_file**

```javascript
// MCP-based equivalent for moving files
await mcp__desktop-commander__move_file({
  source: ".planning/todos/pending/[filename]",
  destination: ".planning/todos/done/[filename]"
});
```

Update STATE.md todo count. Present problem/solution context. Begin work or ask how to proceed.

**Add to phase plan:**
Note todo reference in phase planning notes. Keep in pending. Return to list or exit.

**Create a phase:**
Display: `/GSI:add-phase [description from todo]`
Keep in pending. User runs command in fresh context.

**Brainstorm approach:**
Keep in pending. Start discussion about problem and approaches.

**Put it back:**
Return to list_todos step.
</step>

<step name="update_state">
After any action that changes todo count:

Re-run `init todos` to get updated count, then update STATE.md "### Pending Todos" section if exists.
</step>

<step name="git_commit">
If todo was moved to done/, commit the change using MCP process tool:

**Use MCP tool: mcp__desktop-commander__start_process**

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs: start work on todo - [title]" --files .planning/todos/done/[filename] .planning/STATE.md
```

Tool respects `commit_docs` config and gitignore automatically.

Confirm: "Committed: docs: start work on todo - [title]"
</step>

</process>

<success_criteria>
- [ ] All pending todos listed with title, area, age
- [ ] Area filter applied if specified
- [ ] Selected todo's full context loaded using MCP read_file
- [ ] Roadmap context checked for phase match
- [ ] Appropriate actions offered
- [ ] Selected action executed
- [ ] STATE.md updated if todo count changed
- [ ] Changes committed to git (if todo moved to done/)
</success_criteria>

</document_content>
</document>
<document index="89">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\complete-milestone.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "list_directory"]
  priority: 1
  rationale: "Primary workflow for reading roadmap, writing milestone status, and listing phase directories"
code_index:
  tools: ["find_files"]
  priority: 2
  rationale: "Secondary use for finding all phase SUMMARY.md files"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>
Mark a shipped version (v1.0, v1.1, v2.0) as complete. Creates historical record in MILESTONES.md, performs full PROJECT.md evolution review, reorganizes ROADMAP.md with milestone groupings, and tags the release in git.

</purpose>

<required_reading>

1. templates/milestone.md
2. templates/milestone-archive.md
3. `.planning/ROADMAP.md`
4. `.planning/REQUIREMENTS.md`
5. `.planning/PROJECT.md`

</required_reading>

<archival_behavior>

When a milestone completes:

1. Extract full milestone details to `.planning/milestones/v[X.Y]-ROADMAP.md`
2. Archive requirements to `.planning/milestones/v[X.Y]-REQUIREMENTS.md`
3. Update ROADMAP.md — replace milestone details with one-line summary
4. Delete REQUIREMENTS.md (fresh one for next milestone)
5. Perform full PROJECT.md evolution review
6. Offer to create next milestone inline

**Context Efficiency:** Archives keep ROADMAP.md constant-size and REQUIREMENTS.md milestone-scoped.

**ROADMAP archive** uses `templates/milestone-archive.md` — includes milestone header (status, phases, date), full phase details, milestone summary (decisions, issues, tech debt).

**REQUIREMENTS archive** contains all requirements marked complete with outcomes, traceability table with final status, notes on changed requirements.

</archival_behavior>

<process>

<step name="verify_readiness">

**Use `roadmap analyze` for comprehensive readiness check:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const ROADMAP = await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js roadmap analyze",
  timeout_ms: 15000
});
```

This returns all phases with plan/summary counts and disk status. Use this to verify:
- Which phases belong to this milestone?
- All phases complete (all plans have summaries)? Check `disk_status === 'complete'` for each.
- `progress_percent` should be 100%.

Present:

```
Milestone: [Name, e.g., "v1.0 MVP"]

Includes:
- Phase 1: Foundation (2/2 plans complete)
- Phase 2: Authentication (2/2 plans complete)
- Phase 3: Core Features (3/3 plans complete)
- Phase 4: Polish (1/1 plan complete)

Total: {phase_count} phases, {total_plans} plans, all complete
```

<config-check>

**Use MCP tool: mcp__desktop-commander__read_file**

```javascript
// MCP-based equivalent for reading config
const config = await mcp__desktop-commander__read_file({
  path: ".planning/config.json"
});
```

</config-check>

<if mode="yolo">

```
⚡ Auto-approved: Milestone scope verification
[Show breakdown summary without prompting]
Proceeding to stats gathering...
```

Proceed to gather_stats.

</if>

<if mode="interactive" OR="custom with gates.confirm_milestone_scope true">

```
Ready to mark this milestone as shipped?
(yes / wait / adjust scope)
```

Wait for confirmation.
- "adjust scope": Ask which phases to include.
- "wait": Stop, user returns when ready.

</if>

</step>

<step name="gather_stats">

Calculate milestone statistics using MCP process tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent for git and file stats
const gitLog = await mcp__desktop-commander__start_process({
  command: "git log --oneline --grep=\"feat(\" | head -20",
  timeout_ms: 10000
});

const gitDiff = await mcp__desktop-commander__start_process({
  command: "git diff --stat FIRST_COMMIT..LAST_COMMIT | tail -1",
  timeout_ms: 10000
});

const loc = await mcp__desktop-commander__start_process({
  command: "find . -name \"*.swift\" -o -name \"*.ts\" -o -name \"*.py\" | xargs wc -l 2>/dev/null",
  timeout_ms: 10000
});

const gitStart = await mcp__desktop-commander__start_process({
  command: "git log --format=\"%ai\" FIRST_COMMIT | tail -1",
  timeout_ms: 10000
});

const gitEnd = await mcp__desktop-commander__start_process({
  command: "git log --format=\"%ai\" LAST_COMMIT | head -1",
  timeout_ms: 10000
});
```

Present:

```
Milestone Stats:
- Phases: [X-Y]
- Plans: [Z] total
- Tasks: [N] total (from phase summaries)
- Files modified: [M]
- Lines of code: [LOC] [language]
- Timeline: [Days] days ([Start] → [End])
- Git range: feat(XX-XX) → feat(YY-YY)
```

</step>

<step name="extract_accomplishments">

Extract one-liners from SUMMARY.md files using MCP process tool:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent for summary extraction
for (const summary of summaryFiles) {
  const result = await mcp__desktop-commander__start_process({
    command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js summary-extract "${summary}" --fields one_liner --raw`,
    timeout_ms: 10000
  });
  // Parse result for one_liner
}
```

Extract 4-6 key accomplishments. Present:

```
Key accomplishments for this milestone:
1. [Achievement from phase 1]
2. [Achievement from phase 2]
3. [Achievement from phase 3]
4. [Achievement from phase 4]
5. [Achievement from phase 5]
```

</step>

<step name="create_milestone_entry">

**Note:** MILESTONES.md entry is now created automatically by `GSI-tools milestone complete` in the archive_milestone step. The entry includes version, date, phase/plan/task counts, and accomplishments extracted from SUMMARY.md files.

If additional details are needed (e.g., user-provided "Delivered" summary, git range, LOC stats), add them manually after the CLI creates the base entry.
</step>

<step name="evolve_project_full_review">

Full PROJECT.md evolution review at milestone completion.

**Use MCP tools to read all phase summaries:**

**Use MCP tool: mcp__desktop-commander__read_file** or **mcp__desktop-commander__read_multiple_files**

```javascript
// MCP-based equivalent for reading multiple files
const summaries = await mcp__desktop-commander__read_multiple_files({
  paths: [
    ".planning/phases/01-*/01-*-SUMMARY.md",
    ".planning/phases/02-*/02-*-SUMMARY.md",
    // etc.
  ]
});
```

**Full review checklist:**

1. **"What This Is" accuracy:**
   - Compare current description to what was built
   - Update if product has meaningfully changed

2. **Core Value check:**
   - Still the right priority? Did shipping reveal a different core value?
   - Update if the ONE thing has shifted

3. **Requirements audit:**

   **Validated section:**
   - All Active requirements shipped this milestone → Move to Validated
   - Format: `- ✓ [Requirement] — v[X.Y]`

   **Active section:**
   - Remove requirements moved to Validated
   - Add new requirements for next milestone
   - Keep unaddressed requirements

   **Out of Scope audit:**
   - Review each item — reasoning still valid?
   - Remove irrelevant items
   - Add requirements invalidated during milestone

4. **Context update:**
   - Current codebase state (LOC, tech stack)
   - User feedback themes (if any)
   - Known issues or technical debt

5. **Key Decisions audit:**
   - Extract all decisions from milestone phase summaries
   - Add to Key Decisions table with outcomes
   - Mark ✓ Good, ⚠️ Revisit, or — Pending

6. **Constraints check:**
   - Any constraints changed during development? Update as needed

**Use MCP tool: mcp__desktop-commander__edit_block** to update PROJECT.md inline.

Update "Last updated" footer:

```markdown
---
*Last updated: [date] after v[X.Y] milestone*
```

**Example full evolution (v1.0 → v1.1 prep):**

Before:

```markdown
## What This Is

A real-time collaborative whiteboard for remote teams.

## Core Value

Real-time sync that feels instant.

## Requirements

### Validated

(None yet — ship to validate)

### Active

- [ ] Canvas drawing tools
- [ ] Real-time sync < 500ms
- [ ] User authentication

### Out of Scope

- Mobile app — web-first approach
- Video chat — use external tools
```

After v1.0:

```markdown
## What This Is

A real-time collaborative whiteboard for remote teams with instant sync and drawing tools.

## Core Value

Real-time sync that feels instant.

## Requirements

### Validated

- ✓ Canvas drawing tools — v1.0
- ✓ Real-time sync < 500ms — v1.0 (achieved 200ms avg)
- ✓ User authentication — v1.0

### Active

- [ ] Export to PNG
- [ ] Undo/redo history
- [ ] Shape tools (rectangles, circles)

### Out of Scope

- Mobile app — web-first approach, PWA works well
- Video chat — use external tools
- Offline mode — real-time is core value

## Context

Shipped v1.0 with 2,400 LOC TypeScript.
Tech stack: Next.js, Supabase, Canvas API.
Initial user testing showed demand for shape tools.
```

**Step complete when:**

- [ ] "What This Is" reviewed and updated if needed
- [ ] Core Value verified as still correct
- [ ] All shipped requirements moved to Validated
- [ ] New requirements added to Active for next milestone
- [ ] Out of Scope reasoning audited
- [ ] Context updated with current state
- [ ] All milestone decisions added to Key Decisions
- [ ] "Last updated" footer reflects milestone completion

</step>

<step name="reorganize_roadmap">

Update `.planning/ROADMAP.md` — group completed milestone phases.

**Use MCP tool: mcp__desktop-commander__read_file** and **mcp__desktop-commander__edit_block**

```markdown
# Roadmap: [Project Name]

## Milestones

- ✅ **v1.0 MVP** — Phases 1-4 (shipped YYYY-MM-DD)
- 🚧 **v1.1 Security** — Phases 5-6 (in progress)
- 📋 **v2.0 Redesign** — Phases 7-10 (planned)

## Phases

<details>
<summary>✅ v1.0 MVP (Phases 1-4) — SHIPPED YYYY-MM-DD</summary>

- [x] Phase 1: Foundation (2/2 plans) — completed YYYY-MM-DD
- [x] Phase 2: Authentication (2/2 plans) — completed YYYY-MM-DD
- [x] Phase 3: Core Features (3/3 plans) — completed YYYY-MM-DD
- [x] Phase 4: Polish (1/1 plan) — completed YYYY-MM-DD

</details>

### 🚧 v[Next] [Name] (In Progress / Planned)

- [ ] Phase 5: [Name] ([N] plans)
- [ ] Phase 6: [Name] ([N] plans)

## Progress

| Phase             | Milestone | Plans Complete | Status      | Completed  |
| ----------------- | --------- | -------------- | ----------- | ---------- |
| 1. Foundation     | v1.0      | 2/2            | Complete    | YYYY-MM-DD |
| 2. Authentication | v1.0      | 2/2            | Complete    | YYYY-MM-DD |
| 3. Core Features  | v1.0      | 3/3            | Complete    | YYYY-MM-DD |
| 4. Polish         | v1.0      | 1/1            | Complete    | YYYY-MM-DD |
| 5. Security Audit | v1.1      | 0/1            | Not started | -          |
| 6. Hardening      | v1.1      | 0/2            | Not started | -          |
```
</step>

<step name="archive_milestone">

**Delegate archival to GSI-tools:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const ARCHIVE = await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js milestone complete "v[X.Y]" --name "[Milestone Name]"`,
  timeout_ms: 15000
});
```

The CLI handles:
- Creating `.planning/milestones/` directory
- Archiving ROADMAP.md to `milestones/v[X.Y]-ROADMAP.md`
- Archiving REQUIREMENTS.md to `milestones/v[X.Y]-REQUIREMENTS.md` with archive header
- Moving audit file to milestones if it exists
- Creating/appending MILESTONES.md entry with accomplishments from SUMMARY.md files
- Updating STATE.md (status, last activity)

Extract from result: `version`, `date`, `phases`, `plans`, `tasks`, `accomplishments`, `archived`.

Verify: `✅ Milestone archived to .planning/milestones/`

**Note:** Phase directories (`.planning/phases/`) are NOT deleted — they accumulate across milestones as raw execution history. Phase numbering continues (v1.0 phases 1-4, v1.1 phases 5-8, etc.).

After archival, the AI still handles:
- Reorganizing ROADMAP.md with milestone grouping (requires judgment)
- Full PROJECT.md evolution review (requires understanding)
- Deleting original ROADMAP.md and REQUIREMENTS.md
- These are NOT fully delegated because they require AI interpretation of content

</step>

<step name="reorganize_roadmap_and_delete_originals">

After `milestone complete` has archived, reorganize ROADMAP.md with milestone groupings, then delete originals:

**Reorganize ROADMAP.md** — group completed milestone phases.

**Use MCP tool: mcp__desktop-commander__write_file**

```markdown
# Roadmap: [Project Name]

## Milestones

- ✅ **v1.0 MVP** — Phases 1-4 (shipped YYYY-MM-DD)
- 🚧 **v1.1 Security** — Phases 5-6 (in progress)

## Phases

<details>
<summary>✅ v1.0 MVP (Phases 1-4) — SHIPPED YYYY-MM-DD</summary>

- [x] Phase 1: Foundation (2/2 plans) — completed YYYY-MM-DD
- [x] Phase 2: Authentication (2/2 plans) — completed YYYY-MM-DD

</details>
```

**Then delete originals using MCP process tool:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent for file deletion
await mcp__desktop-commander__start_process({
  command: "rm .planning/ROADMAP.md",
  timeout_ms: 5000
});

await mcp__desktop-commander__start_process({
  command: "rm .planning/REQUIREMENTS.md",
  timeout_ms: 5000
});
```

</step>

<step name="update_state">

Most STATE.md updates were handled by `milestone complete`, but verify and update remaining fields.

**Project Reference:**

```markdown
## Project Reference

See: .planning/PROJECT.md (updated [today])

**Core value:** [Current core value from PROJECT.md]
**Current focus:** [Next milestone or "Planning next milestone"]
```

**Accumulated Context:**
- Clear decisions summary (full log in PROJECT.md)
- Clear resolved blockers
- Keep open blockers for next milestone

</step>

<step name="handle_branches">

Check branching strategy and offer merge options.

**Use MCP tool: mcp__desktop-commander__start_process** for context, or load config directly:

```javascript
const INIT = await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js init execute-phase \"1\"",
  timeout_ms: 10000
});
```

Extract `branching_strategy`, `phase_branch_template`, `milestone_branch_template` from init JSON.

**If "none":** Skip to git_tag.

**For "phase" strategy:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
const BRANCH_PREFIX = await mcp__desktop-commander__start_process({
  command: `echo "$PHASE_BRANCH_TEMPLATE" | sed 's/{.*//'`,
  timeout_ms: 5000
});

const PHASE_BRANCHES = await mcp__desktop-commander__start_process({
  command: `git branch --list "${BRANCH_PREFIX}*" 2>/dev/null | sed 's/^[* ]*//' | tr -d ' '`,
  timeout_ms: 5000
});
```

**For "milestone" strategy:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
const BRANCH_PREFIX = await mcp__desktop-commander__start_process({
  command: `echo "$MILESTONE_BRANCH_TEMPLATE" | sed 's/{.*//'`,
  timeout_ms: 5000
});

const MILESTONE_BRANCH = await mcp__desktop-commander__start_process({
  command: `git branch --list "${BRANCH_PREFIX}*" 2>/dev/null | sed 's/^[* ]*//' | tr -d ' ' | head -1`,
  timeout_ms: 5000
});
```

**If no branches found:** Skip to git_tag.

**If branches exist:**

```
## Git Branches Detected

Branching strategy: {phase/milestone}
Branches: {list}

Options:
1. **Merge to main** — Merge branch(es) to main
2. **Delete without merging** — Already merged or not needed
3. **Keep branches** — Leave for manual handling
```

AskUserQuestion with options: Squash merge (Recommended), Merge with history, Delete without merging, Keep branches.

**Squash merge:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent for git operations
const CURRENT_BRANCH = await mcp__desktop-commander__start_process({
  command: "git branch --show-current",
  timeout_ms: 5000
});

await mcp__desktop-commander__start_process({
  command: "git checkout main",
  timeout_ms: 5000
});

// Merge each branch with squash
for (const branch of phaseBranches) {
  await mcp__desktop-commander__start_process({
    command: `git merge --squash "${branch}"`,
    timeout_ms: 10000
  });
  await mcp__desktop-commander__start_process({
    command: `git commit -m "feat: ${branch} for v[X.Y]"`,
    timeout_ms: 5000
  });
}

await mcp__desktop-commander__start_process({
  command: `git checkout "${CURRENT_BRANCH}"`,
  timeout_ms: 5000
});
```

**Merge with history:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
const CURRENT_BRANCH = await mcp__desktop-commander__start_process({
  command: "git branch --show-current",
  timeout_ms: 5000
});

await mcp__desktop-commander__start_process({
  command: "git checkout main",
  timeout_ms: 5000
});

// Merge each branch with history
for (const branch of phaseBranches) {
  await mcp__desktop-commander__start_process({
    command: `git merge --no-ff "${branch}" -m "Merge branch '${branch}' for v[X.Y]"`,
    timeout_ms: 10000
  });
}

await mcp__desktop-commander__start_process({
  command: `git checkout "${CURRENT_BRANCH}"`,
  timeout_ms: 5000
});
```

**Delete without merging:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent for branch deletion
for (const branch of phaseBranches) {
  await mcp__desktop-commander__start_process({
    command: `git branch -d "${branch}" 2>/dev/null || git branch -D "${branch}"`,
    timeout_ms: 5000
  });
}
```

**Keep branches:** Report "Branches preserved for manual handling"

</step>

<step name="git_tag">

Create git tag using MCP process tool:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent for git tagging
await mcp__desktop-commander__start_process({
  command: `git tag -a v[X.Y] -m "v[X.Y] [Name]

Delivered: [One sentence]

Key accomplishments:
- [Item 1]
- [Item 2]
- [Item 3]

See .planning/MILESTONES.md for full details."`,
  timeout_ms: 5000
});
```

Confirm: "Tagged: v[X.Y]"

Ask: "Push tag to remote? (y/n)"

If yes:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
await mcp__desktop-commander__start_process({
  command: `git push origin v[X.Y]`,
  timeout_ms: 15000
});
```

</step>

<step name="git_commit_milestone">

Commit milestone completion using MCP process tool:

**Use MCP tool: mcp__desktop-commander__start_process**

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "chore: complete v[X.Y] milestone" --files .planning/milestones/v[X.Y]-ROADMAP.md .planning/milestones/v[X.Y]-REQUIREMENTS.md .planning/milestones/v[X.Y]-MILESTONE-AUDIT.md .planning/MILESTONES.md .planning/PROJECT.md .planning/STATE.md
```
```
Confirm: "Committed: chore: complete v[X.Y] milestone"

</step>

<step name="offer_next">

```
✅ Milestone v[X.Y] [Name] complete

Shipped:
- [N] phases ([M] plans, [P] tasks)
- [One sentence of what shipped]

Archived:
- milestones/v[X.Y]-ROADMAP.md
- milestones/v[X.Y]-REQUIREMENTS.md

Summary: .planning/MILESTONES.md
Tag: v[X.Y]

---

## ▶ Next Up

**Start Next Milestone** — questioning → research → requirements → roadmap

`/GSI:new-milestone`

<sub>`/clear` first → fresh context window</sub>

---
```

</step>

</process>

<milestone_naming>

**Version conventions:**
- **v1.0** — Initial MVP
- **v1.1, v1.2** — Minor updates, new features, fixes
- **v2.0, v3.0** — Major rewrites, breaking changes, new direction

**Names:** Short 1-2 words (v1.0 MVP, v1.1 Security, v1.2 Performance, v2.0 Redesign).

</milestone_naming>

<what_qualifies>

**Create milestones for:** Initial release, public releases, major feature sets shipped, before archiving planning.

**Don't create milestones for:** Every phase completion (too granular), work in progress, internal dev iterations (unless truly shipped).

Heuristic: "Is this deployed/usable/shipped?" If yes → milestone. If no → keep working.

</what_qualifies>

<success_criteria>

Milestone completion is successful when:

- [ ] MILESTONES.md entry created with stats and accomplishments
- [ ] PROJECT.md full evolution review completed
- [ ] All shipped requirements moved to Validated in PROJECT.md
- [ ] Key Decisions updated with outcomes
- [ ] ROADMAP.md reorganized with milestone grouping
- [ ] Roadmap archive created (milestones/v[X.Y]-ROADMAP.md)
- [ ] Requirements archive created (milestones/v[X.Y]-REQUIREMENTS.md)
- [ ] REQUIREMENTS.md deleted (fresh for next milestone)
- [ ] STATE.md updated with fresh project reference
- [ ] Git tag created (v[X.Y])
- [ ] Milestone commit made (includes archive files and deletion)
- [ ] User knows next step (/GSI:new-milestone)

</success_criteria>

</document_content>
</document>
<document index="90">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\diagnose-issues.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file"]
  priority: 1
  rationale: "Primary workflow for reading issue context and writing diagnosis documents"
code_index:
  tools: ["search_code_advanced"]
  priority: 2
  rationale: "Secondary use for searching error patterns across codebase"
debug_thinking:
  tools: ["debug_thinking"]
  priority: 2
  rationale: "Secondary use for graph-based problem tracking and knowledge retrieval"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Orchestrate parallel debug agents to investigate UAT gaps and find root causes.

After UAT finds gaps, spawn one debug agent per gap. Each agent investigates autonomously with symptoms pre-filled from UAT. Collect root causes, update UAT.md gaps with diagnosis, then hand off to plan-phase --gaps with actual diagnoses.

Orchestrator stays lean: parse gaps, spawn agents, collect results, update UAT.
</purpose>

<paths>
DEBUG_DIR=.planning/debug

Debug files use `.planning/debug/` path (hidden directory with leading dot).
</paths>

<core_principle>
**Diagnose before planning fixes.**

UAT tells us WHAT is broken (symptoms). Debug agents find WHY (root cause). plan-phase --gaps then creates targeted fixes based on actual causes, not guesses.

Without diagnosis: "Comment doesn't refresh" → guess at fix → maybe wrong
With diagnosis: "Comment doesn't refresh" → "useEffect missing dependency" → precise fix
</core_principle>

<process>

<step name="parse_gaps">
**Extract gaps from UAT.md:**

**Use MCP tool: mcp__desktop-commander__read_file**

```javascript
// MCP-based equivalent for reading files (80-90% token savings vs cat)
const uatContent = await mcp__desktop-commander__read_file({
  path: ".planning/phases/XX-name/{phase}-UAT.md"
});
```

Read "Gaps" section (YAML format):
```yaml
- truth: "Comment appears immediately after submission"
  status: failed
  reason: "User reported: works but doesn't show until I refresh page"
  severity: major
  test: 2
  artifacts: []
  missing: []
```

For each gap, also read the corresponding test from "Tests" section to get full context.

Build gap list:
```
gaps = [
  {truth: "Comment appears immediately...", severity: "major", test_num: 2, reason: "..."},
  {truth: "Reply button positioned correctly...", severity: "minor", test_num: 5, reason: "..."},
  ...
]
```
</step>

<step name="report_plan">
**Report diagnosis plan to user:**

```
## Diagnosing {N} Gaps

Spawning parallel debug agents to investigate root causes:

| Gap (Truth) | Severity |
|-------------|----------|
| Comment appears immediately after submission | major |
| Reply button positioned correctly | minor |
| Delete removes comment | blocker |

Each agent will:
1. Create DEBUG-{slug}.md with symptoms pre-filled
2. Investigate autonomously (read code, form hypotheses, test)
3. Return root cause

This runs in parallel - all gaps investigated simultaneously.
```
</step>

<step name="graph_based_diagnosis">
**For systematic debugging with knowledge graph:**

**Use MCP tool: mcp__debug-thinking__debug_thinking**

```javascript
// Query for similar problems first
const similar = await mcp__debug-thinking__debug_thinking({
  action: "query",
  queryType: "similar-problems",
  parameters: {
    pattern: "{error pattern or symptom}",
    limit: 5,
    minSimilarity: 0.5
  }
});

// Review past solutions and adapt if applicable

// Create problem node for current issue
const problem = await mcp__debug-thinking__debug_thinking({
  action: "create",
  nodeType: "problem",
  content: "{error description with context}"
});

// Create hypothesis nodes based on similar cases
const hypothesis = await mcp__debug-thinking__debug_thinking({
  action: "create",
  nodeType: "hypothesis",
  content: "{proposed explanation}",
  parentId: problem.nodeId
});

// Connect hypothesis to problem
await mcp__debug-thinking__debug_thinking({
  action: "connect",
  from: hypothesis.nodeId,
  to: problem.nodeId,
  type: "hypothesizes",
  strength: 0.7
});

// Create experiment nodes for each hypothesis
// Track results in observation nodes
// Create solution and learning nodes when resolved
```

**Integration with agents**: Each debug agent uses debug-thinking for tracking

**Knowledge graph query examples**:
- Pattern: "TypeError undefined" → Find past null safety solutions
- Pattern: "timeout connection" → Find past timeout fixes
- Pattern: "authentication failed" → Find past auth debugging

</step>

<step name="spawn_agents">
**Spawn debug agents in parallel:**

For each gap, fill in debug-subagent-prompt template and spawn:

```
Task(
  prompt=filled_debug_subagent_prompt,
  subagent_type="general-purpose",
  description="Debug: {truth_short}"
)
```

**All agents spawn in single message** (parallel execution).

Template placeholders:
- `{truth}`: The expected behavior that failed
- `{expected}`: From UAT test
- `{actual}`: Verbatim user description from reason field
- `{errors}`: Any error messages from UAT (or "None reported")
- `{reproduction}`: "Test {test_num} in UAT"
- `{timeline}`: "Discovered during UAT"
- `{goal}`: `find_root_cause_only` (UAT flow - plan-phase --gaps handles fixes)
- `{slug}`: Generated from truth
</step>

<step name="collect_results">
**Collect root causes from agents:**

Each agent returns with:
```
## ROOT CAUSE FOUND

**Debug Session:** ${DEBUG_DIR}/{slug}.md

**Root Cause:** {specific cause with evidence}

**Evidence Summary:**
- {key finding 1}
- {key finding 2}
- {key finding 3}

**Files Involved:**
- {file1}: {what's wrong}
- {file2}: {related issue}

**Suggested Fix Direction:** {brief hint for plan-phase --gaps}
```

Parse each return to extract:
- root_cause: The diagnosed cause
- files: Files involved
- debug_path: Path to debug session file
- suggested_fix: Hint for gap closure plan

If agent returns `## INVESTIGATION INCONCLUSIVE`:
- root_cause: "Investigation inconclusive - manual review needed"
- Note which issue needs manual attention
- Include remaining possibilities from agent return
</step>

<step name="update_uat">
**Update UAT.md gaps with diagnosis:**

For each gap in the Gaps section, add artifacts and missing fields:

**Use MCP tool: mcp__desktop-commander__edit_block**

```javascript
// MCP-based equivalent for editing files
await mcp__desktop-commander__edit_block({
  file_path: ".planning/phases/XX-name/{phase}-UAT.md",
  old_string: "- truth: \"Comment appears immediately after submission\"\n  status: failed\n  reason: \"User reported: works but doesn't show until I refresh page\"\n  severity: major\n  test: 2",
  new_string: "- truth: \"Comment appears immediately after submission\"\n  status: diagnosed\n  reason: \"User reported: works but doesn't show until I refresh page\"\n  severity: major\n  test: 2\n  root_cause: \"useEffect in CommentList.tsx missing commentCount dependency\"\n  artifacts:\n    - path: \"src/components/CommentList.tsx\"\n      issue: \"useEffect missing dependency\"\n  missing:\n    - \"Add commentCount to useEffect dependency array\"\n    - \"Trigger re-render when new comment added\"\n  debug_session: .planning/debug/comment-not-refreshing.md"
});
```

Update status in frontmatter to "diagnosed".

Commit updated UAT.md using MCP process tool:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit \"docs({phase}): add root causes from diagnosis\" --files \".planning/phases/XX-name/{phase}-UAT.md\"",
  timeout_ms: 10000
});
```
</step>

<step name="report_results">
**Report diagnosis results and hand off:**

Display:
```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► DIAGNOSIS COMPLETE
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

| Gap (Truth) | Root Cause | Files |
|-------------|------------|-------|
| Comment appears immediately | useEffect missing dependency | CommentList.tsx |
| Reply button positioned correctly | CSS flex order incorrect | ReplyButton.tsx |
| Delete removes comment | API missing auth header | api/comments.ts |

Debug sessions: ${DEBUG_DIR}/

Proceeding to plan fixes...
```

Return to verify-work orchestrator for automatic planning.
Do NOT offer manual next steps - verify-work handles the rest.
</step>

</process>

<context_efficiency>
Agents start with symptoms pre-filled from UAT (no symptom gathering).
Agents only diagnose—plan-phase --gaps handles fixes (no fix application).
</context_efficiency>

<failure_handling>
**Agent fails to find root cause:**
- Mark gap as "needs manual review"
- Continue with other gaps
- Report incomplete diagnosis

**Agent times out:**
- Check DEBUG-{slug}.md for partial progress
- Can resume with /GSI:debug

**All agents fail:**
- Something systemic (permissions, git, etc.)
- Report for manual investigation
- Fall back to plan-phase --gaps without root causes (less precise)
</failure_handling>

<success_criteria>
- [ ] Gaps parsed from UAT.md using MCP read_file
- [ ] Debug agents spawned in parallel
- [ ] Root causes collected from all agents
- [ ] UAT.md gaps updated with artifacts and missing using MCP edit_block
- [ ] Debug sessions saved to ${DEBUG_DIR}/
- [ ] Hand off to verify-work for automatic planning
</success_criteria>

</document_content>
</document>
<document index="91">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\discovery-phase.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "list_directory"]
  priority: 1
  rationale: "Primary workflow for reading requirements, writing discovery documents, and listing project files"
code_index:
  tools: ["search_code_advanced", "find_files"]
  priority: 2
  rationale: "Secondary use for searching codebase patterns and discovering relevant files"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Execute discovery at appropriate depth level.
Produces DISCOVERY.md (for Level 2-3) that informs PLAN.md creation.

Called from plan-phase.md's mandatory_discovery step with a depth parameter.

NOTE: For comprehensive ecosystem research ("how do experts build this"), use /GSI:research-phase instead, which produces RESEARCH.md.
</purpose>

<depth_levels>
**This workflow supports three depth levels:**

| Level | Name         | Time      | Output                                       | When                                      |
| ----- | ------------ | --------- | -------------------------------------------- | ----------------------------------------- |
| 1     | Quick Verify | 2-5 min   | No file, proceed with verified knowledge     | Single library, confirming current syntax |
| 2     | Standard     | 15-30 min | DISCOVERY.md                                 | Choosing between options, new integration |
| 3     | Deep Dive    | 1+ hour   | Detailed DISCOVERY.md with validation gates  | Architectural decisions, novel problems   |

**Depth is determined by plan-phase.md before routing here.**
</depth_levels>

<source_hierarchy>
**MANDATORY: Context7 BEFORE WebSearch**

Claude's training data is 6-18 months stale. Always verify.

1. **Context7 MCP FIRST** - Current docs, no hallucination
2. **Official docs** - When Context7 lacks coverage
3. **WebSearch LAST** - For comparisons and trends only

See ~/.claude/get-shit-indexed/templates/discovery.md `<discovery_protocol>` for full protocol.
</source_hierarchy>

<process>

<step name="determine_depth">
Check the depth parameter passed from plan-phase.md:
- `depth=verify` → Level 1 (Quick Verification)
- `depth=standard` → Level 2 (Standard Discovery)
- `depth=deep` → Level 3 (Deep Dive)

Route to the appropriate level workflow below.
</step>

<step name="level_1_quick_verify">
**Level 1: Quick Verification (2-5 minutes)**

For: Single known library, confirming syntax/version still correct.

**Process:**

1. Resolve library in Context7:

   **Use MCP tool: mcp__context7__resolve-library-id**

   ```
   mcp__context7__resolve-library-id with libraryName: "[library]"
   ```

2. Fetch relevant docs:

   **Use MCP tool: mcp__context7__get-library-docs**

   ```
   mcp__context7__get-library-docs with:
   - context7CompatibleLibraryID: [from step 1]
   - topic: [specific concern]
   ```

3. Verify:

   - Current version matches expectations
   - API syntax unchanged
   - No breaking changes in recent versions

4. **If verified:** Return to plan-phase.md with confirmation. No DISCOVERY.md needed.

5. **If concerns found:** Escalate to Level 2.

**Output:** Verbal confirmation to proceed, or escalation to Level 2.
</step>

<step name="level_2_standard">
**Level 2: Standard Discovery (15-30 minutes)**

For: Choosing between options, new external integration.

**Process:**

1. **Identify what to discover:**

   - What options exist?
   - What are the key comparison criteria?
   - What's our specific use case?

2. **Context7 for each option:**

   **Use MCP tools: mcp__context7__resolve-library-id and mcp__context7__get-library-docs**

   ```
   For each library/framework:
   - mcp__context7__resolve-library-id
   - mcp__context7__get-library-docs (mode: "code" for API, "info" for concepts)
   ```

3. **Official docs** for anything Context7 lacks.

4. **WebSearch** for comparisons:

   **Use MCP tool: mcp__rag-web-browser__search**

   ```
   mcp__rag-web-browser__search with:
   - query: "[option A] vs [option B] {current_year}"
   - query: "[option] known issues"
   - query: "[option] with [our stack]"
   ```

5. **Cross-verify:** Any WebSearch finding → confirm with Context7/official docs.

6. **Create DISCOVERY.md** using ~/.claude/get-shit-indexed/templates/discovery.md structure:

   **Use MCP tool: mcp__desktop-commander__write_file**

   ```
   // MCP-based equivalent for file writing (80-90% token savings vs bash)
   await mcp__desktop-commander__write_file({
     path: ".planning/phases/XX-name/DISCOVERY.md",
     content: `[discovery content with summary, findings, code examples]`
   });
   ```

   - Summary with recommendation
   - Key findings per option
   - Code examples from Context7
   - Confidence level (should be MEDIUM-HIGH for Level 2)

7. Return to plan-phase.md.

**Output:** `.planning/phases/XX-name/DISCOVERY.md`
</step>

<step name="level_3_deep_dive">
**Level 3: Deep Dive (1+ hour)**

For: Architectural decisions, novel problems, high-risk choices.

**Process:**

1. **Scope discovery** using ~/.claude/get-shit-indexed/templates/discovery.md:

   - Define clear scope
   - Define include/exclude boundaries
   - List specific questions to answer

2. **Exhaustive Context7 research:**

   **Use MCP tools: mcp__context7__resolve-library-id and mcp__context7__get-library-docs**

   ```
   // MCP-based equivalent (80-90% token savings vs bash)
   - All relevant libraries
   - Related patterns and concepts
   - Multiple topics per library if needed
   ```

3. **Official documentation deep read:**

   - Architecture guides
   - Best practices sections
   - Migration/upgrade guides
   - Known limitations

4. **WebSearch for ecosystem context:**

   **Use MCP tool: mcp__rag-web-browser__search**

   ```
   // MCP-based search for current info
   - How others solved similar problems
   - Production experiences
   - Gotchas and anti-patterns
   - Recent changes/announcements
   ```

5. **Cross-verify ALL findings:**

   - Every WebSearch claim → verify with authoritative source
   - Mark what's verified vs assumed
   - Flag contradictions

6. **Create comprehensive DISCOVERY.md:**

   **Use MCP tool: mcp__desktop-commander__write_file**

   ```
   // Full structure from ~/.claude/get-shit-indexed/templates/discovery.md
   - Quality report with source attribution
   - Confidence by finding
   ```

7. **Confidence gate:** If overall confidence is LOW, present options before proceeding.

8. Return to plan-phase.md.

**Output:** `.planning/phases/XX-name/DISCOVERY.md` (comprehensive)
</step>

<step name="identify_unknowns">
**For Level 2-3:** Define what we need to learn.

Ask: What do we need to learn before we can plan this phase?

- Technology choices?
- Best practices?
- API patterns?
- Architecture approach?
</step>

<step name="create_discovery_scope">
Use ~/.claude/get-shit-indexed/templates/discovery.md.

Include:

- Clear discovery objective
- Scoped include/exclude lists
- Source preferences (official docs, Context7, current year)
- Output structure for DISCOVERY.md
</step>

<step name="execute_discovery">
Run discovery:
- **Use MCP tool: mcp__rag-web-browser__search** for current info
- **Use MCP tools: mcp__context7__resolve-library-id and mcp__context7__get-library-docs** for library docs
- Prefer current year sources
- Structure findings per template
</step>

<step name="create_discovery_output">
Write `.planning/phases/XX-name/DISCOVERY.md`:

**Use MCP tool: mcp__desktop-commander__write_file**

```javascript
// MCP-based equivalent for file writing
await mcp__desktop-commander__write_file({
  path: ".planning/phases/XX-name/DISCOVERY.md",
  content: `[discovery content with summary, findings, code examples, metadata]`
});
```
</step>

<step name="confidence_gate">
After creating DISCOVERY.md, check the confidence level.

If confidence is LOW:
Use AskUserQuestion:

- header: "Low Confidence"
- question: "Discovery confidence is LOW: [reason]. How would you like to proceed?"
- options:
  - "Dig deeper" - Do more research before planning
  - "Proceed anyway" - Accept uncertainty, plan with caveats
  - "Pause" - I need to think about this

If confidence is MEDIUM:
Inline: "Discovery complete (medium confidence). [brief reason]. Proceed to planning?"

If confidence is HIGH:
Proceed directly, just note: "Discovery complete (high confidence)."
</step>

<step name="open_questions_gate">
If DISCOVERY.md has open_questions:

Present them inline:
"Open questions from discovery:

- [Question 1]
- [Question 2]

These may affect implementation. Acknowledge and proceed? (yes / address first)"

If "address first": Gather user input on questions, update discovery.
</step>

<step name="offer_next">
```
Discovery complete: .planning/phases/XX-name/DISCOVERY.md
Recommendation: [one-liner]
Confidence: [level]

What's next?

1. Discuss phase context (/GSI:discuss-phase [current-phase])
2. Create phase plan (/GSI:plan-phase [current-phase])
3. Refine discovery (dig deeper)
4. Review discovery

```

NOTE: DISCOVERY.md is NOT committed separately. It will be committed with phase completion.
</step>

</process>

<success_criteria>
**Level 1 (Quick Verify):**
- Context7 consulted using mcp__context7 tools
- Current state verified or concerns escalated
- Verbal confirmation to proceed (no files)

**Level 2 (Standard):**
- Context7 consulted using mcp__context7 tools for all options
- WebSearch findings cross-verified using mcp__rag-web-browser__search
- DISCOVERY.md created using mcp__desktop-commander__write_file
- Confidence level MEDIUM or higher
- Ready to inform PLAN.md creation

**Level 3 (Deep Dive):**
- Discovery scope defined
- Context7 exhaustively consulted using mcp__context7 tools
- All WebSearch findings verified against authoritative sources using mcp__rag-web-browser__search
- DISCOVERY.md created using mcp__desktop-commander__write_file with comprehensive analysis
- Quality report with source attribution
- If LOW confidence findings → validation checkpoints defined
- Confidence gate passed
- Ready to inform PLAN.md creation
</success_criteria>

</document_content>
</document>
<document index="92">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\discuss-phase.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file"]
  priority: 1
  rationale: "Primary workflow for reading phase documents and writing discussion summaries"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Extract implementation decisions that downstream agents need. Analyze the phase to identify gray areas, let the user choose what to discuss, then deep-dive each selected area until satisfied.

You are a thinking partner, not an interviewer. The user is the visionary — you are the builder. Your job is to capture decisions that will guide research and planning, not to figure out implementation yourself.
</purpose>

<downstream_awareness>
**CONTEXT.md feeds into:**

1. **GSI-phase-researcher** — Reads CONTEXT.md to know WHAT to research
   - "User wants card-based layout" → researcher investigates card component patterns
   - "Infinite scroll decided" → researcher looks into virtualization libraries

2. **GSI-planner** — Reads CONTEXT.md to know WHAT decisions are locked
   - "Pull-to-refresh on mobile" → planner includes that in task specs
   - "Claude's Discretion: loading skeleton" → planner can decide approach

**Your job:** Capture decisions clearly enough that downstream agents can act on them without asking the user again.

**Not your job:** Figure out HOW to implement. That's what research and planning do with the decisions you capture.
</downstream_awareness>

<philosophy>
**User = founder/visionary. Claude = builder.**

The user knows:
- How they imagine it working
- What it should look/feel like
- What's essential vs nice-to-have
- Specific behaviors or references they have in mind

The user doesn't know (and shouldn't be asked):
- Codebase patterns (researcher reads the code)
- Technical risks (researcher identifies these)
- Implementation approach (planner figures this out)
- Success metrics (inferred from the work)

Ask about vision and implementation choices. Capture decisions for downstream agents.
</philosophy>

<scope_guardrail>
**CRITICAL: No scope creep.**

The phase boundary comes from ROADMAP.md and is FIXED. Discussion clarifies HOW to implement what's scoped, never WHETHER to add new capabilities.

**Allowed (clarifying ambiguity):**
- "How should posts be displayed?" (layout, density, info shown)
- "What happens on empty state?" (within the feature)
- "Pull to refresh or manual?" (behavior choice)

**Not allowed (scope creep):**
- "Should we also add comments?" (new capability)
- "What about search/filtering?" (new capability)
- "Maybe include bookmarking?" (new capability)

**The heuristic:** Does this clarify how we implement what's already in the phase, or does it add a new capability that could be its own phase?

**When user suggests scope creep:**
```
"[Feature X] would be a new capability — that's its own phase.
Want me to note it for the roadmap backlog?

For now, let's focus on [phase domain]."
```

Capture the idea in a "Deferred Ideas" section. Don't lose it, don't act on it.
</scope_guardrail>

<gray_area_identification>
Gray areas are **implementation decisions the user cares about** — things that could go multiple ways and would change the result.

**How to identify gray areas:**

1. **Read the phase goal** from ROADMAP.md
2. **Understand the domain** — What kind of thing is being built?
   - Something users SEE → visual presentation, interactions, states matter
   - Something users CALL → interface contracts, responses, errors matter
   - Something users RUN → invocation, output, behavior modes matter
   - Something users READ → structure, tone, depth, flow matter
   - Something being ORGANIZED → criteria, grouping, handling exceptions matter
3. **Generate phase-specific gray areas** — Not generic categories, but concrete decisions for THIS phase

**Don't use generic category labels** (UI, UX, Behavior). Generate specific gray areas:

```
Phase: "User authentication"
→ Session handling, Error responses, Multi-device policy, Recovery flow

Phase: "Organize photo library"
→ Grouping criteria, Duplicate handling, Naming convention, Folder structure

Phase: "CLI for database backups"
→ Output format, Flag design, Progress reporting, Error recovery

Phase: "API documentation"
→ Structure/navigation, Code examples depth, Versioning approach, Interactive elements
```

**The key question:** What decisions would change the outcome that the user should weigh in on?

**Claude handles these (don't ask):**
- Technical implementation details
- Architecture patterns
- Performance optimization
- Scope (roadmap defines this)
</gray_area_identification>

<process>

<step name="initialize" priority="first">
Phase number from argument (required).

```bash
INIT=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js init phase-op "${PHASE}")
```

Parse JSON for: `commit_docs`, `phase_found`, `phase_dir`, `phase_number`, `phase_name`, `phase_slug`, `padded_phase`, `has_research`, `has_context`, `has_plans`, `has_verification`, `plan_count`, `roadmap_exists`, `planning_exists`.

**If `phase_found` is false:**
```
Phase [X] not found in roadmap.

Use /GSI:progress to see available phases.
```
Exit workflow.

**If `phase_found` is true:** Continue to check_existing.
</step>

<step name="check_existing">
Check if CONTEXT.md already exists using `has_context` from init.

```bash
ls ${phase_dir}/*-CONTEXT.md 2>/dev/null
```

**If exists:**
Use AskUserQuestion:
- header: "Existing context"
- question: "Phase [X] already has context. What do you want to do?"
- options:
  - "Update it" — Review and revise existing context
  - "View it" — Show me what's there
  - "Skip" — Use existing context as-is

If "Update": Load existing, continue to analyze_phase
If "View": Display CONTEXT.md, then offer update/skip
If "Skip": Exit workflow

**If doesn't exist:** Continue to analyze_phase.
</step>

<step name="analyze_phase">
Analyze the phase to identify gray areas worth discussing.

**Read the phase description from ROADMAP.md and determine:**

1. **Domain boundary** — What capability is this phase delivering? State it clearly.

2. **Gray areas by category** — For each relevant category (UI, UX, Behavior, Empty States, Content), identify 1-2 specific ambiguities that would change implementation.

3. **Skip assessment** — If no meaningful gray areas exist (pure infrastructure, clear-cut implementation), the phase may not need discussion.

**Output your analysis internally, then present to user.**

Example analysis for "Post Feed" phase:
```
Domain: Displaying posts from followed users
Gray areas:
- UI: Layout style (cards vs timeline vs grid)
- UI: Information density (full posts vs previews)
- Behavior: Loading pattern (infinite scroll vs pagination)
- Empty State: What shows when no posts exist
- Content: What metadata displays (time, author, reactions count)
```
</step>

<step name="present_gray_areas">
Present the domain boundary and gray areas to user.

**First, state the boundary:**
```
Phase [X]: [Name]
Domain: [What this phase delivers — from your analysis]

We'll clarify HOW to implement this.
(New capabilities belong in other phases.)
```

**Then use AskUserQuestion (multiSelect: true):**
- header: "Discuss"
- question: "Which areas do you want to discuss for [phase name]?"
- options: Generate 3-4 phase-specific gray areas, each formatted as:
  - "[Specific area]" (label) — concrete, not generic
  - [1-2 questions this covers] (description)

**Do NOT include a "skip" or "you decide" option.** User ran this command to discuss — give them real choices.

**Examples by domain:**

For "Post Feed" (visual feature):
```
☐ Layout style — Cards vs list vs timeline? Information density?
☐ Loading behavior — Infinite scroll or pagination? Pull to refresh?
☐ Content ordering — Chronological, algorithmic, or user choice?
☐ Post metadata — What info per post? Timestamps, reactions, author?
```

For "Database backup CLI" (command-line tool):
```
☐ Output format — JSON, table, or plain text? Verbosity levels?
☐ Flag design — Short flags, long flags, or both? Required vs optional?
☐ Progress reporting — Silent, progress bar, or verbose logging?
☐ Error recovery — Fail fast, retry, or prompt for action?
```

For "Organize photo library" (organization task):
```
☐ Grouping criteria — By date, location, faces, or events?
☐ Duplicate handling — Keep best, keep all, or prompt each time?
☐ Naming convention — Original names, dates, or descriptive?
☐ Folder structure — Flat, nested by year, or by category?
```

Continue to discuss_areas with selected areas.
</step>

<step name="discuss_areas">
For each selected area, conduct a focused discussion loop.

**Philosophy: 4 questions, then check.**

Ask 4 questions per area before offering to continue or move on. Each answer often reveals the next question.

**For each area:**

1. **Announce the area:**
   ```
   Let's talk about [Area].
   ```

2. **Ask 4 questions using AskUserQuestion:**
   - header: "[Area]"
   - question: Specific decision for this area
   - options: 2-3 concrete choices (AskUserQuestion adds "Other" automatically)
   - Include "You decide" as an option when reasonable — captures Claude discretion

3. **After 4 questions, check:**
   - header: "[Area]"
   - question: "More questions about [area], or move to next?"
   - options: "More questions" / "Next area"

   If "More questions" → ask 4 more, then check again
   If "Next area" → proceed to next selected area

4. **After all areas complete:**
   - header: "Done"
   - question: "That covers [list areas]. Ready to create context?"
   - options: "Create context" / "Revisit an area"

**Question design:**
- Options should be concrete, not abstract ("Cards" not "Option A")
- Each answer should inform the next question
- If user picks "Other", receive their input, reflect it back, confirm

**Scope creep handling:**
If user mentions something outside the phase domain:
```
"[Feature] sounds like a new capability — that belongs in its own phase.
I'll note it as a deferred idea.

Back to [current area]: [return to current question]"
```

Track deferred ideas internally.
</step>

<step name="write_context">
Create CONTEXT.md capturing decisions made.

**Find or create phase directory:**

Use values from init: `phase_dir`, `phase_slug`, `padded_phase`.

If `phase_dir` is null (phase exists in roadmap but no directory):
```bash
mkdir -p ".planning/phases/${padded_phase}-${phase_slug}"
```

**File location:** `${phase_dir}/${padded_phase}-CONTEXT.md`

**Structure the content by what was discussed:**

```markdown
# Phase [X]: [Name] - Context

**Gathered:** [date]
**Status:** Ready for planning

<domain>
## Phase Boundary

[Clear statement of what this phase delivers — the scope anchor]

</domain>

<decisions>
## Implementation Decisions

### [Category 1 that was discussed]
- [Decision or preference captured]
- [Another decision if applicable]

### [Category 2 that was discussed]
- [Decision or preference captured]

### Claude's Discretion
[Areas where user said "you decide" — note that Claude has flexibility here]

</decisions>

<specifics>
## Specific Ideas

[Any particular references, examples, or "I want it like X" moments from discussion]

[If none: "No specific requirements — open to standard approaches"]

</specifics>

<deferred>
## Deferred Ideas

[Ideas that came up but belong in other phases. Don't lose them.]

[If none: "None — discussion stayed within phase scope"]

</deferred>

---

*Phase: XX-name*
*Context gathered: [date]*
```

Write file.
</step>

<step name="confirm_creation">
Present summary and next steps:

```
Created: .planning/phases/${PADDED_PHASE}-${SLUG}/${PADDED_PHASE}-CONTEXT.md

## Decisions Captured

### [Category]
- [Key decision]

### [Category]
- [Key decision]

[If deferred ideas exist:]
## Noted for Later
- [Deferred idea] — future phase

---

## ▶ Next Up

**Phase ${PHASE}: [Name]** — [Goal from ROADMAP.md]

`/GSI:plan-phase ${PHASE}`

<sub>`/clear` first → fresh context window</sub>

---

**Also available:**
- `/GSI:plan-phase ${PHASE} --skip-research` — plan without research
- Review/edit CONTEXT.md before continuing

---
```
</step>

<step name="git_commit">
Commit phase context (uses `commit_docs` from init internally):

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs(${padded_phase}): capture phase context" --files "${phase_dir}/${padded_phase}-CONTEXT.md"
```

Confirm: "Committed: docs(${padded_phase}): capture phase context"
</step>

</process>

<success_criteria>
- Phase validated against roadmap
- Gray areas identified through intelligent analysis (not generic questions)
- User selected which areas to discuss
- Each selected area explored until user satisfied
- Scope creep redirected to deferred ideas
- CONTEXT.md captures actual decisions, not vague vision
- Deferred ideas preserved for future phases
- User knows next steps
</success_criteria>

</document_content>
</document>
<document index="93">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\execute-phase.md</source>
<document_content>
﻿<thinking>auto</thinking>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**File Operations:**
- Use `mcp__desktop-commander__read_file` instead of Read
- Use `mcp__desktop-commander__write_file` instead of Write
- Use `mcp__desktop-commander__start_process` instead of Bash

**Code Search:**
- Use `mcp__code-index-mcp__search_code_advanced` instead of Grep

**NEVER USE native tools (Read, Write, Edit, Grep, Glob, Bash) when MCP alternatives exist.**

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "start_process"]
  priority: 1
  rationale: "Primary workflow for reading plans, writing execution state, and spawning subagent processes"
code_index:
  tools: ["search_code_advanced"]
  priority: 2
  rationale: "Secondary use for searching plan patterns and task definitions"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Execute all plans in a phase using wave-based parallel execution. Orchestrator stays lean — delegates plan execution to subagents.
</purpose>

<core_principle>
Orchestrator coordinates, not executes. Each subagent loads full execute-plan context. Orchestrator: discover plans → analyze deps → group waves → spawn agents → handle checkpoints → collect results.
</core_principle>

<required_reading>
Read STATE.md before any operation to load project context.

**Use MCP tool: mcp__desktop-commander__read_file**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const stateContent = await mcp__desktop-commander__read_file({
  path: ".planning/STATE.md"
});
```
</required_reading>

<process>

<step name="initialize" priority="first">
Load all context in one call using MCP process tool:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const INIT = await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js init execute-phase "${PHASE_ARG}"`,
  timeout_ms: 10000
});
```

Parse JSON for: `executor_model`, `verifier_model`, `commit_docs`, `parallelization`, `branching_strategy`, `branch_name`, `phase_found`, `phase_dir`, `phase_number`, `phase_name`, `phase_slug`, `plans`, `incomplete_plans`, `plan_count`, `incomplete_count`, `state_exists`, `roadmap_exists`.

**If `phase_found` is false:** Error — phase directory not found.
**If `plan_count` is 0:** Error — no plans found in phase.
**If `state_exists` is false but `.planning/` exists:** Offer reconstruct or continue.

When `parallelization` is false, plans within a wave execute sequentially.
</step>

<step name="handle_branching">
Check `branching_strategy` from init:

**"none":** Skip, continue on current branch.

**"phase" or "milestone":** Use pre-computed `branch_name` from init:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent for git operations
await mcp__desktop-commander__start_process({
  command: `git checkout -b "$BRANCH_NAME" 2>/dev/null || git checkout "$BRANCH_NAME"`,
  timeout_ms: 10000
});
```

All subsequent commits go to this branch. User handles merging.
</step>

<step name="validate_phase">
From init JSON: `phase_dir`, `plan_count`, `incomplete_count`.

Report: "Found {plan_count} plans in {phase_dir} ({incomplete_count} incomplete)"
</step>

<step name="discover_and_group_plans">
Load plan inventory with wave grouping in one call using MCP process tool:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const PLAN_INDEX = await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js phase-plan-index "${PHASE_NUMBER}"`,
  timeout_ms: 10000
});
```

Parse JSON for: `phase`, `plans[]` (each with `id`, `wave`, `autonomous`, `objective`, `files_modified`, `task_count`, `has_summary`), `waves` (map of wave number → plan IDs), `incomplete`, `has_checkpoints`.

**Filtering:** Skip plans where `has_summary: true`. If `--gaps-only`: also skip non-gap_closure plans. If all filtered: "No matching incomplete plans" → exit.

Report:
```
## Execution Plan

**Phase {X}: {Name}** — {total_plans} plans across {wave_count} waves

| Wave | Plans | What it builds |
|------|-------|----------------|
| 1 | 01-01, 01-02 | {from plan objectives, 3-8 words} |
| 2 | 01-03 | ... |
```
</step>

<step name="execute_waves">
Execute each wave in sequence. Within a wave: parallel if `PARALLELIZATION=true`, sequential if `false`.

**For each wave:**

1. **Describe what's being built (BEFORE spawning):**

   Read each plan's `<objective>`. Extract what's being built and why.

   **Use MCP tool: mcp__desktop-commander__read_file**

   ```
   // MCP-based equivalent for reading plan files
   const planContent = await mcp__desktop-commander__read_file({
     path: ".planning/phases/XX-name/{plan_file}"
   });
   ```

   ```
   ---
   ## Wave {N}

   **{Plan ID}: {Plan Name}**
   {2-3 sentences: what this builds, technical approach, why it matters}

   Spawning {count} agent(s)...
   ---
   ```

   - Bad: "Executing terrain generation plan"
   - Good: "Procedural terrain generator using Perlin noise — creates height maps, biome zones, and collision meshes. Required before vehicle physics can interact with ground."

2. **Spawn executor agents:**

   Pass paths only — executors read files themselves with their fresh 200k context.
   This keeps orchestrator context lean (~10-15%).

   ```
   Task(
     subagent_type="GSI-executor",
     model="{executor_model}",
     prompt="
       <objective>
       Execute plan {plan_number} of phase {phase_number}-{phase_name}.
       Commit each task atomically. Create SUMMARY.md. Update STATE.md.
       </objective>

       <execution_context>
       @~/.claude/get-shit-indexed/workflows/execute-plan.md
       @~/.claude/get-shit-indexed/templates/summary.md
       @~/.claude/get-shit-indexed/references/checkpoints.md
       @~/.claude/get-shit-indexed/references/tdd.md
       </execution_context>

       <files_to_read>
       Read these files at execution start using MCP tools:
       - Plan: {phase_dir}/{plan_file}
       - State: .planning/STATE.md
       - Config: .planning/config.json (if exists)
       </files_to_read>

       <success_criteria>
       - [ ] All tasks executed
       - [ ] Each task committed individually
       - [ ] SUMMARY.md created in plan directory
       - [ ] STATE.md updated with position and decisions
       </success_criteria>
     "
   )
   ```

3. **Wait for all agents in wave to complete.**

4. **Report completion — spot-check claims first:**

   For each SUMMARY.md:

   **Use MCP tool: mcp__desktop-commander__list_directory** to verify files exist

   ```javascript
   // MCP-based equivalent for checking file existence (80-90% token savings vs bash test commands)
   const summaryDir = await mcp__desktop-commander__list_directory({
     path: ".planning/phases/XX-name",
     depth: 1
   });
   // Check if SUMMARY.md exists in the listing
   ```

   - Verify first 2 files from `key-files.created` exist on disk with `[ -f ]`
   - Check `git log --oneline --all --grep="{phase}-{plan}"` returns ≥1 commit
   - Check for `## Self-Check: FAILED` marker

   If ANY spot-check fails: report which plan failed, route to failure handler — ask "Retry plan?" or "Continue with remaining waves?"

   If pass:
   ```
   ---
   ## Wave {N} Complete

   **{Plan ID}: {Plan Name}**
   {What was built — from SUMMARY.md}
   {Notable deviations, if any}

   {If more waves: what this enables for next wave}
   ---
   ```

   - Bad: "Wave 2 complete. Proceeding to Wave 3."
   - Good: "Terrain system complete — 3 biome types, height-based texturing, physics collision meshes. Vehicle physics (Wave 3) can now reference ground surfaces."

5. **Handle failures:**

   **Known Claude Code bug (classifyHandoffIfNeeded):** If an agent reports "failed" with error containing `classifyHandoffIfNeeded is not defined`, this is a Claude Code runtime bug — not a GSI or agent issue. The error fires in the completion handler AFTER all tool calls finish. In this case: run the same spot-checks as step 4 (SUMMARY.md exists, git commits present, no Self-Check: FAILED). If spot-checks PASS → treat as **successful**. If spot-checks FAIL → treat as real failure below.

   For real failures: report which plan failed → ask "Continue?" or "Stop?" → if continue, dependent plans may also fail. If stop, partial completion report.

6. **Execute checkpoint plans between waves** — see `<checkpoint_handling>`.
</step>

<step name="checkpoint_handling">
Plans with `autonomous: false` require user interaction.

**Flow:**

1. Spawn agent for checkpoint plan
2. Agent runs until checkpoint task or auth gate → returns structured state
3. Agent return includes: completed tasks table, current task + blocker, checkpoint type/details, what's awaited
4. **Present to user:**
   ```
   ## Checkpoint: [Type]

   **Plan:** 03-03 Dashboard Layout
   **Progress:** 2/3 tasks complete

   [Checkpoint Details from agent return]
   [Awaiting section from agent return]
   ```
5. User responds: "approved"/"done" | issue description | decision selection
6. **Spawn continuation agent (NOT resume)** using continuation-prompt.md template:
   - `{completed_tasks_table}`: From checkpoint return
   - `{resume_task_number}` + `{resume_task_name}`: Current task
   - `{user_response}`: What user provided
   - `{resume_instructions}`: Based on checkpoint type
7. Continuation agent verifies previous commits, continues from resume point
8. Repeat until plan completes or user stops

**Why fresh agent, not resume:** Resume relies on internal serialization that breaks with parallel tool calls. Fresh agents with explicit state are more reliable.

**Checkpoints in parallel waves:** Agent pauses and returns while other parallel agents may complete. Present checkpoint, spawn continuation, wait for all before next wave.
</step>

<step name="aggregate_results">
After all waves:

```markdown
## Phase {X}: {Name} Execution Complete

**Waves:** {N} | **Plans:** {M}/{total} complete

| Wave | Plans | Status |
|------|-------|--------|
| 1 | plan-01, plan-02 | ✓ Complete |
| CP | plan-03 | ✓ Verified |
| 2 | plan-04 | ✓ Complete |

### Plan Details
1. **03-01**: [one-liner from SUMMARY.md]
2. **03-02**: [one-liner from SUMMARY.md]

### Issues Encountered
[Aggregate from SUMMARYs, or "None"]
```
</step>

<step name="verify_phase_goal">
Verify phase achieved its GOAL, not just completed tasks.

```
Task(
  prompt="Verify phase {phase_number} goal achievement.
Phase directory: {phase_dir}
Phase goal: {goal from ROADMAP.md}
Check must_haves against actual codebase. Create VERIFICATION.md.",
  subagent_type="GSI-verifier",
  model="{verifier_model}"
)
```

Read status:

**Use MCP tool: mcp__code-index-mcp__search_code_advanced** or **mcp__desktop-commander__read_file**

```javascript
// MCP-based equivalent for reading verification status
const statusMatch = await mcp__code-index-mcp__search_code_advanced({
  pattern: "^status:",
  file_pattern: "*-VERIFICATION.md",
  path: ".planning/phases/XX-name"
});
```

| Status | Action |
|--------|--------|
| `passed` | → update_roadmap |
| `human_needed` | Present items for human testing, get approval or feedback |
| `gaps_found` | Present gap summary, offer `/GSI:plan-phase {phase} --gaps` |

**If human_needed:**
```
## ✓ Phase {X}: {Name} — Human Verification Required

All automated checks passed. {N} items need human testing:

[From VERIFICATION.md human_verification section]

"approved" → continue | Report issues → gap closure
```

**If gaps_found:**
```
## ⚠ Phase {X}: {Name} — Gaps Found

**Score:** {N}/{M} must-haves verified
**Report:** {phase_dir}/{phase}-VERIFICATION.md

### What's Missing
[Gap summaries from VERIFICATION.md]

---
## ▶ Next Up

`/GSI:plan-phase {X} --gaps`

<sub>`/clear` first → fresh context window</sub>

Also: Use MCP tool mcp__desktop-commander__read_file to view full report

```

Gap closure cycle: `/GSI:plan-phase {X} --gaps` reads VERIFICATION.md → creates gap plans with `gap_closure: true` → user runs `/GSI:execute-phase {X} --gaps-only` → verifier re-runs.
</step>

<step name="update_roadmap">
Mark phase complete in ROADMAP.md (date, status) using MCP process and edit tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit \"docs(phase-{X}): complete phase execution\" --files .planning/ROADMAP.md .planning/STATE.md .planning/phases/{phase_dir}/*-VERIFICATION.md .planning/REQUIREMENTS.md",
  timeout_ms: 10000
});
```
</step>

<step name="offer_next">

**If more phases:**
```
## Next Up

**Phase {X+1}: {Name}** — {Goal}

`/GSI:plan-phase {X+1}`

<sub>`/clear` first for fresh context</sub>
```

**If milestone complete:**
```
MILESTONE COMPLETE!

All {N} phases executed.

`/GSI:complete-milestone`
```
</step>

</process>

<context_efficiency>
Orchestrator: ~10-15% context. Subagents: fresh 200k each. No polling (Task blocks). No context bleed.
</context_efficiency>

<failure_handling>
- **classifyHandoffIfNeeded false failure:** Agent reports "failed" but error is `classifyHandoffIfNeeded is not defined` → Claude Code bug, not GSI. Spot-check (SUMMARY exists, commits present) → if pass, treat as success
- **Agent fails mid-plan:** Missing SUMMARY.md → report, ask user how to proceed
- **Dependency chain breaks:** Wave 1 fails → Wave 2 dependents likely fail → user chooses attempt or skip
- **All agents in wave fail:** Systemic issue → stop, report for investigation
- **Checkpoint unresolvable:** "Skip this plan?" or "Abort phase execution?" → record partial progress in STATE.md
</failure_handling>

<resumption>
Re-run `/GSI:execute-phase {phase}` → discover_plans finds completed SUMMARYs → skips them → resumes from first incomplete plan → continues wave execution.

STATE.md tracks: last completed plan, current wave, pending checkpoints.
</resumption>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**File Operations:**
- Use `mcp__desktop-commander__read_file` instead of Read
- Use `mcp__desktop-commander__write_file` instead of Write
- Use `mcp__desktop-commander__edit_block` instead of Edit
- Use `mcp__desktop-commander__list_directory` instead of ls
- Use `mcp__desktop-commander__create_directory` instead of mkdir

**Code Search:**
- Use `mcp__code-index-mcp__search_code_advanced` instead of Grep
- Use `mcp__code-index-mcp__find_files` instead of find
- Use `mcp__code-index-mcp__get_file_summary` for file analysis

**Process Operations:**
- Use `mcp__desktop-commander__start_process` instead of Bash for commands
- Use `mcp__desktop-commander__interact_with_process` for interactive processes
</tool_requirements>

</document_content>
</document>
<document index="94">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\execute-plan.md</source>
<document_content>
﻿<thinking>auto</thinking>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**File Operations:**
- Use `mcp__desktop-commander__read_file` instead of Read
- Use `mcp__desktop-commander__write_file` instead of Write
- Use `mcp__desktop-commander__edit_block` instead of Edit
- Use `mcp__desktop-commander__list_directory` instead of ls

**Code Search:**
- Use `mcp__code-index-mcp__search_code_advanced` instead of Grep
- Use `mcp__code-index-mcp__find_files` instead of find
- Use `mcp__code-index-mcp__get_file_summary` for file analysis

**Process Operations:**
- Use `mcp__desktop-commander__start_process` instead of Bash for commands

**NEVER USE native tools (Read, Write, Edit, Grep, Glob, Bash) when MCP alternatives exist.**

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<purpose>
Execute a phase prompt (PLAN.md) and create the outcome summary (SUMMARY.md).
</purpose>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "start_process"]
  priority: 1
  rationale: "Primary workflow for reading plan files, writing summaries, and running git/process commands"
code_index:
  tools: ["search_code_advanced"]
  priority: 2
  rationale: "Secondary use for searching plan patterns and discovering phase files during execution"
sequential_thinking:
  tools: ["sequentialthinking"]
  priority: 2
  rationale: "Secondary use for complex execution with multi-step verification"
tractatus_thinking:
  tools: ["tractatus_thinking"]
  priority: 2
  rationale: "Secondary use for architectural decisions requiring structural analysis"
debug_thinking:
  tools: ["debug_thinking"]
  priority: 2
  rationale: "Secondary use for systematic debugging with knowledge graph tracking"
thinking_aware:
  tools: ["sequential-thinking", "tractatus-thinking", "debug-thinking"]
  priority: 1
  rationale: "Primary for complex planning - thinking output guides MCP tool selection"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<required_reading>
Read STATE.md before any operation to load project context.
Read config.json for planning behavior settings.

@~/.claude/get-shit-indexed/references/git-integration.md
</required_reading>

<process>

<step name="init_context" priority="first">
Load execution context (uses `init execute-phase` for full context, including file contents):

```bash
INIT=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js init execute-phase "${PHASE}" --include state,config)
```

Extract from init JSON: `executor_model`, `commit_docs`, `phase_dir`, `phase_number`, `plans`, `summaries`, `incomplete_plans`.

**File contents (from --include):** `state_content`, `config_content`. Access with:
```bash
STATE_CONTENT=$(echo "$INIT" | jq -r '.state_content // empty')
CONFIG_CONTENT=$(echo "$INIT" | jq -r '.config_content // empty')
```

If `.planning/` missing: error.
</step>

<step name="identify_plan">
```bash
# Use plans/summaries from INIT JSON, or list files
ls .planning/phases/XX-name/*-PLAN.md 2>/dev/null | sort
ls .planning/phases/XX-name/*-SUMMARY.md 2>/dev/null | sort
```

Find first PLAN without matching SUMMARY. Decimal phases supported (`01.1-hotfix/`):

```bash
PHASE=$(echo "$PLAN_PATH" | grep -oE '[0-9]+(\.[0-9]+)?-[0-9]+')
# config_content already loaded via --include config in init_context
```

<if mode="yolo">
Auto-approve: `⚡ Execute {phase}-{plan}-PLAN.md [Plan X of Y for Phase Z]` → parse_segments.
</if>

<if mode="interactive" OR="custom with gates.execute_next_plan true">
Present plan identification, wait for confirmation.
</if>
</step>

<step name="record_start_time">
```bash
PLAN_START_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
PLAN_START_EPOCH=$(date +%s)
```
</step>

<step name="parse_segments">
```bash
grep -n "type=\"checkpoint" .planning/phases/XX-name/{phase}-{plan}-PLAN.md
```

**Routing by checkpoint type:**

| Checkpoints | Pattern | Execution |
|-------------|---------|-----------|
| None | A (autonomous) | Single subagent: full plan + SUMMARY + commit |
| Verify-only | B (segmented) | Segments between checkpoints. After none/human-verify → SUBAGENT. After decision/human-action → MAIN |
| Decision | C (main) | Execute entirely in main context |

**Pattern A:** init_agent_tracking → spawn Task(subagent_type="GSI-executor", model=executor_model) with prompt: execute plan at [path], autonomous, all tasks + SUMMARY + commit, follow deviation/auth rules, report: plan name, tasks, SUMMARY path, commit hash → track agent_id → wait → update tracking → report.

**Pattern B:** Execute segment-by-segment. Autonomous segments: spawn subagent for assigned tasks only (no SUMMARY/commit). Checkpoints: main context. After all segments: aggregate, create SUMMARY, commit. See segment_execution.

**Pattern C:** Execute in main using standard flow (step name="execute").

Fresh context per subagent preserves peak quality. Main context stays lean.
</step>

<step name="init_agent_tracking">
```bash
if [ ! -f .planning/agent-history.json ]; then
  echo '{"version":"1.0","max_entries":50,"entries":[]}' > .planning/agent-history.json
fi
rm -f .planning/current-agent-id.txt
if [ -f .planning/current-agent-id.txt ]; then
  INTERRUPTED_ID=$(cat .planning/current-agent-id.txt)
  echo "Found interrupted agent: $INTERRUPTED_ID"
fi
```

If interrupted: ask user to resume (Task `resume` parameter) or start fresh.

**Tracking protocol:** On spawn: write agent_id to `current-agent-id.txt`, append to agent-history.json: `{"agent_id":"[id]","task_description":"[desc]","phase":"[phase]","plan":"[plan]","segment":[num|null],"timestamp":"[ISO]","status":"spawned","completion_timestamp":null}`. On completion: status → "completed", set completion_timestamp, delete current-agent-id.txt. Prune: if entries > max_entries, remove oldest "completed" (never "spawned").

Run for Pattern A/B before spawning. Pattern C: skip.
</step>

<step name="segment_execution">
Pattern B only (verify-only checkpoints). Skip for A/C.

1. Parse segment map: checkpoint locations and types
2. Per segment:
   - Subagent route: spawn GSI-executor for assigned tasks only. Prompt: task range, plan path, read full plan for context, execute assigned tasks, track deviations, NO SUMMARY/commit. Track via agent protocol.
   - Main route: execute tasks using standard flow (step name="execute")
3. After ALL segments: aggregate files/deviations/decisions → create SUMMARY.md → commit → self-check:
   - Verify key-files.created exist on disk with `[ -f ]`
   - Check `git log --oneline --all --grep="{phase}-{plan}"` returns ≥1 commit
   - Append `## Self-Check: PASSED` or `## Self-Check: FAILED` to SUMMARY

   **Known Claude Code bug (classifyHandoffIfNeeded):** If any segment agent reports "failed" with `classifyHandoffIfNeeded is not defined`, this is a Claude Code runtime bug — not a real failure. Run spot-checks; if they pass, treat as successful.




</step>

<step name="load_prompt">
```bash
cat .planning/phases/XX-name/{phase}-{plan}-PLAN.md
```
This IS the execution instructions. Follow exactly. If plan references CONTEXT.md: honor user's vision throughout.
</step>

<step name="previous_phase_check">
```bash
ls .planning/phases/*/SUMMARY.md 2>/dev/null | sort -r | head -2 | tail -1
```
If previous SUMMARY has unresolved "Issues Encountered" or "Next Phase Readiness" blockers: AskUserQuestion(header="Previous Issues", options: "Proceed anyway" | "Address first" | "Review previous").
</step>

<step name="execute">
Deviations are normal — handle via rules below.

1. Read @context files from prompt
2. Per task:
   - `type="auto"`: if `tdd="true"` → TDD execution. Implement with deviation rules + auth gates. Verify done criteria. Commit (see task_commit). Track hash for Summary.
   - `type="checkpoint:*"`: STOP → checkpoint_protocol → wait for user → continue only after confirmation.
3. Run `<verification>` checks
4. Confirm `<success_criteria>` met
5. Document deviations in Summary
</step>

<authentication_gates>

## Authentication Gates

Auth errors during execution are NOT failures — they're expected interaction points.

**Indicators:** "Not authenticated", "Unauthorized", 401/403, "Please run {tool} login", "Set {ENV_VAR}"

**Protocol:**
1. Recognize auth gate (not a bug)
2. STOP task execution
3. Create dynamic checkpoint:human-action with exact auth steps
4. Wait for user to authenticate
5. Verify credentials work
6. Retry original task
7. Continue normally

**Example:** `vercel --yes` → "Not authenticated" → checkpoint asking user to `vercel login` → verify with `vercel whoami` → retry deploy → continue

**In Summary:** Document as normal flow under "## Authentication Gates", not as deviations.

</authentication_gates>

<deviation_rules>

## Deviation Rules

You WILL discover unplanned work. Apply automatically, track all for Summary.

| Rule | Trigger | Action | Permission |
|------|---------|--------|------------|
| **1: Bug** | Broken behavior, errors, wrong queries, type errors, security vulns, race conditions, leaks | Fix → test → verify → track `[Rule 1 - Bug]` | Auto |
| **2: Missing Critical** | Missing essentials: error handling, validation, auth, CSRF/CORS, rate limiting, indexes, logging | Add → test → verify → track `[Rule 2 - Missing Critical]` | Auto |
| **3: Blocking** | Prevents completion: missing deps, wrong types, broken imports, missing env/config/files, circular deps | Fix blocker → verify proceeds → track `[Rule 3 - Blocking]` | Auto |
| **4: Architectural** | Structural change: new DB table, schema change, new service, switching libs, breaking API, new infra | STOP → present decision (below) → track `[Rule 4 - Architectural]` | Ask user |

**Rule 1 Enhancement:** For complex bugs requiring investigation, use debug-thinking:
```
1. mcp__debug-thinking__debug_thinking(action: "create", nodeType: "problem", content: "{error}")
2. mcp__debug-thinking__debug_thinking(action: "query", queryType: "similar-problems")
3. Create hypothesis/experiment nodes based on findings
4. After fix: create solution and learning nodes
```

**Rule 4 format:**
```
⚠️ Architectural Decision Needed

Current task: [task name]
Discovery: [what prompted this]
Proposed change: [modification]
Why needed: [rationale]
Impact: [what this affects]
Alternatives: [other approaches]

Proceed with proposed change? (yes / different approach / defer)
```

**Priority:** Rule 4 (STOP) > Rules 1-3 (auto) > unsure → Rule 4
**Edge cases:** missing validation → R2 | null crash → R1 | new table → R4 | new column → R1/2
**Heuristic:** Affects correctness/security/completion? → R1-3. Maybe? → R4.

</deviation_rules>

<thinking_aware_tool_selection>

## Thinking-Aware Tool Selection

For complex tasks requiring structured thinking, select appropriate thinking server first, then use its output to guide MCP tool selection.

**Step 1: Determine if thinking server needed**

| Task Type | Thinking Server | Rationale |
|-----------|----------------|-----------|
| Complex multi-step planning | sequential-thinking | Decompose into 3-7 thoughts with revision support |
| Architectural decisions | tractatus-thinking | Analyze structure into atomic propositions |
| Bug investigation | debug-thinking | Graph-based problem tracking with knowledge base |

**Step 2: Use thinking server output to guide MCP tool selection**

```
Sequential thinking specifies: "Use CI to verify X"
→ Execute: mcp__code-index-mcp__search_code_advanced({pattern: "X"})

Tractatus export specifies: "Use CG to map Y"
→ Execute: mcp__codegraph__query_graph({cypher: "MATCH Y"})

Debug graph suggests: "Query similar problems"
→ Execute: mcp__debug-thinking__debug_thinking({action: "query", queryType: "similar-problems"})
```

**Step 3: Execute MCP operations guided by thinking context**

Batch operations based on thinking server recommendations:
- Sequential thoughts can specify multiple CI searches in sequence
- Tractatus propositions can trigger multiple CG relationship queries
- Debug hypotheses can generate multiple DC experiments

**Token Optimization:**
- One thinking session per workflow (avoid multiple calls)
- Thinking output should specify exact MCP tools to use
- Batch operations based on thinking server recommendations

**Example Flow:**
```
1. Sequential Thinking (5 thoughts)
   - Thought 1: "Need to analyze auth flow"
   - Thought 2: "Use CI to search auth middleware"
   - Thought 3: "Use CI to search session storage"
   - Thought 4: "Use DC to read auth implementation"
   - Thought 5: "Synthesize findings"

2. Execute MCP Operations (guided by thoughts 2-4)
   - CI: search_code_advanced("authenticate.*middleware")
   - CI: search_code_advanced("session.*storage")
   - DC: read_file("/src/auth.js")

3. Final Sequential Thought
   - Thought 6: "Auth flows: middleware → route guards → session storage"
```

</thinking_aware_tool_selection>

<deviation_documentation>

## Documenting Deviations

Summary MUST include deviations section. None? → `## Deviations from Plan\n\nNone - plan executed exactly as written.`

Per deviation: **[Rule N - Category] Title** — Found during: Task X | Issue | Fix | Files modified | Verification | Commit hash

End with: **Total deviations:** N auto-fixed (breakdown). **Impact:** assessment.

</deviation_documentation>

<tdd_plan_execution>
## TDD Execution

For `type: tdd` plans — RED-GREEN-REFACTOR:

1. **Infrastructure** (first TDD plan only): detect project, install framework, config, verify empty suite
2. **RED:** Read `<behavior>` → failing test(s) → run (MUST fail) → commit: `test({phase}-{plan}): add failing test for [feature]`
3. **GREEN:** Read `<implementation>` → minimal code → run (MUST pass) → commit: `feat({phase}-{plan}): implement [feature]`
4. **REFACTOR:** Clean up → tests MUST pass → commit: `refactor({phase}-{plan}): clean up [feature]`

Errors: RED doesn't fail → investigate test/existing feature. GREEN doesn't pass → debug, iterate. REFACTOR breaks → undo.

See `~/.claude/get-shit-indexed/references/tdd.md` for structure.
</tdd_plan_execution>

<task_commit>
## Task Commit Protocol

After each task (verification passed, done criteria met), commit immediately.

**1. Check:** `git status --short`

**2. Stage individually** (NEVER `git add .` or `git add -A`):
```bash
git add src/api/auth.ts
git add src/types/user.ts
```

**3. Commit type:**

| Type | When | Example |
|------|------|---------|
| `feat` | New functionality | feat(08-02): create user registration endpoint |
| `fix` | Bug fix | fix(08-02): correct email validation regex |
| `test` | Test-only (TDD RED) | test(08-02): add failing test for password hashing |
| `refactor` | No behavior change (TDD REFACTOR) | refactor(08-02): extract validation to helper |
| `perf` | Performance | perf(08-02): add database index |
| `docs` | Documentation | docs(08-02): add API docs |
| `style` | Formatting | style(08-02): format auth module |
| `chore` | Config/deps | chore(08-02): add bcrypt dependency |

**4. Format:** `{type}({phase}-{plan}): {description}` with bullet points for key changes.

**5. Record hash:**
```bash
TASK_COMMIT=$(git rev-parse --short HEAD)
TASK_COMMITS+=("Task ${TASK_NUM}: ${TASK_COMMIT}")
```

</task_commit>

<step name="checkpoint_protocol">
On `type="checkpoint:*"`: automate everything possible first. Checkpoints are for verification/decisions only.

Display: `CHECKPOINT: [Type]` box → Progress {X}/{Y} → Task name → type-specific content → `YOUR ACTION: [signal]`

| Type | Content | Resume signal |
|------|---------|---------------|
| human-verify (90%) | What was built + verification steps (commands/URLs) | "approved" or describe issues |
| decision (9%) | Decision needed + context + options with pros/cons | "Select: option-id" |
| human-action (1%) | What was automated + ONE manual step + verification plan | "done" |

After response: verify if specified. Pass → continue. Fail → inform, wait. WAIT for user — do NOT hallucinate completion.

See ~/.claude/get-shit-indexed/references/checkpoints.md for details.
</step>

<step name="checkpoint_return_for_orchestrator">
When spawned via Task and hitting checkpoint: return structured state (cannot interact with user directly).

**Required return:** 1) Completed Tasks table (hashes + files) 2) Current Task (what's blocking) 3) Checkpoint Details (user-facing content) 4) Awaiting (what's needed from user)

Orchestrator parses → presents to user → spawns fresh continuation with your completed tasks state. You will NOT be resumed. In main context: use checkpoint_protocol above.
</step>

<step name="execution_thinking_for_architectural_decisions">
For tasks marked as complex (deviation_rule: Architectural) or requiring significant analysis:

**Use mcp__sequential-thinking__sequentialthinking to decompose the decision:**

```javascript
// Step 1: Decompose architectural decision
const thoughts = [
  {
    thought: "Analyze architectural requirements and constraints",
    nextThoughtNeeded: true,
    thoughtNumber: 1,
    totalThoughts: 5
  },
  {
    thought: "Identify technical options and their tradeoffs",
    nextThoughtNeeded: true,
    thoughtNumber: 2,
    totalThoughts: 5
  },
  {
    thought: "Evaluate each option against 7-BMAD circles",
    nextThoughtNeeded: true,
    thoughtNumber: 3,
    totalThoughts: 5
  },
  {
    thought: "Generate recommendation with rationale",
    nextThoughtNeeded: true,
    thoughtNumber: 4,
    totalThoughts: 5
  },
  {
    thought: "Hypothesis: Recommended option best satisfies requirements",
    nextThoughtNeeded: false,
    thoughtNumber: 5,
    totalThoughts: 5
  }
];
```

**For structural analysis, also use tractatus-thinking:**

```javascript
// Step 2: Analyze structural implications
const analysis = await mcp__tractatus-thinking__tractatus_thinking({
  operation: "start",
  concept: "Analyze {architectural change} structure",
  depth_limit: 5
});

// Add propositions for each factor
await mcp__tractatus-thinking__tractatus_thinking({
  operation: "add",
  session_id: analysis.session_id,
  content: "{factor A must be present}",
  is_atomic: false
});

// Export for decision documentation
await mcp__tractatus-thinking__tractatus_thinking({
  operation: "export",
  session_id: analysis.session_id,
  format: "markdown"
});
```

**Present decision with thinking artifacts attached.**
</step>

<step name="verification_failure_gate">
If verification fails: STOP. Present: "Verification failed for Task [X]: [name]. Expected: [criteria]. Actual: [result]." Options: Retry | Skip (mark incomplete) | Stop (investigate). If skipped → SUMMARY "Issues Encountered".
</step>

<step name="record_completion_time">
```bash
PLAN_END_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
PLAN_END_EPOCH=$(date +%s)

DURATION_SEC=$(( PLAN_END_EPOCH - PLAN_START_EPOCH ))
DURATION_MIN=$(( DURATION_SEC / 60 ))

if [[ $DURATION_MIN -ge 60 ]]; then
  HRS=$(( DURATION_MIN / 60 ))
  MIN=$(( DURATION_MIN % 60 ))
  DURATION="${HRS}h ${MIN}m"
else
  DURATION="${DURATION_MIN} min"
fi
```
</step>

<step name="generate_user_setup">
```bash
grep -A 50 "^user_setup:" .planning/phases/XX-name/{phase}-{plan}-PLAN.md | head -50
```

If user_setup exists: create `{phase}-USER-SETUP.md` using template `~/.claude/get-shit-indexed/templates/user-setup.md`. Per service: env vars table, account setup checklist, dashboard config, local dev notes, verification commands. Status "Incomplete". Set `USER_SETUP_CREATED=true`. If empty/missing: skip.
</step>

<step name="create_summary">
Create `{phase}-{plan}-SUMMARY.md` at `.planning/phases/XX-name/`. Use `~/.claude/get-shit-indexed/templates/summary.md`.

**Frontmatter:** phase, plan, subsystem, tags | requires/provides/affects | tech-stack.added/patterns | key-files.created/modified | key-decisions | duration ($DURATION), completed ($PLAN_END_TIME date).

Title: `# Phase [X] Plan [Y]: [Name] Summary`

One-liner SUBSTANTIVE: "JWT auth with refresh rotation using jose library" not "Authentication implemented"

Include: duration, start/end times, task count, file count.

Next: more plans → "Ready for {next-plan}" | last → "Phase complete, ready for transition".
</step>

<step name="update_current_position">
Update STATE.md using GSI-tools:

```bash
# Advance plan counter (handles last-plan edge case)
node ~/.claude/get-shit-indexed/bin/GSI-tools.js state advance-plan

# Recalculate progress bar from disk state
node ~/.claude/get-shit-indexed/bin/GSI-tools.js state update-progress

# Record execution metrics
node ~/.claude/get-shit-indexed/bin/GSI-tools.js state record-metric \
  --phase "${PHASE}" --plan "${PLAN}" --duration "${DURATION}" \
  --tasks "${TASK_COUNT}" --files "${FILE_COUNT}"
```
</step>

<step name="extract_decisions_and_issues">
From SUMMARY: Extract decisions and add to STATE.md:

```bash
# Add each decision from SUMMARY key-decisions
node ~/.claude/get-shit-indexed/bin/GSI-tools.js state add-decision \
  --phase "${PHASE}" --summary "${DECISION_TEXT}" --rationale "${RATIONALE}"

# Add blockers if any found
node ~/.claude/get-shit-indexed/bin/GSI-tools.js state add-blocker "Blocker description"
```
</step>

<step name="update_session_continuity">
Update session info using GSI-tools:

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js state record-session \
  --stopped-at "Completed ${PHASE}-${PLAN}-PLAN.md" \
  --resume-file "None"
```

Keep STATE.md under 150 lines.
</step>

<step name="issues_review_gate">
If SUMMARY "Issues Encountered" ≠ "None": yolo → log and continue. Interactive → present issues, wait for acknowledgment.
</step>

<step name="update_roadmap">
More plans → update plan count, keep "In progress". Last plan → mark phase "Complete", add date.
</step>

<step name="git_commit_metadata">
Task code already committed per-task. Commit plan metadata:

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs({phase}-{plan}): complete [plan-name] plan" --files .planning/phases/XX-name/{phase}-{plan}-SUMMARY.md .planning/STATE.md .planning/ROADMAP.md
```
</step>

<step name="update_codebase_map">
If .planning/codebase/ doesn't exist: skip.

```bash
FIRST_TASK=$(git log --oneline --grep="feat({phase}-{plan}):" --grep="fix({phase}-{plan}):" --grep="test({phase}-{plan}):" --reverse | head -1 | cut -d' ' -f1)
git diff --name-only ${FIRST_TASK}^..HEAD 2>/dev/null
```

Update only structural changes: new src/ dir → STRUCTURE.md | deps → STACK.md | file pattern → CONVENTIONS.md | API client → INTEGRATIONS.md | config → STACK.md | renamed → update paths. Skip code-only/bugfix/content changes.

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "" --files .planning/codebase/*.md --amend
```
</step>

<step name="offer_next">
If `USER_SETUP_CREATED=true`: display `⚠️ USER SETUP REQUIRED` with path + env/config tasks at TOP.

```bash
ls -1 .planning/phases/[current-phase-dir]/*-PLAN.md 2>/dev/null | wc -l
ls -1 .planning/phases/[current-phase-dir]/*-SUMMARY.md 2>/dev/null | wc -l
```

| Condition | Route | Action |
|-----------|-------|--------|
| summaries < plans | **A: More plans** | Find next PLAN without SUMMARY. Yolo: auto-continue. Interactive: show next plan, suggest `/GSI:execute-phase {phase}` + `/GSI:verify-work`. STOP here. |
| summaries = plans, current < highest phase | **B: Phase done** | Show completion, suggest `/GSI:plan-phase {Z+1}` + `/GSI:verify-work {Z}` + `/GSI:discuss-phase {Z+1}` |
| summaries = plans, current = highest phase | **C: Milestone done** | Show banner, suggest `/GSI:complete-milestone` + `/GSI:verify-work` + `/GSI:add-phase` |

All routes: `/clear` first for fresh context.
</step>

</process>

<success_criteria>

- All tasks from PLAN.md completed
- All verifications pass
- USER-SETUP.md generated if user_setup in frontmatter
- SUMMARY.md created with substantive content
- STATE.md updated (position, decisions, issues, session)
- ROADMAP.md updated
- If codebase map exists: map updated with execution changes (or skipped if no significant changes)
- If USER-SETUP.md created: prominently surfaced in completion output
</success_criteria>

</document_content>
</document>
<document index="95">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\help.md</source>
<document_content>
﻿<thinking>auto</thinking>

<purpose>
Display the complete GSI command reference. Output ONLY the reference content. Do NOT add project-specific analysis, git status, next-step suggestions, or any commentary beyond the reference.
</purpose>

<code_index_mcp>
desktop_commander:
  tools: ["read_file"]
  priority: 1
  rationale: "Primary workflow for reading help reference content - minimal tool usage"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<reference>
# GSI Command Reference

**GSI** (Get Shit Indexed) creates hierarchical project plans optimized for solo agentic development with Claude Code.

## Quick Start

1. `/GSI:new-project` - Initialize project (includes research, requirements, roadmap)
2. `/GSI:plan-phase 1` - Create detailed plan for first phase
3. `/GSI:execute-phase 1` - Execute the phase

## Staying Updated

GSI evolves fast. Update periodically:

```bash
npx get-shit-indexed-cc@latest
```

## Core Workflow

```
/GSI:new-project → /GSI:plan-phase → /GSI:execute-phase → repeat
```

### Project Initialization

**`/GSI:new-project`**
Initialize new project through unified flow.

One command takes you from idea to ready-for-planning:
- Deep questioning to understand what you're building
- Optional domain research (spawns 4 parallel researcher agents)
- Requirements definition with v1/v2/out-of-scope scoping
- Roadmap creation with phase breakdown and success criteria

Creates all `.planning/` artifacts:
- `PROJECT.md` — vision and requirements
- `config.json` — workflow mode (interactive/yolo)
- `research/` — domain research (if selected)
- `REQUIREMENTS.md` — scoped requirements with REQ-IDs
- `ROADMAP.md` — phases mapped to requirements
- `STATE.md` — project memory

Usage: `/GSI:new-project`

**`/GSI:map-codebase`**
Map an existing codebase for brownfield projects.

- Analyzes codebase with parallel Explore agents
- Creates `.planning/codebase/` with 7 focused documents
- Covers stack, architecture, structure, conventions, testing, integrations, concerns
- Use before `/GSI:new-project` on existing codebases

Usage: `/GSI:map-codebase`

### Phase Planning

**`/GSI:discuss-phase <number>`**
Help articulate your vision for a phase before planning.

- Captures how you imagine this phase working
- Creates CONTEXT.md with your vision, essentials, and boundaries
- Use when you have ideas about how something should look/feel

Usage: `/GSI:discuss-phase 2`

**`/GSI:research-phase <number>`**
Comprehensive ecosystem research for niche/complex domains.

- Discovers standard stack, architecture patterns, pitfalls
- Creates RESEARCH.md with "how experts build this" knowledge
- Use for 3D, games, audio, shaders, ML, and other specialized domains
- Goes beyond "which library" to ecosystem knowledge

Usage: `/GSI:research-phase 3`

**`/GSI:list-phase-assumptions <number>`**
See what Claude is planning to do before it starts.

- Shows Claude's intended approach for a phase
- Lets you course-correct if Claude misunderstood your vision
- No files created - conversational output only

Usage: `/GSI:list-phase-assumptions 3`

**`/GSI:plan-phase <number>`**
Create detailed execution plan for a specific phase.

- Generates `.planning/phases/XX-phase-name/XX-YY-PLAN.md`
- Breaks phase into concrete, actionable tasks
- Includes verification criteria and success measures
- Multiple plans per phase supported (XX-01, XX-02, etc.)

Usage: `/GSI:plan-phase 1`
Result: Creates `.planning/phases/01-foundation/01-01-PLAN.md`

### Execution

**`/GSI:execute-phase <phase-number>`**
Execute all plans in a phase.

- Groups plans by wave (from frontmatter), executes waves sequentially
- Plans within each wave run in parallel via Task tool
- Verifies phase goal after all plans complete
- Updates REQUIREMENTS.md, ROADMAP.md, STATE.md

Usage: `/GSI:execute-phase 5`

### Quick Mode

**`/GSI:quick`**
Execute small, ad-hoc tasks with GSI guarantees but skip optional agents.

Quick mode uses the same system with a shorter path:
- Spawns planner + executor (skips researcher, checker, verifier)
- Quick tasks live in `.planning/quick/` separate from planned phases
- Updates STATE.md tracking (not ROADMAP.md)

Use when you know exactly what to do and the task is small enough to not need research or verification.

Usage: `/GSI:quick`
Result: Creates `.planning/quick/NNN-slug/PLAN.md`, `.planning/quick/NNN-slug/SUMMARY.md`

### Roadmap Management

**`/GSI:add-phase <description>`**
Add new phase to end of current milestone.

- Appends to ROADMAP.md
- Uses next sequential number
- Updates phase directory structure

Usage: `/GSI:add-phase "Add admin dashboard"`

**`/GSI:insert-phase <after> <description>`**
Insert urgent work as decimal phase between existing phases.

- Creates intermediate phase (e.g., 7.1 between 7 and 8)
- Useful for discovered work that must happen mid-milestone
- Maintains phase ordering

Usage: `/GSI:insert-phase 7 "Fix critical auth bug"`
Result: Creates Phase 7.1

**`/GSI:remove-phase <number>`**
Remove a future phase and renumber subsequent phases.

- Deletes phase directory and all references
- Renumbers all subsequent phases to close the gap
- Only works on future (unstarted) phases
- Git commit preserves historical record

Usage: `/GSI:remove-phase 17`
Result: Phase 17 deleted, phases 18-20 become 17-19

### Milestone Management

**`/GSI:new-milestone <name>`**
Start a new milestone through unified flow.

- Deep questioning to understand what you're building next
- Optional domain research (spawns 4 parallel researcher agents)
- Requirements definition with scoping
- Roadmap creation with phase breakdown

Mirrors `/GSI:new-project` flow for brownfield projects (existing PROJECT.md).

Usage: `/GSI:new-milestone "v2.0 Features"`

**`/GSI:complete-milestone <version>`**
Archive completed milestone and prepare for next version.

- Creates MILESTONES.md entry with stats
- Archives full details to milestones/ directory
- Creates git tag for the release
- Prepares workspace for next version

Usage: `/GSI:complete-milestone 1.0.0`

### Progress Tracking

**`/GSI:progress`**
Check project status and intelligently route to next action.

- Shows visual progress bar and completion percentage
- Summarizes recent work from SUMMARY files
- Displays current position and what's next
- Lists key decisions and open issues
- Offers to execute next plan or create it if missing
- Detects 100% milestone completion

Usage: `/GSI:progress`

### Session Management

**`/GSI:resume-work`**
Resume work from previous session with full context restoration.

- Reads STATE.md for project context
- Shows current position and recent progress
- Offers next actions based on project state

Usage: `/GSI:resume-work`

**`/GSI:pause-work`**
Create context handoff when pausing work mid-phase.

- Creates .continue-here file with current state
- Updates STATE.md session continuity section
- Captures in-progress work context

Usage: `/GSI:pause-work`

### Debugging

**`/GSI:debug [issue description]`**
Systematic debugging with persistent state across context resets.

- Gathers symptoms through adaptive questioning
- Creates `.planning/debug/[slug].md` to track investigation
- Investigates using scientific method (evidence → hypothesis → test)
- Survives `/clear` — run `/GSI:debug` with no args to resume
- Archives resolved issues to `.planning/debug/resolved/`

Usage: `/GSI:debug "login button doesn't work"`
Usage: `/GSI:debug` (resume active session)

### Todo Management

**`/GSI:add-todo [description]`**
Capture idea or task as todo from current conversation.

- Extracts context from conversation (or uses provided description)
- Creates structured todo file in `.planning/todos/pending/`
- Infers area from file paths for grouping
- Checks for duplicates before creating
- Updates STATE.md todo count

Usage: `/GSI:add-todo` (infers from conversation)
Usage: `/GSI:add-todo Add auth token refresh`

**`/GSI:check-todos [area]`**
List pending todos and select one to work on.

- Lists all pending todos with title, area, age
- Optional area filter (e.g., `/GSI:check-todos api`)
- Loads full context for selected todo
- Routes to appropriate action (work now, add to phase, brainstorm)
- Moves todo to done/ when work begins

Usage: `/GSI:check-todos`
Usage: `/GSI:check-todos api`

### User Acceptance Testing

**`/GSI:verify-work [phase]`**
Validate built features through conversational UAT.

- Extracts testable deliverables from SUMMARY.md files
- Presents tests one at a time (yes/no responses)
- Automatically diagnoses failures and creates fix plans
- Ready for re-execution if issues found

Usage: `/GSI:verify-work 3`

### Milestone Auditing

**`/GSI:audit-milestone [version]`**
Audit milestone completion against original intent.

- Reads all phase VERIFICATION.md files
- Checks requirements coverage
- Spawns integration checker for cross-phase wiring
- Creates MILESTONE-AUDIT.md with gaps and tech debt

Usage: `/GSI:audit-milestone`

**`/GSI:plan-milestone-gaps`**
Create phases to close gaps identified by audit.

- Reads MILESTONE-AUDIT.md and groups gaps into phases
- Prioritizes by requirement priority (must/should/nice)
- Adds gap closure phases to ROADMAP.md
- Ready for `/GSI:plan-phase` on new phases

Usage: `/GSI:plan-milestone-gaps`

### Configuration

**`/GSI:settings`**
Configure workflow toggles and model profile interactively.

- Toggle researcher, plan checker, verifier agents
- Select model profile (quality/balanced/budget)
- Updates `.planning/config.json`

Usage: `/GSI:settings`

**`/GSI:set-profile <profile>`**
Quick switch model profile for GSI agents.

- `quality` — Opus everywhere except verification
- `balanced` — Opus for planning, Sonnet for execution (default)
- `budget` — Sonnet for writing, Haiku for research/verification

Usage: `/GSI:set-profile budget`

### Utility Commands

**`/GSI:help`**
Show this command reference.

**`/GSI:update`**
Update GSI to latest version with changelog preview.

- Shows installed vs latest version comparison
- Displays changelog entries for versions you've missed
- Highlights breaking changes
- Confirms before running install
- Better than raw `npx get-shit-indexed-cc`

Usage: `/GSI:update`

**`/GSI:join-discord`**
Join the GSI Discord community.

- Get help, share what you're building, stay updated
- Connect with other GSI users

Usage: `/GSI:join-discord`

## Files & Structure

```
.planning/
├── PROJECT.md            # Project vision
├── ROADMAP.md            # Current phase breakdown
├── STATE.md              # Project memory & context
├── config.json           # Workflow mode & gates
├── todos/                # Captured ideas and tasks
│   ├── pending/          # Todos waiting to be worked on
│   └── done/             # Completed todos
├── debug/                # Active debug sessions
│   └── resolved/         # Archived resolved issues
├── codebase/             # Codebase map (brownfield projects)
│   ├── STACK.md          # Languages, frameworks, dependencies
│   ├── ARCHITECTURE.md   # Patterns, layers, data flow
│   ├── STRUCTURE.md      # Directory layout, key files
│   ├── CONVENTIONS.md    # Coding standards, naming
│   ├── TESTING.md        # Test setup, patterns
│   ├── INTEGRATIONS.md   # External services, APIs
│   └── CONCERNS.md       # Tech debt, known issues
└── phases/
    ├── 01-foundation/
    │   ├── 01-01-PLAN.md
    │   └── 01-01-SUMMARY.md
    └── 02-core-features/
        ├── 02-01-PLAN.md
        └── 02-01-SUMMARY.md
```

## Workflow Modes

Set during `/GSI:new-project`:

**Interactive Mode**

- Confirms each major decision
- Pauses at checkpoints for approval
- More guidance throughout

**YOLO Mode**

- Auto-approves most decisions
- Executes plans without confirmation
- Only stops for critical checkpoints

Change anytime by editing `.planning/config.json`

## Planning Configuration

Configure how planning artifacts are managed in `.planning/config.json`:

**`planning.commit_docs`** (default: `true`)
- `true`: Planning artifacts committed to git (standard workflow)
- `false`: Planning artifacts kept local-only, not committed

When `commit_docs: false`:
- Add `.planning/` to your `.gitignore`
- Useful for OSS contributions, client projects, or keeping planning private
- All planning files still work normally, just not tracked in git

**`planning.search_gitignored`** (default: `false`)
- `true`: Add `--no-ignore` to broad ripgrep searches
- Only needed when `.planning/` is gitignored and you want project-wide searches to include it

Example config:
```json
{
  "planning": {
    "commit_docs": false,
    "search_gitignored": true
  }
}
```

## Common Workflows

**Starting a new project:**

```
/GSI:new-project        # Unified flow: questioning → research → requirements → roadmap
/clear
/GSI:plan-phase 1       # Create plans for first phase
/clear
/GSI:execute-phase 1    # Execute all plans in phase
```

**Resuming work after a break:**

```
/GSI:progress  # See where you left off and continue
```

**Adding urgent mid-milestone work:**

```
/GSI:insert-phase 5 "Critical security fix"
/GSI:plan-phase 5.1
/GSI:execute-phase 5.1
```

**Completing a milestone:**

```
/GSI:complete-milestone 1.0.0
/clear
/GSI:new-milestone  # Start next milestone (questioning → research → requirements → roadmap)
```

**Capturing ideas during work:**

```
/GSI:add-todo                    # Capture from conversation context
/GSI:add-todo Fix modal z-index  # Capture with explicit description
/GSI:check-todos                 # Review and work on todos
/GSI:check-todos api             # Filter by area
```

**Debugging an issue:**

```
/GSI:debug "form submission fails silently"  # Start debug session
# ... investigation happens, context fills up ...
/clear
/GSI:debug                                    # Resume from where you left off
```

## Getting Help

- Read `.planning/PROJECT.md` for project vision
- Read `.planning/STATE.md` for current context
- Check `.planning/ROADMAP.md` for phase status
- Run `/GSI:progress` to check where you're up to
</reference>

</document_content>
</document>
<document index="96">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\insert-phase.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "list_directory"]
  priority: 1
  rationale: "Primary workflow for reading roadmap, writing updated files, and listing phase directories"
code_index:
  tools: ["find_files"]
  priority: 2
  rationale: "Secondary use for discovering phase files in target directory"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Insert a decimal phase for urgent work discovered mid-milestone between existing integer phases. Uses decimal numbering (72.1, 72.2, etc.) to preserve the logical sequence of planned phases while accommodating urgent insertions without renumbering the entire roadmap.
</purpose>

<required_reading>
Read all files referenced by the invoking prompt's execution_context before starting.
</required_reading>

<process>

<step name="parse_arguments">
Parse the command arguments:
- First argument: integer phase number to insert after
- Remaining arguments: phase description

Example: `/GSI:insert-phase 72 Fix critical auth bug`
-> after = 72
-> description = "Fix critical auth bug"

If arguments missing:

```
ERROR: Both phase number and description required
Usage: /GSI:insert-phase <after> <description>
Example: /GSI:insert-phase 72 Fix critical auth bug
```

Exit.

Validate first argument is an integer.
</step>

<step name="init_context">
Load phase operation context:

```bash
INIT=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js init phase-op "${after_phase}")
```

Check `roadmap_exists` from init JSON. If false:
```
ERROR: No roadmap found (.planning/ROADMAP.md)
```
Exit.
</step>

<step name="insert_phase">
**Delegate the phase insertion to GSI-tools:**

```bash
RESULT=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js phase insert "${after_phase}" "${description}")
```

The CLI handles:
- Verifying target phase exists in ROADMAP.md
- Calculating next decimal phase number (checking existing decimals on disk)
- Generating slug from description
- Creating the phase directory (`.planning/phases/{N.M}-{slug}/`)
- Inserting the phase entry into ROADMAP.md after the target phase with (INSERTED) marker

Extract from result: `phase_number`, `after_phase`, `name`, `slug`, `directory`.
</step>

<step name="update_project_state">
Update STATE.md to reflect the inserted phase:

1. Read `.planning/STATE.md`
2. Under "## Accumulated Context" → "### Roadmap Evolution" add entry:
   ```
   - Phase {decimal_phase} inserted after Phase {after_phase}: {description} (URGENT)
   ```

If "Roadmap Evolution" section doesn't exist, create it.
</step>

<step name="completion">
Present completion summary:

```
Phase {decimal_phase} inserted after Phase {after_phase}:
- Description: {description}
- Directory: .planning/phases/{decimal-phase}-{slug}/
- Status: Not planned yet
- Marker: (INSERTED) - indicates urgent work

Roadmap updated: .planning/ROADMAP.md
Project state updated: .planning/STATE.md

---

## Next Up

**Phase {decimal_phase}: {description}** -- urgent insertion

`/GSI:plan-phase {decimal_phase}`

<sub>`/clear` first -> fresh context window</sub>

---

**Also available:**
- Review insertion impact: Check if Phase {next_integer} dependencies still make sense
- Review roadmap

---
```
</step>

</process>

<anti_patterns>

- Don't use this for planned work at end of milestone (use /GSI:add-phase)
- Don't insert before Phase 1 (decimal 0.1 makes no sense)
- Don't renumber existing phases
- Don't modify the target phase content
- Don't create plans yet (that's /GSI:plan-phase)
- Don't commit changes (user decides when to commit)
</anti_patterns>

<success_criteria>
Phase insertion is complete when:

- [ ] `GSI-tools phase insert` executed successfully
- [ ] Phase directory created
- [ ] Roadmap updated with new phase entry (includes "(INSERTED)" marker)
- [ ] STATE.md updated with roadmap evolution note
- [ ] User informed of next steps and dependency implications
</success_criteria>

</document_content>
</document>
<document index="97">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\list-phase-assumptions.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file"]
  priority: 1
  rationale: "Primary workflow for reading phase plans and writing assumption lists"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Surface Claude's assumptions about a phase before planning, enabling users to correct misconceptions early.

Key difference from discuss-phase: This is ANALYSIS of what Claude thinks, not INTAKE of what user knows. No file output - purely conversational to prompt discussion.
</purpose>

<process>

<step name="validate_phase" priority="first">
Phase number: $ARGUMENTS (required)

**If argument missing:**

```
Error: Phase number required.

Usage: /GSI:list-phase-assumptions [phase-number]
Example: /GSI:list-phase-assumptions 3
```

Exit workflow.

**If argument provided:**
Validate phase exists in roadmap:

```bash
cat .planning/ROADMAP.md | grep -i "Phase ${PHASE}"
```

**If phase not found:**

```
Error: Phase ${PHASE} not found in roadmap.

Available phases:
[list phases from roadmap]
```

Exit workflow.

**If phase found:**
Parse phase details from roadmap:

- Phase number
- Phase name
- Phase description/goal
- Any scope details mentioned

Continue to analyze_phase.
</step>

<step name="analyze_phase">
Based on roadmap description and project context, identify assumptions across five areas:

**1. Technical Approach:**
What libraries, frameworks, patterns, or tools would Claude use?
- "I'd use X library because..."
- "I'd follow Y pattern because..."
- "I'd structure this as Z because..."

**2. Implementation Order:**
What would Claude build first, second, third?
- "I'd start with X because it's foundational"
- "Then Y because it depends on X"
- "Finally Z because..."

**3. Scope Boundaries:**
What's included vs excluded in Claude's interpretation?
- "This phase includes: A, B, C"
- "This phase does NOT include: D, E, F"
- "Boundary ambiguities: G could go either way"

**4. Risk Areas:**
Where does Claude expect complexity or challenges?
- "The tricky part is X because..."
- "Potential issues: Y, Z"
- "I'd watch out for..."

**5. Dependencies:**
What does Claude assume exists or needs to be in place?
- "This assumes X from previous phases"
- "External dependencies: Y, Z"
- "This will be consumed by..."

Be honest about uncertainty. Mark assumptions with confidence levels:
- "Fairly confident: ..." (clear from roadmap)
- "Assuming: ..." (reasonable inference)
- "Unclear: ..." (could go multiple ways)
</step>

<step name="present_assumptions">
Present assumptions in a clear, scannable format:

```
## My Assumptions for Phase ${PHASE}: ${PHASE_NAME}

### Technical Approach
[List assumptions about how to implement]

### Implementation Order
[List assumptions about sequencing]

### Scope Boundaries
**In scope:** [what's included]
**Out of scope:** [what's excluded]
**Ambiguous:** [what could go either way]

### Risk Areas
[List anticipated challenges]

### Dependencies
**From prior phases:** [what's needed]
**External:** [third-party needs]
**Feeds into:** [what future phases need from this]

---

**What do you think?**

Are these assumptions accurate? Let me know:
- What I got right
- What I got wrong
- What I'm missing
```

Wait for user response.
</step>

<step name="gather_feedback">
**If user provides corrections:**

Acknowledge the corrections:

```
Key corrections:
- [correction 1]
- [correction 2]

This changes my understanding significantly. [Summarize new understanding]
```

**If user confirms assumptions:**

```
Assumptions validated.
```

Continue to offer_next.
</step>

<step name="offer_next">
Present next steps:

```
What's next?
1. Discuss context (/GSI:discuss-phase ${PHASE}) - Let me ask you questions to build comprehensive context
2. Plan this phase (/GSI:plan-phase ${PHASE}) - Create detailed execution plans
3. Re-examine assumptions - I'll analyze again with your corrections
4. Done for now
```

Wait for user selection.

If "Discuss context": Note that CONTEXT.md will incorporate any corrections discussed here
If "Plan this phase": Proceed knowing assumptions are understood
If "Re-examine": Return to analyze_phase with updated understanding
</step>

</process>

<success_criteria>
- Phase number validated against roadmap
- Assumptions surfaced across five areas: technical approach, implementation order, scope, risks, dependencies
- Confidence levels marked where appropriate
- "What do you think?" prompt presented
- User feedback acknowledged
- Clear next steps offered
</success_criteria>

</document_content>
</document>
<document index="98">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\map-codebase.md</source>
<document_content>
﻿<thinking>auto</thinking>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**File Operations:**
- Use `mcp__desktop-commander__read_file` instead of Read
- Use `mcp__desktop-commander__write_file` instead of Write
- Use `mcp__desktop-commander__list_directory` instead of ls
- Use `mcp__desktop-commander__create_directory` instead of mkdir

**Code Search:**
- Use `mcp__code-index-mcp__find_files` instead of find
- Use `mcp__code-index-mcp__search_code_advanced` instead of Grep
- Use `mcp__code-index-mcp__get_file_summary` for file analysis

**Process Operations:**
- Use `mcp__desktop-commander__start_process` instead of Bash for commands

**NEVER USE native tools (Read, Write, Edit, Grep, Glob, Bash) when MCP alternatives exist.**

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<purpose>
Orchestrate parallel codebase mapper agents to analyze codebase and produce structured documents in .planning/codebase/

Each agent has fresh context, explores a specific focus area, and **writes documents directly**. The orchestrator only receives confirmation + line counts, then writes a summary.

Output: .planning/codebase/ folder with 7 structured documents about the codebase state.
</purpose>

<code_index_mcp>
desktop_commander:
  tools: ["list_directory", "read_file", "write_file", "start_process"]
  priority: 1
  rationale: "Primary workflow for file system operations - listing directories, reading/writing files, spawning subprocesses for agent tracking"
code_index:
  tools: ["find_files"]
  priority: 2
  rationale: "Secondary use for discovering specific file patterns in codebase (e.g., finding all test files)"
native:
  priority: 3
  rationale: "Fallback only - all operations use MCP tools for 80-90% token savings"
</code_index_mcp>

<philosophy>
**Why dedicated mapper agents:**
- Fresh context per domain (no token contamination)
- Agents write documents directly (no context transfer back to orchestrator)
- Orchestrator only summarizes what was created (minimal context usage)
- Faster execution (agents run simultaneously)

**Document quality over length:**
Include enough detail to be useful as reference. Prioritize practical examples (especially code patterns) over arbitrary brevity.

**Always include file paths:**
Documents are reference material for Claude when planning/executing. Always include actual file paths formatted with backticks: `src/services/user.ts`.
</philosophy>

<wave_architecture>
**Wave-based spawning for parallel agent orchestration**

**Purpose:** Enable safe concurrent agent execution without overwhelming MCP servers or hitting API rate limits

**Wave Structure:**

- **Wave 1:** Independent parallel agents (tech, arch, quality, concerns)
  - No dependencies between agents
  - Can run simultaneously within rate limits
  
- **Wave 2:** Dependent refinement agents (if Wave 1 incomplete)
  - Spawned only if Wave 1 agents need additional analysis
  - Typically 0-2 agents based on Wave 1 results
  
- **Wave 3:** Synthesis agents (cross-cutting analysis)
  - Combines results from previous waves
  - Final integration and verification

**Rate Limiting Parameters:**

```yaml
rate_limiting:
  enabled: true
  max_concurrent_agents: 3      # Maximum agents running simultaneously
  inter_wave_delay_ms: 2000        # Delay between waves
  stagger_delay_ms: 500            # Delay between agent spawns within a wave
  wave_timeout_seconds: 300         # Maximum wait time per wave
```

**Configuration Source:**
- Read from `.planning/config.json` -> `rate_limiting` section
- Fallback to defaults if config missing
- Log actual values used in wave execution

**Adaptive Behavior:**
- On 429/rate_limit errors: increase stagger_delay_ms by 2x
- Back off max_concurrent_agents by 1 on errors
- Max stagger: 5000ms, Min concurrent: 1
- Log all adaptations to wave-history.json
</wave_architecture>

<process>

<step name="init_context" priority="first">
Load codebase mapping context:

```bash
INIT=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js init map-codebase)
```

Extract from init JSON: `mapper_model`, `commit_docs`, `codebase_dir`, `existing_maps`, `has_maps`, `codebase_dir_exists`.
</step>

<step name="check_existing">
Check if .planning/codebase/ already exists using `has_maps` from init context.

If `codebase_dir_exists` is true:
```bash
ls -la .planning/codebase/
```

**If exists:**

```
.planning/codebase/ already exists with these documents:
[List files found]

What's next?
1. Refresh - Delete existing and remap codebase
2. Update - Keep existing, only update specific documents
3. Skip - Use existing codebase map as-is
```

Wait for user response.

If "Refresh": Delete .planning/codebase/, continue to create_structure
If "Update": Ask which documents to update, continue to spawn_agents (filtered)
If "Skip": Exit workflow

**If doesn't exist:**
Continue to create_structure.
</step>

<step name="create_structure">
Create .planning/codebase/ directory:

```bash
mkdir -p .planning/codebase
```

**Expected output files:**
- STACK.md (from tech mapper)
- INTEGRATIONS.md (from tech mapper)
- ARCHITECTURE.md (from arch mapper)
- STRUCTURE.md (from arch mapper)
- CONVENTIONS.md (from quality mapper)
- TESTING.md (from quality mapper)
- CONCERNS.md (from concerns mapper)

Continue to spawn_agents.
</step>

<step name="spawn_agents">
Spawn 4 parallel GSI-codebase-mapper agents using **wave-based execution** with rate limiting.

**Wave-Based Architecture:**

Agents are organized into waves to prevent overwhelming MCP servers and API rate limits:

- **Wave 1 (Independent agents):** Tech, Architecture, Quality, Concerns mappers
  - All 4 agents can run in parallel (no dependencies between them)
  - Maximum concurrent agents: 3 (rate limit protection)
  - Stagger delay: 500ms between each spawn

- **Wave 2 (Dependent agents):** Optional refinement agents
  - Only run if Wave 1 produces incomplete results
  - Depends on Wave 1 documents for context

- **Wave 3 (Synthesis agents):** Optional cross-cutting analysis
  - Analyzes relationships between Wave 1 documents
  - Depends on all Wave 1 and Wave 2 completions

**Rate Limiting Parameters:**

```json
{
  "rate_limiting": {
    "max_concurrent_agents": 3,
    "inter_wave_delay_ms": 2000,
    "stagger_delay_ms": 500,
    "wave_timeout_seconds": 300
  }
}
```

**Wave Execution Flow:**

1. **Pre-wave check:** Verify `.planning/agent-history.json` exists (see init_agent_tracking step)
2. **Generate agent IDs:** Create unique IDs for each agent: `{focus}-{datestamp}`
3. **Launch Wave 1:** Spawn agents with 500ms stagger delay
4. **Track each spawn:** Update agent-history.json with `status: "running"`
5. **Monitor Wave 1:** Wait for all agents in wave to complete
6. **Wave completion:** Report status before starting next wave
7. **Launch Wave 2:** If needed, after Wave 1 fully completes
8. **Continue** until all waves complete

**Agent ID Format:**

```
mapper-tech-20250211-192500
mapper-arch-20250211-192500
mapper-quality-20250211-192500
mapper-concerns-20250211-192500
```

**Tracking Operations:**

On spawn:
```bash
# Generate unique agent ID
AGENT_ID="mapper-${FOCUS}-$(date -u +%Y%m%d-%H%M%S)"

# Add to agent-history.json
node ~/.claude/get-shit-indexed/bin/GSI-tools.js track-agent "$AGENT_ID" "$FOCUS" "spawned"

# Write current agent ID for resumption
echo "$AGENT_ID" > .planning/current-agent-id.txt
```

On completion:
```bash
# Update agent status in history
node ~/.claude/get-shit-indexed/bin/GSI-tools.js track-agent "$AGENT_ID" "$FOCUS" "completed" --docs "$DOCUMENTS"

# Clean up current agent ID
rm -f .planning/current-agent-id.txt
```

Use Task tool with `subagent_type="GSI-codebase-mapper"`, `model="{mapper_model}"`, and `run_in_background=true` for parallel execution.

**CRITICAL:** Use the dedicated `GSI-codebase-mapper` agent, NOT `Explore`. The mapper agent writes documents directly.

**Agent 1: Tech Focus**

Task tool parameters:
```
subagent_type: "GSI-codebase-mapper"
model: "{mapper_model}"
run_in_background: true
description: "Map codebase tech stack"
```

Prompt:
```
Focus: tech

Analyze this codebase for technology stack and external integrations.

Write these documents to .planning/codebase/:
- STACK.md - Languages, runtime, frameworks, dependencies, configuration
- INTEGRATIONS.md - External APIs, databases, auth providers, webhooks

Explore thoroughly. Write documents directly using templates. Return confirmation only.
```

**Agent 2: Architecture Focus**

Task tool parameters:
```
subagent_type: "GSI-codebase-mapper"
model: "{mapper_model}"
run_in_background: true
description: "Map codebase architecture"
```

Prompt:
```
Focus: arch

Analyze this codebase architecture and directory structure.

Write these documents to .planning/codebase/:
- ARCHITECTURE.md - Pattern, layers, data flow, abstractions, entry points
- STRUCTURE.md - Directory layout, key locations, naming conventions

Explore thoroughly. Write documents directly using templates. Return confirmation only.
```

**Agent 3: Quality Focus**

Task tool parameters:
```
subagent_type: "GSI-codebase-mapper"
model: "{mapper_model}"
run_in_background: true
description: "Map codebase conventions"
```

Prompt:
```
Focus: quality

Analyze this codebase for coding conventions and testing patterns.

Write these documents to .planning/codebase/:
- CONVENTIONS.md - Code style, naming, patterns, error handling
- TESTING.md - Framework, structure, mocking, coverage

Explore thoroughly. Write documents directly using templates. Return confirmation only.
```

**Agent 4: Concerns Focus**

Task tool parameters:
```
subagent_type: "GSI-codebase-mapper"
model: "{mapper_model}"
run_in_background: true
description: "Map codebase concerns"
```

Prompt:
```
Focus: concerns

Analyze this codebase for technical debt, known issues, and areas of concern.

Write this document to .planning/codebase/:
- CONCERNS.md - Tech debt, bugs, security, performance, fragile areas

Explore thoroughly. Write document directly using template. Return confirmation only.
```

Continue to collect_confirmations.
</step>

<step name="init_agent_tracking">
Initialize agent tracking system.

**Create tracking file if not exists:**

```bash
# Check if agent-history.json exists
test -f .planning/agent-history.json || echo '{"agents":[]}' > .planning/agent-history.json
```

**Tracking data structure:**

```json
{
  "agents": [
    {
      "agent_id": "mapper-tech-20250211-192500",
      "task_description": "Map codebase tech stack",
      "focus": "tech",
      "phase": "02-workflow-integration",
      "plan": "02-02",
      "wave": 1,
      "status": "spawned",
      "spawn_time": "2025-02-11T19:25:00Z",
      "completion_time": null,
      "documents_created": ["STACK.md", "INTEGRATIONS.md"],
      "exit_status": null
    }
  ],
  "last_updated": "2025-02-11T19:25:00Z"
}
```

**Status values:**
- `spawned` - Agent created but not yet running
- `running` - Agent is actively working
- `completed` - Agent finished successfully
- `failed` - Agent encountered an error
- `timed_out` - Agent exceeded wave timeout

**Current agent tracking file:**

```bash
# Write current agent ID for resumption support
echo "mapper-tech-$(date -u +%Y%m%d-%H%M%S)" > .planning/current-agent-id.txt
```

Continue to spawn_agents.
</step>

<step name="collect_confirmations">
Wait for agents to complete using **wave-based collection**.

**Wave Completion Checking:**

For each wave, verify completion before starting the next wave:

```bash
# Check agent status for all agents in current wave
node ~/.claude/get-shit-indexed/bin/GSI-tools.js check-wave-complete --wave 1

# Expected output:
# Wave 1 Status:
# - mapper-tech-20250211-192500: completed
# - mapper-arch-20250211-192505: completed
# - mapper-quality-20250211-192510: completed
# - mapper-concerns-20250211-192515: completed
# 
# Wave 1 complete: 4/4 agents finished
```

**Wave Completion Criteria:**
- All agents in wave have status `completed` or `failed`
- No agents still `running` or `spawned`
- Wave timeout (300s) not exceeded

**Staggered Launch Timing:**

Agents are launched with 500ms delays between each spawn:

```bash
# Spawn Agent 1
spawn_agent "tech" && sleep 0.5

# Spawn Agent 2
spawn_agent "arch" && sleep 0.5

# Spawn Agent 3
spawn_agent "quality" && sleep 0.5

# Spawn Agent 4
spawn_agent "concerns"
```

This prevents overwhelming MCP servers with simultaneous requests.

**Wave Reporting Format:**

After each wave completes, report:

```
=== Wave 1 Complete ===

Agents spawned: 4
Completed: 4
Failed: 0
Duration: 2m 15s

Agent Results:
- mapper-tech-20250211-192500: SUCCESS (STACK.md: 145 lines, INTEGRATIONS.md: 89 lines)
- mapper-arch-20250211-192505: SUCCESS (ARCHITECTURE.md: 178 lines, STRUCTURE.md: 134 lines)
- mapper-quality-20250211-192510: SUCCESS (CONVENTIONS.md: 112 lines, TESTING.md: 98 lines)
- mapper-concerns-20250211-192515: SUCCESS (CONCERNS.md: 67 lines)

Wave 1 summary: 7 documents created, 823 total lines

Ready for Wave 2 (if needed)
```

**Read each agent's output file to collect confirmations.**

Expected confirmation format from each agent:**
```
## Mapping Complete

**Focus:** {focus}
**Documents written:**
- `.planning/codebase/{DOC1}.md` ({N} lines)
- `.planning/codebase/{DOC2}.md` ({N} lines)

Ready for orchestrator summary.
```

**What you receive:** Just file paths, line counts, and agent status. NOT document contents.

**Wave progression:**
- Wave 1 completes → Report results → Check if Wave 2 needed
- Wave 2 (if needed) → Launch → Report results
- All waves complete → Continue to verify_output

If any agent failed, note the failure and continue with successful documents.

**Handling Failed Agents:**

```bash
# Check for failed agents in wave
node ~/.claude/get-shit-indexed/bin/GSI-tools.js list-failed-agents --wave 1

# If any failed, offer retry option:
# "Agent mapper-quality-xxx failed. Retry? [y/N]"
```

Continue to verify_output.
</step>

<step name="verify_output">
Verify all documents created successfully:

```bash
ls -la .planning/codebase/
wc -l .planning/codebase/*.md
```

**Verification checklist:**
- All 7 documents exist
- No empty documents (each should have >20 lines)

If any documents missing or empty, note which agents may have failed.

Continue to scan_for_secrets.
</step>

<step name="scan_for_secrets">
**CRITICAL SECURITY CHECK:** Scan output files for accidentally leaked secrets before committing.

Run secret pattern detection:

```bash
# Check for common API key patterns in generated docs
grep -E '(sk-[a-zA-Z0-9]{20,}|sk_live_[a-zA-Z0-9]+|sk_test_[a-zA-Z0-9]+|ghp_[a-zA-Z0-9]{36}|gho_[a-zA-Z0-9]{36}|glpat-[a-zA-Z0-9_-]+|AKIA[A-Z0-9]{16}|xox[baprs]-[a-zA-Z0-9-]+|-----BEGIN.*PRIVATE KEY|eyJ[a-zA-Z0-9_-]+\.eyJ[a-zA-Z0-9_-]+\.)' .planning/codebase/*.md 2>/dev/null && SECRETS_FOUND=true || SECRETS_FOUND=false
```

**If SECRETS_FOUND=true:**

```
⚠️  SECURITY ALERT: Potential secrets detected in codebase documents!

Found patterns that look like API keys or tokens in:
[show grep output]

This would expose credentials if committed.

**Action required:**
1. Review the flagged content above
2. If these are real secrets, they must be removed before committing
3. Consider adding sensitive files to Claude Code "Deny" permissions

Pausing before commit. Reply "safe to proceed" if the flagged content is not actually sensitive, or edit the files first.
```

Wait for user confirmation before continuing to commit_codebase_map.

**If SECRETS_FOUND=false:**

Continue to commit_codebase_map.
</step>

<step name="commit_codebase_map">
Commit the codebase map:

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs: map existing codebase" --files .planning/codebase/*.md
```

Continue to offer_next.
</step>

<step name="offer_next">
Present completion summary and next steps.

**Get line counts:**
```bash
wc -l .planning/codebase/*.md
```

**Output format:**

```
Codebase mapping complete.

Created .planning/codebase/:
- STACK.md ([N] lines) - Technologies and dependencies
- ARCHITECTURE.md ([N] lines) - System design and patterns
- STRUCTURE.md ([N] lines) - Directory layout and organization
- CONVENTIONS.md ([N] lines) - Code style and patterns
- TESTING.md ([N] lines) - Test structure and practices
- INTEGRATIONS.md ([N] lines) - External services and APIs
- CONCERNS.md ([N] lines) - Technical debt and issues


---

## ▶ Next Up

**Initialize project** — use codebase context for planning

`/GSI:new-project`

<sub>`/clear` first → fresh context window</sub>

---

**Also available:**
- Re-run mapping: `/GSI:map-codebase`
- Review specific file: `cat .planning/codebase/STACK.md`
- Edit any document before proceeding

---
```

End workflow.
</step>

</process>

<success_criteria>
- .planning/codebase/ directory created
- 4 parallel GSI-codebase-mapper agents spawned with run_in_background=true
- Agents write documents directly (orchestrator doesn't receive document contents)
- Read agent output files to collect confirmations
- All 7 codebase documents exist
- Clear completion summary with line counts
- User offered clear next steps in GSI style
</success_criteria>

</document_content>
</document>
<document index="99">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\new-milestone.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "list_directory", "create_directory"]
  priority: 1
  rationale: "Primary workflow for reading roadmap, writing milestone files, listing phases, and creating directories"
code_index:
  tools: ["find_files"]
  priority: 2
  rationale: "Secondary use for discovering existing phase directories"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>
Start a new milestone cycle for an existing project. Loads project context, gathers milestone goals (from MILESTONE-CONTEXT.md or conversation), updates PROJECT.md and STATE.md, optionally runs parallel research, defines scoped requirements with REQ-IDs, spawns the roadmapper to create phased execution plan, and commits all artifacts. Brownfield equivalent of new-project.

</purpose>

<required_reading>

Read all files referenced by the invoking prompt's execution_context before starting.

</required_reading>

<process>

## 1. Load Context

- Read PROJECT.md (existing project, validated requirements, decisions)
- Read MILESTONES.md (what shipped previously)
- Read STATE.md (pending todos, blockers)
- Check for MILESTONE-CONTEXT.md (from /GSI:discuss-milestone)

## 2. Gather Milestone Goals

**If MILESTONE-CONTEXT.md exists:**
- Use features and scope from discuss-milestone
- Present summary for confirmation

**If no context file:**
- Present what shipped in last milestone
- Ask: "What do you want to build next?"
- Use AskUserQuestion to explore features, priorities, constraints, scope

## 3. Determine Milestone Version

- Parse last version from MILESTONES.md
- Suggest next version (v1.0 → v1.1, or v2.0 for major)
- Confirm with user

## 4. Update PROJECT.md

Add/update:

```markdown
## Current Milestone: v[X.Y] [Name]

**Goal:** [One sentence describing milestone focus]

**Target features:**
- [Feature 1]
- [Feature 2]
- [Feature 3]
```

Update Active requirements section and "Last updated" footer.

## 5. Update STATE.md

```markdown
## Current Position

Phase: Not started (defining requirements)
Plan: —
Status: Defining requirements
Last activity: [today] — Milestone v[X.Y] started
```

Keep Accumulated Context section from previous milestone.

## 6. Cleanup and Commit

Delete MILESTONE-CONTEXT.md if exists (consumed).

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs: start milestone v[X.Y] [Name]" --files .planning/PROJECT.md .planning/STATE.md
```

## 7. Load Context and Resolve Models

```bash
INIT=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js init new-milestone)
```

Extract from init JSON: `researcher_model`, `synthesizer_model`, `roadmapper_model`, `commit_docs`, `research_enabled`, `current_milestone`, `project_exists`, `roadmap_exists`.

## 8. Research Decision

AskUserQuestion: "Research the domain ecosystem for new features before defining requirements?"
- "Research first (Recommended)" — Discover patterns, features, architecture for NEW capabilities
- "Skip research" — Go straight to requirements

**Persist choice to config** (so future `/GSI:plan-phase` honors it):

```bash
# If "Research first": persist true
node ~/.claude/get-shit-indexed/bin/GSI-tools.js config-set workflow.research true

# If "Skip research": persist false
node ~/.claude/get-shit-indexed/bin/GSI-tools.js config-set workflow.research false
```

**If "Research first":**

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► RESEARCHING
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

◆ Spawning 4 researchers in parallel...
  → Stack, Features, Architecture, Pitfalls
```

```bash
mkdir -p .planning/research
```

Spawn 4 parallel GSI-project-researcher agents. Each uses this template with dimension-specific fields:

**Common structure for all 4 researchers:**
```
Task(prompt="
<research_type>Project Research — {DIMENSION} for [new features].</research_type>

<milestone_context>
SUBSEQUENT MILESTONE — Adding [target features] to existing app.
{EXISTING_CONTEXT}
Focus ONLY on what's needed for the NEW features.
</milestone_context>

<question>{QUESTION}</question>

<project_context>[PROJECT.md summary]</project_context>

<downstream_consumer>{CONSUMER}</downstream_consumer>

<quality_gate>{GATES}</quality_gate>

<output>
Write to: .planning/research/{FILE}
Use template: ~/.claude/get-shit-indexed/templates/research-project/{FILE}
</output>
", subagent_type="GSI-project-researcher", model="{researcher_model}", description="{DIMENSION} research")
```

**Dimension-specific fields:**

| Field | Stack | Features | Architecture | Pitfalls |
|-------|-------|----------|-------------|----------|
| EXISTING_CONTEXT | Existing validated capabilities (DO NOT re-research): [from PROJECT.md] | Existing features (already built): [from PROJECT.md] | Existing architecture: [from PROJECT.md or codebase map] | Focus on common mistakes when ADDING these features to existing system |
| QUESTION | What stack additions/changes are needed for [new features]? | How do [target features] typically work? Expected behavior? | How do [target features] integrate with existing architecture? | Common mistakes when adding [target features] to [domain]? |
| CONSUMER | Specific libraries with versions for NEW capabilities, integration points, what NOT to add | Table stakes vs differentiators vs anti-features, complexity noted, dependencies on existing | Integration points, new components, data flow changes, suggested build order | Warning signs, prevention strategy, which phase should address it |
| GATES | Versions current (verify with Context7), rationale explains WHY, integration considered | Categories clear, complexity noted, dependencies identified | Integration points identified, new vs modified explicit, build order considers deps | Pitfalls specific to adding these features, integration pitfalls covered, prevention actionable |
| FILE | STACK.md | FEATURES.md | ARCHITECTURE.md | PITFALLS.md |

After all 4 complete, spawn synthesizer:

```
Task(prompt="
Synthesize research outputs into SUMMARY.md.

Read: .planning/research/STACK.md, FEATURES.md, ARCHITECTURE.md, PITFALLS.md

Write to: .planning/research/SUMMARY.md
Use template: ~/.claude/get-shit-indexed/templates/research-project/SUMMARY.md
Commit after writing.
", subagent_type="GSI-research-synthesizer", model="{synthesizer_model}", description="Synthesize research")
```

Display key findings from SUMMARY.md:
```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► RESEARCH COMPLETE ✓
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

**Stack additions:** [from SUMMARY.md]
**Feature table stakes:** [from SUMMARY.md]
**Watch Out For:** [from SUMMARY.md]
```

**If "Skip research":** Continue to Step 9.

## 9. Define Requirements

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► DEFINING REQUIREMENTS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

Read PROJECT.md: core value, current milestone goals, validated requirements (what exists).

**If research exists:** Read FEATURES.md, extract feature categories.

Present features by category:
```
## [Category 1]
**Table stakes:** Feature A, Feature B
**Differentiators:** Feature C, Feature D
**Research notes:** [any relevant notes]
```

**If no research:** Gather requirements through conversation. Ask: "What are the main things users need to do with [new features]?" Clarify, probe for related capabilities, group into categories.

**Scope each category** via AskUserQuestion (multiSelect: true):
- "[Feature 1]" — [brief description]
- "[Feature 2]" — [brief description]
- "None for this milestone" — Defer entire category

Track: Selected → this milestone. Unselected table stakes → future. Unselected differentiators → out of scope.

**Identify gaps** via AskUserQuestion:
- "No, research covered it" — Proceed
- "Yes, let me add some" — Capture additions

**Generate REQUIREMENTS.md:**
- v1 Requirements grouped by category (checkboxes, REQ-IDs)
- Future Requirements (deferred)
- Out of Scope (explicit exclusions with reasoning)
- Traceability section (empty, filled by roadmap)

**REQ-ID format:** `[CATEGORY]-[NUMBER]` (AUTH-01, NOTIF-02). Continue numbering from existing.

**Requirement quality criteria:**

Good requirements are:
- **Specific and testable:** "User can reset password via email link" (not "Handle password reset")
- **User-centric:** "User can X" (not "System does Y")
- **Atomic:** One capability per requirement (not "User can login and manage profile")
- **Independent:** Minimal dependencies on other requirements

Present FULL requirements list for confirmation:

```
## Milestone v[X.Y] Requirements

### [Category 1]
- [ ] **CAT1-01**: User can do X
- [ ] **CAT1-02**: User can do Y

### [Category 2]
- [ ] **CAT2-01**: User can do Z

Does this capture what you're building? (yes / adjust)
```

If "adjust": Return to scoping.

**Commit requirements:**
```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs: define milestone v[X.Y] requirements" --files .planning/REQUIREMENTS.md
```

## 10. Create Roadmap

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► CREATING ROADMAP
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

◆ Spawning roadmapper...
```

**Starting phase number:** Read MILESTONES.md for last phase number. Continue from there (v1.0 ended at phase 5 → v1.1 starts at phase 6).

```
Task(prompt="
<planning_context>
@.planning/PROJECT.md
@.planning/REQUIREMENTS.md
@.planning/research/SUMMARY.md (if exists)
@.planning/config.json
@.planning/MILESTONES.md
</planning_context>

<instructions>
Create roadmap for milestone v[X.Y]:
1. Start phase numbering from [N]
2. Derive phases from THIS MILESTONE's requirements only
3. Map every requirement to exactly one phase
4. Derive 2-5 success criteria per phase (observable user behaviors)
5. Validate 100% coverage
6. Write files immediately (ROADMAP.md, STATE.md, update REQUIREMENTS.md traceability)
7. Return ROADMAP CREATED with summary

Write files first, then return.
</instructions>
", subagent_type="GSI-roadmapper", model="{roadmapper_model}", description="Create roadmap")
```

**Handle return:**

**If `## ROADMAP BLOCKED`:** Present blocker, work with user, re-spawn.

**If `## ROADMAP CREATED`:** Read ROADMAP.md, present inline:

```
## Proposed Roadmap

**[N] phases** | **[X] requirements mapped** | All covered ✓

| # | Phase | Goal | Requirements | Success Criteria |
|---|-------|------|--------------|------------------|
| [N] | [Name] | [Goal] | [REQ-IDs] | [count] |

### Phase Details

**Phase [N]: [Name]**
Goal: [goal]
Requirements: [REQ-IDs]
Success criteria:
1. [criterion]
2. [criterion]
```

**Ask for approval** via AskUserQuestion:
- "Approve" — Commit and continue
- "Adjust phases" — Tell me what to change
- "Review full file" — Show raw ROADMAP.md

**If "Adjust":** Get notes, re-spawn roadmapper with revision context, loop until approved.
**If "Review":** Display raw ROADMAP.md, re-ask.

**Commit roadmap** (after approval):
```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs: create milestone v[X.Y] roadmap ([N] phases)" --files .planning/ROADMAP.md .planning/STATE.md .planning/REQUIREMENTS.md
```

## 11. Done

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► MILESTONE INITIALIZED ✓
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

**Milestone v[X.Y]: [Name]**

| Artifact       | Location                    |
|----------------|-----------------------------|
| Project        | `.planning/PROJECT.md`      |
| Research       | `.planning/research/`       |
| Requirements   | `.planning/REQUIREMENTS.md` |
| Roadmap        | `.planning/ROADMAP.md`      |

**[N] phases** | **[X] requirements** | Ready to build ✓

## ▶ Next Up

**Phase [N]: [Phase Name]** — [Goal]

`/GSI:discuss-phase [N]` — gather context and clarify approach

<sub>`/clear` first → fresh context window</sub>

Also: `/GSI:plan-phase [N]` — skip discussion, plan directly
```

</process>

<success_criteria>
- [ ] PROJECT.md updated with Current Milestone section
- [ ] STATE.md reset for new milestone
- [ ] MILESTONE-CONTEXT.md consumed and deleted (if existed)
- [ ] Research completed (if selected) — 4 parallel agents, milestone-aware
- [ ] Requirements gathered and scoped per category
- [ ] REQUIREMENTS.md created with REQ-IDs
- [ ] GSI-roadmapper spawned with phase numbering context
- [ ] Roadmap files written immediately (not draft)
- [ ] User feedback incorporated (if any)
- [ ] ROADMAP.md phases continue from previous milestone
- [ ] All commits made (if planning docs committed)
- [ ] User knows next step: `/GSI:discuss-phase [N]`

**Atomic commits:** Each phase commits its artifacts immediately.
</success_criteria>

</document_content>
</document>
<document index="100">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\new-project.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "list_directory", "create_directory"]
  priority: 1
  rationale: "Primary workflow for reading templates, writing project files, creating planning directories, and listing contents"
code_index:
  tools: ["find_files"]
  priority: 2
  rationale: "Secondary use for discovering codebase structure during initialization"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Initialize a new project through unified flow: questioning, research (optional), requirements, roadmap. This is the most leveraged moment in any project — deep questioning here means better plans, better execution, better outcomes. One workflow takes you from idea to ready-for-planning.
</purpose>

<required_reading>
Read all files referenced by the invoking prompt's execution_context before starting.
</required_reading>

<auto_mode>
## Auto Mode Detection

Check if `--auto` flag is present in $ARGUMENTS.

**If auto mode:**
- Skip brownfield mapping offer (assume greenfield)
- Skip deep questioning (extract context from provided document)
- Config questions still required (Step 5)
- After config: run Steps 6-9 automatically with smart defaults:
  - Research: Always yes
  - Requirements: Include all table stakes + features from provided document
  - Requirements approval: Auto-approve
  - Roadmap approval: Auto-approve

**Document requirement:**
Auto mode requires an idea document via @ reference (e.g., `/GSI:new-project --auto @prd.md`). If no document provided, error:

```
Error: --auto requires an idea document via @ reference.

Usage: /GSI:new-project --auto @your-idea.md

The document should describe what you want to build.
```
</auto_mode>

<process>

## 1. Setup

**MANDATORY FIRST STEP — Execute these checks before ANY user interaction:**

```bash
INIT=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js init new-project)
```

Parse JSON for: `researcher_model`, `synthesizer_model`, `roadmapper_model`, `commit_docs`, `project_exists`, `has_codebase_map`, `planning_exists`, `has_existing_code`, `has_package_file`, `is_brownfield`, `needs_codebase_map`, `has_git`.

**If `project_exists` is true:** Error — project already initialized. Use `/GSI:progress`.

**If `has_git` is false:** Initialize git:
```bash
git init
```

## 2. Brownfield Offer

**If auto mode:** Skip to Step 4 (assume greenfield, synthesize PROJECT.md from provided document).

**If `needs_codebase_map` is true** (from init — existing code detected but no codebase map):

Use AskUserQuestion:
- header: "Existing Code"
- question: "I detected existing code in this directory. Would you like to map the codebase first?"
- options:
  - "Map codebase first" — Run /GSI:map-codebase to understand existing architecture (Recommended)
  - "Skip mapping" — Proceed with project initialization

**If "Map codebase first":**
```
Run `/GSI:map-codebase` first, then return to `/GSI:new-project`
```
Exit command.

**If "Skip mapping" OR `needs_codebase_map` is false:** Continue to Step 3.

## 3. Deep Questioning

**If auto mode:** Skip. Extract project context from provided document instead and proceed to Step 4.

**Display stage banner:**

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► QUESTIONING
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**Open the conversation:**

Ask inline (freeform, NOT AskUserQuestion):

"What do you want to build?"

Wait for their response. This gives you the context needed to ask intelligent follow-up questions.

**Follow the thread:**

Based on what they said, ask follow-up questions that dig into their response. Use AskUserQuestion with options that probe what they mentioned — interpretations, clarifications, concrete examples.

Keep following threads. Each answer opens new threads to explore. Ask about:
- What excited them
- What problem sparked this
- What they mean by vague terms
- What it would actually look like
- What's already decided

Consult `questioning.md` for techniques:
- Challenge vagueness
- Make abstract concrete
- Surface assumptions
- Find edges
- Reveal motivation

**Check context (background, not out loud):**

As you go, mentally check the context checklist from `questioning.md`. If gaps remain, weave questions naturally. Don't suddenly switch to checklist mode.

**Decision gate:**

When you could write a clear PROJECT.md, use AskUserQuestion:

- header: "Ready?"
- question: "I think I understand what you're after. Ready to create PROJECT.md?"
- options:
  - "Create PROJECT.md" — Let's move forward
  - "Keep exploring" — I want to share more / ask me more

If "Keep exploring" — ask what they want to add, or identify gaps and probe naturally.

Loop until "Create PROJECT.md" selected.

## 4. Write PROJECT.md

**If auto mode:** Synthesize from provided document. No "Ready?" gate was shown — proceed directly to commit.

Synthesize all context into `.planning/PROJECT.md` using the template from `templates/project.md`.

**For greenfield projects:**

Initialize requirements as hypotheses:

```markdown
## Requirements

### Validated

(None yet — ship to validate)

### Active

- [ ] [Requirement 1]
- [ ] [Requirement 2]
- [ ] [Requirement 3]

### Out of Scope

- [Exclusion 1] — [why]
- [Exclusion 2] — [why]
```

All Active requirements are hypotheses until shipped and validated.

**For brownfield projects (codebase map exists):**

Infer Validated requirements from existing code:

1. Read `.planning/codebase/ARCHITECTURE.md` and `STACK.md`
2. Identify what the codebase already does
3. These become the initial Validated set

```markdown
## Requirements

### Validated

- ✓ [Existing capability 1] — existing
- ✓ [Existing capability 2] — existing
- ✓ [Existing capability 3] — existing

### Active

- [ ] [New requirement 1]
- [ ] [New requirement 2]

### Out of Scope

- [Exclusion 1] — [why]
```

**Key Decisions:**

Initialize with any decisions made during questioning:

```markdown
## Key Decisions

| Decision | Rationale | Outcome |
|----------|-----------|---------|
| [Choice from questioning] | [Why] | — Pending |
```

**Last updated footer:**

```markdown
---
*Last updated: [date] after initialization*
```

Do not compress. Capture everything gathered.

**Commit PROJECT.md:**

```bash
mkdir -p .planning
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs: initialize project" --files .planning/PROJECT.md
```

## 5. Workflow Preferences

**Round 1 — Core workflow settings (4 questions):**

```
questions: [
  {
    header: "Mode",
    question: "How do you want to work?",
    multiSelect: false,
    options: [
      { label: "YOLO (Recommended)", description: "Auto-approve, just execute" },
      { label: "Interactive", description: "Confirm at each step" }
    ]
  },
  {
    header: "Depth",
    question: "How thorough should planning be?",
    multiSelect: false,
    options: [
      { label: "Quick", description: "Ship fast (3-5 phases, 1-3 plans each)" },
      { label: "Standard", description: "Balanced scope and speed (5-8 phases, 3-5 plans each)" },
      { label: "Comprehensive", description: "Thorough coverage (8-12 phases, 5-10 plans each)" }
    ]
  },
  {
    header: "Execution",
    question: "Run plans in parallel?",
    multiSelect: false,
    options: [
      { label: "Parallel (Recommended)", description: "Independent plans run simultaneously" },
      { label: "Sequential", description: "One plan at a time" }
    ]
  },
  {
    header: "Git Tracking",
    question: "Commit planning docs to git?",
    multiSelect: false,
    options: [
      { label: "Yes (Recommended)", description: "Planning docs tracked in version control" },
      { label: "No", description: "Keep .planning/ local-only (add to .gitignore)" }
    ]
  }
]
```

**Round 2 — Workflow agents:**

These spawn additional agents during planning/execution. They add tokens and time but improve quality.

| Agent | When it runs | What it does |
|-------|--------------|--------------|
| **Researcher** | Before planning each phase | Investigates domain, finds patterns, surfaces gotchas |
| **Plan Checker** | After plan is created | Verifies plan actually achieves the phase goal |
| **Verifier** | After phase execution | Confirms must-haves were delivered |

All recommended for important projects. Skip for quick experiments.

```
questions: [
  {
    header: "Research",
    question: "Research before planning each phase? (adds tokens/time)",
    multiSelect: false,
    options: [
      { label: "Yes (Recommended)", description: "Investigate domain, find patterns, surface gotchas" },
      { label: "No", description: "Plan directly from requirements" }
    ]
  },
  {
    header: "Plan Check",
    question: "Verify plans will achieve their goals? (adds tokens/time)",
    multiSelect: false,
    options: [
      { label: "Yes (Recommended)", description: "Catch gaps before execution starts" },
      { label: "No", description: "Execute plans without verification" }
    ]
  },
  {
    header: "Verifier",
    question: "Verify work satisfies requirements after each phase? (adds tokens/time)",
    multiSelect: false,
    options: [
      { label: "Yes (Recommended)", description: "Confirm deliverables match phase goals" },
      { label: "No", description: "Trust execution, skip verification" }
    ]
  },
  {
    header: "Model Profile",
    question: "Which AI models for planning agents?",
    multiSelect: false,
    options: [
      { label: "Balanced (Recommended)", description: "Sonnet for most agents — good quality/cost ratio" },
      { label: "Quality", description: "Opus for research/roadmap — higher cost, deeper analysis" },
      { label: "Budget", description: "Haiku where possible — fastest, lowest cost" }
    ]
  }
]
```

Create `.planning/config.json` with all settings:

```json
{
  "mode": "yolo|interactive",
  "depth": "quick|standard|comprehensive",
  "parallelization": true|false,
  "commit_docs": true|false,
  "model_profile": "quality|balanced|budget",
  "workflow": {
    "research": true|false,
    "plan_check": true|false,
    "verifier": true|false
  }
}
```

**If commit_docs = No:**
- Set `commit_docs: false` in config.json
- Add `.planning/` to `.gitignore` (create if needed)

**If commit_docs = Yes:**
- No additional gitignore entries needed

**Commit config.json:**

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "chore: add project config" --files .planning/config.json
```

**Note:** Run `/GSI:settings` anytime to update these preferences.

## 5.5. Resolve Model Profile

Use models from init: `researcher_model`, `synthesizer_model`, `roadmapper_model`.

## 6. Research Decision

**If auto mode:** Default to "Research first" without asking.

Use AskUserQuestion:
- header: "Research"
- question: "Research the domain ecosystem before defining requirements?"
- options:
  - "Research first (Recommended)" — Discover standard stacks, expected features, architecture patterns
  - "Skip research" — I know this domain well, go straight to requirements

**If "Research first":**

Display stage banner:
```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► RESEARCHING
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Researching [domain] ecosystem...
```

Create research directory:
```bash
mkdir -p .planning/research
```

**Determine milestone context:**

Check if this is greenfield or subsequent milestone:
- If no "Validated" requirements in PROJECT.md → Greenfield (building from scratch)
- If "Validated" requirements exist → Subsequent milestone (adding to existing app)

Display spawning indicator:
```
◆ Spawning 4 researchers in parallel...
  → Stack research
  → Features research
  → Architecture research
  → Pitfalls research
```

Spawn 4 parallel GSI-project-researcher agents with rich context:

```
Task(prompt="First, read ~/.claude/agents/GSI-project-researcher.md for your role and instructions.

<research_type>
Project Research — Stack dimension for [domain].
</research_type>

<milestone_context>
[greenfield OR subsequent]

Greenfield: Research the standard stack for building [domain] from scratch.
Subsequent: Research what's needed to add [target features] to an existing [domain] app. Don't re-research the existing system.
</milestone_context>

<question>
What's the standard 2025 stack for [domain]?
</question>

<project_context>
[PROJECT.md summary - core value, constraints, what they're building]
</project_context>

<downstream_consumer>
Your STACK.md feeds into roadmap creation. Be prescriptive:
- Specific libraries with versions
- Clear rationale for each choice
- What NOT to use and why
</downstream_consumer>

<quality_gate>
- [ ] Versions are current (verify with Context7/official docs, not training data)
- [ ] Rationale explains WHY, not just WHAT
- [ ] Confidence levels assigned to each recommendation
</quality_gate>

<output>
Write to: .planning/research/STACK.md
Use template: ~/.claude/get-shit-indexed/templates/research-project/STACK.md
</output>
", subagent_type="general-purpose", model="{researcher_model}", description="Stack research")

Task(prompt="First, read ~/.claude/agents/GSI-project-researcher.md for your role and instructions.

<research_type>
Project Research — Features dimension for [domain].
</research_type>

<milestone_context>
[greenfield OR subsequent]

Greenfield: What features do [domain] products have? What's table stakes vs differentiating?
Subsequent: How do [target features] typically work? What's expected behavior?
</milestone_context>

<question>
What features do [domain] products have? What's table stakes vs differentiating?
</question>

<project_context>
[PROJECT.md summary]
</project_context>

<downstream_consumer>
Your FEATURES.md feeds into requirements definition. Categorize clearly:
- Table stakes (must have or users leave)
- Differentiators (competitive advantage)
- Anti-features (things to deliberately NOT build)
</downstream_consumer>

<quality_gate>
- [ ] Categories are clear (table stakes vs differentiators vs anti-features)
- [ ] Complexity noted for each feature
- [ ] Dependencies between features identified
</quality_gate>

<output>
Write to: .planning/research/FEATURES.md
Use template: ~/.claude/get-shit-indexed/templates/research-project/FEATURES.md
</output>
", subagent_type="general-purpose", model="{researcher_model}", description="Features research")

Task(prompt="First, read ~/.claude/agents/GSI-project-researcher.md for your role and instructions.

<research_type>
Project Research — Architecture dimension for [domain].
</research_type>

<milestone_context>
[greenfield OR subsequent]

Greenfield: How are [domain] systems typically structured? What are major components?
Subsequent: How do [target features] integrate with existing [domain] architecture?
</milestone_context>

<question>
How are [domain] systems typically structured? What are major components?
</question>

<project_context>
[PROJECT.md summary]
</project_context>

<downstream_consumer>
Your ARCHITECTURE.md informs phase structure in roadmap. Include:
- Component boundaries (what talks to what)
- Data flow (how information moves)
- Suggested build order (dependencies between components)
</downstream_consumer>

<quality_gate>
- [ ] Components clearly defined with boundaries
- [ ] Data flow direction explicit
- [ ] Build order implications noted
</quality_gate>

<output>
Write to: .planning/research/ARCHITECTURE.md
Use template: ~/.claude/get-shit-indexed/templates/research-project/ARCHITECTURE.md
</output>
", subagent_type="general-purpose", model="{researcher_model}", description="Architecture research")

Task(prompt="First, read ~/.claude/agents/GSI-project-researcher.md for your role and instructions.

<research_type>
Project Research — Pitfalls dimension for [domain].
</research_type>

<milestone_context>
[greenfield OR subsequent]

Greenfield: What do [domain] projects commonly get wrong? Critical mistakes?
Subsequent: What are common mistakes when adding [target features] to [domain]?
</milestone_context>

<question>
What do [domain] projects commonly get wrong? Critical mistakes?
</question>

<project_context>
[PROJECT.md summary]
</project_context>

<downstream_consumer>
Your PITFALLS.md prevents mistakes in roadmap/planning. For each pitfall:
- Warning signs (how to detect early)
- Prevention strategy (how to avoid)
- Which phase should address it
</downstream_consumer>

<quality_gate>
- [ ] Pitfalls are specific to this domain (not generic advice)
- [ ] Prevention strategies are actionable
- [ ] Phase mapping included where relevant
</quality_gate>

<output>
Write to: .planning/research/PITFALLS.md
Use template: ~/.claude/get-shit-indexed/templates/research-project/PITFALLS.md
</output>
", subagent_type="general-purpose", model="{researcher_model}", description="Pitfalls research")
```

After all 4 agents complete, spawn synthesizer to create SUMMARY.md:

```
Task(prompt="
<task>
Synthesize research outputs into SUMMARY.md.
</task>

<research_files>
Read these files:
- .planning/research/STACK.md
- .planning/research/FEATURES.md
- .planning/research/ARCHITECTURE.md
- .planning/research/PITFALLS.md
</research_files>

<output>
Write to: .planning/research/SUMMARY.md
Use template: ~/.claude/get-shit-indexed/templates/research-project/SUMMARY.md
Commit after writing.
</output>
", subagent_type="GSI-research-synthesizer", model="{synthesizer_model}", description="Synthesize research")
```

Display research complete banner and key findings:
```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► RESEARCH COMPLETE ✓
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

## Key Findings

**Stack:** [from SUMMARY.md]
**Table Stakes:** [from SUMMARY.md]
**Watch Out For:** [from SUMMARY.md]

Files: `.planning/research/`
```

**If "Skip research":** Continue to Step 7.

## 7. Define Requirements

Display stage banner:
```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► DEFINING REQUIREMENTS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**Load context:**

Read PROJECT.md and extract:
- Core value (the ONE thing that must work)
- Stated constraints (budget, timeline, tech limitations)
- Any explicit scope boundaries

**If research exists:** Read research/FEATURES.md and extract feature categories.

**If auto mode:**
- Auto-include all table stakes features (users expect these)
- Include features explicitly mentioned in provided document
- Auto-defer differentiators not mentioned in document
- Skip per-category AskUserQuestion loops
- Skip "Any additions?" question
- Skip requirements approval gate
- Generate REQUIREMENTS.md and commit directly

**Present features by category (interactive mode only):**

```
Here are the features for [domain]:

## Authentication
**Table stakes:**
- Sign up with email/password
- Email verification
- Password reset
- Session management

**Differentiators:**
- Magic link login
- OAuth (Google, GitHub)
- 2FA

**Research notes:** [any relevant notes]

---

## [Next Category]
...
```

**If no research:** Gather requirements through conversation instead.

Ask: "What are the main things users need to be able to do?"

For each capability mentioned:
- Ask clarifying questions to make it specific
- Probe for related capabilities
- Group into categories

**Scope each category:**

For each category, use AskUserQuestion:

- header: "[Category name]"
- question: "Which [category] features are in v1?"
- multiSelect: true
- options:
  - "[Feature 1]" — [brief description]
  - "[Feature 2]" — [brief description]
  - "[Feature 3]" — [brief description]
  - "None for v1" — Defer entire category

Track responses:
- Selected features → v1 requirements
- Unselected table stakes → v2 (users expect these)
- Unselected differentiators → out of scope

**Identify gaps:**

Use AskUserQuestion:
- header: "Additions"
- question: "Any requirements research missed? (Features specific to your vision)"
- options:
  - "No, research covered it" — Proceed
  - "Yes, let me add some" — Capture additions

**Validate core value:**

Cross-check requirements against Core Value from PROJECT.md. If gaps detected, surface them.

**Generate REQUIREMENTS.md:**

Create `.planning/REQUIREMENTS.md` with:
- v1 Requirements grouped by category (checkboxes, REQ-IDs)
- v2 Requirements (deferred)
- Out of Scope (explicit exclusions with reasoning)
- Traceability section (empty, filled by roadmap)

**REQ-ID format:** `[CATEGORY]-[NUMBER]` (AUTH-01, CONTENT-02)

**Requirement quality criteria:**

Good requirements are:
- **Specific and testable:** "User can reset password via email link" (not "Handle password reset")
- **User-centric:** "User can X" (not "System does Y")
- **Atomic:** One capability per requirement (not "User can login and manage profile")
- **Independent:** Minimal dependencies on other requirements

Reject vague requirements. Push for specificity:
- "Handle authentication" → "User can log in with email/password and stay logged in across sessions"
- "Support sharing" → "User can share post via link that opens in recipient's browser"

**Present full requirements list (interactive mode only):**

Show every requirement (not counts) for user confirmation:

```
## v1 Requirements

### Authentication
- [ ] **AUTH-01**: User can create account with email/password
- [ ] **AUTH-02**: User can log in and stay logged in across sessions
- [ ] **AUTH-03**: User can log out from any page

### Content
- [ ] **CONT-01**: User can create posts with text
- [ ] **CONT-02**: User can edit their own posts

[... full list ...]

---

Does this capture what you're building? (yes / adjust)
```

If "adjust": Return to scoping.

**Commit requirements:**

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs: define v1 requirements" --files .planning/REQUIREMENTS.md
```

## 8. Create Roadmap

Display stage banner:
```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► CREATING ROADMAP
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

◆ Spawning roadmapper...
```

Spawn GSI-roadmapper agent with context:

```
Task(prompt="
<planning_context>

**Project:**
@.planning/PROJECT.md

**Requirements:**
@.planning/REQUIREMENTS.md

**Research (if exists):**
@.planning/research/SUMMARY.md

**Config:**
@.planning/config.json

</planning_context>

<instructions>
Create roadmap:
1. Derive phases from requirements (don't impose structure)
2. Map every v1 requirement to exactly one phase
3. Derive 2-5 success criteria per phase (observable user behaviors)
4. Validate 100% coverage
5. Write files immediately (ROADMAP.md, STATE.md, update REQUIREMENTS.md traceability)
6. Return ROADMAP CREATED with summary

Write files first, then return. This ensures artifacts persist even if context is lost.
</instructions>
", subagent_type="GSI-roadmapper", model="{roadmapper_model}", description="Create roadmap")
```

**Handle roadmapper return:**

**If `## ROADMAP BLOCKED`:**
- Present blocker information
- Work with user to resolve
- Re-spawn when resolved

**If `## ROADMAP CREATED`:**

Read the created ROADMAP.md and present it nicely inline:

```
---

## Proposed Roadmap

**[N] phases** | **[X] requirements mapped** | All v1 requirements covered ✓

| # | Phase | Goal | Requirements | Success Criteria |
|---|-------|------|--------------|------------------|
| 1 | [Name] | [Goal] | [REQ-IDs] | [count] |
| 2 | [Name] | [Goal] | [REQ-IDs] | [count] |
| 3 | [Name] | [Goal] | [REQ-IDs] | [count] |
...

### Phase Details

**Phase 1: [Name]**
Goal: [goal]
Requirements: [REQ-IDs]
Success criteria:
1. [criterion]
2. [criterion]
3. [criterion]

**Phase 2: [Name]**
Goal: [goal]
Requirements: [REQ-IDs]
Success criteria:
1. [criterion]
2. [criterion]

[... continue for all phases ...]

---
```

**If auto mode:** Skip approval gate — auto-approve and commit directly.

**CRITICAL: Ask for approval before committing (interactive mode only):**

Use AskUserQuestion:
- header: "Roadmap"
- question: "Does this roadmap structure work for you?"
- options:
  - "Approve" — Commit and continue
  - "Adjust phases" — Tell me what to change
  - "Review full file" — Show raw ROADMAP.md

**If "Approve":** Continue to commit.

**If "Adjust phases":**
- Get user's adjustment notes
- Re-spawn roadmapper with revision context:
  ```
  Task(prompt="
  <revision>
  User feedback on roadmap:
  [user's notes]

  Current ROADMAP.md: @.planning/ROADMAP.md

  Update the roadmap based on feedback. Edit files in place.
  Return ROADMAP REVISED with changes made.
  </revision>
  ", subagent_type="GSI-roadmapper", model="{roadmapper_model}", description="Revise roadmap")
  ```
- Present revised roadmap
- Loop until user approves

**If "Review full file":** Display raw `cat .planning/ROADMAP.md`, then re-ask.

**Commit roadmap (after approval or auto mode):**

```bash
node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs: create roadmap ([N] phases)" --files .planning/ROADMAP.md .planning/STATE.md .planning/REQUIREMENTS.md
```

## 9. Done

Present completion with next steps:

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 GSI ► PROJECT INITIALIZED ✓
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

**[Project Name]**

| Artifact       | Location                    |
|----------------|-----------------------------|
| Project        | `.planning/PROJECT.md`      |
| Config         | `.planning/config.json`     |
| Research       | `.planning/research/`       |
| Requirements   | `.planning/REQUIREMENTS.md` |
| Roadmap        | `.planning/ROADMAP.md`      |

**[N] phases** | **[X] requirements** | Ready to build ✓

───────────────────────────────────────────────────────────────

## ▶ Next Up

**Phase 1: [Phase Name]** — [Goal from ROADMAP.md]

/GSI:discuss-phase 1 — gather context and clarify approach

<sub>/clear first → fresh context window</sub>

---

**Also available:**
- /GSI:plan-phase 1 — skip discussion, plan directly

───────────────────────────────────────────────────────────────
```

</process>

<output>

- `.planning/PROJECT.md`
- `.planning/config.json`
- `.planning/research/` (if research selected)
  - `STACK.md`
  - `FEATURES.md`
  - `ARCHITECTURE.md`
  - `PITFALLS.md`
  - `SUMMARY.md`
- `.planning/REQUIREMENTS.md`
- `.planning/ROADMAP.md`
- `.planning/STATE.md`

</output>

<success_criteria>

- [ ] .planning/ directory created
- [ ] Git repo initialized
- [ ] Brownfield detection completed
- [ ] Deep questioning completed (threads followed, not rushed)
- [ ] PROJECT.md captures full context → **committed**
- [ ] config.json has workflow mode, depth, parallelization → **committed**
- [ ] Research completed (if selected) — 4 parallel agents spawned → **committed**
- [ ] Requirements gathered (from research or conversation)
- [ ] User scoped each category (v1/v2/out of scope)
- [ ] REQUIREMENTS.md created with REQ-IDs → **committed**
- [ ] GSI-roadmapper spawned with context
- [ ] Roadmap files written immediately (not draft)
- [ ] User feedback incorporated (if any)
- [ ] ROADMAP.md created with phases, requirement mappings, success criteria
- [ ] STATE.md initialized
- [ ] REQUIREMENTS.md traceability updated
- [ ] User knows next step is `/GSI:discuss-phase 1`

**Atomic commits:** Each phase commits its artifacts immediately. If context is lost, artifacts persist.

</success_criteria>

</document_content>
</document>
<document index="101">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\pause-work.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file"]
  priority: 1
  rationale: "Primary workflow for reading state and writing pause notes"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Create `.continue-here.md` handoff file to preserve complete work state across sessions. Enables seamless resumption with full context restoration.
</purpose>

<required_reading>
Read all files referenced by the invoking prompt's execution_context before starting.
</required_reading>

<process>

<step name="detect">
Find current phase directory from most recently modified files using MCP tools:

**Use MCP tool: mcp__code-index-mcp__find_files**

```javascript
// MCP-based equivalent for finding files (80-90% token savings vs bash ls)
const phaseDirs = await mcp__code-index-mcp__find_files({
  pattern: "*-PLAN.md",
  path: ".planning/phases"
});
```

If no active phase detected, ask user which phase they're pausing work on.
</step>

<step name="gather">
**Collect complete state for handoff:**

1. **Current position**: Which phase, which plan, which task
2. **Work completed**: What got done this session
3. **Work remaining**: What's left in current plan/phase
4. **Decisions made**: Key decisions and rationale
5. **Blockers/issues**: Anything stuck or concerning
6. **Mental context**: The approach, next steps, "vibe"
7. **Files modified**: What's changed but not committed
8. **Timestamps**: When each task completed

Ask user for clarifications if needed via conversational questions.
</step>

<step name="write">
**Write handoff to `.planning/phases/XX-name/.continue-here.md`:**

**Use MCP tool: mcp__desktop-commander__write_file**

```javascript
// MCP-based equivalent for file writing (80-90% token savings vs bash)
await mcp__desktop-commander__write_file({
  path: ".planning/phases/XX-name/.continue-here.md",
  content: `---
phase: XX-name
task: 3
total_tasks: 7
status: in_progress
last_updated: [timestamp from current-timestamp]

---

<current_state>
[Where exactly are we? Immediate context]
</current_state>

<completed_work>
- Task 1: [name] - Done
- Task 2: [name] - Done
- Task 3: [what's left] - In progress, [what's done]
</completed_work>

<remaining_work>
- Task 4: [what's left]
- Task 5: [what's left]
- Task 6: [what's left]
- Task 7: [what's left]
</remaining_work>

<decisions_made>
- Decided to use [X] because [reason]
- Chose [approach] over [alternative] because [rationale]
</decisions_made>

<blockers>
- [Blocker 1]: [status/workaround]
</blockers>

<context>
[Mental state, what were you thinking, plan]
</context>

<next_action>
Start with: [specific first action when resuming]
</next_action>

<timestamp>
${timestamp}
</timestamp>

---

Be specific enough for a fresh Claude to understand immediately.
```
</step>

<step name="commit">
**Commit handoff using MCP process tool:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "wip: ${phase-name} paused at task ${X}" --files .planning/phases/XX-name/.continue-here.md`,
  timeout_ms: 10000
});
```
</step>

<step name="confirm">
```
✓ Handoff created: .planning/phases/[XX-name]/.continue-here.md

Current state:

- Phase: [XX-name]
- Task: [X] of [Y]
- Status: [in_progress/blocked]
- Committed as WIP

To resume: /GSI:resume-work

```
</step>

</process>

<success_criteria>
- [ ] `.continue-here.md` created in correct phase directory
- [ ] All sections filled with specific content
- [ ] Handoff committed to git
- [ ] User knows location and how to resume
</success_criteria>

</document_content>
</document>
<document index="102">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\plan-milestone-gaps.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file"]
  priority: 1
  rationale: "Primary workflow for reading milestone plans and writing gap analysis"
code_index:
  tools: ["find_files"]
  priority: 2
  rationale: "Secondary use for discovering phase plans to analyze"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Create all phases necessary to close gaps identified by `/GSI:audit-milestone`. Reads MILESTONE-AUDIT.md, groups gaps into logical phases, creates phase entries in ROADMAP.md, and offers to plan each phase. One command creates all fix phases — no manual `/GSI:add-phase` per gap.
</purpose>

<required_reading>
Read all files referenced by the invoking prompt's execution_context before starting.

**Use MCP tool: mcp__desktop-commander__read_file**

```javascript
// MCP-based equivalent for reading audit file
const auditContent = await mcp__desktop-commander__read_file({
  path: ".planning/v*-MILESTONE-AUDIT.md"
});
```
</required_reading>

<process>

## 1. Load Audit Results

**Use MCP tool: mcp__desktop-commander__read_file**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const auditContent = await mcp__desktop-commander__read_file({
  path: ".planning/v*-MILESTONE-AUDIT.md"
});
```

Parse YAML frontmatter to extract structured gaps:
- `gaps.requirements` — unsatisfied requirements
- `gaps.integration` — missing cross-phase connections
- `gaps.flows` — broken E2E user flows

## 2. Prioritize Gaps

Group gaps by priority from REQUIREMENTS.md:

| Priority | Action |
|----------|--------|
| `must` | Create phase, blocks milestone |
| `should` | Create phase, recommended |
| `nice` | Ask user: include or defer |

For integration/flow gaps, infer priority from affected requirements.

## 3. Group Gaps into Phases

Cluster related gaps into logical phases using MCP search:

**Use MCP tool: mcp__code-index-mcp__search_code_advanced**

```javascript
// Search for patterns to group related gaps
const gapPatterns = await mcp__code-index-mcp__search_code_advanced({
  pattern: "(auth|dashboard|api)",
  file_pattern: "*-AUDIT.md",
  path: ".planning"
});
```

**Grouping rules:**
- Same affected phase → combine into one fix phase
- Same subsystem (auth, API, UI) → combine
- Dependency order (fix stubs before wiring) → sequence phases

**Example grouping:**
```
Gap: Auth token missing (DASH-01)
Gap: API calls don't include auth (DASH-01)
Gap: Dashboard can't fetch data (DASH-01)
→ Phase 6: "Wire Auth to API and Dashboard"
```

## 4. Determine Phase Numbers

**Use MCP tool: mcp__code-index-mcp__find_files**

```javascript
// Find existing phases to determine next numbers
const existingPhases = await mcp__code-index-mcp__find_files({
  pattern: "*-PLAN.md",
  path: ".planning/phases"
});
```

Find highest existing phase number. Continue from there.

## 5. Present Gap Closure Plan

Display markdown showing proposed phases:

```
## Gap Closure Plan

**Milestone:** {version}
**Gaps:** {N} requirements, {M} integration, {K} flows

### Proposed Phases

**Phase {N}: {Name}**
Closes:
- {REQ-ID}: {description} (requirement gap)
- Integration: {from} → {to} (integration gap)
- Flow: {flow name} (flow gap)

Tasks: {count estimated}

[Next phase...]
```

## 6. Update ROADMAP.md

**Use MCP tool: mcp__desktop-commander__edit_block**

```javascript
// MCP-based equivalent for editing files
await mcp__desktop-commander__edit_block({
  file_path: ".planning/ROADMAP.md",
  old_string: "[existing roadmap section before gaps]",
  new_string: "[new roadmap section with gap phases]"
});
```

Add new phase entries after current milestone with `(GAP CLOSURE)` marker.

## 7. Create Phase Directories

**Use MCP tool: mcp__desktop-commander__create_directory**

```javascript
// MCP-based equivalent for mkdir (80-90% token savings vs bash)
await mcp__desktop-commander__create_directory({
  path: ".planning/phases/{NN}-{slug}"
});
```

Create one directory per gap closure phase.

## 8. Commit Roadmap Update

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs(roadmap): add gap closure phases" --files .planning/ROADMAP.md`,
  timeout_ms: 10000
});
```

## 9. Offer Next Steps

```
✓ Gap closure phases created

## ▶ Next Up

**Plan first gap closure phase**

`/GSI:plan-phase {N}`

<sub>`/clear` first → fresh context window</sub>

---

**Also available:**
- Review roadmap: Use MCP read tool to view .planning/ROADMAP.md
- `/GSI:execute-phase {N}` — if plans already exist
```
</step>

</process>

<success_criteria>
- [ ] MILESTONE-AUDIT.md loaded using MCP read_file
- [ ] Gaps parsed and prioritized
- [ ] Gaps grouped into logical phases
- [ ] Phase numbers determined using MCP find_files
- [ ] Gap closure plan presented with phases, tasks, requirements
- [ ] ROADMAP.md updated using MCP edit_block
- [ ] Phase directories created using MCP create_directory
- [ ] Roadmap committed using MCP start_process
- [ ] User informed of next steps
</success_criteria>

</document_content>
</document>
<document index="103">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\plan-phase.md</source>
<document_content>
﻿<thinking>auto</thinking>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**File Operations:**
- Use `mcp__desktop-commander__read_file` instead of Read
- Use `mcp__desktop-commander__write_file` instead of Write
- Use `mcp__desktop-commander__edit_block` instead of Edit
- Use `mcp__desktop-commander__list_directory` instead of ls
- Use `mcp__desktop-commander__create_directory` instead of mkdir

**Code Search:**
- Use `mcp__code-index-mcp__search_code_advanced` instead of Grep
- Use `mcp__code-index-mcp__find_files` instead of find
- Use `mcp__code-index-mcp__get_file_summary` for file analysis

**External Research:**
- Use `mcp__rag-web-browser__search` for web searches instead of native search
- Use `mcp__context7__resolve-library-id` and `mcp__context7__get-library-docs` for library documentation

**Process Operations:**
- Use `mcp__desktop-commander__start_process` instead of Bash for commands

**NEVER USE native tools (Read, Write, Edit, Grep, Glob, Bash) when MCP alternatives exist.**

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<purpose>
Create executable phase prompts (PLAN.md files) for a roadmap phase with integrated research and verification. Default flow: Research (if needed) -> Plan -> Verify -> Done. Orchestrates GSI-phase-researcher, GSI-planner, and GSI-plan-checker agents with a revision loop (max 3 iterations).
</purpose>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "list_directory", "create_directory"]
  priority: 1
  rationale: "Primary workflow for reading context files, writing plan documents, and managing planning directory structure"
code_index:
  tools: ["search_code_advanced", "find_files", "get_file_summary"]
  priority: 1
  rationale: "Co-primary workflow for searching existing plans, discovering files, and getting file metadata during planning"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<required_reading>
**Use MCP tools for reading files:**

- mcp__desktop-commander__read_file — Read STATE.md, ROADMAP.md, CONTEXT.md
- mcp__code-index-mcp__search_code_advanced — Search for patterns across planning files
- mcp__code-index-mcp__get_file_summary — Get file metadata and structure

**Use MCP tool: mcp__context7__resolve-library-id and mcp__context7__get-library-docs** for library research

**Use MCP tool: mcp__sequential-thinking__sequentialthinking** for complex planning:
- Multi-step problem decomposition (3-7 thoughts typical)
- Planning with room for revision (isRevision parameter)
- Hypothesis generation and verification

**Use MCP tool: mcp__tractatus-thinking__tractatus_thinking** for logical structure analysis:
- Concept decomposition into atomic propositions
- Architecture analysis before planning
- Verification of structural completeness
- Export to markdown/graphviz for documentation

@~/.claude/get-shit-indexed/references/ui-brand.md
</required_reading>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**File Operations:**
- Use `mcp__desktop-commander__read_file` instead of Read
- Use `mcp__desktop-commander__write_file` instead of Write
- Use `mcp__desktop-commander__edit_block` instead of Edit
- Use `mcp__desktop-commander__list_directory` instead of ls
- Use `mcp__desktop-commander__create_directory` instead of mkdir

**Code Search:**
- Use `mcp__code-index-mcp__search_code_advanced` instead of Grep
- Use `mcp__code-index-mcp__find_files` instead of find
- Use `mcp__code-index-mcp__get_file_summary` for file analysis

**External Research:**
- Use `mcp__rag-web-browser__search` for web searches instead of native search
- Use `mcp__context7__resolve-library-id` and `mcp__context7__get-library-docs` for library documentation

**Process Operations:**
- Use `mcp__desktop-commander__start_process` instead of Bash for commands
- Use `mcp__desktop-commander__interact_with_process` for interactive processes

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<thinking_aware_planning>
**For complex phases requiring structured thinking:**

1. **Select thinking server based on phase type:**
   - Complex planning (5+ plans) → sequential-thinking
   - Architectural decisions → tractatus-thinking
   - Bug investigation → debug-thinking

2. **Use thinking output to select optimal tool chain:**
   - Sequential thoughts specify: "Use CI to search for X"
   - Tractatus propositions specify: "Use CG to map Y"
   - Debug graph suggests: "Query similar problems"

3. **Reference TOOL-CHAIN-PATTERNS.md for variant patterns:**
   - Sequential + CI for multi-step analysis
   - Tractatus + CG for architectural mapping
   - Debug + DC for systematic debugging

4. **Batch MCP operations per thinking server recommendations:**
   - One thinking session covers multiple MCP calls
   - Reuse thinking context across related operations
</thinking_aware_planning>

<process>

## 1. Initialize

Load all context in one call using MCP tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```bash
# MCP-based equivalent (80-90% token savings vs bash)
INIT=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js init plan-phase "$PHASE" --include state,roadmap,requirements,context,research,verification,uat,config)
```

Parse JSON for all file contents and settings.

**If `.planning/` missing:** Error — run `/GSI:new-project` first.

## 2. Parse and Normalize Arguments

Extract from $ARGUMENTS: phase number (integer or decimal like `2.1`), flags (`--research`, `--skip-research`, `--gaps`, `--skip-verify`).

## 3. Validate Phase

**Use MCP tool: mcp__code-index-mcp__search_code_advanced**

```bash
# MCP-based equivalent for validating phase in roadmap
PHASE_INFO=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js roadmap get-phase "${PHASE}")
```

If phase not found in ROADMAP.md: Error.

## 4. Load CONTEXT.md (if exists)

**Use MCP tool: mcp__desktop-commander__read_file**

```javascript
const contextContent = await mcp__desktop-commander__read_file({
  path: ".planning/phases/XX-name/CONTEXT.md"
});
```

## 5. Handle Research

**If `--skip-research` flag:** Skip to step 6.

**Use MCP tools: mcp__context7__resolve-library-id and mcp__context7__get-library-docs**

```javascript
// MCP-based library research (80-90% token savings vs bash)
const libId = await mcp__context7__resolve-library-id({ libraryName: "[library]" });
const docs = await mcp__context7__get-library-docs({
  context7CompatibleLibraryID: libId,
  topic: "[specific topic]",
  mode: "code" // for API reference, "info" for conceptual
});
```

## 5.5. Apply Sequential Thinking (for complex phases)

**For complex phases (5+ plans or architectural decisions):**

**Use MCP tool: mcp__sequential-thinking__sequentialthinking**

```javascript
// Sequential thinking for multi-step problem decomposition
const thoughts = [
  {
    thought: "Analyze phase requirements and identify key components",
    nextThoughtNeeded: true,
    thoughtNumber: 1,
    totalThoughts: 5
  },
  {
    thought: "Break down phase into logical plan sequence",
    nextThoughtNeeded: true,
    thoughtNumber: 2,
    totalThoughts: 5
  },
  {
    thought: "Identify dependencies between plans",
    nextThoughtNeeded: true,
    thoughtNumber: 3,
    totalThoughts: 5
  },
  {
    thought: "Generate task breakdown for each plan",
    nextThoughtNeeded: true,
    thoughtNumber: 4,
    totalThoughts: 5
  },
  {
    thought: "Hypothesis: Phase structure complete with all dependencies mapped",
    nextThoughtNeeded: false,
    thoughtNumber: 5,
    totalThoughts: 5
  }
];
```

**For architectural decisions, also apply tractatus thinking:**

**Use MCP tool: mcp__tractatus-thinking__tractatus_thinking**

```javascript
// Tractatus thinking for structural analysis
const analysis = await mcp__tractatus-thinking__tractatus_thinking({
  operation: "start",
  concept: "Analyze architecture for {phase goal}",
  depth_limit: 5,
  style: "analytical"
});

// Add propositions for key decisions
await mcp__tractatus-thinking__tractatus_thinking({
  operation: "add",
  session_id: analysis.session_id,
  content: "{architectural decision proposition}",
  parent_number: null,
  is_atomic: false
});

// Verify completeness
await mcp__tractatus-thinking__tractatus_thinking({
  operation: "analyze",
  session_id: analysis.session_id
});

// Export to markdown for reference
await mcp__tractatus-thinking__tractatus_thinking({
  operation: "export",
  session_id: analysis.session_id,
  format: "markdown"
});
```

## 5.6. Apply Thinking-Aware Breakdown (for phases with architectural decisions)

**For phases requiring both structural analysis and task planning:**

**Process:**
1. **Use tractatus-thinking for structural analysis (WHAT)**
2. **Use sequential-thinking for task planning (HOW)**
3. **Select tool chain variants based on thinking output**
4. **Batch MCP operations per thinking server recommendations**

**Example flow:**
```javascript
// Step 1: Tractatus - Analyze architecture
const tractatus = await mcp__tractatus-thinking__tractatus_thinking({
  operation: "start",
  concept: "Analyze {phase} architecture",
  depth_limit: 5
});

// Step 2: Sequential - Plan implementation
const sequential = await mcp__sequential-thinking__sequentialthinking({
  thought: "Plan implementation based on tractatus analysis",
  thoughtNumber: 1,
  totalThoughts: 5,
  nextThoughtNeeded: true
});

// Step 3: Execute MCP operations guided by thinking
// CI: search_code_advanced (guided by sequential thoughts)
// CG: query_graph (guided by tractatus propositions)
// DC: write_file/edit_block (guided by implementation plan)
```

**Reference:** See TOOL-CHAIN-PATTERNS.md for thinking-aware variants

## 6. Spawn GSI-phase-researcher

Researcher uses CONTEXT.md + downstream consumer requirements to create DISCOVERY.md.

**Use MCP tool: mcp__desktop-commander__write_file**

```javascript
// MCP-based for writing discovery output
await mcp__desktop-commander__write_file({
  path: ".planning/phases/XX-name/DISCOVERY.md",
  content: `[discovery content]`
});
```

## 7. Spawn GSI-planner

Planner uses DISCOVERY.md + requirements + ROADMAP to create PLAN.md.

**Use MCP tool: mcp__code-index-mcp__search_code_advanced**

```bash
# MCP-based equivalent for reading existing plans
ls .planning/phases/XX-name/*-PLAN.md 2>/dev/null
```

## 8. Verify, Revise, Present

Run up to 3 revision iterations checking for quality issues.

**Use MCP tool: mcp__code-index-mcp__get_file_summary**

```javascript
// MCP-based equivalent for checking file structure
const planInfo = await mcp__code-index-mcp__get_file_summary({
  file_path: ".planning/phases/XX-name/XX-YY-PLAN.md"
});
```

## 9. Create PLAN.md

**Use MCP tool: mcp__desktop-commander__write_file**

```javascript
await mcp__desktop-commander__write_file({
  path: ".planning/phases/XX-name/XX-YY-PLAN.md",
  content: `[plan content with frontmatter, tasks, verification, success criteria]`
});
```
</step>

</process>

<success_criteria>
- [ ] Phase validated against roadmap
- [ ] All context files loaded using MCP tools
- [ ] DISCOVERY.md created using MCP write_file (if research ran)
- [ ] Existing plans checked using MCP search_code_advanced
- [ ] PLAN.md created with valid frontmatter and tasks
- [ ] Plan verified, revised (max 3 iterations)
- [ ] User presented with actionable next steps
</success_criteria>

</document_content>
</document>
<document index="104">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\progress.md</source>
<document_content>
﻿<thinking>auto</thinking>

<purpose>
Check project progress, summarize recent work and what's ahead, then intelligently route to next action — either executing an existing plan or creating a next one. Provides situational awareness before continuing work.
</purpose>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "start_process"]
  priority: 1
  rationale: "Primary workflow for reading state/roadmap, writing summaries, and running status commands"
code_index:
  tools: ["find_files", "get_file_summary"]
  priority: 2
  rationale: "Secondary use for listing phase directories and getting file metadata"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<required_reading>
**Use MCP tools to read project state:**

- mcp__desktop-commander__read_file — Read STATE.md, ROADMAP.md
- mcp__code-index-mcp__find_files — List phase directories
- mcp__code-index-mcp__get_file_summary — Get file metadata

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</required_reading>

<process>

<step name="init_context">
Load progress context using MCP tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const INIT = await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js init progress --include state,roadmap,project,config`,
  timeout_ms: 10000
});
```

Extract JSON: `project_exists`, `roadmap_exists`, `state_exists`, `phases`, `current_phase`, `next_phase`, `milestone_version`, `completed_count`, `phase_count`, `paused_at`.
</step>

<step name="analyze_roadmap">
**Use MCP tool: mcp__code-index-mcp__search_code_advanced** or **mcp__desktop-commander__read_file**

```javascript
// MCP-based equivalent for roadmap analysis
const roadmap = await mcp__desktop-commander__read_file({
  path: ".planning/ROADMAP.md"
});

// Or use search for pattern matching
```

Parse roadmap structure:
- Current phase number
- Next phase number
- Phase names and goals
- Milestone boundaries

**If roadmap missing:** Error — run `/GSI:new-project` first.
</step>

<step name="recent">
**Gather recent work context:**

**Use MCP tool: mcp__code-index-mcp__find_files** and **mcp__desktop-commander__read_file**

```javascript
// MCP-based equivalent for finding and reading summary files
const summaryFiles = await mcp__code-index-mcp__find_files({
  pattern: "*-SUMMARY.md",
  path: ".planning/phases"
});

// Read last 2-3 summaries for recent work
```

Extract:
- What was built (one-liners)
- Any notable deviations or issues
- Completion timestamps
</step>

<step name="position">
**Parse current position from init context and roadmap:**

- Are we in a phase? What number?
- Is there a next phase?
- Are we at milestone completion?

Determine smart routing based on state.
</step>

<step name="report">
**Generate rich status report:**

```
# [Project Name]

**Progress:** [visual progress bar from init]

## Current Position
Phase [N]: [Name]
[Status: In Progress / Complete / Not Started]

## Recent Work
[Last 2-3 phase summaries]

## What's Ahead
Phase [N+1]: [Name]

## Key Decisions
[From STATE.md decisions table]

## Pending Todos
[Count pending - use /GSI:check-todos]

## Blockers/Concerns
[Any open issues]

---

## ▶ Next Up
[Smart routing suggestion]
```
</step>

<step name="route">
**Smart routing based on state:**

| Condition | Route | Action |
|-----------|--------|--------|
| Phase complete + no next phase | Suggest `/GSI:complete-milestone` | Archive milestone, start next cycle |
| Phase in progress + plans exist | Suggest `/GSI:execute-phase {N}` | Continue current phase |
| Phase in progress + no plans | Suggest `/GSI:plan-phase {N}` | Create execution plans |
| No phase active | Suggest `/GSI:discuss-phase {N}` | Gather context before planning |
| Paused phase | Suggest `/GSI:resume-work` | Continue where left off |
| Pending todos exist | Suggest `/GSI:check-todos` | Review and work on todos |

Present the routed action clearly.
</step>

</process>

<success_criteria>
- [ ] Progress context loaded using MCP start_process
- [ ] Roadmap analyzed using MCP read_file or search_code_advanced
- [ ] Recent summaries found using MCP find_files
- [ ] Current position determined
- [ ] Rich status report displayed with progress bar
- [ ] Smart routing suggestion provided
- [ ] User knows next actions
</success_criteria>

</document_content>
</document>
<document index="105">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\quick.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "start_process"]
  priority: 1
  rationale: "Primary workflow for reading project files, writing quick outputs, and running status checks"
code_index:
  tools: ["find_files"]
  priority: 2
  rationale: "Secondary use for discovering project structure quickly"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Execute small, ad-hoc tasks with GSI guarantees (atomic commits, STATE.md tracking) while skipping optional agents (research, plan-checker, verifier). Quick mode lives in `.planning/quick/` separate from planned phases. Uses same executor and planner agents but streamlined flow.
</purpose>

<required_reading>
**Use MCP tools for reading state:**

- mcp__desktop-commander__read_file — Read STATE.md, config.json
- mcp__code-index-mcp__find_files — Check for existing quick tasks

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</required_reading>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**File Operations:**
- mcp__desktop-commander__read_file — Read plan files
- mcp__desktop-commander__write_file — Write SUMMARY.md
- mcp__desktop-commander__list_directory — Check quick task directory

**Process Operations:**
- mcp__desktop-commander__start_process — Run GSI-tools.js commands

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<process>

## 1. Get Task Description

Prompt user: "What do you want to do?"

Store as `$DESCRIPTION`.

**If empty:** Re-prompt with examples:
- Quick task examples
- Suggest using /GSI:progress to see pending todos

## 2. Initialize

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const INIT = await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js init quick "${DESCRIPTION}"`,
  timeout_ms: 10000
});
```

Parse JSON for: `planner_model`, `executor_model`, `commit_docs`, `next_num`, `slug`, `date`, `timestamp`, `quick_dir`.

## 3. Create Quick Task Directory

**Use MCP tool: mcp__desktop-commander__create_directory**

```javascript
// MCP-based equivalent for mkdir (80-90% token savings vs bash)
await mcp__desktop-commander__create_directory({
  path: ".planning/quick/${next_num}-${slug}"
});
```

## 4. Spawn Planner (Quick Mode)

Spawn GSI-planner with quick mode context:

```
Task(
  subagent_type="GSI-planner",
  model="{planner_model}",
  description="Quick plan: ${DESCRIPTION}"
)
```

## 5. Create PLAN.md

Planner creates `.planning/quick/${next_num}-${slug}/00-PLAN.md`.

## 6. Spawn Executor

Execute the plan using GSI-executor.

## 7. Update STATE.md

**Use MCP tool: mcp__desktop-commander__edit_block** or **mcp__desktop-commander__start_process**

Update "Quick Tasks Completed" table with new entry.
</step>

</process>

<success_criteria>
- [ ] Task description obtained
- [ ] Quick task directory created using MCP create_directory
- [ ] Planner spawned with quick context
- [ ] PLAN.md created by planner
- [ ] Executor spawned and completed tasks
- [ ] STATE.md updated using MCP edit_block or start_process
- [ ] Changes committed using MCP start_process
- [ ] User knows what was accomplished
</success_criteria>

</document_content>
</document>
<document index="106">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\remove-phase.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "start_process"]
  priority: 1
  rationale: "Primary workflow for reading roadmap, writing updates, and running git commands"
code_index:
  tools: ["find_files"]
  priority: 2
  rationale: "Secondary use for discovering phase files to remove"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Remove a future phase from the roadmap and renumber all subsequent phases to close the gap. Updates ROADMAP.md, deletes phase directory, and commits changes.
</purpose>

<required_reading>
**Use MCP tools:**
- mcp__desktop-commander__read_file — Read ROADMAP.md before modification
- mcp__code-index-mcp__search_code_advanced — Find phase references to update

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</required_reading>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**File Operations:**
- mcp__desktop-commander__read_file — Read files
- mcp__desktop-commander__edit_block — Edit ROADMAP.md
- mcp__desktop-commander__list_directory — List phase directories

**Code Search:**
- mcp__code-index-mcp__search_code_advanced — Search for phase references

**Process Operations:**
- mcp__desktop-commander__start_process — Run GSI-tools.js commands

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<process>

<step name="parse_arguments">
Parse command arguments:
- First argument: phase number to remove
- Remaining arguments: (optional) confirmation flag

Example: `/GSI:remove-phase 17` → remove = 17

If no phase number:

```
ERROR: Phase number required
Usage: /GSI:remove-phase <number>
Example: /GSI:remove-phase 17
```

Exit.

Validate first argument is an integer ≤ highest phase number.
</step>

<step name="init_context">
Load phase operation context using MCP tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const INIT = await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js init phase-op "${REMOVE_PHASE}"`,
  timeout_ms: 10000
});
```

Extract `roadmap_exists` from init JSON. If false:
```
ERROR: No roadmap found (.planning/ROADMAP.md)
```
Exit.
</step>

<step name="remove_phase">
**Remove phase using GSI-tools:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js phase remove "${REMOVE_PHASE}"`,
  timeout_ms: 10000
});
```

The CLI handles:
- Validating phase exists in ROADMAP.md
- Removing phase entry from ROADMAP.md
- Deleting phase directory (`.planning/phases/{NN}-{slug}/`)
- Renumbering all subsequent phases (NN becomes NN-1, NN-1 becomes NN-2, etc.)

Extract from result: `removed_phase`, `removed_directory`, `renumbered_count`.

**Note:** Phase directories are NOT deleted from disk — they accumulate as execution history. Only the ROADMAP.md reference is removed.
</step>

<step name="update_state">
Update STATE.md using MCP tools:

**Use MCP tool: mcp__desktop-commander__read_file** and **mcp__desktop-commander__edit_block**

```javascript
// MCP-based equivalent for reading and editing files
const stateContent = await mcp__desktop-commander__read_file({
  path: ".planning/STATE.md"
});

await mcp__desktop-commander__edit_block({
  file_path: ".planning/STATE.md",
  old_string: "[existing roadmap evolution section]",
  new_string: "### Roadmap Evolution\n   - Phase ${removed_phase} removed: ${reason}\n   - Phases ${renumbered_count} renumbered: ${removed_phase}+1 → ${removed_phase}, ${removed_phase}+2 → ..."
});
```

If "Roadmap Evolution" section doesn't exist, create it.
</step>

<step name="completion">
Present completion summary:

```
Phase ${removed_phase} removed from roadmap:
- Directory: .planning/phases/${removed_phase}-{slug}/ (preserved on disk)
- Phases renumbered: ${renumbered_count} phases shifted
- ROADMAP.md updated

State updated: .planning/STATE.md

---

## ▶ Next Up

Review updated roadmap structure.

---

**Also available:**
- `cat .planning/ROADMAP.md` — view updated roadmap
```
</step>

</process>

<success_criteria>
- [ ] Phase exists in roadmap (validated using MCP tools)
- [ ] Phase removed using GSI-tools (MCP start_process)
- [ ] Phase directory deleted (preserved on disk)
- [ ] Subsequent phases renumbered (count tracked)
- [ ] ROADMAP.md updated using MCP edit_block
- [ ] STATE.md updated with roadmap evolution entry
- [ ] User informed of completion and next steps
</success_criteria>

</document_content>
</document>
<document index="107">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\research-phase.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "start_process"]
  priority: 1
  rationale: "Primary workflow for reading context, writing research results, and running analysis commands"
code_index:
  tools: ["search_code_advanced", "find_files"]
  priority: 2
  rationale: "Secondary use for searching codebase patterns and discovering relevant files"
tractatus_thinking:
  tools: ["tractatus_thinking"]
  priority: 2
  rationale: "Secondary use for concept decomposition and architecture analysis during research"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Research how to implement a phase. Spawns GSI-phase-researcher with phase context.

Standalone research command. For most workflows, use `/GSI:plan-phase` which integrates research automatically.
</purpose>

<process>

## Step 0: Resolve Model Profile

@~/.claude/get-shit-indexed/references/model-profile-resolution.md

Resolve model for:
- `GSI-phase-researcher`

## Step 1: Normalize and Validate Phase

@~/.claude/get-shit-indexed/references/phase-argument-parsing.md

```bash
PHASE_INFO=$(node ~/.claude/get-shit-indexed/bin/GSI-tools.js roadmap get-phase "${PHASE}")
```

If `found` is false: Error and exit.

## Step 2: Check Existing Research

```bash
ls .planning/phases/${PHASE}-*/RESEARCH.md 2>/dev/null
```

If exists: Offer update/view/skip options.

## Step 3: Gather Phase Context

```bash
# Phase section from roadmap (already loaded in PHASE_INFO)
echo "$PHASE_INFO" | jq -r '.section'
cat .planning/REQUIREMENTS.md 2>/dev/null
cat .planning/phases/${PHASE}-*/*-CONTEXT.md 2>/dev/null
# Decisions from state-snapshot (structured JSON)
node ~/.claude/get-shit-indexed/bin/GSI-tools.js state-snapshot | jq '.decisions'
```

## Step 3.5: Apply Structural Analysis (for complex research)

**For complex research questions (multiple options, architectural decisions):**

**Use MCP tool: mcp__tractatus-thinking__tractatus_thinking**

```javascript
// Tractatus thinking for structural analysis
const analysis = await mcp__tractatus-thinking__tractatus_thinking({
  operation: "start",
  concept: "Analyze {research question} structure",
  depth_limit: 5,
  style: "analytical"
});

// Add propositions for each option/factor
await mcp__tractatus-thinking__tractatus_thinking({
  operation: "add",
  session_id: analysis.session_id,
  content: "{option A proposition}",
  is_atomic: false
});

await mcp__tractatus-thinking__tractatus_thinking({
  operation: "add",
  session_id: analysis.session_id,
  content: "{option B proposition}",
  is_atomic: false
});

// Navigate between propositions to find dependencies
await mcp__tractatus-thinking__tractatus_thinking({
  operation: "navigate",
  session_id: analysis.session_id,
  target: "child"
});

// Export findings to DISCOVERY.md
await mcp__tractatus-thinking__tractatus_thinking({
  operation: "export",
  session_id: analysis.session_id,
  format: "markdown"
});
```

**Integration Note**: Use tractatus (structure) → sequential (process) for complex research

## Step 4: Spawn Researcher

```
Task(
  prompt="<objective>
Research implementation approach for Phase {phase}: {name}
</objective>

<context>
Phase description: {description}
Requirements: {requirements}
Prior decisions: {decisions}
Phase context: {context_md}
</context>

<output>
Write to: .planning/phases/${PHASE}-{slug}/${PHASE}-RESEARCH.md
</output>",
  subagent_type="GSI-phase-researcher",
  model="{researcher_model}"
)
```

## Step 5: Handle Return

- `## RESEARCH COMPLETE` — Display summary, offer: Plan/Dig deeper/Review/Done
- `## CHECKPOINT REACHED` — Present to user, spawn continuation
- `## RESEARCH INCONCLUSIVE` — Show attempts, offer: Add context/Try different mode/Manual

</process>

</document_content>
</document>
<document index="108">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\resume-project.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "start_process"]
  priority: 1
  rationale: "Primary workflow for reading state, writing updates, and running git/analysis commands"
code_index:
  tools: ["search_code_advanced"]
  priority: 2
  rationale: "Secondary use for searching project context during resumption"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Resume work from a previous session that used `.continue-here.md` handoff file. Loads complete state, finds where left off, and continues execution. Orchestrator stays lean — delegates to subagents.
</purpose>

<required_reading>
**Use MCP tools to read project state and handoff file:**

- mcp__desktop-commander__read_file — Read STATE.md
- mcp__desktop-commander__read_file — Read .continue-here.md
- mcp__code-index-mcp__find_files — List phase directories

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</required_reading>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**File Operations:**
- mcp__desktop-commander__read_file — Read handoff file
- mcp__desktop-commander__list_directory — Find current phase

**Process Operations:**
- mcp__desktop-commander__start_process — Run GSI-tools.js commands

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<process>

## 1. Detect Current Phase

**Use MCP tool: mcp__code-index-mcp__find_files**

```javascript
// MCP-based equivalent for finding files (80-90% token savings vs bash ls)
const phaseDirs = await mcp__code-index-mcp__find_files({
  pattern: "*-PLAN.md",
  path: ".planning/phases"
});
```

Find most recently modified phase directory.

**If no active phase detected:** Ask user which phase they're resuming.
</step>

<step name="load_handoff">
**Use MCP tool: mcp__desktop-commander__read_file**

```javascript
// MCP-based equivalent (80-90% token savings vs bash cat)
const handoffContent = await mcp__desktop-commander__read_file({
  path: ".planning/phases/XX-name/.continue-here.md"
});
```

Parse YAML frontmatter:
- `phase`
- `task`
- `total_tasks`
- `status`
- `last_updated`
- `current_state` with completed/remaining work arrays
- `decisions_made`
- `blockers`
- `context`
- `next_action`

Extract all context for seamless continuation.
</step>

<step name="verify_continuation">
Check if handoff file exists and is recent.

**If missing:** Warn user that state may be stale. Ask if they want to continue anyway.
</step>

<step name="spawn_continuation">
Spawn GSI-executor with continuation context:

```
Task(
  subagent_type="GSI-executor",
  prompt="<complete state from handoff, continue from task X>",
  model="{executor_model}"
)
```

No new planning — executor reads handoff state and continues from exactly where previous session stopped.

Fresh context per subagent — no token contamination from orchestrator.
</step>

<step name="update_state">
After continuation completes, update STATE.md:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js state record-session --stopped-at "Continuation complete" --resume-file "None"`,
  timeout_ms: 10000
});
```

Remove `.continue-here.md` after successful continuation.
</step>

<step name="completion">
Present completion report:

```
✓ Work resumed from session handoff

Phase: [XX-name]
Continued from: Task [X] of [Y]
[Summary of what was done]

---

## ▶ Next Up

Continue with remaining tasks or mark phase complete.
```
</step>

</process>

<success_criteria>
- [ ] Current phase detected using MCP find_files
- [ ] Handoff file loaded using MCP read_file
- [ ] Continuation spawned with complete state
- [ ] Work continued and tasks completed
- [ ] STATE.md updated using MCP start_process
- [ ] User informed of completion and next steps
- [ ] Handoff file cleaned up after successful continuation
</success_criteria>

</document_content>
</document>
<document index="109">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\set-profile.md</source>
<document_content>
﻿<thinking>auto</thinking>

---
<code_index_mcp>
enabled: true
auto_continue: true
project_index: .planning/codebase-index
</code_index_mcp>

<purpose>
Switch active model profile for GSI workflows to balance speed vs capability.

Three profiles available:
- **quality**: Maximum capability (Opus for all agents)
- **balanced**: Balanced performance/cost (Sonnet for execution/planning, Opus for verification)
- **budget**: Maximum speed (Haiku for execution/verification, Sonnet for planning)
</purpose>

<process>

<step name="load_current_profile">
Read current active profile from config.json:

```bash
# Use mcp__desktop-commander__read_file for config operations
ACTIVE_PROFILE=$(cat .planning/config.json | grep -oP '"active_profile"' | head -1)
```

Display current profile and model assignments:

```
Current Profile: {quality|balanced|budget}

Model Assignments:
- Executor: {model}
- Planner: {model}
- Verifier: {model}
```

</step>

<step name="list_profiles">
Display all available profiles with descriptions:

```
Available Profiles:

1. quality — Maximum capability
   Executor: claude-opus-4-6
   Planner: claude-opus-4-6
   Verifier: claude-opus-4-6
   
   Use for: Complex analysis, architectural decisions, critical tasks
   
2. balanced — Balanced performance/cost
   Executor: claude-sonnet-4-5
   Planner: claude-opus-4-6
   Verifier: claude-sonnet-4-5
   
   Use for: Standard workflows, most development tasks
   
3. budget — Maximum speed
   Executor: claude-haiku-4-5
   Planner: claude-sonnet-4-5
   Verifier: claude-haiku-4-5
   
   Use for: Quick iterations, experimental features, cost-sensitive operations
```

</step>

<step name="select_profile">
Prompt user to select new profile:

```
Select new profile (1-3):
1. quality (Opus everywhere)
2. balanced (Sonnet execution/planning, Opus verification)
3. budget (Haiku execution/verification, Sonnet planning)

Current: {active_profile}
```

Wait for user input (1, 2, or 3).
</step>

<step name="update_config">
Update .planning/config.json with new active_profile:

```bash
# Use mcp__desktop-commander__edit_block to update config
# Read current config first, then edit the active_profile value
```

New config entry:

```json
{
  "model_profile": "quality|balanced|budget",
  "active_profile": "{selected_profile}",
  "profiles": {
    "quality": {
      "executor_model": "claude-opus-4-6",
      "planner_model": "claude-opus-4-6",
      "verifier_model": "claude-opus-4-6"
    },
    "balanced": {
      "executor_model": "claude-sonnet-4-5",
      "planner_model": "claude-opus-4-6",
      "verifier_model": "claude-sonnet-4-5"
    },
    "budget": {
      "executor_model": "claude-haiku-4-5",
      "planner_model": "claude-sonnet-4-5",
      "verifier_model": "claude-haiku-4-5"
    }
  }
}
```

</step>

<step name="verify">
Verify and confirm the profile change:

```bash
# Re-read config to verify
NEW_PROFILE=$(cat .planning/config.json | grep -oP '"active_profile"' | head -1)

echo "Profile changed: $OLD_PROFILE -> $NEW_PROFILE"
echo "Executor model: {executor_model}"
echo "Planner model: {planner_model}"
echo "Verifier model: {verifier_model}"
```

Display confirmation:

```
✓ Profile updated successfully

Active Profile: {selected}
Models in use:
- Executor: {model}
- Planner: {model}
- Verifier: {model}
```

</step>

</process>

<examples>

### Example 1: Switch to quality profile

```bash
/GSI:set-profile quality

Current Profile: balanced
Available Profiles:

1. quality — Maximum capability
   Executor: claude-opus-4-6
   Planner: claude-opus-4-6
   Verifier: claude-opus-4-6
   
2. balanced — Balanced performance/cost
   ...
   
3. budget — Maximum speed
   ...

Select new profile (1-3):
1
```

User selects "1":

```
✓ Profile updated successfully

Active Profile: quality
Models in use:
- Executor: claude-opus-4-6
- Planner: claude-opus-4-6
- Verifier: claude-opus-4-6
```

### Example 2: Switch to budget profile for speed

```bash
/GSI:set-profile budget

Current Profile: quality
...
Select new profile (1-3):
3
```

Output:

```
✓ Profile updated successfully

Active Profile: budget
Models in use:
- Executor: claude-haiku-4-5
- Planner: claude-sonnet-4-5
- Verifier: claude-haiku-4-5
```

---

## Profile Trade-offs

| Profile | Speed | Capability | Cost | Best For |
|---------|-------|------------|-------|-----------|
| quality | Slow | Maximum | High | Complex tasks, architecture |
| balanced | Medium | High | Medium | Standard workflows |
| budget | Fast | Low | Low | Quick iterations, testing |

---

*Generated for GSI Phase 8 - Advanced Workflow Features*
</document_content>
</document>
<document index="110">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\settings.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file"]
  priority: 1
  rationale: "Primary workflow for reading and writing configuration"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Configure workflow toggles and model profile interactively. Changes mode (interactive/yolo), depth (quick/standard/comprehensive), parallelization, and model assignments for planning agents.
</purpose>

<required_reading>
**Use MCP tool: mcp__desktop-commander__read_file** to read current config

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</required_reading>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**File Operations:**
- mcp__desktop-commander__read_file — Read config.json
- mcp__desktop-commander__write_file — Write updated config

**Process Operations:**
- mcp__desktop-commander__start_process — Run GSI-tools.js config commands

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<process>

<step name="init_context">
Load settings context using MCP tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const CONFIG_JSON = await mcp__desktop-commander__read_file({
  path: ".planning/config.json"
});

await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js config-init",
  timeout_ms: 10000
});
```

Display current config with menu for toggles.
</step>

<step name="interactive_menu">
Present settings menu:

```
## GSI Settings

**Current Configuration:**

Mode: [interactive | yolo]
Depth: [quick | standard | comprehensive]
Parallelization: [enabled | disabled]
Commit Docs: [true | false]
Model Profile: [quality | balanced | budget]

---

## Toggle Mode

/GSI:settings --mode [interactive|yolo]

## Set Depth

/GSI:settings --depth [quick|standard|comprehensive]

## Toggle Parallelization

/GSI:settings --parallelization [true|false]

## Toggle Commit Docs

/GSI:settings --commit-docs [true|false]

## Set Model Profile

/GSI:settings --profile [quality|balanced|budget]

---

What would you like to change?
```

Wait for user response.
</step>

<step name="apply_changes">
Apply selected setting using MCP tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js config-set ${KEY} ${VALUE}`,
  timeout_ms: 10000
});
```

**Use MCP tool: mcp__desktop-commander__write_file** to update config.json

```javascript
await mcp__desktop-commander__write_file({
  path: ".planning/config.json",
  content: `[updated config JSON]`
});
```

Commit config changes:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "chore: update GSI settings" --files .planning/config.json`,
  timeout_ms: 10000
});
```

Confirm: "Settings updated. [Key]: [new value]"
</step>

<step name="model_profile_info">
If user wants to change model profile, show current assignments:

| Agent | Quality Profile | Balanced Profile | Budget Profile |
|-------|---------------|----------------|--------------|
| Researcher | Opus | Sonnet | Haiku |
| Synthesizer | Opus | Sonnet | Haiku |
| Roadmapper | Opus | Sonnet | Haiku |
| Planner | Opus | Sonnet | Sonnet |
| Plan Checker | Sonnet | Sonnet | Haiku |

Note: Quality = best performance, Budget = lowest cost.
</step>

</process>

<success_criteria>
- [ ] Current config loaded using MCP read_file
- [ ] User presented with settings menu
- [ ] Setting applied using MCP start_process and write_file
- [ ] Config committed using MCP start_process
- [ ] User informed of changes
- [ ] Model profile information provided if requested
</success_criteria>

</document_content>
</document>
<document index="111">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\transition.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "list_directory"]
  priority: 1
  rationale: "Primary workflow for reading phase summaries, writing transition notes, and listing next phase files"
code_index:
  tools: ["find_files"]
  priority: 2
  rationale: "Secondary use for discovering phase directories and summary files"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Join the GSI Discord community. Get help, share what you're building, stay updated. Connect with other GSI users.
</purpose>

<required_reading>
**Use MCP tool: mcp__desktop-commander__start_process** to run Discord join command

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</required_reading>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**Process Operations:**
- mcp__desktop-commander__start_process — Run Discord CLI or open invite link

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<process>

<step name="join_discord">
Open Discord invite link using MCP tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
await mcp__desktop-commander__start_process({
  command: "start https://discord.gg/get-shit-indexed",
  timeout_ms: 10000
});
```

This opens the Discord invite page in browser.

Alternatively, show invite URL for manual joining:

```
Join GSI Discord:
https://discord.gg/get-shit-indexed
```
</step>

<step name="confirm">
Confirm user joined:

"Have you joined? Let me know when you're in."

Once confirmed, offer help channels and links.
</step>

<step name="completion">
Present completion:

```
✓ Discord invite sent

Join: https://discord.gg/get-shit-indexed

---

## ▶ Next Up

Share your project in #show-and-tell or get help in #help
```
</step>

</process>

<success_criteria>
- [ ] Discord invite link opened using MCP start_process
- [ ] Invite URL displayed to user
- [ ] User confirmation requested
- [ ] User informed of community resources
- [ ] Next steps provided
</success_criteria>

</document_content>
</document>
<document index="112">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\update.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "start_process"]
  priority: 1
  rationale: "Primary workflow for reading state, writing updates, and running upgrade commands"
code_index:
  tools: ["find_files"]
  priority: 2
  rationale: "Secondary use for discovering workflow and template files during update"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Update GSI to latest version and show changelog preview. Checks installed vs latest version comparison and displays changelog entries for versions user may have missed. Better than raw `npx get-shit-indexed-cc@latest` — has intelligent checks and confirmation.
</purpose>

<required_reading>
**Use MCP tool: mcp__desktop-commander__start_process** to check version and run update

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</required_reading>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**Process Operations:**
- mcp__desktop-commander__start_process — Run GSI-tools.js update and install commands

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<process>

<step name="check_version">
Check installed and latest versions using MCP tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const versionInfo = await mcp__desktop-commander__start_process({
  command: "npm show get-shit-indexed version && npm view get-shit-indexed dist/tags",
  timeout_ms: 15000
});
```

Parse versions:
- `installed`: Current version in package.json
- `latest`: Latest from npm registry

If installed is latest: Already up to date.

If out of date: Show preview of changelogs and confirm update.
</step>

<step name="fetch_changelog">
If out of date, fetch changelog using MCP tools:

**Use MCP tool: mcp__rag-web-browser__search** or **mcp__web_reader__webReader**

```javascript
// MCP-based web search for changelog
const changelog = await mcp__rag-web-browser__search({
  query: "get-shit-indexed changelog ${installed}..${latest}",
  maxResults: 10
});

// Or use web reader
const changelog = await mcp__web_reader__webReader({
  url: "https://github.com/Alot1z/get-shit-indexed/blob/main/CHANGELOG.md",
  returnFormat: "markdown"
});
```

## 3. Preview Changes

Display key changes between versions:

```
## Changes Since [Installed Version]

[Browse full changelogs at https://github.com/Alot1z/get-shit-indexed/commits/main]

### Added
- [Feature 1]
- [Feature 2]

### Changed
- [Breaking change 1]
- [Improvement 1]

### Fixed
- [Bug fix 1]
- [Bug fix 2]
```
</step>

<step name="confirm_update">
Ask user confirmation:

```
Update from ${installed} to ${latest}?
[y] - Download and install
[n] - Skip for now

Run /GSI:update anytime to check again.
```

**If yes:**

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
// MCP-based equivalent (80-90% token savings vs bash npm install)
await mcp__desktop-commander__start_process({
  command: "npx get-shit-indexed-cc@latest",
  timeout_ms: 120000
});
```

Confirm: "Updated to ${latest}"

**If no:**
Note that future `/GSI:progress` checks will continue showing out of date status.
</step>

<step name="completion">
Present completion:

```
✓ Version check complete

Installed: ${installed}
Latest: ${latest}

Status: [Up to date / Update available]

---

## ▶ Next Up

`/GSI:progress` — Check project status
```
</step>

</process>

<success_criteria>
- [ ] Version check completed using MCP start_process
- [ ] Changelog fetched using MCP web search tools
- [ ] Changes preview displayed to user
- [ ] User confirmation obtained
- [ ] Update installed using MCP start_process if confirmed
- [ ] User informed of current status
- [ ] Next steps provided
</success_criteria>

</document_content>
</document>
<document index="113">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\verify-phase.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "list_directory"]
  priority: 1
  rationale: "Primary workflow for reading phase plans, writing verification results, and listing deliverables"
code_index:
  tools: ["search_code_advanced", "find_files"]
  priority: 2
  rationale: "Secondary use for searching success criteria and finding deliverable files"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Validate built features through conversational UAT. Extracts testable deliverables from SUMMARY.md files, presents tests one at a time (yes/no responses), automatically diagnoses failures and creates fix plans. Ready for re-execution if issues found.
</purpose>

<required_reading>
**Use MCP tools for reading phase summaries and STATE.md:**

- mcp__desktop-commander__read_file — Read SUMMARY.md files
- mcp__code-index-mcp__find_files — Find phase directories

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</required_reading>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**File Operations:**
- mcp__desktop-commander__read_file — Read SUMMARY.md
- mcp__code-index-mcp__find_files — Find verification files

**Process Operations:**
- mcp__desktop-commander__start_process — Run GSI-tools.js commands

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<process>

## 1. Load Verification Context

**Use MCP tool: mcp__desktop-commander__read_file**

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
const STATE = await mcp__desktop-commander__read_file({
  path: ".planning/STATE.md"
});
```

Extract: Current phase, milestone, position.

**Use MCP tool: mcp__code-index-mcp__find_files**

```javascript
// MCP-based equivalent for finding files (80-90% token savings vs bash ls)
const phaseDirs = await mcp__code-index-mcp__find_files({
  pattern: "*-SUMMARY.md",
  path: ".planning/phases"
});
```

Identify all SUMMARY.md files in current phase.

## 2. Extract Testable Deliverables

From each SUMMARY.md, extract `key-files.created` and map to user-facing tests:

**Use MCP tool: mcp__desktop-commander__read_file**

```javascript
// MCP-based equivalent (80-90% token savings vs bash cat)
for (const summary of summaries) {
  const content = await mcp__desktop-commander__read_file({
    path: `.planning/phases/${phase}/${summary}`
  });
  // Parse key-files.created for testable items
}
```

Create test queue organized by component/feature.
</step>

<step name="run_tests">
Present tests one at a time using conversational prompts:

For each deliverable:
1. Describe what's being tested (from SUMMARY.md)
2. Provide clear test steps
3. Ask: "Ready to test? (yes/no)"

Wait for user response (yes/no/skip/issue description).

**Track results:**
- `yes` → Mark as passed
- `no` → Mark as failed or skipped
- `issue` → Capture failure details

Document any issues found for gap closure planning.
</step>

<step name="diagnose_failures">
For failed tests, spawn debug agents:

**Use MCP tool: mcp__desktop-commander__start_process** to spawn debug agents

```javascript
// MCP-based equivalent (80-90% token savings vs bash)
await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js init debug ${test_name}",
  timeout_ms: 10000
});
```

Each agent investigates root cause.
</step>

<step name="create_fix_plans">
After diagnosis, group issues into gap closure phases using MCP tools:

**Use MCP tool: mcp__desktop-commander__write_file**

```javascript
// MCP-based equivalent for file writing (80-90% token savings vs bash)
await mcp__desktop-commander__start_process({
  command: "node ~/.claude/get-shit-indexed/bin/GSI-tools.js plan-phase ${PHASE} --gaps",
  timeout_ms: 10000
});
```
</step>

<step name="offer_reexecution">
If issues found, offer to re-execute phase with gap closure plans:

```
## ⚠ Verification Issues Found

**Failures:** {N} tests failed

---

## ▶ Next Up

**Plan gap closure** — Create phases to fix issues

`/GSI:plan-phase {PHASE} --gaps`

<sub>`/clear` first → fresh context window</sub>

Or **Skip re-execution** — Accept issues, mark phase complete

---

**All tests passed?**

[yes/no]
```

If all passed: Update phase status to passed in STATE.md.
</step>

<step name="update_phase_status">
Update phase verification status in ROADMAP.md and STATE.md using MCP tools:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs(uat-${PHASE}): all tests passed" --files .planning/ROADMAP.md .planning/STATE.md .planning/phases/${PHASE_DIR}/*-UAT.md`,
  timeout_ms: 10000
});
```
</step>

</process>

<success_criteria>
- [ ] All SUMMARY.md files located using MCP find_files
- [ ] Testable deliverables extracted using MCP read_file
- [ ] Tests executed conversationaly
- [ ] Failures diagnosed using MCP start_process
- [ ] Fix plans created using MCP start_process if issues found
- [ ] Re-execution offered if needed
- [ ] Phase status updated using MCP start_process
- [ ] User informed of verification results
</success_criteria>

</document_content>
</document>
<document index="114">
<source>C:\github-repos\my-claude-code-repos\get-shit-done-code-index\get-shit-indexed\workflows\verify-work.md</source>
<document_content>
﻿<thinking>auto</thinking>

<code_index_mcp>
desktop_commander:
  tools: ["read_file", "write_file", "start_process"]
  priority: 1
  rationale: "Primary workflow for reading phase documents, writing verification results, and running analysis commands"
code_index:
  tools: ["search_code_advanced", "find_files"]
  priority: 2
  rationale: "Secondary use for searching success criteria and finding deliverable files"
native:
  priority: 3
  rationale: "Fallback only - MCP tools provide 80-90% token savings"
</code_index_mcp>

<purpose>Manual testing workflow for when automated UAT isn't enough. Runs verification directly with user driving tests. Same output as verify-work but user controls pace and what to test.
</purpose>

<required_reading>
**Use MCP tools for reading verification context:**

- mcp__desktop-commander__read_file — Read SUMMARY.md, VERIFICATION.md
- mcp__code-index-mcp__find_files — Find deliverable files

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</required_reading>

<tool_requirements>
**MANDATORY: Use MCP tools instead of native tools for all operations.**

**File Operations:**
- mcp__desktop-commander__read_file — Read verification files
- mcp__code-index-mcp__find_files — Find deliverables

**Process Operations:**
- mcp__desktop-commander__start_process — Run GSI-tools.js commands

Token savings: 80-90% per MCP-TOKEN-BENCHMARK.md
</tool_requirements>

<process>

## 1. Load Verification Context

**Use MCP tools: mcp__desktop-commander__read_file** and **mcp__code-index-mcp__find_files**

```javascript
// MCP-based equivalent for reading files and finding deliverables
const STATE = await mcp__desktop-commander__read_file({
  path: ".planning/STATE.md"
});

const summaries = await mcp__code-index-mcp__find_files({
  pattern: "*-SUMMARY.md",
  path: ".planning/phases"
});
```

Identify phase to verify from state.
</step>

<step name="extract_deliverables">
**Use MCP tool: mcp__desktop-commander__read_file**

```javascript
// MCP-based equivalent (80-90% token savings vs bash cat)
for (const summary of summaries) {
  const content = await mcp__desktop-commander__read_file({
    path: `.planning/phases/${phase}/${summary}`
  });
  // Parse key-files.created for testable items
}
```

Extract deliverables from `key-files.created`. Map to user-facing tests.

Organize tests by feature/component with clear steps for each.
</step>

<step name="present_tests">
Present test queue and let user drive pace:

For each deliverable, provide:
1. Feature name
2. What's being tested
3. Clear test steps
4. Ask: "Ready to test? (yes/no)"

User responds when ready. You wait for their response before proceeding.

**Track results:**
- `yes` → Passed
- `no` → Failed
- `skip` → Deferred
- Issue description → Capture details

**Key difference from verify-work:** User controls when to move to next test, not you.
</step>

<step name="document_results">
Create VERIFICATION.md with test results:

**Use MCP tool: mcp__desktop-commander__write_file**

```javascript
// MCP-based equivalent for file writing (80-90% token savings vs bash)
await mcp__desktop-commander__write_file({
  path: ".planning/phases/${PHASE_DIR}/${PHASE}-UAT.md",
  content: `---\nstatus: manual\n\nresults:\n\n[All test results with pass/fail/skip status]\n---`
});
```

Commit verification:

**Use MCP tool: mcp__desktop-commander__start_process**

```javascript
await mcp__desktop-commander__start_process({
  command: `node ~/.claude/get-shit-indexed/bin/GSI-tools.js commit "docs(uat-${PHASE}): manual verification complete" --files .planning/phases/${PHASE_DIR}/${PHASE}-UAT.md .planning/STATE.md`,
  timeout_ms: 10000
});
```
</step>

<step name="completion">
Present completion:

```
✓ Manual verification complete

Phase: ${PHASE_NAME}
Tests: ${N} deliverables
Results: ${passed} passed, ${failed} failed

---

## ▶ Next Up

- Review VERIFICATION.md for full results
- `/GSI:plan-phase ${PHASE} --gaps` — If issues found
- `/GSI:execute-phase ${PHASE}` — Re-run with fixes
```
</step>

</process>

<success_criteria>
- [ ] All SUMMARY.md files located using MCP find_files
- [ ] Deliverables extracted using MCP read_file
- [ ] Tests executed with user controlling pace
- [ ] Results tracked (pass/fail/skip)
- [ ] VERIFICATION.md created using MCP write_file
- [ ] Verification committed using MCP start_process
- [ ] User informed of results and next steps
</success_criteria>

</document_content>
</document>
</documents>
